Feb 19 03:03:42.812: INFO: Overriding default scale value of zero to 1
Feb 19 03:03:42.812: INFO: Overriding default milliseconds value of zero to 5000
I0219 03:03:43.240742      17 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-273970669
I0219 03:03:43.240831      17 e2e.go:304] Starting e2e run "f6d0719b-33f2-11e9-834e-0a58ac100103" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550545422 - Will randomize all specs
Will run 188 of 1814 specs

Feb 19 03:03:43.370: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 03:03:43.372: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 19 03:03:43.384: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 19 03:03:43.408: INFO: 28 / 28 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 19 03:03:43.408: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Feb 19 03:03:43.408: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 19 03:03:43.414: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'ip-masq-agent' (0 seconds elapsed)
Feb 19 03:03:43.414: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 19 03:03:43.414: INFO: e2e test version: v1.12.1
Feb 19 03:03:43.415: INFO: kube-apiserver version: v1.12.4-tke.1.1
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:03:43.415: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
Feb 19 03:03:43.475: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 03:03:43.483: INFO: Waiting up to 5m0s for pod "downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-wtrrw" to be "success or failure"
Feb 19 03:03:43.488: INFO: Pod "downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.366016ms
Feb 19 03:03:45.491: INFO: Pod "downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008249895s
Feb 19 03:03:47.494: INFO: Pod "downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011199847s
Feb 19 03:03:49.497: INFO: Pod "downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013995902s
STEP: Saw pod success
Feb 19 03:03:49.497: INFO: Pod "downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:03:49.499: INFO: Trying to get logs from node 172.26.0.15 pod downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103 container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:03:49.525: INFO: Waiting for pod downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103 to disappear
Feb 19 03:03:49.527: INFO: Pod downward-api-f73fe5bd-33f2-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:03:49.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wtrrw" for this suite.
Feb 19 03:03:55.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:03:55.600: INFO: namespace: e2e-tests-downward-api-wtrrw, resource: bindings, ignored listing per whitelist
Feb 19 03:03:55.636: INFO: namespace e2e-tests-downward-api-wtrrw deletion completed in 6.105908187s

• [SLOW TEST:12.221 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:03:55.636: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 03:03:55.699: INFO: Waiting up to 5m0s for pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-psbsg" to be "success or failure"
Feb 19 03:03:55.702: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.423484ms
Feb 19 03:03:57.705: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005785187s
Feb 19 03:03:59.707: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008430703s
Feb 19 03:04:01.710: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011286811s
Feb 19 03:04:03.716: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017156516s
Feb 19 03:04:05.719: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020062251s
Feb 19 03:04:07.722: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 12.02302337s
Feb 19 03:04:09.725: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 14.026014607s
Feb 19 03:04:11.728: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 16.029197369s
Feb 19 03:04:13.734: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 18.03507556s
Feb 19 03:04:15.737: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 20.037942001s
Feb 19 03:04:17.740: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 22.040686279s
Feb 19 03:04:19.743: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 24.043609108s
Feb 19 03:04:21.745: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 26.046407546s
Feb 19 03:04:23.752: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 28.053109196s
Feb 19 03:04:25.755: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 30.056039634s
Feb 19 03:04:27.758: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 32.059164051s
Feb 19 03:04:29.761: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 34.06242765s
Feb 19 03:04:31.765: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 36.065625781s
Feb 19 03:04:33.771: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 38.071778011s
Feb 19 03:04:35.774: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 40.074682983s
Feb 19 03:04:37.779: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 42.079822342s
Feb 19 03:04:39.782: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 44.082746033s
Feb 19 03:04:41.785: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 46.08577216s
Feb 19 03:04:43.791: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 48.092273944s
Feb 19 03:04:45.794: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 50.095052026s
Feb 19 03:04:47.797: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 52.097681881s
Feb 19 03:04:49.800: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 54.100632271s
Feb 19 03:04:51.802: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 56.103243159s
Feb 19 03:04:53.809: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 58.109821252s
Feb 19 03:04:55.812: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.112682375s
Feb 19 03:04:57.814: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.115418026s
Feb 19 03:04:59.817: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.118351786s
Feb 19 03:05:01.820: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 1m6.121475444s
STEP: Saw pod success
Feb 19 03:05:01.820: INFO: Pod "downward-api-fe87c020-33f2-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:05:01.822: INFO: Trying to get logs from node 172.26.0.5 pod downward-api-fe87c020-33f2-11e9-834e-0a58ac100103 container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:05:01.850: INFO: Waiting for pod downward-api-fe87c020-33f2-11e9-834e-0a58ac100103 to disappear
Feb 19 03:05:01.852: INFO: Pod downward-api-fe87c020-33f2-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:05:01.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-psbsg" for this suite.
Feb 19 03:05:07.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:05:07.891: INFO: namespace: e2e-tests-downward-api-psbsg, resource: bindings, ignored listing per whitelist
Feb 19 03:05:07.930: INFO: namespace e2e-tests-downward-api-psbsg deletion completed in 6.075660912s

• [SLOW TEST:72.294 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:05:07.930: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tg2rw
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-tg2rw
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-tg2rw
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-tg2rw
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-tg2rw
Feb 19 03:05:20.022: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tg2rw, name: ss-0, uid: 2ec94b01-33f3-11e9-9859-5254000410cb, status phase: Pending. Waiting for statefulset controller to delete.
Feb 19 03:05:21.874: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tg2rw, name: ss-0, uid: 2ec94b01-33f3-11e9-9859-5254000410cb, status phase: Failed. Waiting for statefulset controller to delete.
Feb 19 03:05:21.882: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tg2rw, name: ss-0, uid: 2ec94b01-33f3-11e9-9859-5254000410cb, status phase: Failed. Waiting for statefulset controller to delete.
Feb 19 03:05:21.888: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-tg2rw
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-tg2rw
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-tg2rw and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 03:05:25.910: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tg2rw
Feb 19 03:05:25.912: INFO: Scaling statefulset ss to 0
Feb 19 03:05:35.926: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 03:05:35.928: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:05:35.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tg2rw" for this suite.
Feb 19 03:05:41.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:05:41.993: INFO: namespace: e2e-tests-statefulset-tg2rw, resource: bindings, ignored listing per whitelist
Feb 19 03:05:42.028: INFO: namespace e2e-tests-statefulset-tg2rw deletion completed in 6.077681817s

• [SLOW TEST:34.098 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:05:42.029: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 19 03:05:42.091: INFO: Waiting up to 5m0s for pod "pod-3df2336a-33f3-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-hm9m9" to be "success or failure"
Feb 19 03:05:42.095: INFO: Pod "pod-3df2336a-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.419035ms
Feb 19 03:05:44.098: INFO: Pod "pod-3df2336a-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006952182s
Feb 19 03:05:46.105: INFO: Pod "pod-3df2336a-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013234296s
Feb 19 03:05:48.107: INFO: Pod "pod-3df2336a-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016033297s
Feb 19 03:05:50.111: INFO: Pod "pod-3df2336a-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019237967s
Feb 19 03:05:52.114: INFO: Pod "pod-3df2336a-33f3-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.022383959s
STEP: Saw pod success
Feb 19 03:05:52.114: INFO: Pod "pod-3df2336a-33f3-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:05:52.116: INFO: Trying to get logs from node 172.26.0.15 pod pod-3df2336a-33f3-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:05:52.134: INFO: Waiting for pod pod-3df2336a-33f3-11e9-834e-0a58ac100103 to disappear
Feb 19 03:05:52.137: INFO: Pod pod-3df2336a-33f3-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:05:52.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hm9m9" for this suite.
Feb 19 03:05:58.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:05:58.175: INFO: namespace: e2e-tests-emptydir-hm9m9, resource: bindings, ignored listing per whitelist
Feb 19 03:05:58.217: INFO: namespace e2e-tests-emptydir-hm9m9 deletion completed in 6.07717876s

• [SLOW TEST:16.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:05:58.217: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:05:58.280: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-t8n7c" to be "success or failure"
Feb 19 03:05:58.284: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.993433ms
Feb 19 03:06:00.287: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006784852s
Feb 19 03:06:02.290: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009701717s
Feb 19 03:06:04.292: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012228479s
Feb 19 03:06:06.298: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018487166s
Feb 19 03:06:08.301: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021273162s
Feb 19 03:06:10.304: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 12.024150904s
Feb 19 03:06:12.307: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 14.026846777s
Feb 19 03:06:14.310: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 16.029759328s
Feb 19 03:06:16.316: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.035854427s
STEP: Saw pod success
Feb 19 03:06:16.316: INFO: Pod "downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:06:16.318: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 03:06:16.337: INFO: Waiting for pod downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103 to disappear
Feb 19 03:06:16.339: INFO: Pod downwardapi-volume-47984ffd-33f3-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:06:16.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t8n7c" for this suite.
Feb 19 03:06:22.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:06:22.379: INFO: namespace: e2e-tests-projected-t8n7c, resource: bindings, ignored listing per whitelist
Feb 19 03:06:22.414: INFO: namespace e2e-tests-projected-t8n7c deletion completed in 6.072837452s

• [SLOW TEST:24.197 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:06:22.414: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 03:06:22.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-z5zbr'
Feb 19 03:06:22.873: INFO: stderr: ""
Feb 19 03:06:22.873: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 19 03:06:27.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-z5zbr -o json'
Feb 19 03:06:28.012: INFO: stderr: ""
Feb 19 03:06:28.012: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-19T03:06:22Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-z5zbr\",\n        \"resourceVersion\": \"4152\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-z5zbr/pods/e2e-test-nginx-pod\",\n        \"uid\": \"563ecc7b-33f3-11e9-9859-5254000410cb\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-lnqbq\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"172.26.0.15\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-lnqbq\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-lnqbq\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-19T03:06:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-19T03:06:24Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-19T03:06:24Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-19T03:06:22Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://822b2df7a22b496725a16caaec0878d486ab8d661d97b4f96508465410cd7548\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-19T03:06:24Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.26.0.15\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.3.8\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-19T03:06:22Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 19 03:06:28.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 replace -f - --namespace=e2e-tests-kubectl-z5zbr'
Feb 19 03:06:28.245: INFO: stderr: ""
Feb 19 03:06:28.245: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Feb 19 03:06:28.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-z5zbr'
Feb 19 03:06:41.886: INFO: stderr: ""
Feb 19 03:06:41.886: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:06:41.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z5zbr" for this suite.
Feb 19 03:06:47.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:06:47.940: INFO: namespace: e2e-tests-kubectl-z5zbr, resource: bindings, ignored listing per whitelist
Feb 19 03:06:47.970: INFO: namespace e2e-tests-kubectl-z5zbr deletion completed in 6.078313189s

• [SLOW TEST:25.556 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:06:47.970: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 19 03:06:48.036: INFO: Waiting up to 5m0s for pod "var-expansion-654044c9-33f3-11e9-834e-0a58ac100103" in namespace "e2e-tests-var-expansion-928bj" to be "success or failure"
Feb 19 03:06:48.040: INFO: Pod "var-expansion-654044c9-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.766704ms
Feb 19 03:06:50.043: INFO: Pod "var-expansion-654044c9-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006835563s
Feb 19 03:06:52.050: INFO: Pod "var-expansion-654044c9-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013260923s
Feb 19 03:06:54.053: INFO: Pod "var-expansion-654044c9-33f3-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016269364s
STEP: Saw pod success
Feb 19 03:06:54.053: INFO: Pod "var-expansion-654044c9-33f3-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:06:54.055: INFO: Trying to get logs from node 172.26.0.5 pod var-expansion-654044c9-33f3-11e9-834e-0a58ac100103 container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:06:54.074: INFO: Waiting for pod var-expansion-654044c9-33f3-11e9-834e-0a58ac100103 to disappear
Feb 19 03:06:54.076: INFO: Pod var-expansion-654044c9-33f3-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:06:54.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-928bj" for this suite.
Feb 19 03:07:00.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:07:00.105: INFO: namespace: e2e-tests-var-expansion-928bj, resource: bindings, ignored listing per whitelist
Feb 19 03:07:00.153: INFO: namespace e2e-tests-var-expansion-928bj deletion completed in 6.072839652s

• [SLOW TEST:12.183 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:07:00.153: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 19 03:07:00.217: INFO: Waiting up to 5m0s for pod "pod-6c83378b-33f3-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-jpq97" to be "success or failure"
Feb 19 03:07:00.220: INFO: Pod "pod-6c83378b-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.682911ms
Feb 19 03:07:02.227: INFO: Pod "pod-6c83378b-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010219209s
Feb 19 03:07:04.230: INFO: Pod "pod-6c83378b-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013010891s
Feb 19 03:07:06.233: INFO: Pod "pod-6c83378b-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016001494s
Feb 19 03:07:08.236: INFO: Pod "pod-6c83378b-33f3-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.018874966s
STEP: Saw pod success
Feb 19 03:07:08.236: INFO: Pod "pod-6c83378b-33f3-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:07:08.238: INFO: Trying to get logs from node 172.26.0.15 pod pod-6c83378b-33f3-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:07:08.258: INFO: Waiting for pod pod-6c83378b-33f3-11e9-834e-0a58ac100103 to disappear
Feb 19 03:07:08.261: INFO: Pod pod-6c83378b-33f3-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:07:08.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jpq97" for this suite.
Feb 19 03:07:14.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:07:14.332: INFO: namespace: e2e-tests-emptydir-jpq97, resource: bindings, ignored listing per whitelist
Feb 19 03:07:14.343: INFO: namespace e2e-tests-emptydir-jpq97 deletion completed in 6.078440911s

• [SLOW TEST:14.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:07:14.343: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-52v9q
I0219 03:07:14.409231      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-52v9q, replica count: 1
I0219 03:07:15.459535      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:16.459714      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:17.459881      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:18.460034      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:19.460174      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:20.460335      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:21.460543      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:22.460647      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:23.460794      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:24.460937      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:25.461116      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:26.461261      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:27.461428      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 03:07:28.461645      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 19 03:07:28.572: INFO: Created: latency-svc-jwmpj
Feb 19 03:07:28.580: INFO: Got endpoints: latency-svc-jwmpj [18.300214ms]
Feb 19 03:07:28.595: INFO: Created: latency-svc-95tmj
Feb 19 03:07:28.600: INFO: Got endpoints: latency-svc-95tmj [20.021204ms]
Feb 19 03:07:28.602: INFO: Created: latency-svc-9hjhv
Feb 19 03:07:28.607: INFO: Got endpoints: latency-svc-9hjhv [27.178772ms]
Feb 19 03:07:28.613: INFO: Created: latency-svc-bsz4r
Feb 19 03:07:28.619: INFO: Got endpoints: latency-svc-bsz4r [38.632951ms]
Feb 19 03:07:28.619: INFO: Created: latency-svc-vv9xz
Feb 19 03:07:28.625: INFO: Created: latency-svc-lztm8
Feb 19 03:07:28.629: INFO: Got endpoints: latency-svc-vv9xz [48.610438ms]
Feb 19 03:07:28.631: INFO: Got endpoints: latency-svc-lztm8 [50.397813ms]
Feb 19 03:07:28.637: INFO: Created: latency-svc-69vnc
Feb 19 03:07:28.645: INFO: Got endpoints: latency-svc-69vnc [64.24606ms]
Feb 19 03:07:28.645: INFO: Created: latency-svc-8tmd7
Feb 19 03:07:28.649: INFO: Got endpoints: latency-svc-8tmd7 [68.320386ms]
Feb 19 03:07:28.655: INFO: Created: latency-svc-7mfcm
Feb 19 03:07:28.659: INFO: Got endpoints: latency-svc-7mfcm [78.439952ms]
Feb 19 03:07:28.663: INFO: Created: latency-svc-27wzp
Feb 19 03:07:28.670: INFO: Got endpoints: latency-svc-27wzp [89.321838ms]
Feb 19 03:07:28.671: INFO: Created: latency-svc-lvk4n
Feb 19 03:07:28.676: INFO: Got endpoints: latency-svc-lvk4n [94.598727ms]
Feb 19 03:07:28.679: INFO: Created: latency-svc-pxhg4
Feb 19 03:07:28.683: INFO: Got endpoints: latency-svc-pxhg4 [101.680295ms]
Feb 19 03:07:28.689: INFO: Created: latency-svc-lqc8b
Feb 19 03:07:28.693: INFO: Got endpoints: latency-svc-lqc8b [111.234975ms]
Feb 19 03:07:28.696: INFO: Created: latency-svc-zmkfs
Feb 19 03:07:28.700: INFO: Got endpoints: latency-svc-zmkfs [119.054428ms]
Feb 19 03:07:28.704: INFO: Created: latency-svc-h52t6
Feb 19 03:07:28.709: INFO: Got endpoints: latency-svc-h52t6 [127.812802ms]
Feb 19 03:07:28.713: INFO: Created: latency-svc-5dwkd
Feb 19 03:07:28.725: INFO: Got endpoints: latency-svc-5dwkd [142.822054ms]
Feb 19 03:07:28.725: INFO: Created: latency-svc-42bw9
Feb 19 03:07:28.730: INFO: Got endpoints: latency-svc-42bw9 [129.740385ms]
Feb 19 03:07:28.737: INFO: Created: latency-svc-mp2xd
Feb 19 03:07:28.741: INFO: Got endpoints: latency-svc-mp2xd [134.22971ms]
Feb 19 03:07:28.745: INFO: Created: latency-svc-hrnrq
Feb 19 03:07:28.750: INFO: Got endpoints: latency-svc-hrnrq [130.829793ms]
Feb 19 03:07:28.754: INFO: Created: latency-svc-42kmt
Feb 19 03:07:28.760: INFO: Created: latency-svc-xlvp6
Feb 19 03:07:28.760: INFO: Got endpoints: latency-svc-42kmt [131.31875ms]
Feb 19 03:07:28.766: INFO: Got endpoints: latency-svc-xlvp6 [134.969061ms]
Feb 19 03:07:28.770: INFO: Created: latency-svc-kfc6v
Feb 19 03:07:28.779: INFO: Created: latency-svc-9kx96
Feb 19 03:07:28.779: INFO: Got endpoints: latency-svc-kfc6v [134.158204ms]
Feb 19 03:07:28.783: INFO: Got endpoints: latency-svc-9kx96 [134.25014ms]
Feb 19 03:07:28.788: INFO: Created: latency-svc-nqqjc
Feb 19 03:07:28.791: INFO: Got endpoints: latency-svc-nqqjc [131.565503ms]
Feb 19 03:07:28.797: INFO: Created: latency-svc-trtc8
Feb 19 03:07:28.803: INFO: Got endpoints: latency-svc-trtc8 [132.881272ms]
Feb 19 03:07:28.807: INFO: Created: latency-svc-h6zg8
Feb 19 03:07:28.812: INFO: Got endpoints: latency-svc-h6zg8 [136.618421ms]
Feb 19 03:07:28.814: INFO: Created: latency-svc-7q2mz
Feb 19 03:07:28.821: INFO: Got endpoints: latency-svc-7q2mz [17.634107ms]
Feb 19 03:07:28.824: INFO: Created: latency-svc-qxgnv
Feb 19 03:07:28.831: INFO: Got endpoints: latency-svc-qxgnv [147.630425ms]
Feb 19 03:07:28.834: INFO: Created: latency-svc-m5n2s
Feb 19 03:07:28.841: INFO: Got endpoints: latency-svc-m5n2s [148.098461ms]
Feb 19 03:07:28.845: INFO: Created: latency-svc-nqglj
Feb 19 03:07:28.851: INFO: Got endpoints: latency-svc-nqglj [150.158182ms]
Feb 19 03:07:28.854: INFO: Created: latency-svc-wrpbh
Feb 19 03:07:28.860: INFO: Got endpoints: latency-svc-wrpbh [150.465758ms]
Feb 19 03:07:28.865: INFO: Created: latency-svc-cs2vh
Feb 19 03:07:28.870: INFO: Got endpoints: latency-svc-cs2vh [145.587664ms]
Feb 19 03:07:28.872: INFO: Created: latency-svc-44mtl
Feb 19 03:07:28.875: INFO: Got endpoints: latency-svc-44mtl [145.677671ms]
Feb 19 03:07:28.883: INFO: Created: latency-svc-gjc8x
Feb 19 03:07:28.890: INFO: Got endpoints: latency-svc-gjc8x [148.163896ms]
Feb 19 03:07:28.893: INFO: Created: latency-svc-wcfx6
Feb 19 03:07:28.899: INFO: Got endpoints: latency-svc-wcfx6 [149.08762ms]
Feb 19 03:07:28.901: INFO: Created: latency-svc-z84m6
Feb 19 03:07:28.906: INFO: Got endpoints: latency-svc-z84m6 [146.144916ms]
Feb 19 03:07:28.909: INFO: Created: latency-svc-tjsb4
Feb 19 03:07:28.923: INFO: Created: latency-svc-ldm4f
Feb 19 03:07:28.928: INFO: Got endpoints: latency-svc-tjsb4 [162.275655ms]
Feb 19 03:07:28.931: INFO: Created: latency-svc-lhzwx
Feb 19 03:07:28.935: INFO: Created: latency-svc-x9nck
Feb 19 03:07:28.941: INFO: Created: latency-svc-9q4lf
Feb 19 03:07:28.949: INFO: Created: latency-svc-kts8n
Feb 19 03:07:28.964: INFO: Created: latency-svc-td9m5
Feb 19 03:07:28.968: INFO: Created: latency-svc-ctwrv
Feb 19 03:07:28.972: INFO: Created: latency-svc-4gcrx
Feb 19 03:07:28.980: INFO: Created: latency-svc-zx54h
Feb 19 03:07:28.980: INFO: Got endpoints: latency-svc-ldm4f [201.169275ms]
Feb 19 03:07:28.989: INFO: Created: latency-svc-wtbc9
Feb 19 03:07:28.995: INFO: Created: latency-svc-7bkfg
Feb 19 03:07:29.004: INFO: Created: latency-svc-p9fp9
Feb 19 03:07:29.010: INFO: Created: latency-svc-jfmr9
Feb 19 03:07:29.018: INFO: Created: latency-svc-6cnq4
Feb 19 03:07:29.029: INFO: Got endpoints: latency-svc-lhzwx [245.507462ms]
Feb 19 03:07:29.032: INFO: Created: latency-svc-7622r
Feb 19 03:07:29.038: INFO: Created: latency-svc-qm259
Feb 19 03:07:29.042: INFO: Created: latency-svc-vmzlt
Feb 19 03:07:29.077: INFO: Got endpoints: latency-svc-x9nck [286.448487ms]
Feb 19 03:07:29.085: INFO: Created: latency-svc-l8wpw
Feb 19 03:07:29.130: INFO: Got endpoints: latency-svc-9q4lf [317.878188ms]
Feb 19 03:07:29.138: INFO: Created: latency-svc-7hc68
Feb 19 03:07:29.178: INFO: Got endpoints: latency-svc-kts8n [356.766916ms]
Feb 19 03:07:29.185: INFO: Created: latency-svc-w9sb8
Feb 19 03:07:29.227: INFO: Got endpoints: latency-svc-td9m5 [396.390736ms]
Feb 19 03:07:29.236: INFO: Created: latency-svc-htbzb
Feb 19 03:07:29.278: INFO: Got endpoints: latency-svc-ctwrv [437.765469ms]
Feb 19 03:07:29.287: INFO: Created: latency-svc-fhzc7
Feb 19 03:07:29.327: INFO: Got endpoints: latency-svc-4gcrx [476.115037ms]
Feb 19 03:07:29.337: INFO: Created: latency-svc-wnt6f
Feb 19 03:07:29.379: INFO: Got endpoints: latency-svc-zx54h [518.886898ms]
Feb 19 03:07:29.388: INFO: Created: latency-svc-txgzw
Feb 19 03:07:29.429: INFO: Got endpoints: latency-svc-wtbc9 [559.240425ms]
Feb 19 03:07:29.441: INFO: Created: latency-svc-wcw5v
Feb 19 03:07:29.477: INFO: Got endpoints: latency-svc-7bkfg [601.470006ms]
Feb 19 03:07:29.486: INFO: Created: latency-svc-px8c4
Feb 19 03:07:29.527: INFO: Got endpoints: latency-svc-p9fp9 [637.107819ms]
Feb 19 03:07:29.536: INFO: Created: latency-svc-rgg8m
Feb 19 03:07:29.581: INFO: Got endpoints: latency-svc-jfmr9 [681.459546ms]
Feb 19 03:07:29.589: INFO: Created: latency-svc-vmrc8
Feb 19 03:07:29.627: INFO: Got endpoints: latency-svc-6cnq4 [720.816455ms]
Feb 19 03:07:29.636: INFO: Created: latency-svc-57z9k
Feb 19 03:07:29.677: INFO: Got endpoints: latency-svc-7622r [748.801907ms]
Feb 19 03:07:29.684: INFO: Created: latency-svc-kc54t
Feb 19 03:07:29.729: INFO: Got endpoints: latency-svc-qm259 [748.415377ms]
Feb 19 03:07:29.739: INFO: Created: latency-svc-znxph
Feb 19 03:07:29.778: INFO: Got endpoints: latency-svc-vmzlt [748.864675ms]
Feb 19 03:07:29.787: INFO: Created: latency-svc-svjwc
Feb 19 03:07:29.828: INFO: Got endpoints: latency-svc-l8wpw [750.859648ms]
Feb 19 03:07:29.837: INFO: Created: latency-svc-2h5vw
Feb 19 03:07:29.877: INFO: Got endpoints: latency-svc-7hc68 [747.164928ms]
Feb 19 03:07:29.886: INFO: Created: latency-svc-mbjx2
Feb 19 03:07:29.928: INFO: Got endpoints: latency-svc-w9sb8 [750.588708ms]
Feb 19 03:07:29.937: INFO: Created: latency-svc-9v47k
Feb 19 03:07:29.977: INFO: Got endpoints: latency-svc-htbzb [749.980704ms]
Feb 19 03:07:29.988: INFO: Created: latency-svc-qpbgx
Feb 19 03:07:30.027: INFO: Got endpoints: latency-svc-fhzc7 [748.969702ms]
Feb 19 03:07:30.035: INFO: Created: latency-svc-9vs4r
Feb 19 03:07:30.077: INFO: Got endpoints: latency-svc-wnt6f [749.945096ms]
Feb 19 03:07:30.084: INFO: Created: latency-svc-lzlr9
Feb 19 03:07:30.127: INFO: Got endpoints: latency-svc-txgzw [748.241995ms]
Feb 19 03:07:30.138: INFO: Created: latency-svc-hhr2l
Feb 19 03:07:30.177: INFO: Got endpoints: latency-svc-wcw5v [747.275491ms]
Feb 19 03:07:30.184: INFO: Created: latency-svc-xz8fh
Feb 19 03:07:30.227: INFO: Got endpoints: latency-svc-px8c4 [750.482065ms]
Feb 19 03:07:30.236: INFO: Created: latency-svc-khw6f
Feb 19 03:07:30.277: INFO: Got endpoints: latency-svc-rgg8m [749.935455ms]
Feb 19 03:07:30.287: INFO: Created: latency-svc-k55h4
Feb 19 03:07:30.328: INFO: Got endpoints: latency-svc-vmrc8 [747.083604ms]
Feb 19 03:07:30.335: INFO: Created: latency-svc-8kqr4
Feb 19 03:07:30.378: INFO: Got endpoints: latency-svc-57z9k [750.4956ms]
Feb 19 03:07:30.387: INFO: Created: latency-svc-5rkks
Feb 19 03:07:30.427: INFO: Got endpoints: latency-svc-kc54t [750.604285ms]
Feb 19 03:07:30.439: INFO: Created: latency-svc-vdzp6
Feb 19 03:07:30.477: INFO: Got endpoints: latency-svc-znxph [748.493533ms]
Feb 19 03:07:30.487: INFO: Created: latency-svc-jd4nw
Feb 19 03:07:30.526: INFO: Got endpoints: latency-svc-svjwc [748.70022ms]
Feb 19 03:07:30.534: INFO: Created: latency-svc-6flxz
Feb 19 03:07:30.577: INFO: Got endpoints: latency-svc-2h5vw [749.147695ms]
Feb 19 03:07:30.587: INFO: Created: latency-svc-8nbb9
Feb 19 03:07:30.628: INFO: Got endpoints: latency-svc-mbjx2 [750.255761ms]
Feb 19 03:07:30.635: INFO: Created: latency-svc-kmdpp
Feb 19 03:07:30.677: INFO: Got endpoints: latency-svc-9v47k [748.776923ms]
Feb 19 03:07:30.686: INFO: Created: latency-svc-6wnmr
Feb 19 03:07:30.728: INFO: Got endpoints: latency-svc-qpbgx [750.539626ms]
Feb 19 03:07:30.739: INFO: Created: latency-svc-p5k7f
Feb 19 03:07:30.778: INFO: Got endpoints: latency-svc-9vs4r [750.863776ms]
Feb 19 03:07:30.788: INFO: Created: latency-svc-tb4tm
Feb 19 03:07:30.827: INFO: Got endpoints: latency-svc-lzlr9 [750.388627ms]
Feb 19 03:07:30.834: INFO: Created: latency-svc-w5vt7
Feb 19 03:07:30.886: INFO: Got endpoints: latency-svc-hhr2l [758.6779ms]
Feb 19 03:07:30.894: INFO: Created: latency-svc-66l75
Feb 19 03:07:30.930: INFO: Got endpoints: latency-svc-xz8fh [752.937217ms]
Feb 19 03:07:30.939: INFO: Created: latency-svc-g2knh
Feb 19 03:07:30.977: INFO: Got endpoints: latency-svc-khw6f [749.811961ms]
Feb 19 03:07:30.985: INFO: Created: latency-svc-f65tr
Feb 19 03:07:31.031: INFO: Got endpoints: latency-svc-k55h4 [754.558228ms]
Feb 19 03:07:31.041: INFO: Created: latency-svc-7xb4m
Feb 19 03:07:31.077: INFO: Got endpoints: latency-svc-8kqr4 [749.382958ms]
Feb 19 03:07:31.085: INFO: Created: latency-svc-2nnnz
Feb 19 03:07:31.127: INFO: Got endpoints: latency-svc-5rkks [748.916655ms]
Feb 19 03:07:31.134: INFO: Created: latency-svc-hc648
Feb 19 03:07:31.181: INFO: Got endpoints: latency-svc-vdzp6 [753.171798ms]
Feb 19 03:07:31.189: INFO: Created: latency-svc-98tnv
Feb 19 03:07:31.227: INFO: Got endpoints: latency-svc-jd4nw [749.660154ms]
Feb 19 03:07:31.236: INFO: Created: latency-svc-g2cnb
Feb 19 03:07:31.277: INFO: Got endpoints: latency-svc-6flxz [750.349794ms]
Feb 19 03:07:31.284: INFO: Created: latency-svc-tsmk6
Feb 19 03:07:31.335: INFO: Got endpoints: latency-svc-8nbb9 [757.43202ms]
Feb 19 03:07:31.344: INFO: Created: latency-svc-nrqcq
Feb 19 03:07:31.377: INFO: Got endpoints: latency-svc-kmdpp [749.606675ms]
Feb 19 03:07:31.386: INFO: Created: latency-svc-tn6jj
Feb 19 03:07:31.433: INFO: Got endpoints: latency-svc-6wnmr [755.753019ms]
Feb 19 03:07:31.447: INFO: Created: latency-svc-bxmtp
Feb 19 03:07:31.478: INFO: Got endpoints: latency-svc-p5k7f [750.533668ms]
Feb 19 03:07:31.486: INFO: Created: latency-svc-bbfsq
Feb 19 03:07:31.526: INFO: Got endpoints: latency-svc-tb4tm [747.829103ms]
Feb 19 03:07:31.533: INFO: Created: latency-svc-2p59q
Feb 19 03:07:31.577: INFO: Got endpoints: latency-svc-w5vt7 [749.918957ms]
Feb 19 03:07:31.587: INFO: Created: latency-svc-drtlc
Feb 19 03:07:31.627: INFO: Got endpoints: latency-svc-66l75 [741.574436ms]
Feb 19 03:07:31.639: INFO: Created: latency-svc-cr56m
Feb 19 03:07:31.677: INFO: Got endpoints: latency-svc-g2knh [746.790146ms]
Feb 19 03:07:31.686: INFO: Created: latency-svc-jlwhd
Feb 19 03:07:31.728: INFO: Got endpoints: latency-svc-f65tr [750.463323ms]
Feb 19 03:07:31.738: INFO: Created: latency-svc-6slgn
Feb 19 03:07:31.778: INFO: Got endpoints: latency-svc-7xb4m [746.182924ms]
Feb 19 03:07:31.789: INFO: Created: latency-svc-4djn9
Feb 19 03:07:31.827: INFO: Got endpoints: latency-svc-2nnnz [749.887549ms]
Feb 19 03:07:31.836: INFO: Created: latency-svc-b279m
Feb 19 03:07:31.880: INFO: Got endpoints: latency-svc-hc648 [753.605001ms]
Feb 19 03:07:31.890: INFO: Created: latency-svc-5v8sl
Feb 19 03:07:31.928: INFO: Got endpoints: latency-svc-98tnv [747.109748ms]
Feb 19 03:07:31.936: INFO: Created: latency-svc-bwgss
Feb 19 03:07:31.977: INFO: Got endpoints: latency-svc-g2cnb [749.73113ms]
Feb 19 03:07:31.985: INFO: Created: latency-svc-5cc5g
Feb 19 03:07:32.030: INFO: Got endpoints: latency-svc-tsmk6 [753.018014ms]
Feb 19 03:07:32.038: INFO: Created: latency-svc-ntwvt
Feb 19 03:07:32.076: INFO: Got endpoints: latency-svc-nrqcq [741.452007ms]
Feb 19 03:07:32.087: INFO: Created: latency-svc-99nnr
Feb 19 03:07:32.127: INFO: Got endpoints: latency-svc-tn6jj [749.670437ms]
Feb 19 03:07:32.138: INFO: Created: latency-svc-l8hcg
Feb 19 03:07:32.179: INFO: Got endpoints: latency-svc-bxmtp [746.302554ms]
Feb 19 03:07:32.187: INFO: Created: latency-svc-j6pqs
Feb 19 03:07:32.226: INFO: Got endpoints: latency-svc-bbfsq [748.241578ms]
Feb 19 03:07:32.237: INFO: Created: latency-svc-sbw2k
Feb 19 03:07:32.278: INFO: Got endpoints: latency-svc-2p59q [751.880934ms]
Feb 19 03:07:32.288: INFO: Created: latency-svc-z7wxl
Feb 19 03:07:32.330: INFO: Got endpoints: latency-svc-drtlc [752.437945ms]
Feb 19 03:07:32.337: INFO: Created: latency-svc-vjpkl
Feb 19 03:07:32.377: INFO: Got endpoints: latency-svc-cr56m [749.300052ms]
Feb 19 03:07:32.386: INFO: Created: latency-svc-hj5kn
Feb 19 03:07:32.427: INFO: Got endpoints: latency-svc-jlwhd [750.405101ms]
Feb 19 03:07:32.436: INFO: Created: latency-svc-hpfsx
Feb 19 03:07:32.480: INFO: Got endpoints: latency-svc-6slgn [752.14262ms]
Feb 19 03:07:32.488: INFO: Created: latency-svc-q2cq7
Feb 19 03:07:32.527: INFO: Got endpoints: latency-svc-4djn9 [749.21472ms]
Feb 19 03:07:32.535: INFO: Created: latency-svc-7n6dp
Feb 19 03:07:32.577: INFO: Got endpoints: latency-svc-b279m [749.704493ms]
Feb 19 03:07:32.585: INFO: Created: latency-svc-j2j7c
Feb 19 03:07:32.628: INFO: Got endpoints: latency-svc-5v8sl [748.135018ms]
Feb 19 03:07:32.636: INFO: Created: latency-svc-46vrh
Feb 19 03:07:32.677: INFO: Got endpoints: latency-svc-bwgss [749.585681ms]
Feb 19 03:07:32.686: INFO: Created: latency-svc-rllqt
Feb 19 03:07:32.727: INFO: Got endpoints: latency-svc-5cc5g [750.612176ms]
Feb 19 03:07:32.735: INFO: Created: latency-svc-tsdn5
Feb 19 03:07:32.779: INFO: Got endpoints: latency-svc-ntwvt [749.471669ms]
Feb 19 03:07:32.788: INFO: Created: latency-svc-nm967
Feb 19 03:07:32.828: INFO: Got endpoints: latency-svc-99nnr [751.648032ms]
Feb 19 03:07:32.836: INFO: Created: latency-svc-h26hw
Feb 19 03:07:32.878: INFO: Got endpoints: latency-svc-l8hcg [750.977076ms]
Feb 19 03:07:32.889: INFO: Created: latency-svc-zpwhv
Feb 19 03:07:32.927: INFO: Got endpoints: latency-svc-j6pqs [747.533901ms]
Feb 19 03:07:32.935: INFO: Created: latency-svc-srw74
Feb 19 03:07:32.977: INFO: Got endpoints: latency-svc-sbw2k [750.397132ms]
Feb 19 03:07:32.987: INFO: Created: latency-svc-lwrw9
Feb 19 03:07:33.027: INFO: Got endpoints: latency-svc-z7wxl [748.877527ms]
Feb 19 03:07:33.038: INFO: Created: latency-svc-cdwsc
Feb 19 03:07:33.077: INFO: Got endpoints: latency-svc-vjpkl [747.005813ms]
Feb 19 03:07:33.086: INFO: Created: latency-svc-lp6ff
Feb 19 03:07:33.127: INFO: Got endpoints: latency-svc-hj5kn [750.248748ms]
Feb 19 03:07:33.135: INFO: Created: latency-svc-t6vhd
Feb 19 03:07:33.180: INFO: Got endpoints: latency-svc-hpfsx [752.652495ms]
Feb 19 03:07:33.195: INFO: Created: latency-svc-tzwcv
Feb 19 03:07:33.229: INFO: Got endpoints: latency-svc-q2cq7 [749.487814ms]
Feb 19 03:07:33.238: INFO: Created: latency-svc-rdnpc
Feb 19 03:07:33.277: INFO: Got endpoints: latency-svc-7n6dp [749.928599ms]
Feb 19 03:07:33.285: INFO: Created: latency-svc-cktbk
Feb 19 03:07:33.329: INFO: Got endpoints: latency-svc-j2j7c [752.575825ms]
Feb 19 03:07:33.340: INFO: Created: latency-svc-pnv5d
Feb 19 03:07:33.377: INFO: Got endpoints: latency-svc-46vrh [748.426282ms]
Feb 19 03:07:33.387: INFO: Created: latency-svc-kxnw7
Feb 19 03:07:33.428: INFO: Got endpoints: latency-svc-rllqt [750.736156ms]
Feb 19 03:07:33.441: INFO: Created: latency-svc-wp2v4
Feb 19 03:07:33.480: INFO: Got endpoints: latency-svc-tsdn5 [753.110463ms]
Feb 19 03:07:33.489: INFO: Created: latency-svc-xjtvc
Feb 19 03:07:33.527: INFO: Got endpoints: latency-svc-nm967 [747.848402ms]
Feb 19 03:07:33.537: INFO: Created: latency-svc-jrvt8
Feb 19 03:07:33.578: INFO: Got endpoints: latency-svc-h26hw [750.328267ms]
Feb 19 03:07:33.586: INFO: Created: latency-svc-xtbvw
Feb 19 03:07:33.629: INFO: Got endpoints: latency-svc-zpwhv [751.060661ms]
Feb 19 03:07:33.638: INFO: Created: latency-svc-r95fq
Feb 19 03:07:33.677: INFO: Got endpoints: latency-svc-srw74 [750.373133ms]
Feb 19 03:07:33.684: INFO: Created: latency-svc-7s9wv
Feb 19 03:07:33.727: INFO: Got endpoints: latency-svc-lwrw9 [750.270158ms]
Feb 19 03:07:33.736: INFO: Created: latency-svc-mdvr6
Feb 19 03:07:33.781: INFO: Got endpoints: latency-svc-cdwsc [753.622978ms]
Feb 19 03:07:33.789: INFO: Created: latency-svc-vddss
Feb 19 03:07:33.828: INFO: Got endpoints: latency-svc-lp6ff [751.058683ms]
Feb 19 03:07:33.836: INFO: Created: latency-svc-kqlwk
Feb 19 03:07:33.877: INFO: Got endpoints: latency-svc-t6vhd [749.899991ms]
Feb 19 03:07:33.891: INFO: Created: latency-svc-n2phz
Feb 19 03:07:33.927: INFO: Got endpoints: latency-svc-tzwcv [746.823696ms]
Feb 19 03:07:33.934: INFO: Created: latency-svc-gpr2q
Feb 19 03:07:33.977: INFO: Got endpoints: latency-svc-rdnpc [747.637131ms]
Feb 19 03:07:33.987: INFO: Created: latency-svc-9bdvl
Feb 19 03:07:34.028: INFO: Got endpoints: latency-svc-cktbk [751.644925ms]
Feb 19 03:07:34.046: INFO: Created: latency-svc-7nxrv
Feb 19 03:07:34.077: INFO: Got endpoints: latency-svc-pnv5d [747.827681ms]
Feb 19 03:07:34.085: INFO: Created: latency-svc-jmkj8
Feb 19 03:07:34.129: INFO: Got endpoints: latency-svc-kxnw7 [752.469276ms]
Feb 19 03:07:34.139: INFO: Created: latency-svc-rd52z
Feb 19 03:07:34.176: INFO: Got endpoints: latency-svc-wp2v4 [748.214174ms]
Feb 19 03:07:34.192: INFO: Created: latency-svc-wqtkz
Feb 19 03:07:34.227: INFO: Got endpoints: latency-svc-xjtvc [746.5416ms]
Feb 19 03:07:34.235: INFO: Created: latency-svc-qr5wf
Feb 19 03:07:34.277: INFO: Got endpoints: latency-svc-jrvt8 [749.486864ms]
Feb 19 03:07:34.287: INFO: Created: latency-svc-plc8l
Feb 19 03:07:34.328: INFO: Got endpoints: latency-svc-xtbvw [749.426846ms]
Feb 19 03:07:34.338: INFO: Created: latency-svc-f75qd
Feb 19 03:07:34.379: INFO: Got endpoints: latency-svc-r95fq [749.544056ms]
Feb 19 03:07:34.389: INFO: Created: latency-svc-vhggn
Feb 19 03:07:34.427: INFO: Got endpoints: latency-svc-7s9wv [749.663803ms]
Feb 19 03:07:34.435: INFO: Created: latency-svc-l7l4l
Feb 19 03:07:34.478: INFO: Got endpoints: latency-svc-mdvr6 [750.426946ms]
Feb 19 03:07:34.489: INFO: Created: latency-svc-x6r68
Feb 19 03:07:34.528: INFO: Got endpoints: latency-svc-vddss [747.204612ms]
Feb 19 03:07:34.537: INFO: Created: latency-svc-p8zm6
Feb 19 03:07:34.581: INFO: Got endpoints: latency-svc-kqlwk [752.942546ms]
Feb 19 03:07:34.588: INFO: Created: latency-svc-l2gr6
Feb 19 03:07:34.628: INFO: Got endpoints: latency-svc-n2phz [750.696059ms]
Feb 19 03:07:34.640: INFO: Created: latency-svc-2pv9q
Feb 19 03:07:34.678: INFO: Got endpoints: latency-svc-gpr2q [751.096196ms]
Feb 19 03:07:34.694: INFO: Created: latency-svc-8v62m
Feb 19 03:07:34.729: INFO: Got endpoints: latency-svc-9bdvl [751.695613ms]
Feb 19 03:07:34.739: INFO: Created: latency-svc-khz29
Feb 19 03:07:34.777: INFO: Got endpoints: latency-svc-7nxrv [748.389258ms]
Feb 19 03:07:34.788: INFO: Created: latency-svc-2lr7k
Feb 19 03:07:34.829: INFO: Got endpoints: latency-svc-jmkj8 [751.699007ms]
Feb 19 03:07:34.837: INFO: Created: latency-svc-ksrfl
Feb 19 03:07:34.877: INFO: Got endpoints: latency-svc-rd52z [747.240129ms]
Feb 19 03:07:34.885: INFO: Created: latency-svc-6xpxp
Feb 19 03:07:34.931: INFO: Got endpoints: latency-svc-wqtkz [754.914853ms]
Feb 19 03:07:34.939: INFO: Created: latency-svc-klpdd
Feb 19 03:07:34.980: INFO: Got endpoints: latency-svc-qr5wf [752.730951ms]
Feb 19 03:07:34.988: INFO: Created: latency-svc-cx9qs
Feb 19 03:07:35.027: INFO: Got endpoints: latency-svc-plc8l [750.155847ms]
Feb 19 03:07:35.034: INFO: Created: latency-svc-pzfdv
Feb 19 03:07:35.079: INFO: Got endpoints: latency-svc-f75qd [751.082783ms]
Feb 19 03:07:35.095: INFO: Created: latency-svc-mvdp2
Feb 19 03:07:35.127: INFO: Got endpoints: latency-svc-vhggn [747.880713ms]
Feb 19 03:07:35.134: INFO: Created: latency-svc-fvr8k
Feb 19 03:07:35.178: INFO: Got endpoints: latency-svc-l7l4l [751.019817ms]
Feb 19 03:07:35.187: INFO: Created: latency-svc-qxqpt
Feb 19 03:07:35.231: INFO: Got endpoints: latency-svc-x6r68 [753.343387ms]
Feb 19 03:07:35.241: INFO: Created: latency-svc-vpsjg
Feb 19 03:07:35.277: INFO: Got endpoints: latency-svc-p8zm6 [749.187062ms]
Feb 19 03:07:35.285: INFO: Created: latency-svc-zlhjt
Feb 19 03:07:35.328: INFO: Got endpoints: latency-svc-l2gr6 [746.954606ms]
Feb 19 03:07:35.336: INFO: Created: latency-svc-9xwq7
Feb 19 03:07:35.379: INFO: Got endpoints: latency-svc-2pv9q [751.463363ms]
Feb 19 03:07:35.393: INFO: Created: latency-svc-j4bjn
Feb 19 03:07:35.428: INFO: Got endpoints: latency-svc-8v62m [750.548708ms]
Feb 19 03:07:35.438: INFO: Created: latency-svc-cvftv
Feb 19 03:07:35.478: INFO: Got endpoints: latency-svc-khz29 [749.556514ms]
Feb 19 03:07:35.494: INFO: Created: latency-svc-7p8qn
Feb 19 03:07:35.529: INFO: Got endpoints: latency-svc-2lr7k [751.778009ms]
Feb 19 03:07:35.539: INFO: Created: latency-svc-8rfmw
Feb 19 03:07:35.577: INFO: Got endpoints: latency-svc-ksrfl [748.197571ms]
Feb 19 03:07:35.585: INFO: Created: latency-svc-tbsqf
Feb 19 03:07:35.627: INFO: Got endpoints: latency-svc-6xpxp [750.266432ms]
Feb 19 03:07:35.639: INFO: Created: latency-svc-hsv8d
Feb 19 03:07:35.679: INFO: Got endpoints: latency-svc-klpdd [747.746271ms]
Feb 19 03:07:35.688: INFO: Created: latency-svc-qshbj
Feb 19 03:07:35.727: INFO: Got endpoints: latency-svc-cx9qs [747.409115ms]
Feb 19 03:07:35.737: INFO: Created: latency-svc-c7stg
Feb 19 03:07:35.777: INFO: Got endpoints: latency-svc-pzfdv [750.170125ms]
Feb 19 03:07:35.788: INFO: Created: latency-svc-zr4mb
Feb 19 03:07:35.827: INFO: Got endpoints: latency-svc-mvdp2 [748.392808ms]
Feb 19 03:07:35.840: INFO: Created: latency-svc-b76qt
Feb 19 03:07:35.878: INFO: Got endpoints: latency-svc-fvr8k [751.077312ms]
Feb 19 03:07:35.886: INFO: Created: latency-svc-fvg6x
Feb 19 03:07:35.929: INFO: Got endpoints: latency-svc-qxqpt [751.030785ms]
Feb 19 03:07:35.937: INFO: Created: latency-svc-dcglt
Feb 19 03:07:35.979: INFO: Got endpoints: latency-svc-vpsjg [747.827413ms]
Feb 19 03:07:35.987: INFO: Created: latency-svc-wht8n
Feb 19 03:07:36.027: INFO: Got endpoints: latency-svc-zlhjt [749.756291ms]
Feb 19 03:07:36.035: INFO: Created: latency-svc-brr92
Feb 19 03:07:36.077: INFO: Got endpoints: latency-svc-9xwq7 [749.508752ms]
Feb 19 03:07:36.088: INFO: Created: latency-svc-rsb9z
Feb 19 03:07:36.129: INFO: Got endpoints: latency-svc-j4bjn [750.163986ms]
Feb 19 03:07:36.139: INFO: Created: latency-svc-rndzx
Feb 19 03:07:36.177: INFO: Got endpoints: latency-svc-cvftv [748.323293ms]
Feb 19 03:07:36.184: INFO: Created: latency-svc-78v9s
Feb 19 03:07:36.227: INFO: Got endpoints: latency-svc-7p8qn [748.607732ms]
Feb 19 03:07:36.237: INFO: Created: latency-svc-9zksc
Feb 19 03:07:36.281: INFO: Got endpoints: latency-svc-8rfmw [752.461781ms]
Feb 19 03:07:36.289: INFO: Created: latency-svc-kh2g9
Feb 19 03:07:36.327: INFO: Got endpoints: latency-svc-tbsqf [749.640264ms]
Feb 19 03:07:36.334: INFO: Created: latency-svc-g5h6m
Feb 19 03:07:36.377: INFO: Got endpoints: latency-svc-hsv8d [750.24144ms]
Feb 19 03:07:36.387: INFO: Created: latency-svc-gz74j
Feb 19 03:07:36.430: INFO: Got endpoints: latency-svc-qshbj [750.411277ms]
Feb 19 03:07:36.477: INFO: Got endpoints: latency-svc-c7stg [750.043853ms]
Feb 19 03:07:36.529: INFO: Got endpoints: latency-svc-zr4mb [751.966068ms]
Feb 19 03:07:36.578: INFO: Got endpoints: latency-svc-b76qt [750.40412ms]
Feb 19 03:07:36.628: INFO: Got endpoints: latency-svc-fvg6x [750.104679ms]
Feb 19 03:07:36.678: INFO: Got endpoints: latency-svc-dcglt [748.68273ms]
Feb 19 03:07:36.727: INFO: Got endpoints: latency-svc-wht8n [747.798196ms]
Feb 19 03:07:36.778: INFO: Got endpoints: latency-svc-brr92 [750.880153ms]
Feb 19 03:07:36.827: INFO: Got endpoints: latency-svc-rsb9z [749.604866ms]
Feb 19 03:07:36.877: INFO: Got endpoints: latency-svc-rndzx [747.486415ms]
Feb 19 03:07:36.927: INFO: Got endpoints: latency-svc-78v9s [750.31907ms]
Feb 19 03:07:36.977: INFO: Got endpoints: latency-svc-9zksc [749.980313ms]
Feb 19 03:07:37.030: INFO: Got endpoints: latency-svc-kh2g9 [748.357301ms]
Feb 19 03:07:37.078: INFO: Got endpoints: latency-svc-g5h6m [751.353411ms]
Feb 19 03:07:37.127: INFO: Got endpoints: latency-svc-gz74j [749.726944ms]
Feb 19 03:07:37.127: INFO: Latencies: [17.634107ms 20.021204ms 27.178772ms 38.632951ms 48.610438ms 50.397813ms 64.24606ms 68.320386ms 78.439952ms 89.321838ms 94.598727ms 101.680295ms 111.234975ms 119.054428ms 127.812802ms 129.740385ms 130.829793ms 131.31875ms 131.565503ms 132.881272ms 134.158204ms 134.22971ms 134.25014ms 134.969061ms 136.618421ms 142.822054ms 145.587664ms 145.677671ms 146.144916ms 147.630425ms 148.098461ms 148.163896ms 149.08762ms 150.158182ms 150.465758ms 162.275655ms 201.169275ms 245.507462ms 286.448487ms 317.878188ms 356.766916ms 396.390736ms 437.765469ms 476.115037ms 518.886898ms 559.240425ms 601.470006ms 637.107819ms 681.459546ms 720.816455ms 741.452007ms 741.574436ms 746.182924ms 746.302554ms 746.5416ms 746.790146ms 746.823696ms 746.954606ms 747.005813ms 747.083604ms 747.109748ms 747.164928ms 747.204612ms 747.240129ms 747.275491ms 747.409115ms 747.486415ms 747.533901ms 747.637131ms 747.746271ms 747.798196ms 747.827413ms 747.827681ms 747.829103ms 747.848402ms 747.880713ms 748.135018ms 748.197571ms 748.214174ms 748.241578ms 748.241995ms 748.323293ms 748.357301ms 748.389258ms 748.392808ms 748.415377ms 748.426282ms 748.493533ms 748.607732ms 748.68273ms 748.70022ms 748.776923ms 748.801907ms 748.864675ms 748.877527ms 748.916655ms 748.969702ms 749.147695ms 749.187062ms 749.21472ms 749.300052ms 749.382958ms 749.426846ms 749.471669ms 749.486864ms 749.487814ms 749.508752ms 749.544056ms 749.556514ms 749.585681ms 749.604866ms 749.606675ms 749.640264ms 749.660154ms 749.663803ms 749.670437ms 749.704493ms 749.726944ms 749.73113ms 749.756291ms 749.811961ms 749.887549ms 749.899991ms 749.918957ms 749.928599ms 749.935455ms 749.945096ms 749.980313ms 749.980704ms 750.043853ms 750.104679ms 750.155847ms 750.163986ms 750.170125ms 750.24144ms 750.248748ms 750.255761ms 750.266432ms 750.270158ms 750.31907ms 750.328267ms 750.349794ms 750.373133ms 750.388627ms 750.397132ms 750.40412ms 750.405101ms 750.411277ms 750.426946ms 750.463323ms 750.482065ms 750.4956ms 750.533668ms 750.539626ms 750.548708ms 750.588708ms 750.604285ms 750.612176ms 750.696059ms 750.736156ms 750.859648ms 750.863776ms 750.880153ms 750.977076ms 751.019817ms 751.030785ms 751.058683ms 751.060661ms 751.077312ms 751.082783ms 751.096196ms 751.353411ms 751.463363ms 751.644925ms 751.648032ms 751.695613ms 751.699007ms 751.778009ms 751.880934ms 751.966068ms 752.14262ms 752.437945ms 752.461781ms 752.469276ms 752.575825ms 752.652495ms 752.730951ms 752.937217ms 752.942546ms 753.018014ms 753.110463ms 753.171798ms 753.343387ms 753.605001ms 753.622978ms 754.558228ms 754.914853ms 755.753019ms 757.43202ms 758.6779ms]
Feb 19 03:07:37.127: INFO: 50 %ile: 749.300052ms
Feb 19 03:07:37.127: INFO: 90 %ile: 752.14262ms
Feb 19 03:07:37.127: INFO: 99 %ile: 757.43202ms
Feb 19 03:07:37.127: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:07:37.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-52v9q" for this suite.
Feb 19 03:07:59.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:07:59.188: INFO: namespace: e2e-tests-svc-latency-52v9q, resource: bindings, ignored listing per whitelist
Feb 19 03:07:59.214: INFO: namespace e2e-tests-svc-latency-52v9q deletion completed in 22.08345958s

• [SLOW TEST:44.872 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:07:59.214: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 03:07:59.275: INFO: Waiting up to 5m0s for pod "downward-api-8fb6b7eb-33f3-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-rcn5p" to be "success or failure"
Feb 19 03:07:59.280: INFO: Pod "downward-api-8fb6b7eb-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.211283ms
Feb 19 03:08:01.286: INFO: Pod "downward-api-8fb6b7eb-33f3-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010647572s
STEP: Saw pod success
Feb 19 03:08:01.286: INFO: Pod "downward-api-8fb6b7eb-33f3-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:08:01.288: INFO: Trying to get logs from node 172.26.0.15 pod downward-api-8fb6b7eb-33f3-11e9-834e-0a58ac100103 container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:08:01.305: INFO: Waiting for pod downward-api-8fb6b7eb-33f3-11e9-834e-0a58ac100103 to disappear
Feb 19 03:08:01.306: INFO: Pod downward-api-8fb6b7eb-33f3-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:08:01.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rcn5p" for this suite.
Feb 19 03:08:07.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:08:07.339: INFO: namespace: e2e-tests-downward-api-rcn5p, resource: bindings, ignored listing per whitelist
Feb 19 03:08:07.386: INFO: namespace e2e-tests-downward-api-rcn5p deletion completed in 6.076682294s

• [SLOW TEST:8.172 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:08:07.386: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vnkcf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 03:08:07.441: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 03:08:51.509: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.4.7:8080/dial?request=hostName&protocol=udp&host=172.16.3.12&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vnkcf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:08:51.509: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 03:08:51.586: INFO: Waiting for endpoints: map[]
Feb 19 03:08:51.588: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.4.7:8080/dial?request=hostName&protocol=udp&host=172.16.4.6&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vnkcf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:08:51.588: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 03:08:51.658: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:08:51.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vnkcf" for this suite.
Feb 19 03:09:13.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:09:13.681: INFO: namespace: e2e-tests-pod-network-test-vnkcf, resource: bindings, ignored listing per whitelist
Feb 19 03:09:13.736: INFO: namespace e2e-tests-pod-network-test-vnkcf deletion completed in 22.074340371s

• [SLOW TEST:66.350 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:09:13.736: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 19 03:09:13.799: INFO: Waiting up to 5m0s for pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-dzj57" to be "success or failure"
Feb 19 03:09:13.803: INFO: Pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.874623ms
Feb 19 03:09:15.808: INFO: Pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009291184s
Feb 19 03:09:17.811: INFO: Pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012289007s
Feb 19 03:09:19.814: INFO: Pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015116448s
Feb 19 03:09:21.817: INFO: Pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017893619s
Feb 19 03:09:23.820: INFO: Pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020729566s
Feb 19 03:09:25.826: INFO: Pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.026917155s
STEP: Saw pod success
Feb 19 03:09:25.826: INFO: Pod "pod-bc21ef5c-33f3-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:09:25.828: INFO: Trying to get logs from node 172.26.0.5 pod pod-bc21ef5c-33f3-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:09:25.844: INFO: Waiting for pod pod-bc21ef5c-33f3-11e9-834e-0a58ac100103 to disappear
Feb 19 03:09:25.846: INFO: Pod pod-bc21ef5c-33f3-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:09:25.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dzj57" for this suite.
Feb 19 03:09:31.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:09:31.923: INFO: namespace: e2e-tests-emptydir-dzj57, resource: bindings, ignored listing per whitelist
Feb 19 03:09:31.927: INFO: namespace e2e-tests-emptydir-dzj57 deletion completed in 6.078639632s

• [SLOW TEST:18.191 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:09:31.928: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 19 03:09:36.009: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-c6f9fa3e-33f3-11e9-834e-0a58ac100103", GenerateName:"", Namespace:"e2e-tests-pods-8lzbk", SelfLink:"/api/v1/namespaces/e2e-tests-pods-8lzbk/pods/pod-submit-remove-c6f9fa3e-33f3-11e9-834e-0a58ac100103", UID:"c6fa7479-33f3-11e9-9859-5254000410cb", ResourceVersion:"6033", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686142571, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"985163590"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-nlqnw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42183ac00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nlqnw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4200ce328), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"172.26.0.15", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4214a47e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4200ce370)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4200ce390)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4200ce398), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686142572, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686142574, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686142574, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686142571, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.26.0.15", PodIP:"172.16.3.13", StartTime:(*v1.Time)(0xc421207d60), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421207da0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://39bbd121ee84945e8641347675face8365c4b5327b13ca3954653c0e3168a948"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 19 03:09:41.024: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:09:41.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8lzbk" for this suite.
Feb 19 03:09:47.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:09:47.087: INFO: namespace: e2e-tests-pods-8lzbk, resource: bindings, ignored listing per whitelist
Feb 19 03:09:47.106: INFO: namespace e2e-tests-pods-8lzbk deletion completed in 6.077757105s

• [SLOW TEST:15.179 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:09:47.106: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 19 03:09:55.208: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:09:55.211: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:09:57.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:09:57.217: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:09:59.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:09:59.214: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:10:01.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:10:01.214: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:10:03.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:10:03.214: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:10:05.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:10:05.213: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:10:07.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:10:07.214: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:10:09.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:10:09.217: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:10:11.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:10:11.214: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 03:10:13.211: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 03:10:13.214: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:10:13.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-s952z" for this suite.
Feb 19 03:10:35.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:10:35.245: INFO: namespace: e2e-tests-container-lifecycle-hook-s952z, resource: bindings, ignored listing per whitelist
Feb 19 03:10:35.297: INFO: namespace e2e-tests-container-lifecycle-hook-s952z deletion completed in 22.080139132s

• [SLOW TEST:48.191 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:10:35.297: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 19 03:10:35.350: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:10:41.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tk2rp" for this suite.
Feb 19 03:10:47.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:10:47.985: INFO: namespace: e2e-tests-init-container-tk2rp, resource: bindings, ignored listing per whitelist
Feb 19 03:10:48.046: INFO: namespace e2e-tests-init-container-tk2rp deletion completed in 6.076466079s

• [SLOW TEST:12.749 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:10:48.046: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 19 03:10:48.111: INFO: Waiting up to 5m0s for pod "pod-f45918af-33f3-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-mcqff" to be "success or failure"
Feb 19 03:10:48.118: INFO: Pod "pod-f45918af-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.90907ms
Feb 19 03:10:50.121: INFO: Pod "pod-f45918af-33f3-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009845908s
Feb 19 03:10:52.127: INFO: Pod "pod-f45918af-33f3-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016517073s
STEP: Saw pod success
Feb 19 03:10:52.127: INFO: Pod "pod-f45918af-33f3-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:10:52.129: INFO: Trying to get logs from node 172.26.0.15 pod pod-f45918af-33f3-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:10:52.149: INFO: Waiting for pod pod-f45918af-33f3-11e9-834e-0a58ac100103 to disappear
Feb 19 03:10:52.152: INFO: Pod pod-f45918af-33f3-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:10:52.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mcqff" for this suite.
Feb 19 03:10:58.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:10:58.225: INFO: namespace: e2e-tests-emptydir-mcqff, resource: bindings, ignored listing per whitelist
Feb 19 03:10:58.234: INFO: namespace e2e-tests-emptydir-mcqff deletion completed in 6.079038282s

• [SLOW TEST:10.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:10:58.234: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:10:58.306: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 19 03:10:58.313: INFO: Number of nodes with available pods: 0
Feb 19 03:10:58.313: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 19 03:10:58.330: INFO: Number of nodes with available pods: 0
Feb 19 03:10:58.330: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:10:59.334: INFO: Number of nodes with available pods: 0
Feb 19 03:10:59.334: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:00.333: INFO: Number of nodes with available pods: 0
Feb 19 03:11:00.333: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:01.334: INFO: Number of nodes with available pods: 0
Feb 19 03:11:01.334: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:02.337: INFO: Number of nodes with available pods: 0
Feb 19 03:11:02.337: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:03.333: INFO: Number of nodes with available pods: 0
Feb 19 03:11:03.333: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:04.333: INFO: Number of nodes with available pods: 0
Feb 19 03:11:04.333: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:05.343: INFO: Number of nodes with available pods: 0
Feb 19 03:11:05.343: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:06.333: INFO: Number of nodes with available pods: 0
Feb 19 03:11:06.333: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:07.334: INFO: Number of nodes with available pods: 0
Feb 19 03:11:07.334: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:08.333: INFO: Number of nodes with available pods: 1
Feb 19 03:11:08.333: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 19 03:11:08.346: INFO: Number of nodes with available pods: 1
Feb 19 03:11:08.346: INFO: Number of running nodes: 0, number of available pods: 1
Feb 19 03:11:09.350: INFO: Number of nodes with available pods: 0
Feb 19 03:11:09.350: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 19 03:11:09.361: INFO: Number of nodes with available pods: 0
Feb 19 03:11:09.361: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:10.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:10.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:11.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:11.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:12.367: INFO: Number of nodes with available pods: 0
Feb 19 03:11:12.367: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:13.363: INFO: Number of nodes with available pods: 0
Feb 19 03:11:13.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:14.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:14.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:15.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:15.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:16.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:16.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:17.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:17.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:18.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:18.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:19.363: INFO: Number of nodes with available pods: 0
Feb 19 03:11:19.363: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:20.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:20.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:21.363: INFO: Number of nodes with available pods: 0
Feb 19 03:11:21.363: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:22.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:22.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:23.366: INFO: Number of nodes with available pods: 0
Feb 19 03:11:23.366: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:24.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:24.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:25.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:25.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:26.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:26.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:27.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:27.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:28.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:28.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:29.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:29.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:30.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:30.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:31.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:31.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:32.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:32.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:33.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:33.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:34.367: INFO: Number of nodes with available pods: 0
Feb 19 03:11:34.367: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:35.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:35.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:36.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:36.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:37.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:37.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:38.363: INFO: Number of nodes with available pods: 0
Feb 19 03:11:38.363: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:39.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:39.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:40.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:40.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:41.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:41.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:42.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:42.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:43.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:43.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:44.364: INFO: Number of nodes with available pods: 0
Feb 19 03:11:44.364: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:11:45.367: INFO: Number of nodes with available pods: 1
Feb 19 03:11:45.367: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-cjbrr, will wait for the garbage collector to delete the pods
Feb 19 03:11:45.429: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.571219ms
Feb 19 03:11:45.529: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.13389ms
Feb 19 03:12:20.735: INFO: Number of nodes with available pods: 0
Feb 19 03:12:20.735: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 03:12:20.739: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cjbrr/daemonsets","resourceVersion":"6584"},"items":null}

Feb 19 03:12:20.741: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cjbrr/pods","resourceVersion":"6584"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:12:20.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cjbrr" for this suite.
Feb 19 03:12:26.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:12:26.808: INFO: namespace: e2e-tests-daemonsets-cjbrr, resource: bindings, ignored listing per whitelist
Feb 19 03:12:26.832: INFO: namespace e2e-tests-daemonsets-cjbrr deletion completed in 6.072558246s

• [SLOW TEST:88.598 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:12:26.832: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-n4l8z
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-n4l8z
STEP: Deleting pre-stop pod
Feb 19 03:12:53.935: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:12:53.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-n4l8z" for this suite.
Feb 19 03:13:31.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:13:31.979: INFO: namespace: e2e-tests-prestop-n4l8z, resource: bindings, ignored listing per whitelist
Feb 19 03:13:32.021: INFO: namespace e2e-tests-prestop-n4l8z deletion completed in 38.07723402s

• [SLOW TEST:65.189 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:13:32.021: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:13:32.089: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-8b45k" to be "success or failure"
Feb 19 03:13:32.092: INFO: Pod "downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.269971ms
Feb 19 03:13:34.095: INFO: Pod "downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006530419s
Feb 19 03:13:36.098: INFO: Pod "downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009504687s
Feb 19 03:13:38.105: INFO: Pod "downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015843948s
STEP: Saw pod success
Feb 19 03:13:38.105: INFO: Pod "downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:13:38.106: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 03:13:38.130: INFO: Waiting for pod downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103 to disappear
Feb 19 03:13:38.132: INFO: Pod downwardapi-volume-5615b104-33f4-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:13:38.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8b45k" for this suite.
Feb 19 03:13:44.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:13:44.202: INFO: namespace: e2e-tests-downward-api-8b45k, resource: bindings, ignored listing per whitelist
Feb 19 03:13:44.211: INFO: namespace e2e-tests-downward-api-8b45k deletion completed in 6.076772136s

• [SLOW TEST:12.191 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:13:44.212: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5d597c15-33f4-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:13:44.281: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d5a69b2-33f4-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-kj5q6" to be "success or failure"
Feb 19 03:13:44.284: INFO: Pod "pod-projected-configmaps-5d5a69b2-33f4-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.102216ms
Feb 19 03:13:46.287: INFO: Pod "pod-projected-configmaps-5d5a69b2-33f4-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005785541s
Feb 19 03:13:48.293: INFO: Pod "pod-projected-configmaps-5d5a69b2-33f4-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012097526s
STEP: Saw pod success
Feb 19 03:13:48.293: INFO: Pod "pod-projected-configmaps-5d5a69b2-33f4-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:13:48.295: INFO: Trying to get logs from node 172.26.0.15 pod pod-projected-configmaps-5d5a69b2-33f4-11e9-834e-0a58ac100103 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:13:48.313: INFO: Waiting for pod pod-projected-configmaps-5d5a69b2-33f4-11e9-834e-0a58ac100103 to disappear
Feb 19 03:13:48.315: INFO: Pod pod-projected-configmaps-5d5a69b2-33f4-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:13:48.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kj5q6" for this suite.
Feb 19 03:13:54.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:13:54.389: INFO: namespace: e2e-tests-projected-kj5q6, resource: bindings, ignored listing per whitelist
Feb 19 03:13:54.406: INFO: namespace e2e-tests-projected-kj5q6 deletion completed in 6.087989084s

• [SLOW TEST:10.194 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:13:54.406: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0219 03:14:24.996853      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 03:14:24.996: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:14:24.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7ntx4" for this suite.
Feb 19 03:14:31.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:14:31.054: INFO: namespace: e2e-tests-gc-7ntx4, resource: bindings, ignored listing per whitelist
Feb 19 03:14:31.075: INFO: namespace e2e-tests-gc-7ntx4 deletion completed in 6.076193882s

• [SLOW TEST:36.669 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:14:31.075: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:14:37.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-qhvrq" for this suite.
Feb 19 03:14:43.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:14:43.269: INFO: namespace: e2e-tests-namespaces-qhvrq, resource: bindings, ignored listing per whitelist
Feb 19 03:14:43.280: INFO: namespace e2e-tests-namespaces-qhvrq deletion completed in 6.077594128s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hzhzk" for this suite.
Feb 19 03:14:43.281: INFO: Namespace e2e-tests-nsdeletetest-hzhzk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-n8kxj" for this suite.
Feb 19 03:14:49.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:14:49.302: INFO: namespace: e2e-tests-nsdeletetest-n8kxj, resource: bindings, ignored listing per whitelist
Feb 19 03:14:49.358: INFO: namespace e2e-tests-nsdeletetest-n8kxj deletion completed in 6.077010885s

• [SLOW TEST:18.283 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:14:49.358: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wxp2m
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-wxp2m
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-wxp2m
Feb 19 03:14:49.427: INFO: Found 0 stateful pods, waiting for 1
Feb 19 03:14:59.433: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 19 03:14:59.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-wxp2m ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 03:14:59.738: INFO: stderr: ""
Feb 19 03:14:59.738: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 03:14:59.738: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 03:14:59.741: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 19 03:15:09.747: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 03:15:09.747: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 03:15:09.761: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998745s
Feb 19 03:15:10.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995684638s
Feb 19 03:15:11.768: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992490545s
Feb 19 03:15:12.771: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989102828s
Feb 19 03:15:13.774: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.986238441s
Feb 19 03:15:14.777: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.983094622s
Feb 19 03:15:15.780: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.980058191s
Feb 19 03:15:16.783: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.976703672s
Feb 19 03:15:17.787: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.973482035s
Feb 19 03:15:18.790: INFO: Verifying statefulset ss doesn't scale past 1 for another 970.089938ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-wxp2m
Feb 19 03:15:19.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-wxp2m ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 03:15:19.949: INFO: stderr: ""
Feb 19 03:15:19.949: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 03:15:19.949: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 03:15:19.953: INFO: Found 1 stateful pods, waiting for 3
Feb 19 03:15:29.960: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 03:15:29.960: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 03:15:29.960: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 19 03:15:29.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-wxp2m ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 03:15:30.115: INFO: stderr: ""
Feb 19 03:15:30.115: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 03:15:30.115: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 03:15:30.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-wxp2m ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 03:15:30.387: INFO: stderr: ""
Feb 19 03:15:30.387: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 03:15:30.387: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 03:15:30.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-wxp2m ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 03:15:30.858: INFO: stderr: ""
Feb 19 03:15:30.858: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 03:15:30.858: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 03:15:30.858: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 03:15:30.861: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 19 03:15:40.869: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 03:15:40.869: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 03:15:40.869: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 03:15:40.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998642s
Feb 19 03:15:41.889: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996910722s
Feb 19 03:15:42.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993178061s
Feb 19 03:15:43.896: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989552601s
Feb 19 03:15:44.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985900253s
Feb 19 03:15:45.904: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982963572s
Feb 19 03:15:46.907: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977596471s
Feb 19 03:15:47.911: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974687072s
Feb 19 03:15:48.914: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971325967s
Feb 19 03:15:49.917: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.918179ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-wxp2m
Feb 19 03:15:50.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-wxp2m ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 03:15:51.072: INFO: stderr: ""
Feb 19 03:15:51.072: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 03:15:51.072: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 03:15:51.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-wxp2m ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 03:15:51.217: INFO: stderr: ""
Feb 19 03:15:51.217: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 03:15:51.217: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 03:15:51.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-wxp2m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 03:15:51.361: INFO: stderr: ""
Feb 19 03:15:51.361: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 03:15:51.361: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 03:15:51.361: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 03:16:11.372: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wxp2m
Feb 19 03:16:11.374: INFO: Scaling statefulset ss to 0
Feb 19 03:16:11.384: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 03:16:11.386: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:16:11.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wxp2m" for this suite.
Feb 19 03:16:17.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:16:17.442: INFO: namespace: e2e-tests-statefulset-wxp2m, resource: bindings, ignored listing per whitelist
Feb 19 03:16:17.476: INFO: namespace e2e-tests-statefulset-wxp2m deletion completed in 6.078073637s

• [SLOW TEST:88.118 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:16:17.477: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 03:16:17.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-pjxhw'
Feb 19 03:16:17.651: INFO: stderr: ""
Feb 19 03:16:17.651: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Feb 19 03:16:17.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pjxhw'
Feb 19 03:16:21.878: INFO: stderr: ""
Feb 19 03:16:21.878: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:16:21.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pjxhw" for this suite.
Feb 19 03:16:27.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:16:27.925: INFO: namespace: e2e-tests-kubectl-pjxhw, resource: bindings, ignored listing per whitelist
Feb 19 03:16:27.962: INFO: namespace e2e-tests-kubectl-pjxhw deletion completed in 6.078459849s

• [SLOW TEST:10.486 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:16:27.962: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 19 03:16:34.036: INFO: Pod pod-hostip-bef38244-33f4-11e9-834e-0a58ac100103 has hostIP: 172.26.0.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:16:34.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mggxk" for this suite.
Feb 19 03:17:12.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:17:12.114: INFO: namespace: e2e-tests-pods-mggxk, resource: bindings, ignored listing per whitelist
Feb 19 03:17:12.118: INFO: namespace e2e-tests-pods-mggxk deletion completed in 38.078875943s

• [SLOW TEST:44.155 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:17:12.118: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:17:12.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-dhn8s" for this suite.
Feb 19 03:17:18.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:17:18.220: INFO: namespace: e2e-tests-services-dhn8s, resource: bindings, ignored listing per whitelist
Feb 19 03:17:18.255: INFO: namespace e2e-tests-services-dhn8s deletion completed in 6.074833664s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.137 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:17:18.255: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:17:18.314: INFO: (0) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.747461ms)
Feb 19 03:17:18.316: INFO: (1) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.362579ms)
Feb 19 03:17:18.318: INFO: (2) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.255108ms)
Feb 19 03:17:18.320: INFO: (3) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.256453ms)
Feb 19 03:17:18.323: INFO: (4) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.273238ms)
Feb 19 03:17:18.325: INFO: (5) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.399112ms)
Feb 19 03:17:18.327: INFO: (6) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.22304ms)
Feb 19 03:17:18.330: INFO: (7) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.331713ms)
Feb 19 03:17:18.332: INFO: (8) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.282853ms)
Feb 19 03:17:18.334: INFO: (9) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.187276ms)
Feb 19 03:17:18.337: INFO: (10) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.538305ms)
Feb 19 03:17:18.340: INFO: (11) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.951172ms)
Feb 19 03:17:18.343: INFO: (12) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.159686ms)
Feb 19 03:17:18.348: INFO: (13) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.152163ms)
Feb 19 03:17:18.351: INFO: (14) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.644946ms)
Feb 19 03:17:18.353: INFO: (15) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.375889ms)
Feb 19 03:17:18.356: INFO: (16) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.536995ms)
Feb 19 03:17:18.358: INFO: (17) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.365567ms)
Feb 19 03:17:18.360: INFO: (18) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.289421ms)
Feb 19 03:17:18.364: INFO: (19) /api/v1/nodes/172.26.0.15/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.638099ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:17:18.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-k95h4" for this suite.
Feb 19 03:17:24.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:17:24.427: INFO: namespace: e2e-tests-proxy-k95h4, resource: bindings, ignored listing per whitelist
Feb 19 03:17:24.443: INFO: namespace e2e-tests-proxy-k95h4 deletion completed in 6.076281084s

• [SLOW TEST:6.189 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:17:24.443: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 19 03:17:24.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:24.980: INFO: stderr: ""
Feb 19 03:17:24.980: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 03:17:24.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:25.073: INFO: stderr: ""
Feb 19 03:17:25.073: INFO: stdout: "update-demo-nautilus-fmm6s update-demo-nautilus-pvkp4 "
Feb 19 03:17:25.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-fmm6s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:25.161: INFO: stderr: ""
Feb 19 03:17:25.161: INFO: stdout: ""
Feb 19 03:17:25.161: INFO: update-demo-nautilus-fmm6s is created but not running
Feb 19 03:17:30.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:30.257: INFO: stderr: ""
Feb 19 03:17:30.257: INFO: stdout: "update-demo-nautilus-fmm6s update-demo-nautilus-pvkp4 "
Feb 19 03:17:30.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-fmm6s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:30.344: INFO: stderr: ""
Feb 19 03:17:30.344: INFO: stdout: ""
Feb 19 03:17:30.344: INFO: update-demo-nautilus-fmm6s is created but not running
Feb 19 03:17:35.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:35.429: INFO: stderr: ""
Feb 19 03:17:35.429: INFO: stdout: "update-demo-nautilus-fmm6s update-demo-nautilus-pvkp4 "
Feb 19 03:17:35.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-fmm6s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:35.518: INFO: stderr: ""
Feb 19 03:17:35.518: INFO: stdout: ""
Feb 19 03:17:35.518: INFO: update-demo-nautilus-fmm6s is created but not running
Feb 19 03:17:40.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:40.624: INFO: stderr: ""
Feb 19 03:17:40.624: INFO: stdout: "update-demo-nautilus-fmm6s update-demo-nautilus-pvkp4 "
Feb 19 03:17:40.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-fmm6s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:40.712: INFO: stderr: ""
Feb 19 03:17:40.712: INFO: stdout: "true"
Feb 19 03:17:40.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-fmm6s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:40.800: INFO: stderr: ""
Feb 19 03:17:40.800: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:17:40.800: INFO: validating pod update-demo-nautilus-fmm6s
Feb 19 03:17:40.804: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:17:40.804: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:17:40.804: INFO: update-demo-nautilus-fmm6s is verified up and running
Feb 19 03:17:40.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-pvkp4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:40.886: INFO: stderr: ""
Feb 19 03:17:40.886: INFO: stdout: "true"
Feb 19 03:17:40.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-pvkp4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:40.968: INFO: stderr: ""
Feb 19 03:17:40.968: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:17:40.968: INFO: validating pod update-demo-nautilus-pvkp4
Feb 19 03:17:40.971: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:17:40.971: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:17:40.971: INFO: update-demo-nautilus-pvkp4 is verified up and running
STEP: scaling down the replication controller
Feb 19 03:17:40.973: INFO: scanned /root for discovery docs: <nil>
Feb 19 03:17:40.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:42.089: INFO: stderr: ""
Feb 19 03:17:42.089: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 03:17:42.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:42.177: INFO: stderr: ""
Feb 19 03:17:42.177: INFO: stdout: "update-demo-nautilus-fmm6s update-demo-nautilus-pvkp4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 19 03:17:47.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:47.265: INFO: stderr: ""
Feb 19 03:17:47.265: INFO: stdout: "update-demo-nautilus-pvkp4 "
Feb 19 03:17:47.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-pvkp4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:47.347: INFO: stderr: ""
Feb 19 03:17:47.347: INFO: stdout: "true"
Feb 19 03:17:47.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-pvkp4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:47.433: INFO: stderr: ""
Feb 19 03:17:47.433: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:17:47.433: INFO: validating pod update-demo-nautilus-pvkp4
Feb 19 03:17:47.436: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:17:47.436: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:17:47.436: INFO: update-demo-nautilus-pvkp4 is verified up and running
STEP: scaling up the replication controller
Feb 19 03:17:47.437: INFO: scanned /root for discovery docs: <nil>
Feb 19 03:17:47.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:48.556: INFO: stderr: ""
Feb 19 03:17:48.556: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 03:17:48.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:48.664: INFO: stderr: ""
Feb 19 03:17:48.664: INFO: stdout: "update-demo-nautilus-pvkp4 update-demo-nautilus-skfch "
Feb 19 03:17:48.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-pvkp4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:48.746: INFO: stderr: ""
Feb 19 03:17:48.746: INFO: stdout: "true"
Feb 19 03:17:48.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-pvkp4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:48.827: INFO: stderr: ""
Feb 19 03:17:48.827: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:17:48.827: INFO: validating pod update-demo-nautilus-pvkp4
Feb 19 03:17:48.830: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:17:48.830: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:17:48.830: INFO: update-demo-nautilus-pvkp4 is verified up and running
Feb 19 03:17:48.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-skfch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:48.921: INFO: stderr: ""
Feb 19 03:17:48.921: INFO: stdout: ""
Feb 19 03:17:48.921: INFO: update-demo-nautilus-skfch is created but not running
Feb 19 03:17:53.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:54.012: INFO: stderr: ""
Feb 19 03:17:54.012: INFO: stdout: "update-demo-nautilus-pvkp4 update-demo-nautilus-skfch "
Feb 19 03:17:54.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-pvkp4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:54.098: INFO: stderr: ""
Feb 19 03:17:54.098: INFO: stdout: "true"
Feb 19 03:17:54.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-pvkp4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:54.184: INFO: stderr: ""
Feb 19 03:17:54.184: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:17:54.184: INFO: validating pod update-demo-nautilus-pvkp4
Feb 19 03:17:54.187: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:17:54.187: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:17:54.187: INFO: update-demo-nautilus-pvkp4 is verified up and running
Feb 19 03:17:54.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-skfch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:54.270: INFO: stderr: ""
Feb 19 03:17:54.270: INFO: stdout: "true"
Feb 19 03:17:54.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-skfch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:54.353: INFO: stderr: ""
Feb 19 03:17:54.353: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:17:54.353: INFO: validating pod update-demo-nautilus-skfch
Feb 19 03:17:54.356: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:17:54.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:17:54.356: INFO: update-demo-nautilus-skfch is verified up and running
STEP: using delete to clean up resources
Feb 19 03:17:54.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:54.442: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:17:54.442: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 19 03:17:54.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-pvmhn'
Feb 19 03:17:54.536: INFO: stderr: "No resources found.\n"
Feb 19 03:17:54.536: INFO: stdout: ""
Feb 19 03:17:54.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -l name=update-demo --namespace=e2e-tests-kubectl-pvmhn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 03:17:54.621: INFO: stderr: ""
Feb 19 03:17:54.621: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:17:54.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pvmhn" for this suite.
Feb 19 03:18:00.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:18:00.643: INFO: namespace: e2e-tests-kubectl-pvmhn, resource: bindings, ignored listing per whitelist
Feb 19 03:18:00.705: INFO: namespace e2e-tests-kubectl-pvmhn deletion completed in 6.080757952s

• [SLOW TEST:36.262 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:18:00.706: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0219 03:18:01.801335      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 03:18:01.801: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:18:01.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pxqz5" for this suite.
Feb 19 03:18:07.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:18:07.847: INFO: namespace: e2e-tests-gc-pxqz5, resource: bindings, ignored listing per whitelist
Feb 19 03:18:07.886: INFO: namespace e2e-tests-gc-pxqz5 deletion completed in 6.082442318s

• [SLOW TEST:7.180 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:18:07.886: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 19 03:18:23.955: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-fa8278e3-33f4-11e9-834e-0a58ac100103,GenerateName:,Namespace:e2e-tests-events-c9x25,SelfLink:/api/v1/namespaces/e2e-tests-events-c9x25/pods/send-events-fa8278e3-33f4-11e9-834e-0a58ac100103,UID:fa842b2d-33f4-11e9-9859-5254000410cb,ResourceVersion:8025,Generation:0,CreationTimestamp:2019-02-19 03:18:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 940228073,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dlgwt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dlgwt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-dlgwt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42117cdb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42117cdd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:18:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:18:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:18:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:18:07 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:172.16.4.21,StartTime:2019-02-19 03:18:08 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-19 03:18:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a0dbd9b058701d4fdc69275258a6da20963eb0f45c6e94c3f0983186e6a45a03}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 19 03:18:25.962: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 19 03:18:27.965: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:18:27.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-c9x25" for this suite.
Feb 19 03:19:05.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:19:06.043: INFO: namespace: e2e-tests-events-c9x25, resource: bindings, ignored listing per whitelist
Feb 19 03:19:06.049: INFO: namespace e2e-tests-events-c9x25 deletion completed in 38.075978425s

• [SLOW TEST:58.163 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:19:06.049: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 19 03:19:06.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 cluster-info'
Feb 19 03:19:06.187: INFO: stderr: ""
Feb 19 03:19:06.187: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.16.255.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.16.255.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns-tcp/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:19:06.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-65fkh" for this suite.
Feb 19 03:19:12.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:19:12.261: INFO: namespace: e2e-tests-kubectl-65fkh, resource: bindings, ignored listing per whitelist
Feb 19 03:19:12.263: INFO: namespace e2e-tests-kubectl-65fkh deletion completed in 6.072896791s

• [SLOW TEST:6.214 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:19:12.263: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:19:12.314: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:19:13.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-t6kzp" for this suite.
Feb 19 03:19:19.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:19:19.388: INFO: namespace: e2e-tests-custom-resource-definition-t6kzp, resource: bindings, ignored listing per whitelist
Feb 19 03:19:19.435: INFO: namespace e2e-tests-custom-resource-definition-t6kzp deletion completed in 6.075887579s

• [SLOW TEST:7.172 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:19:19.435: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-slv2l/secret-test-252829ac-33f5-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 03:19:19.499: INFO: Waiting up to 5m0s for pod "pod-configmaps-2528b3b0-33f5-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-slv2l" to be "success or failure"
Feb 19 03:19:19.505: INFO: Pod "pod-configmaps-2528b3b0-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025052ms
Feb 19 03:19:21.511: INFO: Pod "pod-configmaps-2528b3b0-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012366437s
Feb 19 03:19:23.514: INFO: Pod "pod-configmaps-2528b3b0-33f5-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015351192s
STEP: Saw pod success
Feb 19 03:19:23.514: INFO: Pod "pod-configmaps-2528b3b0-33f5-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:19:23.516: INFO: Trying to get logs from node 172.26.0.15 pod pod-configmaps-2528b3b0-33f5-11e9-834e-0a58ac100103 container env-test: <nil>
STEP: delete the pod
Feb 19 03:19:23.536: INFO: Waiting for pod pod-configmaps-2528b3b0-33f5-11e9-834e-0a58ac100103 to disappear
Feb 19 03:19:23.538: INFO: Pod pod-configmaps-2528b3b0-33f5-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:19:23.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-slv2l" for this suite.
Feb 19 03:19:29.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:19:29.587: INFO: namespace: e2e-tests-secrets-slv2l, resource: bindings, ignored listing per whitelist
Feb 19 03:19:29.615: INFO: namespace e2e-tests-secrets-slv2l deletion completed in 6.073881368s

• [SLOW TEST:10.179 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:19:29.615: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2b3a3ee3-33f5-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 03:19:29.686: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-qtrbb" to be "success or failure"
Feb 19 03:19:29.690: INFO: Pod "pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.886689ms
Feb 19 03:19:31.696: INFO: Pod "pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010206731s
Feb 19 03:19:33.699: INFO: Pod "pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013207489s
Feb 19 03:19:35.702: INFO: Pod "pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01622922s
Feb 19 03:19:37.705: INFO: Pod "pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.018982444s
STEP: Saw pod success
Feb 19 03:19:37.705: INFO: Pod "pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:19:37.707: INFO: Trying to get logs from node 172.26.0.5 pod pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 03:19:37.723: INFO: Waiting for pod pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103 to disappear
Feb 19 03:19:37.725: INFO: Pod pod-projected-secrets-2b3acb82-33f5-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:19:37.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qtrbb" for this suite.
Feb 19 03:19:43.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:19:43.750: INFO: namespace: e2e-tests-projected-qtrbb, resource: bindings, ignored listing per whitelist
Feb 19 03:19:43.806: INFO: namespace e2e-tests-projected-qtrbb deletion completed in 6.077777118s

• [SLOW TEST:14.191 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:19:43.806: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:19:43.865: INFO: Creating deployment "nginx-deployment"
Feb 19 03:19:43.869: INFO: Waiting for observed generation 1
Feb 19 03:19:45.878: INFO: Waiting for all required pods to come up
Feb 19 03:19:45.881: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 19 03:20:09.888: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 19 03:20:09.892: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 19 03:20:09.898: INFO: Updating deployment nginx-deployment
Feb 19 03:20:09.898: INFO: Waiting for observed generation 2
Feb 19 03:20:11.907: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 19 03:20:11.909: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 19 03:20:11.911: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 19 03:20:11.918: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 19 03:20:11.918: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 19 03:20:11.920: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 19 03:20:11.924: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 19 03:20:11.924: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 19 03:20:11.931: INFO: Updating deployment nginx-deployment
Feb 19 03:20:11.931: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 19 03:20:11.941: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 19 03:20:13.950: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 03:20:13.954: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-24skg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-24skg/deployments/nginx-deployment,UID:33b13ffa-33f5-11e9-9859-5254000410cb,ResourceVersion:8614,Generation:3,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-19 03:20:11 +0000 UTC 2019-02-19 03:20:11 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-19 03:20:12 +0000 UTC 2019-02-19 03:19:43 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 19 03:20:13.956: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-24skg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-24skg/replicasets/nginx-deployment-7dc8f79789,UID:433590bb-33f5-11e9-9859-5254000410cb,ResourceVersion:8607,Generation:3,CreationTimestamp:2019-02-19 03:20:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 33b13ffa-33f5-11e9-9859-5254000410cb 0xc422c0a457 0xc422c0a458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 03:20:13.956: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 19 03:20:13.956: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-24skg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-24skg/replicasets/nginx-deployment-7f9675fb8b,UID:33b27be4-33f5-11e9-9859-5254000410cb,ResourceVersion:8608,Generation:3,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 33b13ffa-33f5-11e9-9859-5254000410cb 0xc422c0a527 0xc422c0a528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 19 03:20:13.960: INFO: Pod "nginx-deployment-7dc8f79789-28smf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-28smf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-28smf,UID:43368edb-33f5-11e9-9859-5254000410cb,ResourceVersion:8658,Generation:0,CreationTimestamp:2019-02-19 03:20:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0b070 0xc422c0b071}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0b0f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0b110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:09 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.960: INFO: Pod "nginx-deployment-7dc8f79789-2qgcz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2qgcz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-2qgcz,UID:44713423-33f5-11e9-9859-5254000410cb,ResourceVersion:8664,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0b1e0 0xc422c0b1e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0b260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0b280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.960: INFO: Pod "nginx-deployment-7dc8f79789-fzgt4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fzgt4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-fzgt4,UID:447307f7-33f5-11e9-9859-5254000410cb,ResourceVersion:8598,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0b340 0xc422c0b341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0b3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0b3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-hkszk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hkszk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-hkszk,UID:44714b70-33f5-11e9-9859-5254000410cb,ResourceVersion:8653,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0b450 0xc422c0b451}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0b4d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0b4f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-k84ww" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-k84ww,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-k84ww,UID:447158b5-33f5-11e9-9859-5254000410cb,ResourceVersion:8662,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0b5b0 0xc422c0b5b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0b630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0b650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-lttxf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-lttxf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-lttxf,UID:446fb8e1-33f5-11e9-9859-5254000410cb,ResourceVersion:8659,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0b710 0xc422c0b711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0b790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0b7b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-prxs2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-prxs2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-prxs2,UID:446fd303-33f5-11e9-9859-5254000410cb,ResourceVersion:8636,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0b870 0xc422c0b871}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0b900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0b920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-qdwcs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qdwcs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-qdwcs,UID:433efdac-33f5-11e9-9859-5254000410cb,ResourceVersion:8539,Generation:0,CreationTimestamp:2019-02-19 03:20:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0b9e0 0xc422c0b9e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0baf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0bb10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:09 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-r2jbs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-r2jbs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-r2jbs,UID:44715831-33f5-11e9-9859-5254000410cb,ResourceVersion:8593,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0bbd0 0xc422c0bbd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0bc90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0bcb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-r8v25" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-r8v25,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-r8v25,UID:43401b10-33f5-11e9-9859-5254000410cb,ResourceVersion:8544,Generation:0,CreationTimestamp:2019-02-19 03:20:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0bd20 0xc422c0bd21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0bdb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0be00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:09 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-rr8md" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rr8md,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-rr8md,UID:446d7bdd-33f5-11e9-9859-5254000410cb,ResourceVersion:8618,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c0bec0 0xc422c0bec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c0bfb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c0bfd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-sbksd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sbksd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-sbksd,UID:43377c08-33f5-11e9-9859-5254000410cb,ResourceVersion:8660,Generation:0,CreationTimestamp:2019-02-19 03:20:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c04100 0xc422c04101}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c041a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:09 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.961: INFO: Pod "nginx-deployment-7dc8f79789-z6tl8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-z6tl8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7dc8f79789-z6tl8,UID:4337435f-33f5-11e9-9859-5254000410cb,ResourceVersion:8536,Generation:0,CreationTimestamp:2019-02-19 03:20:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 433590bb-33f5-11e9-9859-5254000410cb 0xc422c04300 0xc422c04301}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c043a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:09 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-2v22k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2v22k,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-2v22k,UID:446ff14d-33f5-11e9-9859-5254000410cb,ResourceVersion:8661,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c045a0 0xc422c045a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c04630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-4f75n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4f75n,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-4f75n,UID:44701f4f-33f5-11e9-9859-5254000410cb,ResourceVersion:8642,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c04750 0xc422c04751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c047c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c047e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-692pf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-692pf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-692pf,UID:33b79ebd-33f5-11e9-9859-5254000410cb,ResourceVersion:8392,Generation:0,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c048d0 0xc422c048d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c04960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:172.16.3.29,StartTime:2019-02-19 03:19:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 03:19:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ad326d37b6b36e85c341c70e18b31bc687ae3582855a861f83c9dff99cb82b2c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-69tkt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-69tkt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-69tkt,UID:33b79abe-33f5-11e9-9859-5254000410cb,ResourceVersion:8469,Generation:0,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c04a20 0xc422c04a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c04ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:172.16.4.26,StartTime:2019-02-19 03:19:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 03:20:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://20ca9913e72721c7ea624d14cdfe24460b4906ee2c46c817c2b36b960484dcee}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-6lcsq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6lcsq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-6lcsq,UID:44732cae-33f5-11e9-9859-5254000410cb,ResourceVersion:8605,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c04b70 0xc422c04b71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c04c00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-6lssj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6lssj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-6lssj,UID:446da44b-33f5-11e9-9859-5254000410cb,ResourceVersion:8646,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c04c70 0xc422c04c71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c04d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-7jd9d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7jd9d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-7jd9d,UID:447012c9-33f5-11e9-9859-5254000410cb,ResourceVersion:8663,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c04db0 0xc422c04db1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c04e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-8g7mj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8g7mj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-8g7mj,UID:447004dc-33f5-11e9-9859-5254000410cb,ResourceVersion:8648,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c04ef0 0xc422c04ef1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c04f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c04f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-b7266" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-b7266,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-b7266,UID:33b5ca61-33f5-11e9-9859-5254000410cb,ResourceVersion:8467,Generation:0,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c05030 0xc422c05031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c050a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c050c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:172.16.4.23,StartTime:2019-02-19 03:19:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 03:19:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://2334aa817af5c342fe2adeafae585834142d31615d768a00771ba31b2c736427}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.962: INFO: Pod "nginx-deployment-7f9675fb8b-bmxrk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bmxrk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-bmxrk,UID:446c816c-33f5-11e9-9859-5254000410cb,ResourceVersion:8637,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c05180 0xc422c05181}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c051f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c05210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:,StartTime:2019-02-19 03:20:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.963: INFO: Pod "nginx-deployment-7f9675fb8b-btxrj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-btxrj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-btxrj,UID:4473370c-33f5-11e9-9859-5254000410cb,ResourceVersion:8604,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c052c0 0xc422c052c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c05330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c05350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.963: INFO: Pod "nginx-deployment-7f9675fb8b-fmsht" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fmsht,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-fmsht,UID:33b5d349-33f5-11e9-9859-5254000410cb,ResourceVersion:8466,Generation:0,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c053c0 0xc422c053c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c05430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c05450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:172.16.4.24,StartTime:2019-02-19 03:19:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 03:20:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://c2bfbf1767d492fef95cf2128140f0a05bc22a2ac05d2f0405b9e47e40fda9df}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.963: INFO: Pod "nginx-deployment-7f9675fb8b-fwgl5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fwgl5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-fwgl5,UID:33ba19de-33f5-11e9-9859-5254000410cb,ResourceVersion:8484,Generation:0,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c05510 0xc422c05511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c05580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c055a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:172.16.4.27,StartTime:2019-02-19 03:19:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 03:20:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://bb2cec36f03fa45443e3dabf68e971ec045ea71d8e16589629dd30223d78685c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.963: INFO: Pod "nginx-deployment-7f9675fb8b-gn5rg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gn5rg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-gn5rg,UID:447321eb-33f5-11e9-9859-5254000410cb,ResourceVersion:8603,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c05660 0xc422c05661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c056d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c056f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.963: INFO: Pod "nginx-deployment-7f9675fb8b-l6jmk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-l6jmk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-l6jmk,UID:33ba3ceb-33f5-11e9-9859-5254000410cb,ResourceVersion:8390,Generation:0,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c05760 0xc422c05761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c057d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c057f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:172.16.3.30,StartTime:2019-02-19 03:19:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 03:19:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://c782ad23ff88d382781839597cb44ab1bd9dd53b99106be96729ee7bea3b425b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.963: INFO: Pod "nginx-deployment-7f9675fb8b-mspjd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mspjd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-mspjd,UID:446dad5b-33f5-11e9-9859-5254000410cb,ResourceVersion:8625,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c058b0 0xc422c058b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c05920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c05940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:11 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:,StartTime:2019-02-19 03:20:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.963: INFO: Pod "nginx-deployment-7f9675fb8b-pb84h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pb84h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-pb84h,UID:44731658-33f5-11e9-9859-5254000410cb,ResourceVersion:8599,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c059f0 0xc422c059f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c05a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c05a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.964: INFO: Pod "nginx-deployment-7f9675fb8b-qfv8d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qfv8d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-qfv8d,UID:33b7940a-33f5-11e9-9859-5254000410cb,ResourceVersion:8398,Generation:0,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c05af0 0xc422c05af1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c05b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c05b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:172.16.3.31,StartTime:2019-02-19 03:19:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 03:19:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://d86c0dd56ec3cb2c433d1922c4b3c9098cdf3477ce033bc3b1225e334cd370ba}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.964: INFO: Pod "nginx-deployment-7f9675fb8b-sgtgr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sgtgr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-sgtgr,UID:33b52477-33f5-11e9-9859-5254000410cb,ResourceVersion:8395,Generation:0,CreationTimestamp:2019-02-19 03:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c05c40 0xc422c05c41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c05cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c05cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:19:43 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:172.16.3.28,StartTime:2019-02-19 03:19:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 03:19:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://e0cfbba540b7f5e58902edf5c48f7cb5d54a3c2e4cbb6a06dd2a1476f3d6e69e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 03:20:13.964: INFO: Pod "nginx-deployment-7f9675fb8b-x9wlv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-x9wlv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-24skg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-24skg/pods/nginx-deployment-7f9675fb8b-x9wlv,UID:447340fe-33f5-11e9-9859-5254000410cb,ResourceVersion:8602,Generation:0,CreationTimestamp:2019-02-19 03:20:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 33b27be4-33f5-11e9-9859-5254000410cb 0xc422c05d90 0xc422c05d91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-86nd6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-86nd6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-86nd6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c05e00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c05e20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:20:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:20:13.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-24skg" for this suite.
Feb 19 03:20:19.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:20:19.993: INFO: namespace: e2e-tests-deployment-24skg, resource: bindings, ignored listing per whitelist
Feb 19 03:20:20.040: INFO: namespace e2e-tests-deployment-24skg deletion completed in 6.073936799s

• [SLOW TEST:36.234 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:20:20.040: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-s85jj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 03:20:20.096: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 03:21:00.162: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.4.37 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s85jj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:21:00.162: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 03:21:01.220: INFO: Found all expected endpoints: [netserver-0]
Feb 19 03:21:01.223: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.3.46 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s85jj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:21:01.223: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 03:21:02.297: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:21:02.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-s85jj" for this suite.
Feb 19 03:21:24.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:21:24.319: INFO: namespace: e2e-tests-pod-network-test-s85jj, resource: bindings, ignored listing per whitelist
Feb 19 03:21:24.383: INFO: namespace e2e-tests-pod-network-test-s85jj deletion completed in 22.082020171s

• [SLOW TEST:64.342 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:21:24.383: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 03:21:24.446: INFO: Waiting up to 5m0s for pod "downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-fwmql" to be "success or failure"
Feb 19 03:21:24.456: INFO: Pod "downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 10.62491ms
Feb 19 03:21:26.459: INFO: Pod "downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013450635s
Feb 19 03:21:28.462: INFO: Pod "downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016432827s
Feb 19 03:21:30.468: INFO: Pod "downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02251376s
STEP: Saw pod success
Feb 19 03:21:30.468: INFO: Pod "downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:21:30.470: INFO: Trying to get logs from node 172.26.0.5 pod downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103 container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:21:30.488: INFO: Waiting for pod downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103 to disappear
Feb 19 03:21:30.491: INFO: Pod downward-api-6fa1d25b-33f5-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:21:30.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fwmql" for this suite.
Feb 19 03:21:36.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:21:36.543: INFO: namespace: e2e-tests-downward-api-fwmql, resource: bindings, ignored listing per whitelist
Feb 19 03:21:36.573: INFO: namespace e2e-tests-downward-api-fwmql deletion completed in 6.079187961s

• [SLOW TEST:12.190 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:21:36.573: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-p25q
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 03:21:36.643: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-p25q" in namespace "e2e-tests-subpath-5vs62" to be "success or failure"
Feb 19 03:21:36.646: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Pending", Reason="", readiness=false. Elapsed: 3.452184ms
Feb 19 03:21:38.649: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006143287s
Feb 19 03:21:40.655: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01261426s
Feb 19 03:21:42.658: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015681836s
Feb 19 03:21:44.662: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018915249s
Feb 19 03:21:46.665: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021963043s
Feb 19 03:21:48.667: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Pending", Reason="", readiness=false. Elapsed: 12.02465307s
Feb 19 03:21:50.673: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 14.030637395s
Feb 19 03:21:52.676: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 16.03345324s
Feb 19 03:21:54.679: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 18.036297534s
Feb 19 03:21:56.682: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 20.039108061s
Feb 19 03:21:58.685: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 22.042002301s
Feb 19 03:22:00.691: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 24.048082051s
Feb 19 03:22:02.694: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 26.050978233s
Feb 19 03:22:04.696: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 28.053827947s
Feb 19 03:22:06.699: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Running", Reason="", readiness=false. Elapsed: 30.056775911s
Feb 19 03:22:08.702: INFO: Pod "pod-subpath-test-configmap-p25q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.059722047s
STEP: Saw pod success
Feb 19 03:22:08.702: INFO: Pod "pod-subpath-test-configmap-p25q" satisfied condition "success or failure"
Feb 19 03:22:08.705: INFO: Trying to get logs from node 172.26.0.5 pod pod-subpath-test-configmap-p25q container test-container-subpath-configmap-p25q: <nil>
STEP: delete the pod
Feb 19 03:22:08.725: INFO: Waiting for pod pod-subpath-test-configmap-p25q to disappear
Feb 19 03:22:08.727: INFO: Pod pod-subpath-test-configmap-p25q no longer exists
STEP: Deleting pod pod-subpath-test-configmap-p25q
Feb 19 03:22:08.727: INFO: Deleting pod "pod-subpath-test-configmap-p25q" in namespace "e2e-tests-subpath-5vs62"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:22:08.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5vs62" for this suite.
Feb 19 03:22:14.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:22:14.782: INFO: namespace: e2e-tests-subpath-5vs62, resource: bindings, ignored listing per whitelist
Feb 19 03:22:14.813: INFO: namespace e2e-tests-subpath-5vs62 deletion completed in 6.081171828s

• [SLOW TEST:38.241 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:22:14.814: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:22:14.875: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-bqgb2" to be "success or failure"
Feb 19 03:22:14.881: INFO: Pod "downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.899809ms
Feb 19 03:22:16.884: INFO: Pod "downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008762698s
Feb 19 03:22:18.887: INFO: Pod "downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011680811s
Feb 19 03:22:20.893: INFO: Pod "downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017820337s
Feb 19 03:22:22.896: INFO: Pod "downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021039503s
STEP: Saw pod success
Feb 19 03:22:22.896: INFO: Pod "downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:22:22.898: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 03:22:22.917: INFO: Waiting for pod downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103 to disappear
Feb 19 03:22:22.919: INFO: Pod downwardapi-volume-8db0d800-33f5-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:22:22.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bqgb2" for this suite.
Feb 19 03:22:28.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:22:28.945: INFO: namespace: e2e-tests-downward-api-bqgb2, resource: bindings, ignored listing per whitelist
Feb 19 03:22:28.996: INFO: namespace e2e-tests-downward-api-bqgb2 deletion completed in 6.073415251s

• [SLOW TEST:14.182 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:22:28.996: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 19 03:22:35.582: INFO: Successfully updated pod "annotationupdate9624ea33-33f5-11e9-834e-0a58ac100103"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:22:37.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kfhg7" for this suite.
Feb 19 03:22:59.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:22:59.619: INFO: namespace: e2e-tests-downward-api-kfhg7, resource: bindings, ignored listing per whitelist
Feb 19 03:22:59.675: INFO: namespace e2e-tests-downward-api-kfhg7 deletion completed in 22.078311309s

• [SLOW TEST:30.679 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:22:59.675: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:22:59.731: INFO: Creating deployment "test-recreate-deployment"
Feb 19 03:22:59.736: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 19 03:22:59.741: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 19 03:23:01.746: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 19 03:23:01.748: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:03.756: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:05.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:07.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:09.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:11.752: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:13.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:15.754: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:17.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:19.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:21.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686143379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:23:23.751: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 19 03:23:23.758: INFO: Updating deployment test-recreate-deployment
Feb 19 03:23:23.758: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 03:23:23.828: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-bl29l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bl29l/deployments/test-recreate-deployment,UID:a86e1785-33f5-11e9-9859-5254000410cb,ResourceVersion:9521,Generation:2,CreationTimestamp:2019-02-19 03:22:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-19 03:23:23 +0000 UTC 2019-02-19 03:23:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-19 03:23:23 +0000 UTC 2019-02-19 03:22:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 19 03:23:23.830: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-bl29l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bl29l/replicasets/test-recreate-deployment-7cf749666b,UID:b6c5692a-33f5-11e9-9859-5254000410cb,ResourceVersion:9520,Generation:1,CreationTimestamp:2019-02-19 03:23:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a86e1785-33f5-11e9-9859-5254000410cb 0xc422c04677 0xc422c04678}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 03:23:23.830: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 19 03:23:23.831: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-bl29l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bl29l/replicasets/test-recreate-deployment-79f694ff59,UID:a86f4fbf-33f5-11e9-9859-5254000410cb,ResourceVersion:9510,Generation:2,CreationTimestamp:2019-02-19 03:22:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a86e1785-33f5-11e9-9859-5254000410cb 0xc422c045c7 0xc422c045c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 03:23:23.833: INFO: Pod "test-recreate-deployment-7cf749666b-9tg55" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-9tg55,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-bl29l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl29l/pods/test-recreate-deployment-7cf749666b-9tg55,UID:b6c605a0-33f5-11e9-9859-5254000410cb,ResourceVersion:9516,Generation:0,CreationTimestamp:2019-02-19 03:23:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b b6c5692a-33f5-11e9-9859-5254000410cb 0xc421aa4f47 0xc421aa4f48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgt79 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgt79,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgt79 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421aa4fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421aa4fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:23:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:23:23.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bl29l" for this suite.
Feb 19 03:23:29.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:23:29.903: INFO: namespace: e2e-tests-deployment-bl29l, resource: bindings, ignored listing per whitelist
Feb 19 03:23:29.911: INFO: namespace e2e-tests-deployment-bl29l deletion completed in 6.075253008s

• [SLOW TEST:30.235 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:23:29.911: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 03:23:29.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-k9w8f'
Feb 19 03:23:30.071: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 03:23:30.071: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Feb 19 03:23:30.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-k9w8f'
Feb 19 03:23:30.172: INFO: stderr: ""
Feb 19 03:23:30.172: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:23:30.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k9w8f" for this suite.
Feb 19 03:23:52.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:23:52.241: INFO: namespace: e2e-tests-kubectl-k9w8f, resource: bindings, ignored listing per whitelist
Feb 19 03:23:52.252: INFO: namespace e2e-tests-kubectl-k9w8f deletion completed in 22.076066439s

• [SLOW TEST:22.341 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:23:52.252: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0219 03:23:58.334593      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 03:23:58.334: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:23:58.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7x7cq" for this suite.
Feb 19 03:24:04.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:24:04.407: INFO: namespace: e2e-tests-gc-7x7cq, resource: bindings, ignored listing per whitelist
Feb 19 03:24:04.419: INFO: namespace e2e-tests-gc-7x7cq deletion completed in 6.082396364s

• [SLOW TEST:12.168 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:24:04.419: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 19 03:24:05.006: INFO: created pod pod-service-account-defaultsa
Feb 19 03:24:05.006: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 19 03:24:05.013: INFO: created pod pod-service-account-mountsa
Feb 19 03:24:05.013: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 19 03:24:05.020: INFO: created pod pod-service-account-nomountsa
Feb 19 03:24:05.020: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 19 03:24:05.028: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 19 03:24:05.028: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 19 03:24:05.036: INFO: created pod pod-service-account-mountsa-mountspec
Feb 19 03:24:05.036: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 19 03:24:05.043: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 19 03:24:05.043: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 19 03:24:05.051: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 19 03:24:05.051: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 19 03:24:05.059: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 19 03:24:05.059: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 19 03:24:05.066: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 19 03:24:05.066: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:24:05.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-sm46h" for this suite.
Feb 19 03:24:27.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:24:27.099: INFO: namespace: e2e-tests-svcaccounts-sm46h, resource: bindings, ignored listing per whitelist
Feb 19 03:24:27.160: INFO: namespace e2e-tests-svcaccounts-sm46h deletion completed in 22.091277505s

• [SLOW TEST:22.741 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:24:27.161: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 03:24:27.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-jg2l4'
Feb 19 03:24:27.322: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 03:24:27.322: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Feb 19 03:24:31.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jg2l4'
Feb 19 03:24:31.433: INFO: stderr: ""
Feb 19 03:24:31.433: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:24:31.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jg2l4" for this suite.
Feb 19 03:24:37.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:24:37.484: INFO: namespace: e2e-tests-kubectl-jg2l4, resource: bindings, ignored listing per whitelist
Feb 19 03:24:37.521: INFO: namespace e2e-tests-kubectl-jg2l4 deletion completed in 6.080335261s

• [SLOW TEST:10.360 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:24:37.521: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e2c037dd-33f5-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:24:37.586: INFO: Waiting up to 5m0s for pod "pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-kcjdq" to be "success or failure"
Feb 19 03:24:37.590: INFO: Pod "pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.663911ms
Feb 19 03:24:39.593: INFO: Pod "pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00694285s
Feb 19 03:24:41.599: INFO: Pod "pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013499516s
Feb 19 03:24:43.602: INFO: Pod "pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016638925s
STEP: Saw pod success
Feb 19 03:24:43.603: INFO: Pod "pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:24:43.604: INFO: Trying to get logs from node 172.26.0.15 pod pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:24:43.623: INFO: Waiting for pod pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103 to disappear
Feb 19 03:24:43.625: INFO: Pod pod-configmaps-e2c0be23-33f5-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:24:43.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kcjdq" for this suite.
Feb 19 03:24:49.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:24:49.680: INFO: namespace: e2e-tests-configmap-kcjdq, resource: bindings, ignored listing per whitelist
Feb 19 03:24:49.705: INFO: namespace e2e-tests-configmap-kcjdq deletion completed in 6.076748992s

• [SLOW TEST:12.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:24:49.705: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 19 03:24:49.768: INFO: Waiting up to 5m0s for pod "pod-ea03d79f-33f5-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-dn4fz" to be "success or failure"
Feb 19 03:24:49.771: INFO: Pod "pod-ea03d79f-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.133959ms
Feb 19 03:24:51.777: INFO: Pod "pod-ea03d79f-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008993556s
Feb 19 03:24:53.780: INFO: Pod "pod-ea03d79f-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011827365s
Feb 19 03:24:55.783: INFO: Pod "pod-ea03d79f-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014788936s
Feb 19 03:24:57.785: INFO: Pod "pod-ea03d79f-33f5-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.017361459s
STEP: Saw pod success
Feb 19 03:24:57.785: INFO: Pod "pod-ea03d79f-33f5-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:24:57.787: INFO: Trying to get logs from node 172.26.0.5 pod pod-ea03d79f-33f5-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:24:57.805: INFO: Waiting for pod pod-ea03d79f-33f5-11e9-834e-0a58ac100103 to disappear
Feb 19 03:24:57.807: INFO: Pod pod-ea03d79f-33f5-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:24:57.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dn4fz" for this suite.
Feb 19 03:25:03.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:25:03.847: INFO: namespace: e2e-tests-emptydir-dn4fz, resource: bindings, ignored listing per whitelist
Feb 19 03:25:03.885: INFO: namespace e2e-tests-emptydir-dn4fz deletion completed in 6.07540917s

• [SLOW TEST:14.179 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:25:03.885: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:25:03.950: INFO: (0) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.434481ms)
Feb 19 03:25:03.952: INFO: (1) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.659427ms)
Feb 19 03:25:03.958: INFO: (2) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.594127ms)
Feb 19 03:25:03.960: INFO: (3) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.36027ms)
Feb 19 03:25:03.963: INFO: (4) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.382823ms)
Feb 19 03:25:03.965: INFO: (5) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.318824ms)
Feb 19 03:25:03.967: INFO: (6) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.299128ms)
Feb 19 03:25:03.970: INFO: (7) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.295654ms)
Feb 19 03:25:03.972: INFO: (8) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.339638ms)
Feb 19 03:25:03.974: INFO: (9) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.252501ms)
Feb 19 03:25:03.977: INFO: (10) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.468907ms)
Feb 19 03:25:03.979: INFO: (11) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.326112ms)
Feb 19 03:25:03.981: INFO: (12) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.261007ms)
Feb 19 03:25:03.984: INFO: (13) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.612946ms)
Feb 19 03:25:03.986: INFO: (14) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.265405ms)
Feb 19 03:25:03.989: INFO: (15) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.266612ms)
Feb 19 03:25:03.991: INFO: (16) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.390614ms)
Feb 19 03:25:03.993: INFO: (17) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.329608ms)
Feb 19 03:25:03.996: INFO: (18) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.334454ms)
Feb 19 03:25:03.998: INFO: (19) /api/v1/nodes/172.26.0.15:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.309458ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:25:03.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-b94lj" for this suite.
Feb 19 03:25:10.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:25:10.076: INFO: namespace: e2e-tests-proxy-b94lj, resource: bindings, ignored listing per whitelist
Feb 19 03:25:10.078: INFO: namespace e2e-tests-proxy-b94lj deletion completed in 6.077489587s

• [SLOW TEST:6.193 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:25:10.078: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:25:10.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f627dff3-33f5-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-hj6kd" to be "success or failure"
Feb 19 03:25:10.143: INFO: Pod "downwardapi-volume-f627dff3-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.859584ms
Feb 19 03:25:12.151: INFO: Pod "downwardapi-volume-f627dff3-33f5-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013202424s
Feb 19 03:25:14.155: INFO: Pod "downwardapi-volume-f627dff3-33f5-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017284166s
STEP: Saw pod success
Feb 19 03:25:14.155: INFO: Pod "downwardapi-volume-f627dff3-33f5-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:25:14.156: INFO: Trying to get logs from node 172.26.0.15 pod downwardapi-volume-f627dff3-33f5-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 03:25:14.174: INFO: Waiting for pod downwardapi-volume-f627dff3-33f5-11e9-834e-0a58ac100103 to disappear
Feb 19 03:25:14.176: INFO: Pod downwardapi-volume-f627dff3-33f5-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:25:14.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hj6kd" for this suite.
Feb 19 03:25:20.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:25:20.246: INFO: namespace: e2e-tests-downward-api-hj6kd, resource: bindings, ignored listing per whitelist
Feb 19 03:25:20.256: INFO: namespace e2e-tests-downward-api-hj6kd deletion completed in 6.076874746s

• [SLOW TEST:10.178 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:25:20.256: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 19 03:25:20.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:25:20.506: INFO: stderr: ""
Feb 19 03:25:20.506: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 03:25:20.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:25:20.607: INFO: stderr: ""
Feb 19 03:25:20.608: INFO: stdout: "update-demo-nautilus-fvs24 update-demo-nautilus-vwtlk "
Feb 19 03:25:20.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-fvs24 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:25:20.692: INFO: stderr: ""
Feb 19 03:25:20.692: INFO: stdout: ""
Feb 19 03:25:20.692: INFO: update-demo-nautilus-fvs24 is created but not running
Feb 19 03:25:25.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:25:25.793: INFO: stderr: ""
Feb 19 03:25:25.793: INFO: stdout: "update-demo-nautilus-fvs24 update-demo-nautilus-vwtlk "
Feb 19 03:25:25.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-fvs24 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:25:25.885: INFO: stderr: ""
Feb 19 03:25:25.885: INFO: stdout: "true"
Feb 19 03:25:25.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-fvs24 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:25:25.974: INFO: stderr: ""
Feb 19 03:25:25.974: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:25:25.974: INFO: validating pod update-demo-nautilus-fvs24
Feb 19 03:25:25.978: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:25:25.978: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:25:25.978: INFO: update-demo-nautilus-fvs24 is verified up and running
Feb 19 03:25:25.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-vwtlk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:25:26.062: INFO: stderr: ""
Feb 19 03:25:26.062: INFO: stdout: "true"
Feb 19 03:25:26.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-vwtlk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:25:26.145: INFO: stderr: ""
Feb 19 03:25:26.145: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:25:26.145: INFO: validating pod update-demo-nautilus-vwtlk
Feb 19 03:25:26.149: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:25:26.149: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:25:26.149: INFO: update-demo-nautilus-vwtlk is verified up and running
STEP: rolling-update to new replication controller
Feb 19 03:25:26.150: INFO: scanned /root for discovery docs: <nil>
Feb 19 03:25:26.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:26:04.671: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 19 03:26:04.671: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 03:26:04.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:26:04.763: INFO: stderr: ""
Feb 19 03:26:04.763: INFO: stdout: "update-demo-kitten-44796 update-demo-kitten-b4c7n "
Feb 19 03:26:04.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-kitten-44796 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:26:04.851: INFO: stderr: ""
Feb 19 03:26:04.851: INFO: stdout: "true"
Feb 19 03:26:04.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-kitten-44796 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:26:04.935: INFO: stderr: ""
Feb 19 03:26:04.935: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 19 03:26:04.935: INFO: validating pod update-demo-kitten-44796
Feb 19 03:26:04.939: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 19 03:26:04.939: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 19 03:26:04.939: INFO: update-demo-kitten-44796 is verified up and running
Feb 19 03:26:04.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-kitten-b4c7n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:26:05.022: INFO: stderr: ""
Feb 19 03:26:05.022: INFO: stdout: "true"
Feb 19 03:26:05.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-kitten-b4c7n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qqd5z'
Feb 19 03:26:05.106: INFO: stderr: ""
Feb 19 03:26:05.106: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 19 03:26:05.106: INFO: validating pod update-demo-kitten-b4c7n
Feb 19 03:26:05.111: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 19 03:26:05.111: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 19 03:26:05.111: INFO: update-demo-kitten-b4c7n is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:26:05.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qqd5z" for this suite.
Feb 19 03:26:27.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:26:27.182: INFO: namespace: e2e-tests-kubectl-qqd5z, resource: bindings, ignored listing per whitelist
Feb 19 03:26:27.197: INFO: namespace e2e-tests-kubectl-qqd5z deletion completed in 22.082918322s

• [SLOW TEST:66.941 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:26:27.197: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-241fbfce-33f6-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:26:27.263: INFO: Waiting up to 5m0s for pod "pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-wfbgh" to be "success or failure"
Feb 19 03:26:27.269: INFO: Pod "pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.601347ms
Feb 19 03:26:29.272: INFO: Pod "pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009456646s
Feb 19 03:26:31.275: INFO: Pod "pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012060631s
Feb 19 03:26:33.278: INFO: Pod "pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015025971s
Feb 19 03:26:35.281: INFO: Pod "pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017783747s
Feb 19 03:26:37.286: INFO: Pod "pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.023530899s
STEP: Saw pod success
Feb 19 03:26:37.286: INFO: Pod "pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:26:37.288: INFO: Trying to get logs from node 172.26.0.5 pod pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:26:37.304: INFO: Waiting for pod pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103 to disappear
Feb 19 03:26:37.306: INFO: Pod pod-configmaps-24204a01-33f6-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:26:37.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wfbgh" for this suite.
Feb 19 03:26:43.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:26:43.376: INFO: namespace: e2e-tests-configmap-wfbgh, resource: bindings, ignored listing per whitelist
Feb 19 03:26:43.381: INFO: namespace e2e-tests-configmap-wfbgh deletion completed in 6.072589484s

• [SLOW TEST:16.185 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:26:43.381: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 19 03:26:43.439: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-273970669 proxy --unix-socket=/tmp/kubectl-proxy-unix838667368/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:26:43.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p8m8g" for this suite.
Feb 19 03:26:49.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:26:49.590: INFO: namespace: e2e-tests-kubectl-p8m8g, resource: bindings, ignored listing per whitelist
Feb 19 03:26:49.597: INFO: namespace e2e-tests-kubectl-p8m8g deletion completed in 6.07749206s

• [SLOW TEST:6.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:26:49.597: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 03:26:49.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-jlv7t'
Feb 19 03:26:49.747: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 03:26:49.747: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 19 03:26:49.752: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 19 03:26:49.758: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 19 03:26:49.769: INFO: scanned /root for discovery docs: <nil>
Feb 19 03:26:49.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-jlv7t'
Feb 19 03:27:06.591: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 19 03:27:06.591: INFO: stdout: "Created e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4\nScaling up e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 19 03:27:06.591: INFO: stdout: "Created e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4\nScaling up e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 19 03:27:06.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-jlv7t'
Feb 19 03:27:06.678: INFO: stderr: ""
Feb 19 03:27:06.678: INFO: stdout: "e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4-w652c "
Feb 19 03:27:06.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4-w652c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jlv7t'
Feb 19 03:27:06.760: INFO: stderr: ""
Feb 19 03:27:06.760: INFO: stdout: "true"
Feb 19 03:27:06.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4-w652c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jlv7t'
Feb 19 03:27:06.837: INFO: stderr: ""
Feb 19 03:27:06.838: INFO: stdout: "nginx:1.14-alpine"
Feb 19 03:27:06.838: INFO: e2e-test-nginx-rc-dabde75f8e884125b494faeae8c527d4-w652c is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Feb 19 03:27:06.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-jlv7t'
Feb 19 03:27:06.928: INFO: stderr: ""
Feb 19 03:27:06.928: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:27:06.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jlv7t" for this suite.
Feb 19 03:27:28.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:27:28.958: INFO: namespace: e2e-tests-kubectl-jlv7t, resource: bindings, ignored listing per whitelist
Feb 19 03:27:29.010: INFO: namespace e2e-tests-kubectl-jlv7t deletion completed in 22.078426599s

• [SLOW TEST:39.412 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:27:29.010: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 19 03:27:29.086: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xd92n,SelfLink:/api/v1/namespaces/e2e-tests-watch-xd92n/configmaps/e2e-watch-test-label-changed,UID:48f85e14-33f6-11e9-9859-5254000410cb,ResourceVersion:10740,Generation:0,CreationTimestamp:2019-02-19 03:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 03:27:29.086: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xd92n,SelfLink:/api/v1/namespaces/e2e-tests-watch-xd92n/configmaps/e2e-watch-test-label-changed,UID:48f85e14-33f6-11e9-9859-5254000410cb,ResourceVersion:10741,Generation:0,CreationTimestamp:2019-02-19 03:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 19 03:27:29.086: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xd92n,SelfLink:/api/v1/namespaces/e2e-tests-watch-xd92n/configmaps/e2e-watch-test-label-changed,UID:48f85e14-33f6-11e9-9859-5254000410cb,ResourceVersion:10742,Generation:0,CreationTimestamp:2019-02-19 03:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 19 03:27:39.111: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xd92n,SelfLink:/api/v1/namespaces/e2e-tests-watch-xd92n/configmaps/e2e-watch-test-label-changed,UID:48f85e14-33f6-11e9-9859-5254000410cb,ResourceVersion:10767,Generation:0,CreationTimestamp:2019-02-19 03:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 03:27:39.111: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xd92n,SelfLink:/api/v1/namespaces/e2e-tests-watch-xd92n/configmaps/e2e-watch-test-label-changed,UID:48f85e14-33f6-11e9-9859-5254000410cb,ResourceVersion:10768,Generation:0,CreationTimestamp:2019-02-19 03:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 19 03:27:39.111: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xd92n,SelfLink:/api/v1/namespaces/e2e-tests-watch-xd92n/configmaps/e2e-watch-test-label-changed,UID:48f85e14-33f6-11e9-9859-5254000410cb,ResourceVersion:10769,Generation:0,CreationTimestamp:2019-02-19 03:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:27:39.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xd92n" for this suite.
Feb 19 03:27:45.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:27:45.155: INFO: namespace: e2e-tests-watch-xd92n, resource: bindings, ignored listing per whitelist
Feb 19 03:27:45.207: INFO: namespace e2e-tests-watch-xd92n deletion completed in 6.09312439s

• [SLOW TEST:16.198 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:27:45.208: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0219 03:27:55.326093      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 03:27:55.326: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:27:55.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kqlmx" for this suite.
Feb 19 03:28:01.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:28:01.394: INFO: namespace: e2e-tests-gc-kqlmx, resource: bindings, ignored listing per whitelist
Feb 19 03:28:01.412: INFO: namespace e2e-tests-gc-kqlmx deletion completed in 6.084407585s

• [SLOW TEST:16.205 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:28:01.413: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 19 03:28:01.478: INFO: Waiting up to 5m0s for pod "pod-5c4831a7-33f6-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-dw56s" to be "success or failure"
Feb 19 03:28:01.481: INFO: Pod "pod-5c4831a7-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.162374ms
Feb 19 03:28:03.484: INFO: Pod "pod-5c4831a7-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006128489s
Feb 19 03:28:05.486: INFO: Pod "pod-5c4831a7-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008845739s
Feb 19 03:28:07.489: INFO: Pod "pod-5c4831a7-33f6-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011532339s
STEP: Saw pod success
Feb 19 03:28:07.489: INFO: Pod "pod-5c4831a7-33f6-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:28:07.491: INFO: Trying to get logs from node 172.26.0.15 pod pod-5c4831a7-33f6-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:28:07.511: INFO: Waiting for pod pod-5c4831a7-33f6-11e9-834e-0a58ac100103 to disappear
Feb 19 03:28:07.513: INFO: Pod pod-5c4831a7-33f6-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:28:07.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dw56s" for this suite.
Feb 19 03:28:13.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:28:13.567: INFO: namespace: e2e-tests-emptydir-dw56s, resource: bindings, ignored listing per whitelist
Feb 19 03:28:13.590: INFO: namespace e2e-tests-emptydir-dw56s deletion completed in 6.074116115s

• [SLOW TEST:12.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:28:13.590: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6389ccd8-33f6-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 03:28:13.655: INFO: Waiting up to 5m0s for pod "pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-spjwd" to be "success or failure"
Feb 19 03:28:13.657: INFO: Pod "pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.166349ms
Feb 19 03:28:15.660: INFO: Pod "pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005065056s
Feb 19 03:28:17.662: INFO: Pod "pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007606032s
Feb 19 03:28:19.665: INFO: Pod "pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010412872s
Feb 19 03:28:21.671: INFO: Pod "pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016496811s
Feb 19 03:28:23.674: INFO: Pod "pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.019172114s
STEP: Saw pod success
Feb 19 03:28:23.674: INFO: Pod "pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:28:23.676: INFO: Trying to get logs from node 172.26.0.5 pod pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 03:28:23.693: INFO: Waiting for pod pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103 to disappear
Feb 19 03:28:23.695: INFO: Pod pod-secrets-638a66fc-33f6-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:28:23.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-spjwd" for this suite.
Feb 19 03:28:29.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:28:29.764: INFO: namespace: e2e-tests-secrets-spjwd, resource: bindings, ignored listing per whitelist
Feb 19 03:28:29.779: INFO: namespace e2e-tests-secrets-spjwd deletion completed in 6.081029583s

• [SLOW TEST:16.189 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:28:29.780: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-872z
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 03:28:29.848: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-872z" in namespace "e2e-tests-subpath-4l4nr" to be "success or failure"
Feb 19 03:28:29.855: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.904734ms
Feb 19 03:28:31.863: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014412331s
Feb 19 03:28:33.866: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017755974s
Feb 19 03:28:35.869: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020226675s
Feb 19 03:28:37.872: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023426473s
Feb 19 03:28:39.875: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02641038s
Feb 19 03:28:41.882: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Pending", Reason="", readiness=false. Elapsed: 12.033384098s
Feb 19 03:28:43.885: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 14.036737283s
Feb 19 03:28:45.888: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 16.03956923s
Feb 19 03:28:47.891: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 18.042772677s
Feb 19 03:28:49.894: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 20.045740897s
Feb 19 03:28:51.900: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 22.051832829s
Feb 19 03:28:53.903: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 24.054758536s
Feb 19 03:28:55.906: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 26.057507787s
Feb 19 03:28:57.909: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 28.06063964s
Feb 19 03:28:59.912: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Running", Reason="", readiness=false. Elapsed: 30.063519664s
Feb 19 03:29:01.923: INFO: Pod "pod-subpath-test-downwardapi-872z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.074481035s
STEP: Saw pod success
Feb 19 03:29:01.923: INFO: Pod "pod-subpath-test-downwardapi-872z" satisfied condition "success or failure"
Feb 19 03:29:01.925: INFO: Trying to get logs from node 172.26.0.5 pod pod-subpath-test-downwardapi-872z container test-container-subpath-downwardapi-872z: <nil>
STEP: delete the pod
Feb 19 03:29:01.946: INFO: Waiting for pod pod-subpath-test-downwardapi-872z to disappear
Feb 19 03:29:01.952: INFO: Pod pod-subpath-test-downwardapi-872z no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-872z
Feb 19 03:29:01.952: INFO: Deleting pod "pod-subpath-test-downwardapi-872z" in namespace "e2e-tests-subpath-4l4nr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:29:01.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4l4nr" for this suite.
Feb 19 03:29:07.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:29:08.017: INFO: namespace: e2e-tests-subpath-4l4nr, resource: bindings, ignored listing per whitelist
Feb 19 03:29:08.038: INFO: namespace e2e-tests-subpath-4l4nr deletion completed in 6.080471862s

• [SLOW TEST:38.259 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:29:08.038: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:29:08.106: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Feb 19 03:29:08.112: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wvfnl/daemonsets","resourceVersion":"11248"},"items":null}

Feb 19 03:29:08.114: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wvfnl/pods","resourceVersion":"11248"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:29:08.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wvfnl" for this suite.
Feb 19 03:29:14.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:29:14.171: INFO: namespace: e2e-tests-daemonsets-wvfnl, resource: bindings, ignored listing per whitelist
Feb 19 03:29:14.202: INFO: namespace e2e-tests-daemonsets-wvfnl deletion completed in 6.079234745s

S [SKIPPING] [6.164 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 19 03:29:08.106: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:29:14.202: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:29:14.267: INFO: Waiting up to 5m0s for pod "downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-796w5" to be "success or failure"
Feb 19 03:29:14.275: INFO: Pod "downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 7.914776ms
Feb 19 03:29:16.277: INFO: Pod "downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01069175s
Feb 19 03:29:18.280: INFO: Pod "downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013288736s
Feb 19 03:29:20.282: INFO: Pod "downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015686954s
Feb 19 03:29:22.290: INFO: Pod "downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022898417s
Feb 19 03:29:24.292: INFO: Pod "downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.025314481s
STEP: Saw pod success
Feb 19 03:29:24.292: INFO: Pod "downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:29:24.295: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 03:29:24.311: INFO: Waiting for pod downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103 to disappear
Feb 19 03:29:24.313: INFO: Pod downwardapi-volume-87aafa5f-33f6-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:29:24.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-796w5" for this suite.
Feb 19 03:29:30.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:29:30.351: INFO: namespace: e2e-tests-projected-796w5, resource: bindings, ignored listing per whitelist
Feb 19 03:29:30.395: INFO: namespace e2e-tests-projected-796w5 deletion completed in 6.079576359s

• [SLOW TEST:16.193 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:29:30.395: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-91519ce5-33f6-11e9-834e-0a58ac100103
STEP: Creating configMap with name cm-test-opt-upd-91519d27-33f6-11e9-834e-0a58ac100103
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-91519ce5-33f6-11e9-834e-0a58ac100103
STEP: Updating configmap cm-test-opt-upd-91519d27-33f6-11e9-834e-0a58ac100103
STEP: Creating configMap with name cm-test-opt-create-91519d45-33f6-11e9-834e-0a58ac100103
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:30:56.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cdxs8" for this suite.
Feb 19 03:31:18.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:31:18.887: INFO: namespace: e2e-tests-configmap-cdxs8, resource: bindings, ignored listing per whitelist
Feb 19 03:31:18.931: INFO: namespace e2e-tests-configmap-cdxs8 deletion completed in 22.079376701s

• [SLOW TEST:108.536 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:31:18.931: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d2025d6e-33f6-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:31:18.995: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-8mznh" to be "success or failure"
Feb 19 03:31:18.998: INFO: Pod "pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.895005ms
Feb 19 03:31:21.001: INFO: Pod "pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005891492s
Feb 19 03:31:23.004: INFO: Pod "pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009099786s
Feb 19 03:31:25.010: INFO: Pod "pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015215061s
Feb 19 03:31:27.013: INFO: Pod "pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018363945s
Feb 19 03:31:29.016: INFO: Pod "pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.021155292s
STEP: Saw pod success
Feb 19 03:31:29.016: INFO: Pod "pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:31:29.018: INFO: Trying to get logs from node 172.26.0.5 pod pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:31:29.040: INFO: Waiting for pod pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103 to disappear
Feb 19 03:31:29.042: INFO: Pod pod-projected-configmaps-d202dac4-33f6-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:31:29.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8mznh" for this suite.
Feb 19 03:31:35.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:31:35.100: INFO: namespace: e2e-tests-projected-8mznh, resource: bindings, ignored listing per whitelist
Feb 19 03:31:35.123: INFO: namespace e2e-tests-projected-8mznh deletion completed in 6.078105629s

• [SLOW TEST:16.191 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:31:35.123: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 19 03:31:35.183: INFO: Waiting up to 5m0s for pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103" in namespace "e2e-tests-containers-7gvtd" to be "success or failure"
Feb 19 03:31:35.189: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.826517ms
Feb 19 03:31:37.192: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00849062s
Feb 19 03:31:39.195: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011512591s
Feb 19 03:31:41.198: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014348701s
Feb 19 03:31:43.201: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017441384s
Feb 19 03:31:45.208: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 10.024446078s
Feb 19 03:31:47.210: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 12.027037404s
Feb 19 03:31:49.213: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.029951465s
STEP: Saw pod success
Feb 19 03:31:49.213: INFO: Pod "client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:31:49.215: INFO: Trying to get logs from node 172.26.0.15 pod client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:31:49.232: INFO: Waiting for pod client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103 to disappear
Feb 19 03:31:49.234: INFO: Pod client-containers-dba93cfa-33f6-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:31:49.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7gvtd" for this suite.
Feb 19 03:31:55.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:31:55.288: INFO: namespace: e2e-tests-containers-7gvtd, resource: bindings, ignored listing per whitelist
Feb 19 03:31:55.313: INFO: namespace e2e-tests-containers-7gvtd deletion completed in 6.075957865s

• [SLOW TEST:20.190 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:31:55.313: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 19 03:32:03.410: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:32:27.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-5jd5g" for this suite.
Feb 19 03:32:33.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:32:33.479: INFO: namespace: e2e-tests-namespaces-5jd5g, resource: bindings, ignored listing per whitelist
Feb 19 03:32:33.528: INFO: namespace e2e-tests-namespaces-5jd5g deletion completed in 6.072875088s
STEP: Destroying namespace "e2e-tests-nsdeletetest-8vgw6" for this suite.
Feb 19 03:32:33.530: INFO: Namespace e2e-tests-nsdeletetest-8vgw6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-jbqmr" for this suite.
Feb 19 03:32:39.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:32:39.584: INFO: namespace: e2e-tests-nsdeletetest-jbqmr, resource: bindings, ignored listing per whitelist
Feb 19 03:32:39.603: INFO: namespace e2e-tests-nsdeletetest-jbqmr deletion completed in 6.072711335s

• [SLOW TEST:44.290 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:32:39.603: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0219 03:32:49.685935      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 03:32:49.685: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:32:49.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nvfkr" for this suite.
Feb 19 03:32:55.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:32:55.766: INFO: namespace: e2e-tests-gc-nvfkr, resource: bindings, ignored listing per whitelist
Feb 19 03:32:55.766: INFO: namespace e2e-tests-gc-nvfkr deletion completed in 6.078240549s

• [SLOW TEST:16.164 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:32:55.766: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 19 03:32:55.821: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:33:09.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mlrdk" for this suite.
Feb 19 03:33:31.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:33:31.376: INFO: namespace: e2e-tests-init-container-mlrdk, resource: bindings, ignored listing per whitelist
Feb 19 03:33:31.409: INFO: namespace e2e-tests-init-container-mlrdk deletion completed in 22.08205759s

• [SLOW TEST:35.642 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:33:31.409: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 19 03:33:31.476: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-h7vf6" to be "success or failure"
Feb 19 03:33:31.478: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.883886ms
Feb 19 03:33:33.480: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004550468s
Feb 19 03:33:35.483: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007411621s
Feb 19 03:33:37.486: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010422853s
Feb 19 03:33:39.489: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.013109s
STEP: Saw pod success
Feb 19 03:33:39.489: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 19 03:33:39.491: INFO: Trying to get logs from node 172.26.0.5 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 19 03:33:39.509: INFO: Waiting for pod pod-host-path-test to disappear
Feb 19 03:33:39.511: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:33:39.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-h7vf6" for this suite.
Feb 19 03:33:45.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:33:45.583: INFO: namespace: e2e-tests-hostpath-h7vf6, resource: bindings, ignored listing per whitelist
Feb 19 03:33:45.590: INFO: namespace e2e-tests-hostpath-h7vf6 deletion completed in 6.075909312s

• [SLOW TEST:14.181 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:33:45.590: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0219 03:34:25.678573      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 03:34:25.678: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:34:25.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cgdzt" for this suite.
Feb 19 03:34:31.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:34:31.722: INFO: namespace: e2e-tests-gc-cgdzt, resource: bindings, ignored listing per whitelist
Feb 19 03:34:31.756: INFO: namespace e2e-tests-gc-cgdzt deletion completed in 6.075528111s

• [SLOW TEST:46.166 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:34:31.756: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:34:31.808: INFO: Creating ReplicaSet my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103
Feb 19 03:34:31.816: INFO: Pod name my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103: Found 0 pods out of 1
Feb 19 03:34:36.825: INFO: Pod name my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103: Found 1 pods out of 1
Feb 19 03:34:36.825: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103" is running
Feb 19 03:34:38.831: INFO: Pod "my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103-tjzsg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 03:34:32 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 03:34:32 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 03:34:32 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 03:34:31 +0000 UTC Reason: Message:}])
Feb 19 03:34:38.831: INFO: Trying to dial the pod
Feb 19 03:34:43.839: INFO: Controller my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103: Got expected result from replica 1 [my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103-tjzsg]: "my-hostname-basic-44f0e365-33f7-11e9-834e-0a58ac100103-tjzsg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:34:43.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-x66gv" for this suite.
Feb 19 03:34:49.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:34:49.886: INFO: namespace: e2e-tests-replicaset-x66gv, resource: bindings, ignored listing per whitelist
Feb 19 03:34:49.920: INFO: namespace e2e-tests-replicaset-x66gv deletion completed in 6.077486354s

• [SLOW TEST:18.163 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:34:49.920: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4fc51101-33f7-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 03:34:49.989: INFO: Waiting up to 5m0s for pod "pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-xw79k" to be "success or failure"
Feb 19 03:34:49.991: INFO: Pod "pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.133295ms
Feb 19 03:34:51.994: INFO: Pod "pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005210756s
Feb 19 03:34:53.997: INFO: Pod "pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007721143s
Feb 19 03:34:55.999: INFO: Pod "pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01031733s
STEP: Saw pod success
Feb 19 03:34:55.999: INFO: Pod "pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:34:56.001: INFO: Trying to get logs from node 172.26.0.15 pod pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 03:34:56.019: INFO: Waiting for pod pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103 to disappear
Feb 19 03:34:56.021: INFO: Pod pod-secrets-4fc5f404-33f7-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:34:56.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xw79k" for this suite.
Feb 19 03:35:02.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:35:02.100: INFO: namespace: e2e-tests-secrets-xw79k, resource: bindings, ignored listing per whitelist
Feb 19 03:35:02.105: INFO: namespace e2e-tests-secrets-xw79k deletion completed in 6.080633408s

• [SLOW TEST:12.185 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:35:02.105: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 19 03:35:02.178: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-gzfgp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzfgp/configmaps/e2e-watch-test-watch-closed,UID:570a1487-33f7-11e9-9859-5254000410cb,ResourceVersion:12609,Generation:0,CreationTimestamp:2019-02-19 03:35:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 03:35:02.178: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-gzfgp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzfgp/configmaps/e2e-watch-test-watch-closed,UID:570a1487-33f7-11e9-9859-5254000410cb,ResourceVersion:12610,Generation:0,CreationTimestamp:2019-02-19 03:35:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 19 03:35:02.190: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-gzfgp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzfgp/configmaps/e2e-watch-test-watch-closed,UID:570a1487-33f7-11e9-9859-5254000410cb,ResourceVersion:12611,Generation:0,CreationTimestamp:2019-02-19 03:35:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 03:35:02.190: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-gzfgp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzfgp/configmaps/e2e-watch-test-watch-closed,UID:570a1487-33f7-11e9-9859-5254000410cb,ResourceVersion:12612,Generation:0,CreationTimestamp:2019-02-19 03:35:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:35:02.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gzfgp" for this suite.
Feb 19 03:35:08.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:35:08.266: INFO: namespace: e2e-tests-watch-gzfgp, resource: bindings, ignored listing per whitelist
Feb 19 03:35:08.271: INFO: namespace e2e-tests-watch-gzfgp deletion completed in 6.078737235s

• [SLOW TEST:6.167 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:35:08.271: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 19 03:35:08.326: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 19 03:35:08.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:35:08.818: INFO: stderr: ""
Feb 19 03:35:08.818: INFO: stdout: "service/redis-slave created\n"
Feb 19 03:35:08.827: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 19 03:35:08.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:35:09.029: INFO: stderr: ""
Feb 19 03:35:09.029: INFO: stdout: "service/redis-master created\n"
Feb 19 03:35:09.029: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 19 03:35:09.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:35:09.218: INFO: stderr: ""
Feb 19 03:35:09.218: INFO: stdout: "service/frontend created\n"
Feb 19 03:35:09.218: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 19 03:35:09.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:35:09.405: INFO: stderr: ""
Feb 19 03:35:09.405: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 19 03:35:09.405: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 19 03:35:09.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:35:09.597: INFO: stderr: ""
Feb 19 03:35:09.597: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 19 03:35:09.597: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 19 03:35:09.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:35:09.806: INFO: stderr: ""
Feb 19 03:35:09.806: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 19 03:35:09.806: INFO: Waiting for all frontend pods to be Running.
Feb 19 03:37:04.859: INFO: Waiting for frontend to serve content.
Feb 19 03:37:09.879: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 19 03:37:19.899: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 19 03:37:29.916: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 19 03:37:34.933: INFO: Trying to add a new entry to the guestbook.
Feb 19 03:37:39.949: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-master:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-mas...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Str in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 19 03:37:44.965: INFO: Verifying that added entry can be retrieved.
Feb 19 03:37:44.976: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:37:49.987: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:37:55.002: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:38:00.014: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:38:05.029: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:38:10.040: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:38:15.055: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:38:20.064: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:38:25.082: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 03:38:30.093: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb 19 03:38:35.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:38:35.208: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:38:35.208: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:38:35.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:38:35.320: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:38:35.320: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:38:35.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:38:35.425: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:38:35.425: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:38:35.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:38:35.514: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:38:35.514: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:38:35.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:38:35.599: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:38:35.600: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:38:35.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j5ntq'
Feb 19 03:38:35.684: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:38:35.684: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:38:35.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j5ntq" for this suite.
Feb 19 03:39:13.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:39:13.755: INFO: namespace: e2e-tests-kubectl-j5ntq, resource: bindings, ignored listing per whitelist
Feb 19 03:39:13.768: INFO: namespace e2e-tests-kubectl-j5ntq deletion completed in 38.079776473s

• [SLOW TEST:245.496 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:39:13.768: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ed09e3dc-33f7-11e9-834e-0a58ac100103
STEP: Creating secret with name s-test-opt-upd-ed09e45f-33f7-11e9-834e-0a58ac100103
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ed09e3dc-33f7-11e9-834e-0a58ac100103
STEP: Updating secret s-test-opt-upd-ed09e45f-33f7-11e9-834e-0a58ac100103
STEP: Creating secret with name s-test-opt-create-ed09e481-33f7-11e9-834e-0a58ac100103
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:39:25.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7ls5m" for this suite.
Feb 19 03:39:47.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:39:47.954: INFO: namespace: e2e-tests-secrets-7ls5m, resource: bindings, ignored listing per whitelist
Feb 19 03:39:47.996: INFO: namespace e2e-tests-secrets-7ls5m deletion completed in 22.078214451s

• [SLOW TEST:34.228 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:39:47.996: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-0170c2c7-33f8-11e9-834e-0a58ac100103
STEP: Creating configMap with name cm-test-opt-upd-0170c34a-33f8-11e9-834e-0a58ac100103
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0170c2c7-33f8-11e9-834e-0a58ac100103
STEP: Updating configmap cm-test-opt-upd-0170c34a-33f8-11e9-834e-0a58ac100103
STEP: Creating configMap with name cm-test-opt-create-0170c374-33f8-11e9-834e-0a58ac100103
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:41:18.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g6k6j" for this suite.
Feb 19 03:41:40.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:41:40.507: INFO: namespace: e2e-tests-projected-g6k6j, resource: bindings, ignored listing per whitelist
Feb 19 03:41:40.540: INFO: namespace e2e-tests-projected-g6k6j deletion completed in 22.078724583s

• [SLOW TEST:112.544 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:41:40.540: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4484e5af-33f8-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:41:40.610: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-2chmr" to be "success or failure"
Feb 19 03:41:40.612: INFO: Pod "pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.277519ms
Feb 19 03:41:42.615: INFO: Pod "pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004967785s
Feb 19 03:41:44.621: INFO: Pod "pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011099529s
Feb 19 03:41:46.624: INFO: Pod "pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013782369s
STEP: Saw pod success
Feb 19 03:41:46.624: INFO: Pod "pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:41:46.626: INFO: Trying to get logs from node 172.26.0.5 pod pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:41:46.644: INFO: Waiting for pod pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103 to disappear
Feb 19 03:41:46.646: INFO: Pod pod-projected-configmaps-4485c58c-33f8-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:41:46.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2chmr" for this suite.
Feb 19 03:41:52.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:41:52.698: INFO: namespace: e2e-tests-projected-2chmr, resource: bindings, ignored listing per whitelist
Feb 19 03:41:52.729: INFO: namespace e2e-tests-projected-2chmr deletion completed in 6.079337728s

• [SLOW TEST:12.189 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:41:52.729: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4bc8bc0b-33f8-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:41:52.796: INFO: Waiting up to 5m0s for pod "pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-z8x8t" to be "success or failure"
Feb 19 03:41:52.802: INFO: Pod "pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.493065ms
Feb 19 03:41:54.808: INFO: Pod "pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012660597s
Feb 19 03:41:56.812: INFO: Pod "pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015942325s
Feb 19 03:41:58.815: INFO: Pod "pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018880222s
STEP: Saw pod success
Feb 19 03:41:58.815: INFO: Pod "pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:41:58.817: INFO: Trying to get logs from node 172.26.0.15 pod pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:41:58.839: INFO: Waiting for pod pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103 to disappear
Feb 19 03:41:58.841: INFO: Pod pod-configmaps-4bc95ad7-33f8-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:41:58.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z8x8t" for this suite.
Feb 19 03:42:04.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:42:04.863: INFO: namespace: e2e-tests-configmap-z8x8t, resource: bindings, ignored listing per whitelist
Feb 19 03:42:04.921: INFO: namespace e2e-tests-configmap-z8x8t deletion completed in 6.076304864s

• [SLOW TEST:12.192 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:42:04.921: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 19 03:42:04.980: INFO: Waiting up to 5m0s for pod "var-expansion-530c6938-33f8-11e9-834e-0a58ac100103" in namespace "e2e-tests-var-expansion-btjpv" to be "success or failure"
Feb 19 03:42:04.983: INFO: Pod "var-expansion-530c6938-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.179076ms
Feb 19 03:42:06.986: INFO: Pod "var-expansion-530c6938-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006174583s
Feb 19 03:42:08.989: INFO: Pod "var-expansion-530c6938-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008858529s
Feb 19 03:42:10.992: INFO: Pod "var-expansion-530c6938-33f8-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01183788s
STEP: Saw pod success
Feb 19 03:42:10.992: INFO: Pod "var-expansion-530c6938-33f8-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:42:10.994: INFO: Trying to get logs from node 172.26.0.5 pod var-expansion-530c6938-33f8-11e9-834e-0a58ac100103 container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:42:11.011: INFO: Waiting for pod var-expansion-530c6938-33f8-11e9-834e-0a58ac100103 to disappear
Feb 19 03:42:11.013: INFO: Pod var-expansion-530c6938-33f8-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:42:11.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-btjpv" for this suite.
Feb 19 03:42:17.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:42:17.040: INFO: namespace: e2e-tests-var-expansion-btjpv, resource: bindings, ignored listing per whitelist
Feb 19 03:42:17.100: INFO: namespace e2e-tests-var-expansion-btjpv deletion completed in 6.083699903s

• [SLOW TEST:12.179 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:42:17.100: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5a510187-33f8-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:42:17.179: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5a519e15-33f8-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-wn4p7" to be "success or failure"
Feb 19 03:42:17.183: INFO: Pod "pod-projected-configmaps-5a519e15-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.991622ms
Feb 19 03:42:19.186: INFO: Pod "pod-projected-configmaps-5a519e15-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0069924s
Feb 19 03:42:21.189: INFO: Pod "pod-projected-configmaps-5a519e15-33f8-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010082511s
STEP: Saw pod success
Feb 19 03:42:21.189: INFO: Pod "pod-projected-configmaps-5a519e15-33f8-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:42:21.191: INFO: Trying to get logs from node 172.26.0.15 pod pod-projected-configmaps-5a519e15-33f8-11e9-834e-0a58ac100103 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:42:21.208: INFO: Waiting for pod pod-projected-configmaps-5a519e15-33f8-11e9-834e-0a58ac100103 to disappear
Feb 19 03:42:21.211: INFO: Pod pod-projected-configmaps-5a519e15-33f8-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:42:21.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wn4p7" for this suite.
Feb 19 03:42:27.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:42:27.266: INFO: namespace: e2e-tests-projected-wn4p7, resource: bindings, ignored listing per whitelist
Feb 19 03:42:27.297: INFO: namespace e2e-tests-projected-wn4p7 deletion completed in 6.082847922s

• [SLOW TEST:10.197 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:42:27.297: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:42:27.357: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-bvp2c" to be "success or failure"
Feb 19 03:42:27.360: INFO: Pod "downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.689193ms
Feb 19 03:42:29.364: INFO: Pod "downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006510103s
Feb 19 03:42:31.367: INFO: Pod "downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009469524s
Feb 19 03:42:33.370: INFO: Pod "downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012516659s
STEP: Saw pod success
Feb 19 03:42:33.370: INFO: Pod "downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:42:33.372: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 03:42:33.389: INFO: Waiting for pod downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103 to disappear
Feb 19 03:42:33.391: INFO: Pod downwardapi-volume-60630cc2-33f8-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:42:33.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bvp2c" for this suite.
Feb 19 03:42:39.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:42:39.428: INFO: namespace: e2e-tests-projected-bvp2c, resource: bindings, ignored listing per whitelist
Feb 19 03:42:39.471: INFO: namespace e2e-tests-projected-bvp2c deletion completed in 6.076239136s

• [SLOW TEST:12.174 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:42:39.471: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-h2ws6
Feb 19 03:42:51.545: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-h2ws6
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 03:42:51.547: INFO: Initial restart count of pod liveness-http is 0
Feb 19 03:43:11.584: INFO: Restart count of pod e2e-tests-container-probe-h2ws6/liveness-http is now 1 (20.036952401s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:43:11.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-h2ws6" for this suite.
Feb 19 03:43:17.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:43:17.624: INFO: namespace: e2e-tests-container-probe-h2ws6, resource: bindings, ignored listing per whitelist
Feb 19 03:43:17.678: INFO: namespace e2e-tests-container-probe-h2ws6 deletion completed in 6.078524799s

• [SLOW TEST:38.206 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:43:17.678: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-7e6bc5b4-33f8-11e9-834e-0a58ac100103
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-7e6bc5b4-33f8-11e9-834e-0a58ac100103
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:44:36.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v8g4m" for this suite.
Feb 19 03:44:58.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:44:58.109: INFO: namespace: e2e-tests-configmap-v8g4m, resource: bindings, ignored listing per whitelist
Feb 19 03:44:58.146: INFO: namespace e2e-tests-configmap-v8g4m deletion completed in 22.088048615s

• [SLOW TEST:100.468 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:44:58.146: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 19 03:44:58.201: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:45:02.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4wwt9" for this suite.
Feb 19 03:45:08.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:45:08.598: INFO: namespace: e2e-tests-init-container-4wwt9, resource: bindings, ignored listing per whitelist
Feb 19 03:45:08.611: INFO: namespace e2e-tests-init-container-4wwt9 deletion completed in 6.078332229s

• [SLOW TEST:10.465 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:45:08.611: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 19 03:45:20.715: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 03:45:20.717: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 03:45:22.717: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 03:45:22.720: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 03:45:24.717: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 03:45:24.721: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 03:45:26.717: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 03:45:26.720: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 03:45:28.717: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 03:45:28.724: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 03:45:30.717: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 03:45:30.720: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 03:45:32.717: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 03:45:32.720: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:45:32.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-lqfhk" for this suite.
Feb 19 03:45:54.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:45:54.768: INFO: namespace: e2e-tests-container-lifecycle-hook-lqfhk, resource: bindings, ignored listing per whitelist
Feb 19 03:45:54.803: INFO: namespace e2e-tests-container-lifecycle-hook-lqfhk deletion completed in 22.080073876s

• [SLOW TEST:46.193 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:45:54.803: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:45:54.857: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 19 03:45:54.865: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 19 03:45:59.868: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 03:45:59.868: INFO: Creating deployment "test-rolling-update-deployment"
Feb 19 03:45:59.873: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 19 03:45:59.880: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 19 03:46:01.889: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 19 03:46:01.891: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686144759, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686144759, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686144759, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686144759, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:46:03.893: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686144759, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686144759, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686144759, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686144759, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:46:05.894: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 03:46:05.900: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-6dv8c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6dv8c/deployments/test-rolling-update-deployment,UID:df0dc250-33f8-11e9-9859-5254000410cb,ResourceVersion:14751,Generation:1,CreationTimestamp:2019-02-19 03:45:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-19 03:45:59 +0000 UTC 2019-02-19 03:45:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-19 03:46:04 +0000 UTC 2019-02-19 03:45:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 19 03:46:05.902: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-6dv8c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6dv8c/replicasets/test-rolling-update-deployment-65b7695dcf,UID:df11b4e7-33f8-11e9-9859-5254000410cb,ResourceVersion:14742,Generation:1,CreationTimestamp:2019-02-19 03:45:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment df0dc250-33f8-11e9-9859-5254000410cb 0xc420ed56e7 0xc420ed56e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 19 03:46:05.902: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 19 03:46:05.902: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-6dv8c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6dv8c/replicasets/test-rolling-update-controller,UID:dc11472a-33f8-11e9-9859-5254000410cb,ResourceVersion:14750,Generation:2,CreationTimestamp:2019-02-19 03:45:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment df0dc250-33f8-11e9-9859-5254000410cb 0xc420ed54fe 0xc420ed54ff}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 03:46:05.904: INFO: Pod "test-rolling-update-deployment-65b7695dcf-mm8q5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-mm8q5,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-6dv8c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6dv8c/pods/test-rolling-update-deployment-65b7695dcf-mm8q5,UID:df129340-33f8-11e9-9859-5254000410cb,ResourceVersion:14741,Generation:0,CreationTimestamp:2019-02-19 03:45:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf df11b4e7-33f8-11e9-9859-5254000410cb 0xc421b2e567 0xc421b2e568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2w9p9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2w9p9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2w9p9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b2e640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b2e660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:46:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:46:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:46:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:45:59 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.15,PodIP:172.16.3.98,StartTime:2019-02-19 03:46:00 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-19 03:46:03 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8b3da8e0cfcbd5bc22d4b98fa410447ae61ec074c980be5f2ab987da782e4b31}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:46:05.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6dv8c" for this suite.
Feb 19 03:46:11.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:46:11.966: INFO: namespace: e2e-tests-deployment-6dv8c, resource: bindings, ignored listing per whitelist
Feb 19 03:46:11.994: INFO: namespace e2e-tests-deployment-6dv8c deletion completed in 6.087416329s

• [SLOW TEST:17.191 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:46:11.994: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e6518156-33f8-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 03:46:12.062: INFO: Waiting up to 5m0s for pod "pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-dlqm8" to be "success or failure"
Feb 19 03:46:12.064: INFO: Pod "pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.467343ms
Feb 19 03:46:14.067: INFO: Pod "pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005064284s
Feb 19 03:46:16.070: INFO: Pod "pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007873324s
Feb 19 03:46:18.074: INFO: Pod "pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011983356s
Feb 19 03:46:20.077: INFO: Pod "pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014836728s
Feb 19 03:46:22.083: INFO: Pod "pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.021329314s
STEP: Saw pod success
Feb 19 03:46:22.083: INFO: Pod "pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:46:22.085: INFO: Trying to get logs from node 172.26.0.5 pod pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103 container secret-env-test: <nil>
STEP: delete the pod
Feb 19 03:46:22.103: INFO: Waiting for pod pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103 to disappear
Feb 19 03:46:22.104: INFO: Pod pod-secrets-e6521476-33f8-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:46:22.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dlqm8" for this suite.
Feb 19 03:46:28.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:46:28.158: INFO: namespace: e2e-tests-secrets-dlqm8, resource: bindings, ignored listing per whitelist
Feb 19 03:46:28.185: INFO: namespace e2e-tests-secrets-dlqm8 deletion completed in 6.077399516s

• [SLOW TEST:16.191 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:46:28.185: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 19 03:46:28.242: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 03:46:28.248: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 03:46:28.250: INFO: 
Logging pods the kubelet thinks is on node 172.26.0.15 before test
Feb 19 03:46:28.256: INFO: ip-masq-agent-2zl96 from kube-system started at 2019-02-19 02:50:22 +0000 UTC (1 container statuses recorded)
Feb 19 03:46:28.256: INFO: 	Container ip-masq-agent ready: true, restart count 0
Feb 19 03:46:28.256: INFO: kube-proxy-j44xh from kube-system started at 2019-02-19 02:50:22 +0000 UTC (1 container statuses recorded)
Feb 19 03:46:28.256: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 03:46:28.256: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-19 02:59:41 +0000 UTC (1 container statuses recorded)
Feb 19 03:46:28.256: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 19 03:46:28.256: INFO: sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-wqftk from heptio-sonobuoy started at 2019-02-19 02:59:58 +0000 UTC (2 container statuses recorded)
Feb 19 03:46:28.256: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 19 03:46:28.256: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 19 03:46:28.256: INFO: 
Logging pods the kubelet thinks is on node 172.26.0.5 before test
Feb 19 03:46:28.260: INFO: kube-proxy-ddtdb from kube-system started at 2019-02-19 02:56:46 +0000 UTC (1 container statuses recorded)
Feb 19 03:46:28.260: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 03:46:28.260: INFO: sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-7glg5 from heptio-sonobuoy started at 2019-02-19 02:59:58 +0000 UTC (2 container statuses recorded)
Feb 19 03:46:28.260: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 19 03:46:28.260: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 19 03:46:28.260: INFO: ip-masq-agent-rlxwg from kube-system started at 2019-02-19 02:56:46 +0000 UTC (1 container statuses recorded)
Feb 19 03:46:28.260: INFO: 	Container ip-masq-agent ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 172.26.0.15
STEP: verifying the node has the label node 172.26.0.5
Feb 19 03:46:28.290: INFO: Pod sonobuoy requesting resource cpu=0m on Node 172.26.0.15
Feb 19 03:46:28.290: INFO: Pod sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-7glg5 requesting resource cpu=0m on Node 172.26.0.5
Feb 19 03:46:28.290: INFO: Pod sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-wqftk requesting resource cpu=0m on Node 172.26.0.15
Feb 19 03:46:28.290: INFO: Pod ip-masq-agent-2zl96 requesting resource cpu=0m on Node 172.26.0.15
Feb 19 03:46:28.290: INFO: Pod ip-masq-agent-rlxwg requesting resource cpu=0m on Node 172.26.0.5
Feb 19 03:46:28.290: INFO: Pod kube-proxy-ddtdb requesting resource cpu=0m on Node 172.26.0.5
Feb 19 03:46:28.290: INFO: Pod kube-proxy-j44xh requesting resource cpu=0m on Node 172.26.0.15
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-efff5bd7-33f8-11e9-834e-0a58ac100103.1584a72e22122383], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-jb6fq/filler-pod-efff5bd7-33f8-11e9-834e-0a58ac100103 to 172.26.0.15]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-efff5bd7-33f8-11e9-834e-0a58ac100103.1584a72e8d326088], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-efff5bd7-33f8-11e9-834e-0a58ac100103.1584a72e986d7d7b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-efff5bd7-33f8-11e9-834e-0a58ac100103.1584a72ea2c56d97], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f00025c6-33f8-11e9-834e-0a58ac100103.1584a72e222c7a22], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-jb6fq/filler-pod-f00025c6-33f8-11e9-834e-0a58ac100103 to 172.26.0.5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f00025c6-33f8-11e9-834e-0a58ac100103.1584a72f2cf7e47a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f00025c6-33f8-11e9-834e-0a58ac100103.1584a72f72408a34], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f00025c6-33f8-11e9-834e-0a58ac100103.1584a72f992b3a8a], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1584a7300056ee8f], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node 172.26.0.15
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 172.26.0.5
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:46:37.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jb6fq" for this suite.
Feb 19 03:46:43.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:46:43.421: INFO: namespace: e2e-tests-sched-pred-jb6fq, resource: bindings, ignored listing per whitelist
Feb 19 03:46:43.439: INFO: namespace e2e-tests-sched-pred-jb6fq deletion completed in 6.078244198s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:15.254 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:46:43.439: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-f90ef91a-33f8-11e9-834e-0a58ac100103
Feb 19 03:46:43.500: INFO: Pod name my-hostname-basic-f90ef91a-33f8-11e9-834e-0a58ac100103: Found 0 pods out of 1
Feb 19 03:46:48.503: INFO: Pod name my-hostname-basic-f90ef91a-33f8-11e9-834e-0a58ac100103: Found 1 pods out of 1
Feb 19 03:46:48.503: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-f90ef91a-33f8-11e9-834e-0a58ac100103" are running
Feb 19 03:46:48.505: INFO: Pod "my-hostname-basic-f90ef91a-33f8-11e9-834e-0a58ac100103-ww2kd" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 03:46:43 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 03:46:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 03:46:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 03:46:43 +0000 UTC Reason: Message:}])
Feb 19 03:46:48.505: INFO: Trying to dial the pod
Feb 19 03:46:53.516: INFO: Controller my-hostname-basic-f90ef91a-33f8-11e9-834e-0a58ac100103: Got expected result from replica 1 [my-hostname-basic-f90ef91a-33f8-11e9-834e-0a58ac100103-ww2kd]: "my-hostname-basic-f90ef91a-33f8-11e9-834e-0a58ac100103-ww2kd", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:46:53.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-mcw5l" for this suite.
Feb 19 03:46:59.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:46:59.546: INFO: namespace: e2e-tests-replication-controller-mcw5l, resource: bindings, ignored listing per whitelist
Feb 19 03:46:59.597: INFO: namespace e2e-tests-replication-controller-mcw5l deletion completed in 6.078400295s

• [SLOW TEST:16.158 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:46:59.597: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-02b0b1e0-33f9-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:46:59.660: INFO: Waiting up to 5m0s for pod "pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-52kc2" to be "success or failure"
Feb 19 03:46:59.662: INFO: Pod "pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1.794059ms
Feb 19 03:47:01.665: INFO: Pod "pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004657249s
Feb 19 03:47:03.670: INFO: Pod "pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010048227s
Feb 19 03:47:05.673: INFO: Pod "pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012779312s
Feb 19 03:47:07.676: INFO: Pod "pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.015441835s
STEP: Saw pod success
Feb 19 03:47:07.676: INFO: Pod "pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:47:07.678: INFO: Trying to get logs from node 172.26.0.5 pod pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:47:07.692: INFO: Waiting for pod pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103 to disappear
Feb 19 03:47:07.693: INFO: Pod pod-configmaps-02b13ba5-33f9-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:47:07.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-52kc2" for this suite.
Feb 19 03:47:13.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:47:13.768: INFO: namespace: e2e-tests-configmap-52kc2, resource: bindings, ignored listing per whitelist
Feb 19 03:47:13.781: INFO: namespace e2e-tests-configmap-52kc2 deletion completed in 6.084519096s

• [SLOW TEST:14.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:47:13.781: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 19 03:47:13.841: INFO: Waiting up to 5m0s for pod "pod-0b2521b3-33f9-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-92vvs" to be "success or failure"
Feb 19 03:47:13.848: INFO: Pod "pod-0b2521b3-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.257978ms
Feb 19 03:47:15.851: INFO: Pod "pod-0b2521b3-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009173857s
Feb 19 03:47:17.854: INFO: Pod "pod-0b2521b3-33f9-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012379125s
STEP: Saw pod success
Feb 19 03:47:17.854: INFO: Pod "pod-0b2521b3-33f9-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:47:17.856: INFO: Trying to get logs from node 172.26.0.15 pod pod-0b2521b3-33f9-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:47:17.873: INFO: Waiting for pod pod-0b2521b3-33f9-11e9-834e-0a58ac100103 to disappear
Feb 19 03:47:17.876: INFO: Pod pod-0b2521b3-33f9-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:47:17.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-92vvs" for this suite.
Feb 19 03:47:23.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:47:23.902: INFO: namespace: e2e-tests-emptydir-92vvs, resource: bindings, ignored listing per whitelist
Feb 19 03:47:23.961: INFO: namespace e2e-tests-emptydir-92vvs deletion completed in 6.082330083s

• [SLOW TEST:10.181 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:47:23.962: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bqjj4
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bqjj4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bqjj4
Feb 19 03:47:24.034: INFO: Found 0 stateful pods, waiting for 1
Feb 19 03:47:34.040: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 19 03:47:34.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-bqjj4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 03:47:34.704: INFO: stderr: ""
Feb 19 03:47:34.704: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 03:47:34.704: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 03:47:34.707: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 19 03:47:44.713: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 03:47:44.713: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 03:47:44.725: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Feb 19 03:47:44.725: INFO: ss-0  172.26.0.5  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  }]
Feb 19 03:47:44.725: INFO: 
Feb 19 03:47:44.725: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 19 03:47:45.728: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997782435s
Feb 19 03:47:46.731: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994635331s
Feb 19 03:47:47.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991577918s
Feb 19 03:47:48.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988410516s
Feb 19 03:47:49.741: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985024001s
Feb 19 03:47:50.744: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981798099s
Feb 19 03:47:51.748: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.978790491s
Feb 19 03:47:52.751: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975288411s
Feb 19 03:47:53.754: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.07853ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bqjj4
Feb 19 03:47:54.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-bqjj4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 03:47:54.904: INFO: stderr: ""
Feb 19 03:47:54.904: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 03:47:54.904: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 03:47:54.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-bqjj4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 03:47:55.055: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 19 03:47:55.055: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 03:47:55.055: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 03:47:55.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-bqjj4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 03:47:55.211: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 19 03:47:55.211: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 03:47:55.211: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 03:47:55.214: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Feb 19 03:48:05.220: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 03:48:05.220: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 03:48:05.220: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 19 03:48:05.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-bqjj4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 03:48:05.381: INFO: stderr: ""
Feb 19 03:48:05.381: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 03:48:05.381: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 03:48:05.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-bqjj4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 03:48:05.563: INFO: stderr: ""
Feb 19 03:48:05.563: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 03:48:05.563: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 03:48:05.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-bqjj4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 03:48:06.026: INFO: stderr: ""
Feb 19 03:48:06.026: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 03:48:06.026: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 03:48:06.026: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 03:48:06.029: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 19 03:48:16.037: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 03:48:16.037: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 03:48:16.037: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 03:48:16.047: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 19 03:48:16.047: INFO: ss-0  172.26.0.5   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  }]
Feb 19 03:48:16.047: INFO: ss-1  172.26.0.15  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:16.047: INFO: ss-2  172.26.0.5   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:16.047: INFO: 
Feb 19 03:48:16.047: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 19 03:48:17.050: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 19 03:48:17.050: INFO: ss-0  172.26.0.5   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  }]
Feb 19 03:48:17.050: INFO: ss-1  172.26.0.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:17.050: INFO: ss-2  172.26.0.5   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:17.050: INFO: 
Feb 19 03:48:17.050: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 19 03:48:18.054: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 19 03:48:18.054: INFO: ss-0  172.26.0.5   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  }]
Feb 19 03:48:18.054: INFO: ss-1  172.26.0.15  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:18.054: INFO: ss-2  172.26.0.5   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:18.054: INFO: 
Feb 19 03:48:18.054: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 19 03:48:19.056: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Feb 19 03:48:19.056: INFO: ss-0  172.26.0.5  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  }]
Feb 19 03:48:19.056: INFO: ss-2  172.26.0.5  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:19.057: INFO: 
Feb 19 03:48:19.057: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 19 03:48:20.059: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Feb 19 03:48:20.059: INFO: ss-0  172.26.0.5  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:24 +0000 UTC  }]
Feb 19 03:48:20.059: INFO: ss-2  172.26.0.5  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:20.059: INFO: 
Feb 19 03:48:20.059: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 19 03:48:21.063: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Feb 19 03:48:21.063: INFO: ss-2  172.26.0.5  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:21.063: INFO: 
Feb 19 03:48:21.063: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 03:48:22.066: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Feb 19 03:48:22.066: INFO: ss-2  172.26.0.5  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:22.066: INFO: 
Feb 19 03:48:22.066: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 03:48:23.069: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Feb 19 03:48:23.069: INFO: ss-2  172.26.0.5  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:23.069: INFO: 
Feb 19 03:48:23.069: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 03:48:24.071: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Feb 19 03:48:24.071: INFO: ss-2  172.26.0.5  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:24.072: INFO: 
Feb 19 03:48:24.072: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 03:48:25.075: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Feb 19 03:48:25.075: INFO: ss-2  172.26.0.5  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:48:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 03:47:44 +0000 UTC  }]
Feb 19 03:48:25.075: INFO: 
Feb 19 03:48:25.075: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bqjj4
Feb 19 03:48:26.081: INFO: Scaling statefulset ss to 0
Feb 19 03:48:26.087: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 03:48:26.089: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bqjj4
Feb 19 03:48:26.091: INFO: Scaling statefulset ss to 0
Feb 19 03:48:26.096: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 03:48:26.098: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:48:26.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bqjj4" for this suite.
Feb 19 03:48:32.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:48:32.183: INFO: namespace: e2e-tests-statefulset-bqjj4, resource: bindings, ignored listing per whitelist
Feb 19 03:48:32.190: INFO: namespace e2e-tests-statefulset-bqjj4 deletion completed in 6.077073527s

• [SLOW TEST:68.228 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:48:32.190: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qthd9
Feb 19 03:48:36.257: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qthd9
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 03:48:36.259: INFO: Initial restart count of pod liveness-http is 0
Feb 19 03:48:48.280: INFO: Restart count of pod e2e-tests-container-probe-qthd9/liveness-http is now 1 (12.021232631s elapsed)
Feb 19 03:49:08.317: INFO: Restart count of pod e2e-tests-container-probe-qthd9/liveness-http is now 2 (32.057921044s elapsed)
Feb 19 03:49:28.353: INFO: Restart count of pod e2e-tests-container-probe-qthd9/liveness-http is now 3 (52.094028538s elapsed)
Feb 19 03:49:48.387: INFO: Restart count of pod e2e-tests-container-probe-qthd9/liveness-http is now 4 (1m12.128113879s elapsed)
Feb 19 03:50:48.492: INFO: Restart count of pod e2e-tests-container-probe-qthd9/liveness-http is now 5 (2m12.232817597s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:50:48.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qthd9" for this suite.
Feb 19 03:50:54.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:50:54.542: INFO: namespace: e2e-tests-container-probe-qthd9, resource: bindings, ignored listing per whitelist
Feb 19 03:50:54.580: INFO: namespace e2e-tests-container-probe-qthd9 deletion completed in 6.076222889s

• [SLOW TEST:142.390 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:50:54.580: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:50:54.645: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 03:50:54.652: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:54.652: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:54.652: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:54.654: INFO: Number of nodes with available pods: 0
Feb 19 03:50:54.654: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:50:55.658: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:55.658: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:55.658: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:55.660: INFO: Number of nodes with available pods: 0
Feb 19 03:50:55.660: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:50:56.661: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:56.661: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:56.661: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:56.663: INFO: Number of nodes with available pods: 0
Feb 19 03:50:56.663: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:50:57.659: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:57.659: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:57.659: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:57.661: INFO: Number of nodes with available pods: 1
Feb 19 03:50:57.661: INFO: Node 172.26.0.5 is running more than one daemon pod
Feb 19 03:50:58.658: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:58.658: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:58.658: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:58.660: INFO: Number of nodes with available pods: 1
Feb 19 03:50:58.660: INFO: Node 172.26.0.5 is running more than one daemon pod
Feb 19 03:50:59.658: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:59.658: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:59.658: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:50:59.660: INFO: Number of nodes with available pods: 1
Feb 19 03:50:59.660: INFO: Node 172.26.0.5 is running more than one daemon pod
Feb 19 03:51:00.658: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:00.658: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:00.658: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:00.660: INFO: Number of nodes with available pods: 1
Feb 19 03:51:00.660: INFO: Node 172.26.0.5 is running more than one daemon pod
Feb 19 03:51:01.658: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:01.658: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:01.658: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:01.660: INFO: Number of nodes with available pods: 2
Feb 19 03:51:01.660: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 19 03:51:01.675: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:01.675: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:01.679: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:01.679: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:01.679: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:02.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:02.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:02.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:02.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:02.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:03.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:03.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:03.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:03.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:03.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:04.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:04.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:04.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:04.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:04.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:05.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:05.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:05.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:05.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:05.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:06.685: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:06.685: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:06.688: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:06.688: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:06.688: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:07.687: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:07.687: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:07.706: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:07.706: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:07.706: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:08.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:08.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:08.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:08.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:08.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:09.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:09.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:09.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:09.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:09.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:10.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:10.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:10.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:10.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:10.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:11.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:11.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:11.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:11.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:11.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:12.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:12.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:12.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:12.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:12.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:13.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:13.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:13.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:13.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:13.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:14.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:14.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:14.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:14.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:14.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:15.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:15.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:15.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:15.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:15.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:16.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:16.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:16.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:16.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:16.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:17.685: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:17.685: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:17.687: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:17.687: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:17.688: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:18.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:18.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:18.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:18.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:18.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:19.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:19.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:19.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:19.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:19.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:20.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:20.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:20.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:20.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:20.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:21.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:21.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:21.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:21.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:21.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:22.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:22.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:22.686: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:22.686: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:22.686: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:23.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:23.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:23.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:23.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:23.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:24.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:24.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:24.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:24.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:24.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:25.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:25.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:25.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:25.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:25.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:26.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:26.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:26.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:26.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:26.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:27.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:27.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:27.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:27.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:27.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:28.685: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:28.685: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:28.688: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:28.688: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:28.688: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:29.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:29.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:29.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:29.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:29.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:30.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:30.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:30.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:30.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:30.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:31.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:31.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:31.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:31.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:31.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:32.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:32.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:32.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:32.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:32.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:33.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:33.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:33.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:33.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:33.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:34.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:34.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:34.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:34.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:34.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:35.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:35.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:35.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:35.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:35.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:36.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:36.682: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:36.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:36.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:36.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:36.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:37.685: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:37.685: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:37.685: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:37.688: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:37.688: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:37.688: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:38.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:38.682: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:38.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:38.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:38.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:38.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:39.685: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:39.685: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:39.685: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:39.688: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:39.688: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:39.688: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:40.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:40.682: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:40.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:40.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:40.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:40.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:41.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:41.682: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:41.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:41.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:41.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:41.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:42.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:42.682: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:42.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:42.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:42.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:42.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:43.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:43.682: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:43.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:43.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:43.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:43.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:44.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:44.682: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:44.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:44.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:44.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:44.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:45.682: INFO: Wrong image for pod: daemon-set-k5gd7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:45.682: INFO: Pod daemon-set-k5gd7 is not available
Feb 19 03:51:45.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:45.686: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:45.686: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:45.686: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:46.682: INFO: Pod daemon-set-8nv4c is not available
Feb 19 03:51:46.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:46.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:46.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:46.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:47.682: INFO: Pod daemon-set-8nv4c is not available
Feb 19 03:51:47.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:47.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:47.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:47.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:48.682: INFO: Pod daemon-set-8nv4c is not available
Feb 19 03:51:48.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:48.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:48.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:48.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:49.682: INFO: Pod daemon-set-8nv4c is not available
Feb 19 03:51:49.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:49.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:49.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:49.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:50.685: INFO: Pod daemon-set-8nv4c is not available
Feb 19 03:51:50.685: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:50.689: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:50.689: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:50.689: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:51.682: INFO: Pod daemon-set-8nv4c is not available
Feb 19 03:51:51.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:51.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:51.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:51.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:52.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:52.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:52.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:52.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:53.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:53.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:53.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:53.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:54.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:54.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:54.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:54.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:55.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:55.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:55.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:55.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:56.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:56.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:56.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:56.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:57.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:57.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:57.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:57.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:58.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:58.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:58.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:58.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:59.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:51:59.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:59.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:51:59.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:00.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:00.690: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:00.690: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:00.690: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:01.686: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:01.691: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:01.691: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:01.691: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:02.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:02.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:02.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:02.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:03.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:03.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:03.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:03.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:04.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:04.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:04.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:04.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:05.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:05.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:05.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:05.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:06.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:06.686: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:06.686: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:06.686: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:07.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:07.686: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:07.686: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:07.686: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:08.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:08.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:08.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:08.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:09.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:09.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:09.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:09.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:10.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:10.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:10.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:10.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:11.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:11.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:11.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:11.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:12.685: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:12.688: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:12.688: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:12.688: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:13.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:13.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:13.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:13.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:14.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:14.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:14.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:14.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:15.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:15.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:15.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:15.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:16.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:16.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:16.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:16.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:17.681: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:17.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:17.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:17.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:18.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:18.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:18.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:18.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:19.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:19.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:19.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:19.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:20.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:20.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:20.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:20.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:21.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:21.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:21.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:21.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:22.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:22.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:22.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:22.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:23.685: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:23.688: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:23.688: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:23.688: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:24.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:24.682: INFO: Pod daemon-set-r2xxc is not available
Feb 19 03:52:24.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:24.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:24.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:25.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:25.682: INFO: Pod daemon-set-r2xxc is not available
Feb 19 03:52:25.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:25.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:25.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:26.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:26.682: INFO: Pod daemon-set-r2xxc is not available
Feb 19 03:52:26.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:26.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:26.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:27.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:27.682: INFO: Pod daemon-set-r2xxc is not available
Feb 19 03:52:27.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:27.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:27.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:28.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:28.682: INFO: Pod daemon-set-r2xxc is not available
Feb 19 03:52:28.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:28.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:28.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:29.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:29.682: INFO: Pod daemon-set-r2xxc is not available
Feb 19 03:52:29.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:29.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:29.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:30.681: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:30.681: INFO: Pod daemon-set-r2xxc is not available
Feb 19 03:52:30.684: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:30.684: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:30.684: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:31.682: INFO: Wrong image for pod: daemon-set-r2xxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 03:52:31.682: INFO: Pod daemon-set-r2xxc is not available
Feb 19 03:52:31.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:31.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:31.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:32.682: INFO: Pod daemon-set-td8bm is not available
Feb 19 03:52:32.685: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:32.685: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:32.685: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 19 03:52:32.688: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:32.688: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:32.688: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:32.690: INFO: Number of nodes with available pods: 1
Feb 19 03:52:32.690: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:52:33.697: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:33.697: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:33.697: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:33.699: INFO: Number of nodes with available pods: 1
Feb 19 03:52:33.699: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:52:34.694: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:34.694: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:34.694: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:52:34.696: INFO: Number of nodes with available pods: 2
Feb 19 03:52:34.696: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-kvczn, will wait for the garbage collector to delete the pods
Feb 19 03:52:34.766: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.068077ms
Feb 19 03:52:34.866: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.16069ms
Feb 19 03:52:38.768: INFO: Number of nodes with available pods: 0
Feb 19 03:52:38.768: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 03:52:38.770: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kvczn/daemonsets","resourceVersion":"16146"},"items":null}

Feb 19 03:52:38.772: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kvczn/pods","resourceVersion":"16146"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:52:38.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kvczn" for this suite.
Feb 19 03:52:44.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:52:44.830: INFO: namespace: e2e-tests-daemonsets-kvczn, resource: bindings, ignored listing per whitelist
Feb 19 03:52:44.861: INFO: namespace e2e-tests-daemonsets-kvczn deletion completed in 6.079588818s

• [SLOW TEST:110.281 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:52:44.861: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-pk7qg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pk7qg to expose endpoints map[]
Feb 19 03:52:44.931: INFO: Get endpoints failed (2.616201ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 19 03:52:45.934: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pk7qg exposes endpoints map[] (1.005785839s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-pk7qg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pk7qg to expose endpoints map[pod1:[100]]
Feb 19 03:52:48.964: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pk7qg exposes endpoints map[pod1:[100]] (3.024556776s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-pk7qg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pk7qg to expose endpoints map[pod1:[100] pod2:[101]]
Feb 19 03:52:51.999: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pk7qg exposes endpoints map[pod1:[100] pod2:[101]] (3.030155332s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-pk7qg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pk7qg to expose endpoints map[pod2:[101]]
Feb 19 03:52:53.016: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pk7qg exposes endpoints map[pod2:[101]] (1.011479153s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-pk7qg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pk7qg to expose endpoints map[]
Feb 19 03:52:54.028: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pk7qg exposes endpoints map[] (1.00614047s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:52:54.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-pk7qg" for this suite.
Feb 19 03:53:16.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:53:16.079: INFO: namespace: e2e-tests-services-pk7qg, resource: bindings, ignored listing per whitelist
Feb 19 03:53:16.129: INFO: namespace e2e-tests-services-pk7qg deletion completed in 22.075657384s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:31.268 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:53:16.129: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 19 03:53:16.192: INFO: Waiting up to 5m0s for pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103" in namespace "e2e-tests-containers-l77fc" to be "success or failure"
Feb 19 03:53:16.196: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.973686ms
Feb 19 03:53:18.203: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010816246s
Feb 19 03:53:20.206: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013900973s
Feb 19 03:53:22.210: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017838651s
Feb 19 03:53:24.213: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.020831095s
Feb 19 03:53:26.216: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023796223s
Feb 19 03:53:28.222: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 12.030076657s
Feb 19 03:53:30.225: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 14.033158855s
Feb 19 03:53:32.228: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 16.036085862s
Feb 19 03:53:34.231: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.039050339s
STEP: Saw pod success
Feb 19 03:53:34.231: INFO: Pod "client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:53:34.233: INFO: Trying to get logs from node 172.26.0.5 pod client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:53:34.253: INFO: Waiting for pod client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103 to disappear
Feb 19 03:53:34.255: INFO: Pod client-containers-e31f0a4c-33f9-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:53:34.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-l77fc" for this suite.
Feb 19 03:53:40.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:53:40.308: INFO: namespace: e2e-tests-containers-l77fc, resource: bindings, ignored listing per whitelist
Feb 19 03:53:40.333: INFO: namespace e2e-tests-containers-l77fc deletion completed in 6.075330258s

• [SLOW TEST:24.204 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:53:40.334: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Feb 19 03:53:40.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-pmjll'
Feb 19 03:53:40.865: INFO: stderr: ""
Feb 19 03:53:40.865: INFO: stdout: "pod/pause created\n"
Feb 19 03:53:40.865: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 19 03:53:40.866: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-pmjll" to be "running and ready"
Feb 19 03:53:40.868: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.502636ms
Feb 19 03:53:42.871: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005755214s
Feb 19 03:53:44.874: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.008568088s
Feb 19 03:53:44.874: INFO: Pod "pause" satisfied condition "running and ready"
Feb 19 03:53:44.874: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 19 03:53:44.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-pmjll'
Feb 19 03:53:44.972: INFO: stderr: ""
Feb 19 03:53:44.972: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 19 03:53:44.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pod pause -L testing-label --namespace=e2e-tests-kubectl-pmjll'
Feb 19 03:53:45.057: INFO: stderr: ""
Feb 19 03:53:45.057: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 19 03:53:45.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 label pods pause testing-label- --namespace=e2e-tests-kubectl-pmjll'
Feb 19 03:53:45.141: INFO: stderr: ""
Feb 19 03:53:45.141: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 19 03:53:45.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pod pause -L testing-label --namespace=e2e-tests-kubectl-pmjll'
Feb 19 03:53:45.221: INFO: stderr: ""
Feb 19 03:53:45.221: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Feb 19 03:53:45.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pmjll'
Feb 19 03:53:45.310: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:53:45.310: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 19 03:53:45.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-pmjll'
Feb 19 03:53:45.397: INFO: stderr: "No resources found.\n"
Feb 19 03:53:45.397: INFO: stdout: ""
Feb 19 03:53:45.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -l name=pause --namespace=e2e-tests-kubectl-pmjll -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 03:53:45.478: INFO: stderr: ""
Feb 19 03:53:45.478: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:53:45.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pmjll" for this suite.
Feb 19 03:53:51.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:53:51.534: INFO: namespace: e2e-tests-kubectl-pmjll, resource: bindings, ignored listing per whitelist
Feb 19 03:53:51.559: INFO: namespace e2e-tests-kubectl-pmjll deletion completed in 6.07792924s

• [SLOW TEST:11.225 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:53:51.559: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 19 03:53:51.619: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-a,UID:f83d078e-33f9-11e9-9859-5254000410cb,ResourceVersion:16453,Generation:0,CreationTimestamp:2019-02-19 03:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 03:53:51.619: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-a,UID:f83d078e-33f9-11e9-9859-5254000410cb,ResourceVersion:16453,Generation:0,CreationTimestamp:2019-02-19 03:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 19 03:54:01.632: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-a,UID:f83d078e-33f9-11e9-9859-5254000410cb,ResourceVersion:16477,Generation:0,CreationTimestamp:2019-02-19 03:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 19 03:54:01.632: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-a,UID:f83d078e-33f9-11e9-9859-5254000410cb,ResourceVersion:16477,Generation:0,CreationTimestamp:2019-02-19 03:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 19 03:54:11.645: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-a,UID:f83d078e-33f9-11e9-9859-5254000410cb,ResourceVersion:16501,Generation:0,CreationTimestamp:2019-02-19 03:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 03:54:11.645: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-a,UID:f83d078e-33f9-11e9-9859-5254000410cb,ResourceVersion:16501,Generation:0,CreationTimestamp:2019-02-19 03:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 19 03:54:21.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-a,UID:f83d078e-33f9-11e9-9859-5254000410cb,ResourceVersion:16525,Generation:0,CreationTimestamp:2019-02-19 03:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 03:54:21.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-a,UID:f83d078e-33f9-11e9-9859-5254000410cb,ResourceVersion:16525,Generation:0,CreationTimestamp:2019-02-19 03:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 19 03:54:31.664: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-b,UID:101b996e-33fa-11e9-9859-5254000410cb,ResourceVersion:16549,Generation:0,CreationTimestamp:2019-02-19 03:54:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 03:54:31.664: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-b,UID:101b996e-33fa-11e9-9859-5254000410cb,ResourceVersion:16549,Generation:0,CreationTimestamp:2019-02-19 03:54:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 19 03:54:41.674: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-b,UID:101b996e-33fa-11e9-9859-5254000410cb,ResourceVersion:16573,Generation:0,CreationTimestamp:2019-02-19 03:54:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 03:54:41.674: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qcqfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qcqfp/configmaps/e2e-watch-test-configmap-b,UID:101b996e-33fa-11e9-9859-5254000410cb,ResourceVersion:16573,Generation:0,CreationTimestamp:2019-02-19 03:54:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:54:51.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qcqfp" for this suite.
Feb 19 03:54:57.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:54:57.737: INFO: namespace: e2e-tests-watch-qcqfp, resource: bindings, ignored listing per whitelist
Feb 19 03:54:57.758: INFO: namespace e2e-tests-watch-qcqfp deletion completed in 6.076679896s

• [SLOW TEST:66.199 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:54:57.758: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:54:57.820: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 19 03:55:02.826: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 03:55:06.831: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 03:55:06.844: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-22zpn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-22zpn/deployments/test-cleanup-deployment,UID:2512eaf1-33fa-11e9-9859-5254000410cb,ResourceVersion:16653,Generation:1,CreationTimestamp:2019-02-19 03:55:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 19 03:55:06.848: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:55:06.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-22zpn" for this suite.
Feb 19 03:55:12.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:55:12.917: INFO: namespace: e2e-tests-deployment-22zpn, resource: bindings, ignored listing per whitelist
Feb 19 03:55:12.955: INFO: namespace e2e-tests-deployment-22zpn deletion completed in 6.091446342s

• [SLOW TEST:15.197 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:55:12.955: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:55:13.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 version'
Feb 19 03:55:13.098: INFO: stderr: ""
Feb 19 03:55:13.098: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.4-tke.1.1\", GitCommit:\"900490ac7b7ae6a13aa6599d43258f1164e9c458\", GitTreeState:\"clean\", BuildDate:\"2019-01-30T10:22:33Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:55:13.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ndxbm" for this suite.
Feb 19 03:55:19.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:55:19.164: INFO: namespace: e2e-tests-kubectl-ndxbm, resource: bindings, ignored listing per whitelist
Feb 19 03:55:19.184: INFO: namespace e2e-tests-kubectl-ndxbm deletion completed in 6.082689274s

• [SLOW TEST:6.229 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:55:19.184: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2c7868e9-33fa-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 03:55:19.255: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-9wfdx" to be "success or failure"
Feb 19 03:55:19.257: INFO: Pod "pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1.797366ms
Feb 19 03:55:21.260: INFO: Pod "pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0047168s
Feb 19 03:55:23.266: INFO: Pod "pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010909449s
Feb 19 03:55:25.268: INFO: Pod "pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013545032s
Feb 19 03:55:27.271: INFO: Pod "pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016183098s
Feb 19 03:55:29.274: INFO: Pod "pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.019075427s
STEP: Saw pod success
Feb 19 03:55:29.274: INFO: Pod "pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:55:29.276: INFO: Trying to get logs from node 172.26.0.5 pod pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:55:29.296: INFO: Waiting for pod pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103 to disappear
Feb 19 03:55:29.298: INFO: Pod pod-projected-configmaps-2c7928c7-33fa-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:55:29.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9wfdx" for this suite.
Feb 19 03:55:35.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:55:35.327: INFO: namespace: e2e-tests-projected-9wfdx, resource: bindings, ignored listing per whitelist
Feb 19 03:55:35.378: INFO: namespace e2e-tests-projected-9wfdx deletion completed in 6.076677671s

• [SLOW TEST:16.194 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:55:35.378: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:56:35.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kndbj" for this suite.
Feb 19 03:56:57.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:56:57.468: INFO: namespace: e2e-tests-container-probe-kndbj, resource: bindings, ignored listing per whitelist
Feb 19 03:56:57.533: INFO: namespace e2e-tests-container-probe-kndbj deletion completed in 22.083388949s

• [SLOW TEST:82.155 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:56:57.533: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-5s7mh
Feb 19 03:57:03.602: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-5s7mh
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 03:57:03.604: INFO: Initial restart count of pod liveness-exec is 0
Feb 19 03:57:53.694: INFO: Restart count of pod e2e-tests-container-probe-5s7mh/liveness-exec is now 1 (50.089866624s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:57:53.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5s7mh" for this suite.
Feb 19 03:57:59.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:57:59.771: INFO: namespace: e2e-tests-container-probe-5s7mh, resource: bindings, ignored listing per whitelist
Feb 19 03:57:59.781: INFO: namespace e2e-tests-container-probe-5s7mh deletion completed in 6.075652641s

• [SLOW TEST:62.248 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:57:59.781: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-8c31b6f6-33fa-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 03:57:59.853: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8c3252fd-33fa-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-hq6wk" to be "success or failure"
Feb 19 03:57:59.855: INFO: Pod "pod-projected-secrets-8c3252fd-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.175134ms
Feb 19 03:58:01.858: INFO: Pod "pod-projected-secrets-8c3252fd-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005184979s
Feb 19 03:58:03.860: INFO: Pod "pod-projected-secrets-8c3252fd-33fa-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007730125s
STEP: Saw pod success
Feb 19 03:58:03.861: INFO: Pod "pod-projected-secrets-8c3252fd-33fa-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:58:03.862: INFO: Trying to get logs from node 172.26.0.15 pod pod-projected-secrets-8c3252fd-33fa-11e9-834e-0a58ac100103 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 03:58:03.881: INFO: Waiting for pod pod-projected-secrets-8c3252fd-33fa-11e9-834e-0a58ac100103 to disappear
Feb 19 03:58:03.883: INFO: Pod pod-projected-secrets-8c3252fd-33fa-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:58:03.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hq6wk" for this suite.
Feb 19 03:58:09.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:58:09.947: INFO: namespace: e2e-tests-projected-hq6wk, resource: bindings, ignored listing per whitelist
Feb 19 03:58:09.962: INFO: namespace e2e-tests-projected-hq6wk deletion completed in 6.076151723s

• [SLOW TEST:10.181 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:58:09.963: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 19 03:58:10.022: INFO: Waiting up to 5m0s for pod "pod-9242611e-33fa-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-xxztb" to be "success or failure"
Feb 19 03:58:10.027: INFO: Pod "pod-9242611e-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.06867ms
Feb 19 03:58:12.030: INFO: Pod "pod-9242611e-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008215528s
Feb 19 03:58:14.033: INFO: Pod "pod-9242611e-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011014575s
Feb 19 03:58:16.036: INFO: Pod "pod-9242611e-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013957862s
Feb 19 03:58:18.042: INFO: Pod "pod-9242611e-33fa-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020171291s
STEP: Saw pod success
Feb 19 03:58:18.042: INFO: Pod "pod-9242611e-33fa-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:58:18.044: INFO: Trying to get logs from node 172.26.0.5 pod pod-9242611e-33fa-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 03:58:18.061: INFO: Waiting for pod pod-9242611e-33fa-11e9-834e-0a58ac100103 to disappear
Feb 19 03:58:18.063: INFO: Pod pod-9242611e-33fa-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:58:18.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xxztb" for this suite.
Feb 19 03:58:24.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:58:24.122: INFO: namespace: e2e-tests-emptydir-xxztb, resource: bindings, ignored listing per whitelist
Feb 19 03:58:24.141: INFO: namespace e2e-tests-emptydir-xxztb deletion completed in 6.07477053s

• [SLOW TEST:14.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:58:24.141: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 03:58:28.229: INFO: Waiting up to 5m0s for pod "client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103" in namespace "e2e-tests-pods-8fm89" to be "success or failure"
Feb 19 03:58:28.232: INFO: Pod "client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.491402ms
Feb 19 03:58:30.235: INFO: Pod "client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005341343s
Feb 19 03:58:32.238: INFO: Pod "client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008395229s
Feb 19 03:58:34.241: INFO: Pod "client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011380181s
STEP: Saw pod success
Feb 19 03:58:34.241: INFO: Pod "client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:58:34.243: INFO: Trying to get logs from node 172.26.0.5 pod client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103 container env3cont: <nil>
STEP: delete the pod
Feb 19 03:58:34.260: INFO: Waiting for pod client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103 to disappear
Feb 19 03:58:34.262: INFO: Pod client-envvars-9d1cae6e-33fa-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:58:34.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8fm89" for this suite.
Feb 19 03:59:14.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:59:14.318: INFO: namespace: e2e-tests-pods-8fm89, resource: bindings, ignored listing per whitelist
Feb 19 03:59:14.342: INFO: namespace e2e-tests-pods-8fm89 deletion completed in 40.077526736s

• [SLOW TEST:50.201 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:59:14.342: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:59:14.408: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8a29903-33fa-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-c4tt4" to be "success or failure"
Feb 19 03:59:14.415: INFO: Pod "downwardapi-volume-b8a29903-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.341848ms
Feb 19 03:59:16.418: INFO: Pod "downwardapi-volume-b8a29903-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009354965s
Feb 19 03:59:18.420: INFO: Pod "downwardapi-volume-b8a29903-33fa-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011727028s
STEP: Saw pod success
Feb 19 03:59:18.420: INFO: Pod "downwardapi-volume-b8a29903-33fa-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 03:59:18.422: INFO: Trying to get logs from node 172.26.0.15 pod downwardapi-volume-b8a29903-33fa-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 03:59:18.440: INFO: Waiting for pod downwardapi-volume-b8a29903-33fa-11e9-834e-0a58ac100103 to disappear
Feb 19 03:59:18.442: INFO: Pod downwardapi-volume-b8a29903-33fa-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 03:59:18.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c4tt4" for this suite.
Feb 19 03:59:24.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:59:24.505: INFO: namespace: e2e-tests-projected-c4tt4, resource: bindings, ignored listing per whitelist
Feb 19 03:59:24.524: INFO: namespace e2e-tests-projected-c4tt4 deletion completed in 6.079713779s

• [SLOW TEST:10.182 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 03:59:24.525: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 03:59:24.598: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:24.598: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:24.598: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:24.600: INFO: Number of nodes with available pods: 0
Feb 19 03:59:24.600: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:59:25.604: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:25.604: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:25.604: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:25.607: INFO: Number of nodes with available pods: 0
Feb 19 03:59:25.607: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:59:26.604: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:26.604: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:26.604: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:26.607: INFO: Number of nodes with available pods: 0
Feb 19 03:59:26.607: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 03:59:27.604: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:27.604: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:27.604: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:27.607: INFO: Number of nodes with available pods: 1
Feb 19 03:59:27.607: INFO: Node 172.26.0.5 is running more than one daemon pod
Feb 19 03:59:28.604: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:28.604: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:28.604: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:28.606: INFO: Number of nodes with available pods: 1
Feb 19 03:59:28.606: INFO: Node 172.26.0.5 is running more than one daemon pod
Feb 19 03:59:29.604: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:29.604: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:29.605: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:29.607: INFO: Number of nodes with available pods: 1
Feb 19 03:59:29.607: INFO: Node 172.26.0.5 is running more than one daemon pod
Feb 19 03:59:30.605: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:30.605: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:30.605: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:30.607: INFO: Number of nodes with available pods: 2
Feb 19 03:59:30.607: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 19 03:59:30.621: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:30.621: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:30.621: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 03:59:30.625: INFO: Number of nodes with available pods: 2
Feb 19 03:59:30.625: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-tq5rv, will wait for the garbage collector to delete the pods
Feb 19 03:59:31.692: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.020669ms
Feb 19 03:59:31.792: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.169242ms
Feb 19 04:00:11.898: INFO: Number of nodes with available pods: 0
Feb 19 04:00:11.898: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 04:00:11.900: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-tq5rv/daemonsets","resourceVersion":"17674"},"items":null}

Feb 19 04:00:11.902: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-tq5rv/pods","resourceVersion":"17674"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:00:11.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-tq5rv" for this suite.
Feb 19 04:00:17.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:00:17.953: INFO: namespace: e2e-tests-daemonsets-tq5rv, resource: bindings, ignored listing per whitelist
Feb 19 04:00:17.987: INFO: namespace e2e-tests-daemonsets-tq5rv deletion completed in 6.075198103s

• [SLOW TEST:53.463 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:00:17.987: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-de913b5c-33fa-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:00:18.052: INFO: Waiting up to 5m0s for pod "pod-secrets-de91c62c-33fa-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-8ct98" to be "success or failure"
Feb 19 04:00:18.056: INFO: Pod "pod-secrets-de91c62c-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.940321ms
Feb 19 04:00:20.059: INFO: Pod "pod-secrets-de91c62c-33fa-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007376442s
Feb 19 04:00:22.065: INFO: Pod "pod-secrets-de91c62c-33fa-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013008434s
STEP: Saw pod success
Feb 19 04:00:22.065: INFO: Pod "pod-secrets-de91c62c-33fa-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:00:22.067: INFO: Trying to get logs from node 172.26.0.5 pod pod-secrets-de91c62c-33fa-11e9-834e-0a58ac100103 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:00:22.085: INFO: Waiting for pod pod-secrets-de91c62c-33fa-11e9-834e-0a58ac100103 to disappear
Feb 19 04:00:22.086: INFO: Pod pod-secrets-de91c62c-33fa-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:00:22.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8ct98" for this suite.
Feb 19 04:00:28.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:00:28.169: INFO: namespace: e2e-tests-secrets-8ct98, resource: bindings, ignored listing per whitelist
Feb 19 04:00:28.169: INFO: namespace e2e-tests-secrets-8ct98 deletion completed in 6.079853344s

• [SLOW TEST:10.182 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:00:28.169: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gqqmj A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gqqmj A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gqqmj.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gqqmj.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gqqmj.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 2.255.16.172.in-addr.arpa. PTR)" && echo OK > /results/172.16.255.2_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 2.255.16.172.in-addr.arpa. PTR)" && echo OK > /results/172.16.255.2_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gqqmj A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gqqmj;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gqqmj A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gqqmj.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gqqmj.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gqqmj.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 2.255.16.172.in-addr.arpa. PTR)" && echo OK > /results/172.16.255.2_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 2.255.16.172.in-addr.arpa. PTR)" && echo OK > /results/172.16.255.2_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 04:01:58.278: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.284: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.286: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.288: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.290: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.292: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.295: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.310: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.312: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.315: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.317: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.320: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.322: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.324: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.327: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.329: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.331: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.333: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.336: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:01:58.340: INFO: Lookups using e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103 failed for: [wheezy_udp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gqqmj jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-gqqmj.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Feb 19 04:02:08.272: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.281: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.283: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.286: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.288: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.290: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.292: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.307: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.310: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.312: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.314: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.316: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.318: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:08.336: INFO: Lookups using e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103 failed for: [wheezy_udp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gqqmj jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc]

Feb 19 04:02:18.273: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.277: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.280: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.285: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.288: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.291: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.293: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.311: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.313: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.315: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.318: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.321: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.323: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:18.342: INFO: Lookups using e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103 failed for: [wheezy_udp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj wheezy_udp@dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqqmj.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gqqmj jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc]

Feb 19 04:02:28.309: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:28.312: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:28.314: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:28.316: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:28.318: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:28.321: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc from pod e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103: the server could not find the requested resource (get pods dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103)
Feb 19 04:02:28.343: INFO: Lookups using e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gqqmj jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj jessie_udp@dns-test-service.e2e-tests-dns-gqqmj.svc jessie_tcp@dns-test-service.e2e-tests-dns-gqqmj.svc]

Feb 19 04:02:38.346: INFO: DNS probes using e2e-tests-dns-gqqmj/dns-test-e4a66e1e-33fa-11e9-834e-0a58ac100103 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:02:38.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-gqqmj" for this suite.
Feb 19 04:02:44.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:02:44.441: INFO: namespace: e2e-tests-dns-gqqmj, resource: bindings, ignored listing per whitelist
Feb 19 04:02:44.490: INFO: namespace e2e-tests-dns-gqqmj deletion completed in 6.079904635s

• [SLOW TEST:136.321 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:02:44.490: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 19 04:02:44.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 api-versions'
Feb 19 04:02:44.688: INFO: stderr: ""
Feb 19 04:02:44.688: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncustom.metrics.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:02:44.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fqnzb" for this suite.
Feb 19 04:02:50.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:02:50.714: INFO: namespace: e2e-tests-kubectl-fqnzb, resource: bindings, ignored listing per whitelist
Feb 19 04:02:50.768: INFO: namespace e2e-tests-kubectl-fqnzb deletion completed in 6.077560022s

• [SLOW TEST:6.278 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:02:50.769: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 19 04:02:50.822: INFO: PodSpec: initContainers in spec.initContainers
Feb 19 04:03:46.325: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-39a1d3ed-33fb-11e9-834e-0a58ac100103", GenerateName:"", Namespace:"e2e-tests-init-container-zvcrf", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-zvcrf/pods/pod-init-39a1d3ed-33fb-11e9-834e-0a58ac100103", UID:"39a126db-33fb-11e9-9859-5254000410cb", ResourceVersion:"18371", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686145770, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"822564260"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vh8vb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421ad26c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vh8vb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vh8vb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vh8vb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc422abded8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"172.26.0.5", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4220073e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422abdf60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422abdf80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc422abdf88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686145771, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686145771, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686145771, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686145770, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.26.0.5", PodIP:"172.16.4.102", StartTime:(*v1.Time)(0xc421742e80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4229edc70)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4229edce0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://4419d875348d9050053b7a9685c502feee94f0f3f20624449dbaeca2e16de12b"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421742fa0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421742f20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:03:46.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zvcrf" for this suite.
Feb 19 04:04:08.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:04:08.402: INFO: namespace: e2e-tests-init-container-zvcrf, resource: bindings, ignored listing per whitelist
Feb 19 04:04:08.417: INFO: namespace e2e-tests-init-container-zvcrf deletion completed in 22.08469906s

• [SLOW TEST:77.648 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:04:08.417: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 19 04:04:08.477: INFO: Waiting up to 5m0s for pod "pod-67ea1201-33fb-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-js799" to be "success or failure"
Feb 19 04:04:08.485: INFO: Pod "pod-67ea1201-33fb-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 7.679309ms
Feb 19 04:04:10.488: INFO: Pod "pod-67ea1201-33fb-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010715651s
Feb 19 04:04:12.491: INFO: Pod "pod-67ea1201-33fb-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013575049s
STEP: Saw pod success
Feb 19 04:04:12.491: INFO: Pod "pod-67ea1201-33fb-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:04:12.493: INFO: Trying to get logs from node 172.26.0.15 pod pod-67ea1201-33fb-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 04:04:12.508: INFO: Waiting for pod pod-67ea1201-33fb-11e9-834e-0a58ac100103 to disappear
Feb 19 04:04:12.511: INFO: Pod pod-67ea1201-33fb-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:04:12.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-js799" for this suite.
Feb 19 04:04:18.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:04:18.567: INFO: namespace: e2e-tests-emptydir-js799, resource: bindings, ignored listing per whitelist
Feb 19 04:04:18.603: INFO: namespace e2e-tests-emptydir-js799 deletion completed in 6.089819827s

• [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:04:18.604: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 19 04:04:28.697: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:28.699: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:30.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:30.701: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:32.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:32.702: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:34.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:34.702: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:36.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:36.701: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:38.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:38.705: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:40.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:40.701: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:42.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:42.701: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:44.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:44.701: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:46.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:46.701: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:48.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:48.702: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:50.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:50.705: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 04:04:52.699: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 04:04:52.702: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:04:52.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-v5lnc" for this suite.
Feb 19 04:05:14.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:05:14.768: INFO: namespace: e2e-tests-container-lifecycle-hook-v5lnc, resource: bindings, ignored listing per whitelist
Feb 19 04:05:14.794: INFO: namespace e2e-tests-container-lifecycle-hook-v5lnc deletion completed in 22.081055926s

• [SLOW TEST:56.191 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:05:14.794: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 04:05:14.877: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"8f7c154f-33fb-11e9-9859-5254000410cb", Controller:(*bool)(0xc422032c5e), BlockOwnerDeletion:(*bool)(0xc422032c5f)}}
Feb 19 04:05:14.883: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"8f7aae7e-33fb-11e9-9859-5254000410cb", Controller:(*bool)(0xc422032e1e), BlockOwnerDeletion:(*bool)(0xc422032e1f)}}
Feb 19 04:05:14.887: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"8f7b56f3-33fb-11e9-9859-5254000410cb", Controller:(*bool)(0xc4229f5fbe), BlockOwnerDeletion:(*bool)(0xc4229f5fbf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:05:19.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cl57t" for this suite.
Feb 19 04:05:25.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:05:25.946: INFO: namespace: e2e-tests-gc-cl57t, resource: bindings, ignored listing per whitelist
Feb 19 04:05:25.973: INFO: namespace e2e-tests-gc-cl57t deletion completed in 6.074367528s

• [SLOW TEST:11.178 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:05:25.973: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-962458ea-33fb-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 04:05:26.038: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-q9b45" to be "success or failure"
Feb 19 04:05:26.042: INFO: Pod "pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.435073ms
Feb 19 04:05:28.045: INFO: Pod "pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006360516s
Feb 19 04:05:30.048: INFO: Pod "pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009417007s
Feb 19 04:05:32.051: INFO: Pod "pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012561456s
STEP: Saw pod success
Feb 19 04:05:32.051: INFO: Pod "pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:05:32.053: INFO: Trying to get logs from node 172.26.0.15 pod pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:05:32.071: INFO: Waiting for pod pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103 to disappear
Feb 19 04:05:32.073: INFO: Pod pod-projected-configmaps-9624ec1e-33fb-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:05:32.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q9b45" for this suite.
Feb 19 04:05:38.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:05:38.133: INFO: namespace: e2e-tests-projected-q9b45, resource: bindings, ignored listing per whitelist
Feb 19 04:05:38.153: INFO: namespace e2e-tests-projected-q9b45 deletion completed in 6.077884044s

• [SLOW TEST:12.181 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:05:38.154: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-8vtw
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 04:05:38.231: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-8vtw" in namespace "e2e-tests-subpath-8mp79" to be "success or failure"
Feb 19 04:05:38.233: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.184803ms
Feb 19 04:05:40.236: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005107582s
Feb 19 04:05:42.239: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007935803s
Feb 19 04:05:44.245: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013950922s
Feb 19 04:05:46.248: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 8.017441281s
Feb 19 04:05:48.251: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 10.020418266s
Feb 19 04:05:50.254: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 12.023518548s
Feb 19 04:05:52.257: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 14.026603506s
Feb 19 04:05:54.264: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 16.032891055s
Feb 19 04:05:56.267: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 18.035940248s
Feb 19 04:05:58.270: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 20.038779055s
Feb 19 04:06:00.274: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 22.042943787s
Feb 19 04:06:02.277: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Running", Reason="", readiness=false. Elapsed: 24.045965041s
Feb 19 04:06:04.283: INFO: Pod "pod-subpath-test-secret-8vtw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.052106675s
STEP: Saw pod success
Feb 19 04:06:04.283: INFO: Pod "pod-subpath-test-secret-8vtw" satisfied condition "success or failure"
Feb 19 04:06:04.285: INFO: Trying to get logs from node 172.26.0.5 pod pod-subpath-test-secret-8vtw container test-container-subpath-secret-8vtw: <nil>
STEP: delete the pod
Feb 19 04:06:04.303: INFO: Waiting for pod pod-subpath-test-secret-8vtw to disappear
Feb 19 04:06:04.305: INFO: Pod pod-subpath-test-secret-8vtw no longer exists
STEP: Deleting pod pod-subpath-test-secret-8vtw
Feb 19 04:06:04.305: INFO: Deleting pod "pod-subpath-test-secret-8vtw" in namespace "e2e-tests-subpath-8mp79"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:06:04.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8mp79" for this suite.
Feb 19 04:06:10.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:06:10.370: INFO: namespace: e2e-tests-subpath-8mp79, resource: bindings, ignored listing per whitelist
Feb 19 04:06:10.384: INFO: namespace e2e-tests-subpath-8mp79 deletion completed in 6.074008169s

• [SLOW TEST:32.230 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:06:10.384: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:06:10.446: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b09cfed5-33fb-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-rrv58" to be "success or failure"
Feb 19 04:06:10.452: INFO: Pod "downwardapi-volume-b09cfed5-33fb-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.458818ms
Feb 19 04:06:12.455: INFO: Pod "downwardapi-volume-b09cfed5-33fb-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009395934s
Feb 19 04:06:14.461: INFO: Pod "downwardapi-volume-b09cfed5-33fb-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015620385s
STEP: Saw pod success
Feb 19 04:06:14.461: INFO: Pod "downwardapi-volume-b09cfed5-33fb-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:06:14.463: INFO: Trying to get logs from node 172.26.0.15 pod downwardapi-volume-b09cfed5-33fb-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:06:14.480: INFO: Waiting for pod downwardapi-volume-b09cfed5-33fb-11e9-834e-0a58ac100103 to disappear
Feb 19 04:06:14.481: INFO: Pod downwardapi-volume-b09cfed5-33fb-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:06:14.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rrv58" for this suite.
Feb 19 04:06:20.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:06:20.556: INFO: namespace: e2e-tests-downward-api-rrv58, resource: bindings, ignored listing per whitelist
Feb 19 04:06:20.562: INFO: namespace e2e-tests-downward-api-rrv58 deletion completed in 6.077269626s

• [SLOW TEST:10.178 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:06:20.562: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 04:06:20.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dtm7h'
Feb 19 04:06:21.050: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 04:06:21.050: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 19 04:06:21.063: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-p9qf6]
Feb 19 04:06:21.063: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-p9qf6" in namespace "e2e-tests-kubectl-dtm7h" to be "running and ready"
Feb 19 04:06:21.068: INFO: Pod "e2e-test-nginx-rc-p9qf6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.539851ms
Feb 19 04:06:23.070: INFO: Pod "e2e-test-nginx-rc-p9qf6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007035003s
Feb 19 04:06:25.077: INFO: Pod "e2e-test-nginx-rc-p9qf6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013222281s
Feb 19 04:06:27.079: INFO: Pod "e2e-test-nginx-rc-p9qf6": Phase="Running", Reason="", readiness=true. Elapsed: 6.01604803s
Feb 19 04:06:27.080: INFO: Pod "e2e-test-nginx-rc-p9qf6" satisfied condition "running and ready"
Feb 19 04:06:27.080: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-p9qf6]
Feb 19 04:06:27.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dtm7h'
Feb 19 04:06:27.183: INFO: stderr: ""
Feb 19 04:06:27.183: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Feb 19 04:06:27.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dtm7h'
Feb 19 04:06:27.279: INFO: stderr: ""
Feb 19 04:06:27.279: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:06:27.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dtm7h" for this suite.
Feb 19 04:06:49.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:06:49.329: INFO: namespace: e2e-tests-kubectl-dtm7h, resource: bindings, ignored listing per whitelist
Feb 19 04:06:49.358: INFO: namespace e2e-tests-kubectl-dtm7h deletion completed in 22.075925528s

• [SLOW TEST:28.797 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:06:49.358: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6frcp
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 19 04:06:49.433: INFO: Found 0 stateful pods, waiting for 3
Feb 19 04:06:59.440: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:06:59.440: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:06:59.440: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 04:07:09.436: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:07:09.436: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:07:09.436: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:07:09.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-6frcp ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:07:09.865: INFO: stderr: ""
Feb 19 04:07:09.865: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:07:09.865: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 19 04:07:19.897: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 19 04:07:29.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-6frcp ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:07:30.059: INFO: stderr: ""
Feb 19 04:07:30.059: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:07:30.059: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:07:40.076: INFO: Waiting for StatefulSet e2e-tests-statefulset-6frcp/ss2 to complete update
Feb 19 04:07:40.076: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:07:40.076: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:07:40.076: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:07:50.085: INFO: Waiting for StatefulSet e2e-tests-statefulset-6frcp/ss2 to complete update
Feb 19 04:07:50.085: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:07:50.085: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:08:00.082: INFO: Waiting for StatefulSet e2e-tests-statefulset-6frcp/ss2 to complete update
Feb 19 04:08:00.082: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:08:00.082: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:08:10.085: INFO: Waiting for StatefulSet e2e-tests-statefulset-6frcp/ss2 to complete update
Feb 19 04:08:10.085: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:08:20.082: INFO: Waiting for StatefulSet e2e-tests-statefulset-6frcp/ss2 to complete update
Feb 19 04:08:20.082: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:08:30.085: INFO: Waiting for StatefulSet e2e-tests-statefulset-6frcp/ss2 to complete update
STEP: Rolling back to a previous revision
Feb 19 04:08:40.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-6frcp ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:08:40.888: INFO: stderr: ""
Feb 19 04:08:40.888: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:08:40.888: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:08:50.923: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 19 04:09:00.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 exec --namespace=e2e-tests-statefulset-6frcp ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:09:01.080: INFO: stderr: ""
Feb 19 04:09:01.080: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:09:01.080: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:09:21.099: INFO: Waiting for StatefulSet e2e-tests-statefulset-6frcp/ss2 to complete update
Feb 19 04:09:21.099: INFO: Waiting for Pod e2e-tests-statefulset-6frcp/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 04:09:31.107: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6frcp
Feb 19 04:09:31.109: INFO: Scaling statefulset ss2 to 0
Feb 19 04:10:11.123: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:10:11.125: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:10:11.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6frcp" for this suite.
Feb 19 04:10:17.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:10:17.165: INFO: namespace: e2e-tests-statefulset-6frcp, resource: bindings, ignored listing per whitelist
Feb 19 04:10:17.223: INFO: namespace e2e-tests-statefulset-6frcp deletion completed in 6.079868095s

• [SLOW TEST:207.865 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:10:17.223: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:10:17.285: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-tm7ng" to be "success or failure"
Feb 19 04:10:17.292: INFO: Pod "downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.358082ms
Feb 19 04:10:19.295: INFO: Pod "downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009741491s
Feb 19 04:10:21.302: INFO: Pod "downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016510176s
Feb 19 04:10:23.305: INFO: Pod "downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019548971s
Feb 19 04:10:25.308: INFO: Pod "downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022367329s
STEP: Saw pod success
Feb 19 04:10:25.308: INFO: Pod "downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:10:25.310: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:10:25.329: INFO: Waiting for pod downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:10:25.331: INFO: Pod downwardapi-volume-43bde9b7-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:10:25.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tm7ng" for this suite.
Feb 19 04:10:31.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:10:31.367: INFO: namespace: e2e-tests-projected-tm7ng, resource: bindings, ignored listing per whitelist
Feb 19 04:10:31.410: INFO: namespace e2e-tests-projected-tm7ng deletion completed in 6.076514449s

• [SLOW TEST:14.187 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:10:31.410: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:10:31.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-kb8f9" to be "success or failure"
Feb 19 04:10:31.481: INFO: Pod "downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077215ms
Feb 19 04:10:33.484: INFO: Pod "downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004759831s
Feb 19 04:10:35.487: INFO: Pod "downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007545797s
Feb 19 04:10:37.490: INFO: Pod "downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010502858s
STEP: Saw pod success
Feb 19 04:10:37.490: INFO: Pod "downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:10:37.492: INFO: Trying to get logs from node 172.26.0.15 pod downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:10:37.512: INFO: Waiting for pod downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:10:37.514: INFO: Pod downwardapi-volume-4c329530-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:10:37.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kb8f9" for this suite.
Feb 19 04:10:43.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:10:43.560: INFO: namespace: e2e-tests-projected-kb8f9, resource: bindings, ignored listing per whitelist
Feb 19 04:10:43.594: INFO: namespace e2e-tests-projected-kb8f9 deletion completed in 6.077094888s

• [SLOW TEST:12.184 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:10:43.594: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:10:43.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-c2svx" to be "success or failure"
Feb 19 04:10:43.663: INFO: Pod "downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.12828ms
Feb 19 04:10:45.665: INFO: Pod "downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005649931s
Feb 19 04:10:47.668: INFO: Pod "downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008404352s
Feb 19 04:10:49.671: INFO: Pod "downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011239604s
STEP: Saw pod success
Feb 19 04:10:49.671: INFO: Pod "downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:10:49.673: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:10:49.688: INFO: Waiting for pod downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:10:49.690: INFO: Pod downwardapi-volume-5375dd31-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:10:49.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c2svx" for this suite.
Feb 19 04:10:55.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:10:55.722: INFO: namespace: e2e-tests-projected-c2svx, resource: bindings, ignored listing per whitelist
Feb 19 04:10:55.769: INFO: namespace e2e-tests-projected-c2svx deletion completed in 6.075810598s

• [SLOW TEST:12.175 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:10:55.769: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:10:55.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-vpp4k" to be "success or failure"
Feb 19 04:10:55.839: INFO: Pod "downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.246021ms
Feb 19 04:10:57.841: INFO: Pod "downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006232787s
Feb 19 04:10:59.844: INFO: Pod "downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009231797s
Feb 19 04:11:01.851: INFO: Pod "downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015765109s
STEP: Saw pod success
Feb 19 04:11:01.851: INFO: Pod "downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:11:01.853: INFO: Trying to get logs from node 172.26.0.15 pod downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:11:01.872: INFO: Waiting for pod downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:11:01.874: INFO: Pod downwardapi-volume-5ab7b63a-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:11:01.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vpp4k" for this suite.
Feb 19 04:11:07.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:11:07.939: INFO: namespace: e2e-tests-downward-api-vpp4k, resource: bindings, ignored listing per whitelist
Feb 19 04:11:07.953: INFO: namespace e2e-tests-downward-api-vpp4k deletion completed in 6.075668586s

• [SLOW TEST:12.184 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:11:07.953: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 19 04:11:20.044: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:11:20.046: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 04:11:22.046: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:11:22.052: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 04:11:24.046: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:11:24.050: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 04:11:26.046: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:11:26.049: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:11:26.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-djj9r" for this suite.
Feb 19 04:11:48.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:11:48.128: INFO: namespace: e2e-tests-container-lifecycle-hook-djj9r, resource: bindings, ignored listing per whitelist
Feb 19 04:11:48.135: INFO: namespace e2e-tests-container-lifecycle-hook-djj9r deletion completed in 22.075911244s

• [SLOW TEST:40.181 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:11:48.135: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-79eeb627-33fc-11e9-834e-0a58ac100103
STEP: Creating secret with name s-test-opt-upd-79eeb670-33fc-11e9-834e-0a58ac100103
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-79eeb627-33fc-11e9-834e-0a58ac100103
STEP: Updating secret s-test-opt-upd-79eeb670-33fc-11e9-834e-0a58ac100103
STEP: Creating secret with name s-test-opt-create-79eeb6bf-33fc-11e9-834e-0a58ac100103
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:11:58.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pcpdn" for this suite.
Feb 19 04:12:20.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:12:20.304: INFO: namespace: e2e-tests-projected-pcpdn, resource: bindings, ignored listing per whitelist
Feb 19 04:12:20.365: INFO: namespace e2e-tests-projected-pcpdn deletion completed in 22.083616993s

• [SLOW TEST:32.230 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:12:20.365: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-8d23ef46-33fc-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:12:20.433: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-6jqtx" to be "success or failure"
Feb 19 04:12:20.434: INFO: Pod "pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1.867871ms
Feb 19 04:12:22.437: INFO: Pod "pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004884268s
Feb 19 04:12:24.442: INFO: Pod "pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008986832s
Feb 19 04:12:26.448: INFO: Pod "pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015505616s
STEP: Saw pod success
Feb 19 04:12:26.448: INFO: Pod "pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:12:26.450: INFO: Trying to get logs from node 172.26.0.15 pod pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:12:26.468: INFO: Waiting for pod pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:12:26.470: INFO: Pod pod-projected-secrets-8d24a1e8-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:12:26.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6jqtx" for this suite.
Feb 19 04:12:32.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:12:32.518: INFO: namespace: e2e-tests-projected-6jqtx, resource: bindings, ignored listing per whitelist
Feb 19 04:12:32.548: INFO: namespace e2e-tests-projected-6jqtx deletion completed in 6.074033068s

• [SLOW TEST:12.182 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:12:32.548: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-94674fe9-33fc-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:12:32.617: INFO: Waiting up to 5m0s for pod "pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-q96vg" to be "success or failure"
Feb 19 04:12:32.624: INFO: Pod "pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 7.071603ms
Feb 19 04:12:34.627: INFO: Pod "pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009861072s
Feb 19 04:12:36.633: INFO: Pod "pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015787543s
Feb 19 04:12:38.636: INFO: Pod "pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018688319s
Feb 19 04:12:40.639: INFO: Pod "pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021781067s
STEP: Saw pod success
Feb 19 04:12:40.639: INFO: Pod "pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:12:40.641: INFO: Trying to get logs from node 172.26.0.5 pod pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:12:40.657: INFO: Waiting for pod pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:12:40.659: INFO: Pod pod-secrets-9467f169-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:12:40.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-q96vg" for this suite.
Feb 19 04:12:46.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:12:46.722: INFO: namespace: e2e-tests-secrets-q96vg, resource: bindings, ignored listing per whitelist
Feb 19 04:12:46.743: INFO: namespace e2e-tests-secrets-q96vg deletion completed in 6.081190136s

• [SLOW TEST:14.195 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:12:46.743: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 19 04:12:51.342: INFO: Successfully updated pod "annotationupdate9cdd966b-33fc-11e9-834e-0a58ac100103"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:12:53.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zgbb7" for this suite.
Feb 19 04:13:15.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:13:15.395: INFO: namespace: e2e-tests-projected-zgbb7, resource: bindings, ignored listing per whitelist
Feb 19 04:13:15.436: INFO: namespace e2e-tests-projected-zgbb7 deletion completed in 22.076077287s

• [SLOW TEST:28.693 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:13:15.436: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-kc57
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 04:13:15.505: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-kc57" in namespace "e2e-tests-subpath-cpr5p" to be "success or failure"
Feb 19 04:13:15.507: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Pending", Reason="", readiness=false. Elapsed: 1.823651ms
Feb 19 04:13:17.510: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004985582s
Feb 19 04:13:19.516: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011367215s
Feb 19 04:13:21.519: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014622283s
Feb 19 04:13:23.523: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017694383s
Feb 19 04:13:25.526: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021137243s
Feb 19 04:13:27.529: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Pending", Reason="", readiness=false. Elapsed: 12.023820501s
Feb 19 04:13:29.535: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Pending", Reason="", readiness=false. Elapsed: 14.030080517s
Feb 19 04:13:31.538: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 16.032912694s
Feb 19 04:13:33.541: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 18.035840264s
Feb 19 04:13:35.544: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 20.03896524s
Feb 19 04:13:37.547: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 22.042133517s
Feb 19 04:13:39.554: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 24.048694553s
Feb 19 04:13:41.557: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 26.051986699s
Feb 19 04:13:43.560: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 28.054785287s
Feb 19 04:13:45.562: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 30.057324403s
Feb 19 04:13:47.568: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Running", Reason="", readiness=false. Elapsed: 32.063326999s
Feb 19 04:13:49.574: INFO: Pod "pod-subpath-test-projected-kc57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.069344272s
STEP: Saw pod success
Feb 19 04:13:49.574: INFO: Pod "pod-subpath-test-projected-kc57" satisfied condition "success or failure"
Feb 19 04:13:49.576: INFO: Trying to get logs from node 172.26.0.5 pod pod-subpath-test-projected-kc57 container test-container-subpath-projected-kc57: <nil>
STEP: delete the pod
Feb 19 04:13:49.594: INFO: Waiting for pod pod-subpath-test-projected-kc57 to disappear
Feb 19 04:13:49.595: INFO: Pod pod-subpath-test-projected-kc57 no longer exists
STEP: Deleting pod pod-subpath-test-projected-kc57
Feb 19 04:13:49.595: INFO: Deleting pod "pod-subpath-test-projected-kc57" in namespace "e2e-tests-subpath-cpr5p"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:13:49.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cpr5p" for this suite.
Feb 19 04:13:55.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:13:55.679: INFO: namespace: e2e-tests-subpath-cpr5p, resource: bindings, ignored listing per whitelist
Feb 19 04:13:55.680: INFO: namespace e2e-tests-subpath-cpr5p deletion completed in 6.080674843s

• [SLOW TEST:40.244 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:13:55.681: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:13:55.744: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c5f3f049-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-87v5z" to be "success or failure"
Feb 19 04:13:55.750: INFO: Pod "downwardapi-volume-c5f3f049-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.065711ms
Feb 19 04:13:57.753: INFO: Pod "downwardapi-volume-c5f3f049-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009132473s
Feb 19 04:13:59.759: INFO: Pod "downwardapi-volume-c5f3f049-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014727207s
STEP: Saw pod success
Feb 19 04:13:59.759: INFO: Pod "downwardapi-volume-c5f3f049-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:13:59.761: INFO: Trying to get logs from node 172.26.0.15 pod downwardapi-volume-c5f3f049-33fc-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:13:59.775: INFO: Waiting for pod downwardapi-volume-c5f3f049-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:13:59.777: INFO: Pod downwardapi-volume-c5f3f049-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:13:59.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-87v5z" for this suite.
Feb 19 04:14:05.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:14:05.848: INFO: namespace: e2e-tests-downward-api-87v5z, resource: bindings, ignored listing per whitelist
Feb 19 04:14:05.858: INFO: namespace e2e-tests-downward-api-87v5z deletion completed in 6.077891875s

• [SLOW TEST:10.177 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:14:05.858: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 19 04:14:14.441: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cc04f900-33fc-11e9-834e-0a58ac100103"
Feb 19 04:14:14.441: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cc04f900-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-pods-9wmxr" to be "terminated due to deadline exceeded"
Feb 19 04:14:14.444: INFO: Pod "pod-update-activedeadlineseconds-cc04f900-33fc-11e9-834e-0a58ac100103": Phase="Running", Reason="", readiness=true. Elapsed: 2.094875ms
Feb 19 04:14:16.447: INFO: Pod "pod-update-activedeadlineseconds-cc04f900-33fc-11e9-834e-0a58ac100103": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.005083127s
Feb 19 04:14:16.447: INFO: Pod "pod-update-activedeadlineseconds-cc04f900-33fc-11e9-834e-0a58ac100103" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:14:16.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9wmxr" for this suite.
Feb 19 04:14:22.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:14:22.497: INFO: namespace: e2e-tests-pods-9wmxr, resource: bindings, ignored listing per whitelist
Feb 19 04:14:22.526: INFO: namespace e2e-tests-pods-9wmxr deletion completed in 6.075730094s

• [SLOW TEST:16.668 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:14:22.526: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 19 04:14:22.586: INFO: Waiting up to 5m0s for pod "pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-sgr9s" to be "success or failure"
Feb 19 04:14:22.593: INFO: Pod "pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.586238ms
Feb 19 04:14:24.599: INFO: Pod "pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012501703s
Feb 19 04:14:26.602: INFO: Pod "pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015226526s
Feb 19 04:14:28.605: INFO: Pod "pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018436338s
STEP: Saw pod success
Feb 19 04:14:28.605: INFO: Pod "pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:14:28.607: INFO: Trying to get logs from node 172.26.0.15 pod pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 04:14:28.626: INFO: Waiting for pod pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:14:28.629: INFO: Pod pod-d5f3ce2f-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:14:28.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sgr9s" for this suite.
Feb 19 04:14:34.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:14:34.702: INFO: namespace: e2e-tests-emptydir-sgr9s, resource: bindings, ignored listing per whitelist
Feb 19 04:14:34.709: INFO: namespace e2e-tests-emptydir-sgr9s deletion completed in 6.076295348s

• [SLOW TEST:12.183 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:14:34.709: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:14:34.772: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-vjn2j" to be "success or failure"
Feb 19 04:14:34.774: INFO: Pod "downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.171767ms
Feb 19 04:14:36.777: INFO: Pod "downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005032563s
Feb 19 04:14:38.780: INFO: Pod "downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008050375s
Feb 19 04:14:40.786: INFO: Pod "downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014418787s
Feb 19 04:14:42.789: INFO: Pod "downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.017172732s
STEP: Saw pod success
Feb 19 04:14:42.789: INFO: Pod "downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:14:42.791: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:14:42.808: INFO: Waiting for pod downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103 to disappear
Feb 19 04:14:42.810: INFO: Pod downwardapi-volume-dd36dbc6-33fc-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:14:42.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vjn2j" for this suite.
Feb 19 04:14:48.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:14:48.856: INFO: namespace: e2e-tests-downward-api-vjn2j, resource: bindings, ignored listing per whitelist
Feb 19 04:14:48.896: INFO: namespace e2e-tests-downward-api-vjn2j deletion completed in 6.082490347s

• [SLOW TEST:14.188 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:14:48.896: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 19 04:14:55.484: INFO: Successfully updated pod "labelsupdatee5ac2d0a-33fc-11e9-834e-0a58ac100103"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:14:57.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hz7hc" for this suite.
Feb 19 04:15:19.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:15:19.530: INFO: namespace: e2e-tests-downward-api-hz7hc, resource: bindings, ignored listing per whitelist
Feb 19 04:15:19.578: INFO: namespace e2e-tests-downward-api-hz7hc deletion completed in 22.076872666s

• [SLOW TEST:30.681 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:15:19.578: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-n7bf
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 04:15:19.646: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-n7bf" in namespace "e2e-tests-subpath-qv9bg" to be "success or failure"
Feb 19 04:15:19.650: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.229637ms
Feb 19 04:15:21.652: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005995841s
Feb 19 04:15:23.658: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011905952s
Feb 19 04:15:25.661: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014545712s
Feb 19 04:15:27.664: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017679486s
Feb 19 04:15:29.667: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020573875s
Feb 19 04:15:31.670: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 12.02337665s
Feb 19 04:15:33.676: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 14.029529758s
Feb 19 04:15:35.679: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 16.032764997s
Feb 19 04:15:37.682: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 18.035522731s
Feb 19 04:15:39.685: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 20.038276388s
Feb 19 04:15:41.688: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 22.041185636s
Feb 19 04:15:43.695: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 24.048970106s
Feb 19 04:15:45.698: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 26.051743306s
Feb 19 04:15:47.701: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Running", Reason="", readiness=false. Elapsed: 28.054712014s
Feb 19 04:15:49.704: INFO: Pod "pod-subpath-test-configmap-n7bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.057592269s
STEP: Saw pod success
Feb 19 04:15:49.704: INFO: Pod "pod-subpath-test-configmap-n7bf" satisfied condition "success or failure"
Feb 19 04:15:49.706: INFO: Trying to get logs from node 172.26.0.5 pod pod-subpath-test-configmap-n7bf container test-container-subpath-configmap-n7bf: <nil>
STEP: delete the pod
Feb 19 04:15:49.725: INFO: Waiting for pod pod-subpath-test-configmap-n7bf to disappear
Feb 19 04:15:49.727: INFO: Pod pod-subpath-test-configmap-n7bf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-n7bf
Feb 19 04:15:49.727: INFO: Deleting pod "pod-subpath-test-configmap-n7bf" in namespace "e2e-tests-subpath-qv9bg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:15:49.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qv9bg" for this suite.
Feb 19 04:15:55.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:15:55.754: INFO: namespace: e2e-tests-subpath-qv9bg, resource: bindings, ignored listing per whitelist
Feb 19 04:15:55.810: INFO: namespace e2e-tests-subpath-qv9bg deletion completed in 6.075566529s

• [SLOW TEST:36.232 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:15:55.810: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 19 04:15:56.376: INFO: Waiting up to 5m0s for pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n" in namespace "e2e-tests-svcaccounts-x4gqc" to be "success or failure"
Feb 19 04:15:56.381: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n": Phase="Pending", Reason="", readiness=false. Elapsed: 4.313103ms
Feb 19 04:15:58.390: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0136192s
Feb 19 04:16:00.393: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016887554s
Feb 19 04:16:02.396: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020049282s
Feb 19 04:16:04.405: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.028816661s
STEP: Saw pod success
Feb 19 04:16:04.405: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n" satisfied condition "success or failure"
Feb 19 04:16:04.407: INFO: Trying to get logs from node 172.26.0.15 pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n container token-test: <nil>
STEP: delete the pod
Feb 19 04:16:04.440: INFO: Waiting for pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n to disappear
Feb 19 04:16:04.443: INFO: Pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-lc87n no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 19 04:16:04.453: INFO: Waiting up to 5m0s for pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688" in namespace "e2e-tests-svcaccounts-x4gqc" to be "success or failure"
Feb 19 04:16:04.460: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688": Phase="Pending", Reason="", readiness=false. Elapsed: 6.744889ms
Feb 19 04:16:06.462: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009130269s
Feb 19 04:16:08.465: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01191439s
Feb 19 04:16:10.468: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014634566s
Feb 19 04:16:12.471: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017510824s
Feb 19 04:16:14.477: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023480694s
Feb 19 04:16:16.479: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.026165762s
STEP: Saw pod success
Feb 19 04:16:16.479: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688" satisfied condition "success or failure"
Feb 19 04:16:16.481: INFO: Trying to get logs from node 172.26.0.5 pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688 container root-ca-test: <nil>
STEP: delete the pod
Feb 19 04:16:16.497: INFO: Waiting for pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688 to disappear
Feb 19 04:16:16.499: INFO: Pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-8b688 no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 19 04:16:16.508: INFO: Waiting up to 5m0s for pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl" in namespace "e2e-tests-svcaccounts-x4gqc" to be "success or failure"
Feb 19 04:16:16.511: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.60321ms
Feb 19 04:16:18.513: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005273103s
Feb 19 04:16:20.516: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008134796s
Feb 19 04:16:22.519: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01095219s
Feb 19 04:16:24.525: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016899303s
STEP: Saw pod success
Feb 19 04:16:24.525: INFO: Pod "pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl" satisfied condition "success or failure"
Feb 19 04:16:24.527: INFO: Trying to get logs from node 172.26.0.15 pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl container namespace-test: <nil>
STEP: delete the pod
Feb 19 04:16:24.543: INFO: Waiting for pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl to disappear
Feb 19 04:16:24.546: INFO: Pod pod-service-account-0ddaece4-33fd-11e9-834e-0a58ac100103-znpfl no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:16:24.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-x4gqc" for this suite.
Feb 19 04:16:30.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:16:30.568: INFO: namespace: e2e-tests-svcaccounts-x4gqc, resource: bindings, ignored listing per whitelist
Feb 19 04:16:30.634: INFO: namespace e2e-tests-svcaccounts-x4gqc deletion completed in 6.085491584s

• [SLOW TEST:34.824 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:16:30.634: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 19 04:16:30.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-zxxqj'
Feb 19 04:16:31.210: INFO: stderr: ""
Feb 19 04:16:31.210: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 04:16:32.214: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:16:32.214: INFO: Found 0 / 1
Feb 19 04:16:33.214: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:16:33.214: INFO: Found 0 / 1
Feb 19 04:16:34.214: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:16:34.214: INFO: Found 1 / 1
Feb 19 04:16:34.214: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 19 04:16:34.216: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:16:34.216: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 04:16:34.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 patch pod redis-master-sgn94 --namespace=e2e-tests-kubectl-zxxqj -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 19 04:16:34.318: INFO: stderr: ""
Feb 19 04:16:34.318: INFO: stdout: "pod/redis-master-sgn94 patched\n"
STEP: checking annotations
Feb 19 04:16:34.320: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:16:34.320: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:16:34.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zxxqj" for this suite.
Feb 19 04:17:12.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:17:12.428: INFO: namespace: e2e-tests-kubectl-zxxqj, resource: bindings, ignored listing per whitelist
Feb 19 04:17:12.458: INFO: namespace e2e-tests-kubectl-zxxqj deletion completed in 38.13432178s

• [SLOW TEST:41.823 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:17:12.458: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 04:17:12.527: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:12.527: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:12.528: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:12.529: INFO: Number of nodes with available pods: 0
Feb 19 04:17:12.529: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:13.533: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:13.533: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:13.533: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:13.536: INFO: Number of nodes with available pods: 0
Feb 19 04:17:13.536: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:14.534: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:14.534: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:14.534: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:14.536: INFO: Number of nodes with available pods: 0
Feb 19 04:17:14.536: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:15.533: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:15.533: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:15.533: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:15.535: INFO: Number of nodes with available pods: 0
Feb 19 04:17:15.536: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:16.534: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:16.534: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:16.534: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:16.536: INFO: Number of nodes with available pods: 0
Feb 19 04:17:16.536: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:17.533: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:17.533: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:17.533: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:17.535: INFO: Number of nodes with available pods: 0
Feb 19 04:17:17.535: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:18.534: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:18.534: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:18.534: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:18.537: INFO: Number of nodes with available pods: 2
Feb 19 04:17:18.537: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 19 04:17:18.555: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:18.555: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:18.555: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:18.558: INFO: Number of nodes with available pods: 1
Feb 19 04:17:18.558: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:19.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:19.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:19.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:19.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:19.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:20.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:20.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:20.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:20.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:20.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:21.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:21.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:21.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:21.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:21.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:22.566: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:22.566: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:22.566: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:22.568: INFO: Number of nodes with available pods: 1
Feb 19 04:17:22.568: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:23.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:23.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:23.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:23.565: INFO: Number of nodes with available pods: 1
Feb 19 04:17:23.565: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:24.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:24.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:24.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:24.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:24.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:25.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:25.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:25.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:25.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:25.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:26.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:26.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:26.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:26.563: INFO: Number of nodes with available pods: 1
Feb 19 04:17:26.563: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:27.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:27.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:27.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:27.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:27.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:28.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:28.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:28.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:28.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:28.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:29.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:29.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:29.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:29.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:29.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:30.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:30.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:30.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:30.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:30.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:31.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:31.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:31.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:31.563: INFO: Number of nodes with available pods: 1
Feb 19 04:17:31.563: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:32.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:32.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:32.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:32.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:32.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:33.565: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:33.565: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:33.565: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:33.567: INFO: Number of nodes with available pods: 1
Feb 19 04:17:33.567: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:34.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:34.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:34.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:34.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:34.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:35.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:35.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:35.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:35.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:35.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:36.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:36.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:36.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:36.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:36.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:37.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:37.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:37.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:37.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:37.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:38.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:38.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:38.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:38.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:38.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:39.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:39.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:39.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:39.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:39.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:40.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:40.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:40.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:40.563: INFO: Number of nodes with available pods: 1
Feb 19 04:17:40.563: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:41.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:41.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:41.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:41.565: INFO: Number of nodes with available pods: 1
Feb 19 04:17:41.565: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:42.570: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:42.570: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:42.570: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:42.580: INFO: Number of nodes with available pods: 1
Feb 19 04:17:42.580: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:43.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:43.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:43.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:43.567: INFO: Number of nodes with available pods: 1
Feb 19 04:17:43.567: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:44.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:44.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:44.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:44.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:44.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:45.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:45.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:45.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:45.563: INFO: Number of nodes with available pods: 1
Feb 19 04:17:45.563: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:46.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:46.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:46.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:46.565: INFO: Number of nodes with available pods: 1
Feb 19 04:17:46.565: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:47.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:47.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:47.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:47.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:47.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:48.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:48.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:48.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:48.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:48.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:49.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:49.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:49.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:49.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:49.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:50.563: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:50.563: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:50.563: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:50.565: INFO: Number of nodes with available pods: 1
Feb 19 04:17:50.565: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:51.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:51.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:51.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:51.565: INFO: Number of nodes with available pods: 1
Feb 19 04:17:51.565: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:52.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:52.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:52.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:52.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:52.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:53.561: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:53.561: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:53.561: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:53.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:53.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:54.565: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:54.565: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:54.565: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:54.568: INFO: Number of nodes with available pods: 1
Feb 19 04:17:54.568: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:55.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:55.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:55.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:55.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:55.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:56.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:56.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:56.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:56.564: INFO: Number of nodes with available pods: 1
Feb 19 04:17:56.564: INFO: Node 172.26.0.15 is running more than one daemon pod
Feb 19 04:17:57.562: INFO: DaemonSet pods can't tolerate node 172.26.0.11 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:57.562: INFO: DaemonSet pods can't tolerate node 172.26.0.12 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:57.562: INFO: DaemonSet pods can't tolerate node 172.26.0.3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 19 04:17:57.564: INFO: Number of nodes with available pods: 2
Feb 19 04:17:57.564: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-9nbtt, will wait for the garbage collector to delete the pods
Feb 19 04:17:57.625: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.818278ms
Feb 19 04:17:57.726: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.220004ms
Feb 19 04:18:41.932: INFO: Number of nodes with available pods: 0
Feb 19 04:18:41.932: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 04:18:41.933: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9nbtt/daemonsets","resourceVersion":"21719"},"items":null}

Feb 19 04:18:41.935: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9nbtt/pods","resourceVersion":"21719"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:18:41.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9nbtt" for this suite.
Feb 19 04:18:47.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:18:47.970: INFO: namespace: e2e-tests-daemonsets-9nbtt, resource: bindings, ignored listing per whitelist
Feb 19 04:18:48.025: INFO: namespace e2e-tests-daemonsets-9nbtt deletion completed in 6.081321622s

• [SLOW TEST:95.568 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:18:48.026: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 19 04:18:48.083: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 04:18:48.088: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 04:18:48.090: INFO: 
Logging pods the kubelet thinks is on node 172.26.0.15 before test
Feb 19 04:18:48.095: INFO: ip-masq-agent-2zl96 from kube-system started at 2019-02-19 02:50:22 +0000 UTC (1 container statuses recorded)
Feb 19 04:18:48.095: INFO: 	Container ip-masq-agent ready: true, restart count 0
Feb 19 04:18:48.095: INFO: kube-proxy-j44xh from kube-system started at 2019-02-19 02:50:22 +0000 UTC (1 container statuses recorded)
Feb 19 04:18:48.095: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 04:18:48.095: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-19 02:59:41 +0000 UTC (1 container statuses recorded)
Feb 19 04:18:48.095: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 19 04:18:48.095: INFO: sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-wqftk from heptio-sonobuoy started at 2019-02-19 02:59:58 +0000 UTC (2 container statuses recorded)
Feb 19 04:18:48.095: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 04:18:48.095: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 04:18:48.095: INFO: 
Logging pods the kubelet thinks is on node 172.26.0.5 before test
Feb 19 04:18:48.099: INFO: kube-proxy-ddtdb from kube-system started at 2019-02-19 02:56:46 +0000 UTC (1 container statuses recorded)
Feb 19 04:18:48.099: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 04:18:48.099: INFO: sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-7glg5 from heptio-sonobuoy started at 2019-02-19 02:59:58 +0000 UTC (2 container statuses recorded)
Feb 19 04:18:48.099: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 04:18:48.099: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 04:18:48.099: INFO: ip-masq-agent-rlxwg from kube-system started at 2019-02-19 02:56:46 +0000 UTC (1 container statuses recorded)
Feb 19 04:18:48.099: INFO: 	Container ip-masq-agent ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1584a8f1c7d5635b], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:18:49.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-6gx5r" for this suite.
Feb 19 04:18:55.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:18:55.148: INFO: namespace: e2e-tests-sched-pred-6gx5r, resource: bindings, ignored listing per whitelist
Feb 19 04:18:55.201: INFO: namespace e2e-tests-sched-pred-6gx5r deletion completed in 6.079868997s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.175 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:18:55.201: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-787b6055-33fd-11e9-834e-0a58ac100103
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:19:09.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-95ql9" for this suite.
Feb 19 04:19:31.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:19:31.361: INFO: namespace: e2e-tests-configmap-95ql9, resource: bindings, ignored listing per whitelist
Feb 19 04:19:31.377: INFO: namespace e2e-tests-configmap-95ql9 deletion completed in 22.080630622s

• [SLOW TEST:36.176 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:19:31.378: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:19:31.441: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-m7j7t" to be "success or failure"
Feb 19 04:19:31.445: INFO: Pod "downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.992848ms
Feb 19 04:19:33.448: INFO: Pod "downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006577654s
Feb 19 04:19:35.454: INFO: Pod "downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012853731s
Feb 19 04:19:37.458: INFO: Pod "downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01607129s
STEP: Saw pod success
Feb 19 04:19:37.458: INFO: Pod "downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:19:37.459: INFO: Trying to get logs from node 172.26.0.15 pod downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:19:37.475: INFO: Waiting for pod downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103 to disappear
Feb 19 04:19:37.478: INFO: Pod downwardapi-volume-8e0b49ed-33fd-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:19:37.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m7j7t" for this suite.
Feb 19 04:19:43.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:19:43.535: INFO: namespace: e2e-tests-projected-m7j7t, resource: bindings, ignored listing per whitelist
Feb 19 04:19:43.558: INFO: namespace e2e-tests-projected-m7j7t deletion completed in 6.077036009s

• [SLOW TEST:12.180 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:19:43.558: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 04:19:43.629: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 19 04:19:48.636: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 04:19:48.636: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 19 04:19:50.638: INFO: Creating deployment "test-rollover-deployment"
Feb 19 04:19:50.645: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 19 04:19:52.650: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 19 04:19:52.654: INFO: Ensure that both replica sets have 1 created replica
Feb 19 04:19:52.658: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 19 04:19:52.664: INFO: Updating deployment test-rollover-deployment
Feb 19 04:19:52.664: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 19 04:19:54.669: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 19 04:19:54.673: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 19 04:19:54.677: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:19:54.677: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:19:56.682: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:19:56.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:19:58.688: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:19:58.688: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:00.682: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:00.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:02.682: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:02.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:04.682: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:04.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146804, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:06.681: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:06.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146804, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:08.681: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:08.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146804, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:10.685: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:10.685: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146804, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:12.682: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:12.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146804, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686146790, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:14.681: INFO: 
Feb 19 04:20:14.681: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 04:20:14.687: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-5x4zj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5x4zj/deployments/test-rollover-deployment,UID:997e1e68-33fd-11e9-9859-5254000410cb,ResourceVersion:22100,Generation:2,CreationTimestamp:2019-02-19 04:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-19 04:19:50 +0000 UTC 2019-02-19 04:19:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-19 04:20:14 +0000 UTC 2019-02-19 04:19:50 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 19 04:20:14.691: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-5x4zj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5x4zj/replicasets/test-rollover-deployment-5b76ff8c4,UID:9ab34bfa-33fd-11e9-9859-5254000410cb,ResourceVersion:22091,Generation:2,CreationTimestamp:2019-02-19 04:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 997e1e68-33fd-11e9-9859-5254000410cb 0xc422abd9d7 0xc422abd9d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 19 04:20:14.691: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 19 04:20:14.691: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-5x4zj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5x4zj/replicasets/test-rollover-controller,UID:954f3433-33fd-11e9-9859-5254000410cb,ResourceVersion:22099,Generation:2,CreationTimestamp:2019-02-19 04:19:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 997e1e68-33fd-11e9-9859-5254000410cb 0xc422abd8fe 0xc422abd8ff}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 04:20:14.691: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-5x4zj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5x4zj/replicasets/test-rollover-deployment-6975f4fb87,UID:99807112-33fd-11e9-9859-5254000410cb,ResourceVersion:22029,Generation:2,CreationTimestamp:2019-02-19 04:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 997e1e68-33fd-11e9-9859-5254000410cb 0xc422abdaf7 0xc422abdaf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 04:20:14.694: INFO: Pod "test-rollover-deployment-5b76ff8c4-f8q8d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-f8q8d,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-5x4zj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5x4zj/pods/test-rollover-deployment-5b76ff8c4-f8q8d,UID:9ab8b08c-33fd-11e9-9859-5254000410cb,ResourceVersion:22065,Generation:0,CreationTimestamp:2019-02-19 04:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 9ab34bfa-33fd-11e9-9859-5254000410cb 0xc42205f930 0xc42205f931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h4k8w {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h4k8w,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-h4k8w true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.26.0.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42205f9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42205f9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 04:19:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 04:20:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 04:20:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 04:19:52 +0000 UTC  }],Message:,Reason:,HostIP:172.26.0.5,PodIP:172.16.4.126,StartTime:2019-02-19 04:19:53 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-19 04:20:03 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://57abe95c92a0d550b03bbc8ea6387d8c54d3cd775edff3f08261e098f2d0a8b3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:20:14.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5x4zj" for this suite.
Feb 19 04:20:20.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:20:20.745: INFO: namespace: e2e-tests-deployment-5x4zj, resource: bindings, ignored listing per whitelist
Feb 19 04:20:20.779: INFO: namespace e2e-tests-deployment-5x4zj deletion completed in 6.082634949s

• [SLOW TEST:37.221 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:20:20.779: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 19 04:20:29.371: INFO: Successfully updated pod "labelsupdateab7da895-33fd-11e9-834e-0a58ac100103"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:20:31.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hfc5d" for this suite.
Feb 19 04:20:53.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:20:53.429: INFO: namespace: e2e-tests-projected-hfc5d, resource: bindings, ignored listing per whitelist
Feb 19 04:20:53.471: INFO: namespace e2e-tests-projected-hfc5d deletion completed in 22.08095007s

• [SLOW TEST:32.692 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:20:53.471: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 19 04:20:53.535: INFO: Waiting up to 5m0s for pod "client-containers-bef9a16b-33fd-11e9-834e-0a58ac100103" in namespace "e2e-tests-containers-dhsk5" to be "success or failure"
Feb 19 04:20:53.538: INFO: Pod "client-containers-bef9a16b-33fd-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.146202ms
Feb 19 04:20:55.541: INFO: Pod "client-containers-bef9a16b-33fd-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00608687s
Feb 19 04:20:57.544: INFO: Pod "client-containers-bef9a16b-33fd-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009149898s
STEP: Saw pod success
Feb 19 04:20:57.544: INFO: Pod "client-containers-bef9a16b-33fd-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:20:57.546: INFO: Trying to get logs from node 172.26.0.15 pod client-containers-bef9a16b-33fd-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 04:20:57.562: INFO: Waiting for pod client-containers-bef9a16b-33fd-11e9-834e-0a58ac100103 to disappear
Feb 19 04:20:57.564: INFO: Pod client-containers-bef9a16b-33fd-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:20:57.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dhsk5" for this suite.
Feb 19 04:21:03.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:21:03.685: INFO: namespace: e2e-tests-containers-dhsk5, resource: bindings, ignored listing per whitelist
Feb 19 04:21:03.693: INFO: namespace e2e-tests-containers-dhsk5 deletion completed in 6.125514026s

• [SLOW TEST:10.221 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:21:03.693: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 19 04:21:03.763: INFO: Waiting up to 5m0s for pod "pod-c5127ddc-33fd-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-hggtr" to be "success or failure"
Feb 19 04:21:03.768: INFO: Pod "pod-c5127ddc-33fd-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.002548ms
Feb 19 04:21:05.771: INFO: Pod "pod-c5127ddc-33fd-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007791892s
Feb 19 04:21:07.774: INFO: Pod "pod-c5127ddc-33fd-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010281817s
Feb 19 04:21:09.776: INFO: Pod "pod-c5127ddc-33fd-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012832202s
STEP: Saw pod success
Feb 19 04:21:09.776: INFO: Pod "pod-c5127ddc-33fd-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:21:09.778: INFO: Trying to get logs from node 172.26.0.5 pod pod-c5127ddc-33fd-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 04:21:09.798: INFO: Waiting for pod pod-c5127ddc-33fd-11e9-834e-0a58ac100103 to disappear
Feb 19 04:21:09.799: INFO: Pod pod-c5127ddc-33fd-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:21:09.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hggtr" for this suite.
Feb 19 04:21:15.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:21:15.823: INFO: namespace: e2e-tests-emptydir-hggtr, resource: bindings, ignored listing per whitelist
Feb 19 04:21:15.878: INFO: namespace e2e-tests-emptydir-hggtr deletion completed in 6.075382398s

• [SLOW TEST:12.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:21:15.878: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bhzdt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 04:21:15.932: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 04:22:06.007: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.3.144:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhzdt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:22:06.007: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:22:06.072: INFO: Found all expected endpoints: [netserver-0]
Feb 19 04:22:06.075: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.4.129:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhzdt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:22:06.075: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:22:06.143: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:22:06.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bhzdt" for this suite.
Feb 19 04:22:28.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:22:28.193: INFO: namespace: e2e-tests-pod-network-test-bhzdt, resource: bindings, ignored listing per whitelist
Feb 19 04:22:28.223: INFO: namespace e2e-tests-pod-network-test-bhzdt deletion completed in 22.077043357s

• [SLOW TEST:72.346 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:22:28.223: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 04:22:28.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-qlb5v'
Feb 19 04:22:28.398: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 04:22:28.399: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Feb 19 04:22:30.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-qlb5v'
Feb 19 04:22:30.498: INFO: stderr: ""
Feb 19 04:22:30.498: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:22:30.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qlb5v" for this suite.
Feb 19 04:23:46.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:23:46.527: INFO: namespace: e2e-tests-kubectl-qlb5v, resource: bindings, ignored listing per whitelist
Feb 19 04:23:46.578: INFO: namespace e2e-tests-kubectl-qlb5v deletion completed in 1m16.076829957s

• [SLOW TEST:78.354 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:23:46.578: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-26276a5c-33fe-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 04:23:46.645: INFO: Waiting up to 5m0s for pod "pod-configmaps-26281d11-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-z4rpl" to be "success or failure"
Feb 19 04:23:46.648: INFO: Pod "pod-configmaps-26281d11-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.504698ms
Feb 19 04:23:48.654: INFO: Pod "pod-configmaps-26281d11-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009566292s
Feb 19 04:23:50.657: INFO: Pod "pod-configmaps-26281d11-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012233997s
STEP: Saw pod success
Feb 19 04:23:50.657: INFO: Pod "pod-configmaps-26281d11-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:23:50.659: INFO: Trying to get logs from node 172.26.0.5 pod pod-configmaps-26281d11-33fe-11e9-834e-0a58ac100103 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:23:50.679: INFO: Waiting for pod pod-configmaps-26281d11-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:23:50.681: INFO: Pod pod-configmaps-26281d11-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:23:50.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z4rpl" for this suite.
Feb 19 04:23:56.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:23:56.757: INFO: namespace: e2e-tests-configmap-z4rpl, resource: bindings, ignored listing per whitelist
Feb 19 04:23:56.762: INFO: namespace e2e-tests-configmap-z4rpl deletion completed in 6.077798737s

• [SLOW TEST:10.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:23:56.762: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 19 04:23:56.833: INFO: Waiting up to 5m0s for pod "pod-2c3ada73-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-j52bx" to be "success or failure"
Feb 19 04:23:56.837: INFO: Pod "pod-2c3ada73-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.368802ms
Feb 19 04:23:58.843: INFO: Pod "pod-2c3ada73-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009988176s
Feb 19 04:24:00.847: INFO: Pod "pod-2c3ada73-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014566893s
STEP: Saw pod success
Feb 19 04:24:00.847: INFO: Pod "pod-2c3ada73-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:24:00.849: INFO: Trying to get logs from node 172.26.0.15 pod pod-2c3ada73-33fe-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 04:24:00.867: INFO: Waiting for pod pod-2c3ada73-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:24:00.869: INFO: Pod pod-2c3ada73-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:24:00.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j52bx" for this suite.
Feb 19 04:24:06.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:06.901: INFO: namespace: e2e-tests-emptydir-j52bx, resource: bindings, ignored listing per whitelist
Feb 19 04:24:06.950: INFO: namespace e2e-tests-emptydir-j52bx deletion completed in 6.077609993s

• [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:24:06.950: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-324b7414-33fe-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 04:24:07.011: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-9bhx2" to be "success or failure"
Feb 19 04:24:07.016: INFO: Pod "pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.294246ms
Feb 19 04:24:09.022: INFO: Pod "pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011139133s
Feb 19 04:24:11.025: INFO: Pod "pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014127881s
Feb 19 04:24:13.028: INFO: Pod "pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016984223s
Feb 19 04:24:15.031: INFO: Pod "pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020118771s
STEP: Saw pod success
Feb 19 04:24:15.031: INFO: Pod "pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:24:15.033: INFO: Trying to get logs from node 172.26.0.5 pod pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:24:15.049: INFO: Waiting for pod pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:24:15.051: INFO: Pod pod-projected-configmaps-324bf4ac-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:24:15.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9bhx2" for this suite.
Feb 19 04:24:21.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:21.084: INFO: namespace: e2e-tests-projected-9bhx2, resource: bindings, ignored listing per whitelist
Feb 19 04:24:21.132: INFO: namespace e2e-tests-projected-9bhx2 deletion completed in 6.077911822s

• [SLOW TEST:14.182 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:24:21.132: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 04:24:21.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 version --client'
Feb 19 04:24:21.266: INFO: stderr: ""
Feb 19 04:24:21.266: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 19 04:24:21.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-lj5gb'
Feb 19 04:24:21.465: INFO: stderr: ""
Feb 19 04:24:21.465: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 19 04:24:21.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-lj5gb'
Feb 19 04:24:21.654: INFO: stderr: ""
Feb 19 04:24:21.654: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 04:24:22.658: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:24:22.658: INFO: Found 0 / 1
Feb 19 04:24:23.656: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:24:23.656: INFO: Found 0 / 1
Feb 19 04:24:24.657: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:24:24.657: INFO: Found 1 / 1
Feb 19 04:24:24.657: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 04:24:24.659: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:24:24.659: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 04:24:24.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 describe pod redis-master-9cwjr --namespace=e2e-tests-kubectl-lj5gb'
Feb 19 04:24:24.779: INFO: stderr: ""
Feb 19 04:24:24.779: INFO: stdout: "Name:               redis-master-9cwjr\nNamespace:          e2e-tests-kubectl-lj5gb\nPriority:           0\nPriorityClassName:  <none>\nNode:               172.26.0.15/172.26.0.15\nStart Time:         Tue, 19 Feb 2019 04:24:21 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 172.16.3.147\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://d45af51ce3a885b12e3e0fbde773251997e5d58828bcf2f643fe6a3276daa572\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Feb 2019 04:24:23 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9bkmr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-9bkmr:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-9bkmr\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                  Message\n  ----    ------     ----  ----                  -------\n  Normal  Scheduled  3s    default-scheduler     Successfully assigned e2e-tests-kubectl-lj5gb/redis-master-9cwjr to 172.26.0.15\n  Normal  Pulled     2s    kubelet, 172.26.0.15  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 172.26.0.15  Created container\n  Normal  Started    1s    kubelet, 172.26.0.15  Started container\n"
Feb 19 04:24:24.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 describe rc redis-master --namespace=e2e-tests-kubectl-lj5gb'
Feb 19 04:24:24.893: INFO: stderr: ""
Feb 19 04:24:24.893: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-lj5gb\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-9cwjr\n"
Feb 19 04:24:24.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 describe service redis-master --namespace=e2e-tests-kubectl-lj5gb'
Feb 19 04:24:24.989: INFO: stderr: ""
Feb 19 04:24:24.989: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-lj5gb\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.16.255.210\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.16.3.147:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 19 04:24:24.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 describe node 172.26.0.11'
Feb 19 04:24:25.099: INFO: stderr: ""
Feb 19 04:24:25.099: INFO: stdout: "Name:               172.26.0.11\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=QCLOUD\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=usw\n                    failure-domain.beta.kubernetes.io/zone=150001\n                    kubernetes.io/hostname=172.26.0.11\n                    kubernetes.io/node-role-etcd=\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 19 Feb 2019 02:42:41 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 19 Feb 2019 02:43:07 +0000   Tue, 19 Feb 2019 02:43:07 +0000   RouteCreated                 RouteController created a route\n  OutOfDisk            False   Tue, 19 Feb 2019 04:24:20 +0000   Tue, 19 Feb 2019 02:42:38 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Tue, 19 Feb 2019 04:24:20 +0000   Tue, 19 Feb 2019 02:42:38 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 19 Feb 2019 04:24:20 +0000   Tue, 19 Feb 2019 02:42:38 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 19 Feb 2019 04:24:20 +0000   Tue, 19 Feb 2019 02:42:38 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 19 Feb 2019 04:24:20 +0000   Tue, 19 Feb 2019 02:42:57 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.26.0.11\n  ExternalIP:  170.106.64.39\n  Hostname:    172.26.0.11\nCapacity:\n cpu:                4\n ephemeral-storage:  51474044Ki\n hugepages-2Mi:      0\n memory:             8009552Ki\n pods:               110\nAllocatable:\n cpu:                3920m\n ephemeral-storage:  47438478872\n hugepages-2Mi:      0\n memory:             7057232Ki\n pods:               110\nSystem Info:\n Machine ID:                 f9d400c5e1e8c3a8209e990d887d4ac1\n System UUID:                E312D971-230B-4464-8929-D1E9FB7D762A\n Boot ID:                    d903dc33-ca9a-4c74-9c89-9009b119b976\n Kernel Version:             3.10.0-862.9.1.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.12.1-ce\n Kubelet Version:            v1.12.4-tke.1.1\n Kube-Proxy Version:         v1.12.4-tke.1.1\nPodCIDR:                     172.16.1.0/24\nProviderID:                  qcloud:///150001/ins-3ykdol8w\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-e2e-job-efd147871c924a36                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-swvcr    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                cbs-provisioner-5c8cbf45d8-8kq29                           250m (6%)     1 (25%)     256Mi (3%)       1Gi (14%)\n  kube-system                etcd-172.26.0.11                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                ip-masq-agent-dzwb6                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-172.26.0.11                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-172.26.0.11                        0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-9r7k4                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-172.26.0.11                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       250m (6%)   1 (25%)\n  memory    256Mi (3%)  1Gi (14%)\nEvents:     <none>\n"
Feb 19 04:24:25.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 describe namespace e2e-tests-kubectl-lj5gb'
Feb 19 04:24:25.195: INFO: stderr: ""
Feb 19 04:24:25.195: INFO: stdout: "Name:         e2e-tests-kubectl-lj5gb\nLabels:       e2e-framework=kubectl\n              e2e-run=f6d0719b-33f2-11e9-834e-0a58ac100103\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:24:25.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lj5gb" for this suite.
Feb 19 04:24:47.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:47.233: INFO: namespace: e2e-tests-kubectl-lj5gb, resource: bindings, ignored listing per whitelist
Feb 19 04:24:47.277: INFO: namespace e2e-tests-kubectl-lj5gb deletion completed in 22.078972105s

• [SLOW TEST:26.146 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:24:47.278: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4a5587e1-33fe-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 04:24:47.345: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-blv4j" to be "success or failure"
Feb 19 04:24:47.347: INFO: Pod "pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1.770451ms
Feb 19 04:24:49.350: INFO: Pod "pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005139189s
Feb 19 04:24:51.356: INFO: Pod "pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011607243s
Feb 19 04:24:53.359: INFO: Pod "pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01449722s
STEP: Saw pod success
Feb 19 04:24:53.359: INFO: Pod "pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:24:53.361: INFO: Trying to get logs from node 172.26.0.5 pod pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:24:53.378: INFO: Waiting for pod pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:24:53.379: INFO: Pod pod-configmaps-4a56724a-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:24:53.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-blv4j" for this suite.
Feb 19 04:24:59.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:59.430: INFO: namespace: e2e-tests-configmap-blv4j, resource: bindings, ignored listing per whitelist
Feb 19 04:24:59.460: INFO: namespace e2e-tests-configmap-blv4j deletion completed in 6.077388278s

• [SLOW TEST:12.182 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:24:59.460: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-51987d41-33fe-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:24:59.528: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5199831c-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-9qnz4" to be "success or failure"
Feb 19 04:24:59.530: INFO: Pod "pod-projected-secrets-5199831c-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1.892752ms
Feb 19 04:25:01.538: INFO: Pod "pod-projected-secrets-5199831c-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009838673s
Feb 19 04:25:03.541: INFO: Pod "pod-projected-secrets-5199831c-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012639888s
STEP: Saw pod success
Feb 19 04:25:03.541: INFO: Pod "pod-projected-secrets-5199831c-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:25:03.543: INFO: Trying to get logs from node 172.26.0.15 pod pod-projected-secrets-5199831c-33fe-11e9-834e-0a58ac100103 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:25:03.561: INFO: Waiting for pod pod-projected-secrets-5199831c-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:25:03.563: INFO: Pod pod-projected-secrets-5199831c-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:25:03.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9qnz4" for this suite.
Feb 19 04:25:09.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:25:09.621: INFO: namespace: e2e-tests-projected-9qnz4, resource: bindings, ignored listing per whitelist
Feb 19 04:25:09.640: INFO: namespace e2e-tests-projected-9qnz4 deletion completed in 6.074651335s

• [SLOW TEST:10.180 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:25:09.641: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Feb 19 04:25:09.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-7ht9z'
Feb 19 04:25:09.905: INFO: stderr: ""
Feb 19 04:25:09.905: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 19 04:25:10.908: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:25:10.908: INFO: Found 0 / 1
Feb 19 04:25:11.911: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:25:11.911: INFO: Found 0 / 1
Feb 19 04:25:12.908: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:25:12.908: INFO: Found 0 / 1
Feb 19 04:25:13.907: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:25:13.908: INFO: Found 0 / 1
Feb 19 04:25:14.908: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:25:14.908: INFO: Found 0 / 1
Feb 19 04:25:15.908: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:25:15.908: INFO: Found 0 / 1
Feb 19 04:25:16.908: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:25:16.908: INFO: Found 1 / 1
Feb 19 04:25:16.908: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 04:25:16.910: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:25:16.910: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 19 04:25:16.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 logs redis-master-87gc8 redis-master --namespace=e2e-tests-kubectl-7ht9z'
Feb 19 04:25:17.009: INFO: stderr: ""
Feb 19 04:25:17.009: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 04:25:15.058 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 04:25:15.058 # Server started, Redis version 3.2.12\n1:M 19 Feb 04:25:15.058 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 04:25:15.058 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 19 04:25:17.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 log redis-master-87gc8 redis-master --namespace=e2e-tests-kubectl-7ht9z --tail=1'
Feb 19 04:25:17.103: INFO: stderr: ""
Feb 19 04:25:17.103: INFO: stdout: "1:M 19 Feb 04:25:15.058 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 19 04:25:17.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 log redis-master-87gc8 redis-master --namespace=e2e-tests-kubectl-7ht9z --limit-bytes=1'
Feb 19 04:25:17.202: INFO: stderr: ""
Feb 19 04:25:17.202: INFO: stdout: " "
STEP: exposing timestamps
Feb 19 04:25:17.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 log redis-master-87gc8 redis-master --namespace=e2e-tests-kubectl-7ht9z --tail=1 --timestamps'
Feb 19 04:25:17.295: INFO: stderr: ""
Feb 19 04:25:17.295: INFO: stdout: "2019-02-19T04:25:15.058899554Z 1:M 19 Feb 04:25:15.058 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 19 04:25:19.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 log redis-master-87gc8 redis-master --namespace=e2e-tests-kubectl-7ht9z --since=1s'
Feb 19 04:25:19.903: INFO: stderr: ""
Feb 19 04:25:19.903: INFO: stdout: ""
Feb 19 04:25:19.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 log redis-master-87gc8 redis-master --namespace=e2e-tests-kubectl-7ht9z --since=24h'
Feb 19 04:25:19.997: INFO: stderr: ""
Feb 19 04:25:19.997: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 04:25:15.058 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 04:25:15.058 # Server started, Redis version 3.2.12\n1:M 19 Feb 04:25:15.058 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 04:25:15.058 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Feb 19 04:25:19.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7ht9z'
Feb 19 04:25:20.087: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 04:25:20.087: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 19 04:25:20.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-7ht9z'
Feb 19 04:25:20.175: INFO: stderr: "No resources found.\n"
Feb 19 04:25:20.175: INFO: stdout: ""
Feb 19 04:25:20.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -l name=nginx --namespace=e2e-tests-kubectl-7ht9z -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 04:25:20.257: INFO: stderr: ""
Feb 19 04:25:20.257: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:25:20.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7ht9z" for this suite.
Feb 19 04:25:26.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:25:26.294: INFO: namespace: e2e-tests-kubectl-7ht9z, resource: bindings, ignored listing per whitelist
Feb 19 04:25:26.339: INFO: namespace e2e-tests-kubectl-7ht9z deletion completed in 6.078643698s

• [SLOW TEST:16.698 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:25:26.339: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-619da895-33fe-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:25:26.432: INFO: Waiting up to 5m0s for pod "pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-h9g5x" to be "success or failure"
Feb 19 04:25:26.439: INFO: Pod "pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.632636ms
Feb 19 04:25:28.441: INFO: Pod "pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009362369s
Feb 19 04:25:30.444: INFO: Pod "pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012270074s
Feb 19 04:25:32.450: INFO: Pod "pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018206657s
STEP: Saw pod success
Feb 19 04:25:32.450: INFO: Pod "pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:25:32.452: INFO: Trying to get logs from node 172.26.0.15 pod pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:25:32.468: INFO: Waiting for pod pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:25:32.470: INFO: Pod pod-secrets-61a29ff5-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:25:32.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-h9g5x" for this suite.
Feb 19 04:25:38.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:25:38.516: INFO: namespace: e2e-tests-secrets-h9g5x, resource: bindings, ignored listing per whitelist
Feb 19 04:25:38.551: INFO: namespace e2e-tests-secrets-h9g5x deletion completed in 6.077701906s
STEP: Destroying namespace "e2e-tests-secret-namespace-5bmtb" for this suite.
Feb 19 04:25:44.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:25:44.582: INFO: namespace: e2e-tests-secret-namespace-5bmtb, resource: bindings, ignored listing per whitelist
Feb 19 04:25:44.635: INFO: namespace e2e-tests-secret-namespace-5bmtb deletion completed in 6.083887335s

• [SLOW TEST:18.296 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:25:44.635: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 19 04:25:56.732: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:56.732: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:56.794: INFO: Exec stderr: ""
Feb 19 04:25:56.794: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:56.794: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:56.850: INFO: Exec stderr: ""
Feb 19 04:25:56.850: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:56.850: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:56.908: INFO: Exec stderr: ""
Feb 19 04:25:56.908: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:56.908: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:56.968: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 19 04:25:56.968: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:56.968: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:57.026: INFO: Exec stderr: ""
Feb 19 04:25:57.026: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:57.026: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:57.088: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 19 04:25:57.088: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:57.088: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:57.152: INFO: Exec stderr: ""
Feb 19 04:25:57.152: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:57.152: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:57.215: INFO: Exec stderr: ""
Feb 19 04:25:57.215: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:57.215: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:57.273: INFO: Exec stderr: ""
Feb 19 04:25:57.273: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xb84x PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:25:57.273: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:25:57.336: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:25:57.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-xb84x" for this suite.
Feb 19 04:26:47.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:26:47.369: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-xb84x, resource: bindings, ignored listing per whitelist
Feb 19 04:26:47.418: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-xb84x deletion completed in 50.078929386s

• [SLOW TEST:62.783 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:26:47.418: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 19 04:26:47.483: INFO: Waiting up to 5m0s for pod "pod-91f1ef5f-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-fx6b7" to be "success or failure"
Feb 19 04:26:47.489: INFO: Pod "pod-91f1ef5f-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.890617ms
Feb 19 04:26:49.495: INFO: Pod "pod-91f1ef5f-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011891563s
Feb 19 04:26:51.498: INFO: Pod "pod-91f1ef5f-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014836034s
Feb 19 04:26:53.501: INFO: Pod "pod-91f1ef5f-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018045871s
Feb 19 04:26:55.504: INFO: Pod "pod-91f1ef5f-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021383723s
STEP: Saw pod success
Feb 19 04:26:55.504: INFO: Pod "pod-91f1ef5f-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:26:55.506: INFO: Trying to get logs from node 172.26.0.5 pod pod-91f1ef5f-33fe-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 04:26:55.523: INFO: Waiting for pod pod-91f1ef5f-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:26:55.525: INFO: Pod pod-91f1ef5f-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:26:55.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fx6b7" for this suite.
Feb 19 04:27:01.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:27:01.542: INFO: namespace: e2e-tests-emptydir-fx6b7, resource: bindings, ignored listing per whitelist
Feb 19 04:27:01.604: INFO: namespace e2e-tests-emptydir-fx6b7 deletion completed in 6.076937684s

• [SLOW TEST:14.186 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:27:01.604: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-w7pd6/configmap-test-9a668f16-33fe-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 04:27:01.675: INFO: Waiting up to 5m0s for pod "pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-w7pd6" to be "success or failure"
Feb 19 04:27:01.679: INFO: Pod "pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.242401ms
Feb 19 04:27:03.682: INFO: Pod "pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007033926s
Feb 19 04:27:05.684: INFO: Pod "pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009764689s
Feb 19 04:27:07.688: INFO: Pod "pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013130711s
STEP: Saw pod success
Feb 19 04:27:07.688: INFO: Pod "pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:27:07.690: INFO: Trying to get logs from node 172.26.0.15 pod pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103 container env-test: <nil>
STEP: delete the pod
Feb 19 04:27:07.708: INFO: Waiting for pod pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:27:07.711: INFO: Pod pod-configmaps-9a6771f2-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:27:07.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w7pd6" for this suite.
Feb 19 04:27:13.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:27:13.743: INFO: namespace: e2e-tests-configmap-w7pd6, resource: bindings, ignored listing per whitelist
Feb 19 04:27:13.791: INFO: namespace e2e-tests-configmap-w7pd6 deletion completed in 6.076229332s

• [SLOW TEST:12.186 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:27:13.791: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 19 04:27:13.856: INFO: Waiting up to 5m0s for pod "var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-var-expansion-tbv82" to be "success or failure"
Feb 19 04:27:13.862: INFO: Pod "var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 6.500284ms
Feb 19 04:27:15.865: INFO: Pod "var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009233677s
Feb 19 04:27:17.868: INFO: Pod "var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011829193s
Feb 19 04:27:19.873: INFO: Pod "var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017713032s
STEP: Saw pod success
Feb 19 04:27:19.874: INFO: Pod "var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:27:19.875: INFO: Trying to get logs from node 172.26.0.5 pod var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103 container dapi-container: <nil>
STEP: delete the pod
Feb 19 04:27:19.895: INFO: Waiting for pod var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:27:19.897: INFO: Pod var-expansion-a1aa32e9-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:27:19.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tbv82" for this suite.
Feb 19 04:27:25.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:27:25.970: INFO: namespace: e2e-tests-var-expansion-tbv82, resource: bindings, ignored listing per whitelist
Feb 19 04:27:25.981: INFO: namespace e2e-tests-var-expansion-tbv82 deletion completed in 6.080205998s

• [SLOW TEST:12.190 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:27:25.981: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a8eeb0cc-33fe-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:27:26.056: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a8ef447d-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-j5t2z" to be "success or failure"
Feb 19 04:27:26.062: INFO: Pod "pod-projected-secrets-a8ef447d-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.974306ms
Feb 19 04:27:28.064: INFO: Pod "pod-projected-secrets-a8ef447d-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0087069s
Feb 19 04:27:30.070: INFO: Pod "pod-projected-secrets-a8ef447d-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014568302s
STEP: Saw pod success
Feb 19 04:27:30.070: INFO: Pod "pod-projected-secrets-a8ef447d-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:27:30.072: INFO: Trying to get logs from node 172.26.0.15 pod pod-projected-secrets-a8ef447d-33fe-11e9-834e-0a58ac100103 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:27:30.088: INFO: Waiting for pod pod-projected-secrets-a8ef447d-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:27:30.089: INFO: Pod pod-projected-secrets-a8ef447d-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:27:30.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j5t2z" for this suite.
Feb 19 04:27:36.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:27:36.109: INFO: namespace: e2e-tests-projected-j5t2z, resource: bindings, ignored listing per whitelist
Feb 19 04:27:36.170: INFO: namespace e2e-tests-projected-j5t2z deletion completed in 6.078093155s

• [SLOW TEST:10.190 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:27:36.171: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 04:27:36.237: INFO: Waiting up to 5m0s for pod "downward-api-af01482e-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-fdjk4" to be "success or failure"
Feb 19 04:27:36.240: INFO: Pod "downward-api-af01482e-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.369065ms
Feb 19 04:27:38.246: INFO: Pod "downward-api-af01482e-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009722666s
Feb 19 04:27:40.253: INFO: Pod "downward-api-af01482e-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015974858s
Feb 19 04:27:42.256: INFO: Pod "downward-api-af01482e-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019218648s
STEP: Saw pod success
Feb 19 04:27:42.256: INFO: Pod "downward-api-af01482e-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:27:42.258: INFO: Trying to get logs from node 172.26.0.5 pod downward-api-af01482e-33fe-11e9-834e-0a58ac100103 container dapi-container: <nil>
STEP: delete the pod
Feb 19 04:27:42.274: INFO: Waiting for pod downward-api-af01482e-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:27:42.276: INFO: Pod downward-api-af01482e-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:27:42.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fdjk4" for this suite.
Feb 19 04:27:48.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:27:48.327: INFO: namespace: e2e-tests-downward-api-fdjk4, resource: bindings, ignored listing per whitelist
Feb 19 04:27:48.357: INFO: namespace e2e-tests-downward-api-fdjk4 deletion completed in 6.077820898s

• [SLOW TEST:12.186 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:27:48.357: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:27:48.418: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b644120a-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-r9bkm" to be "success or failure"
Feb 19 04:27:48.421: INFO: Pod "downwardapi-volume-b644120a-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.573558ms
Feb 19 04:27:50.428: INFO: Pod "downwardapi-volume-b644120a-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009112607s
Feb 19 04:27:52.431: INFO: Pod "downwardapi-volume-b644120a-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012273072s
STEP: Saw pod success
Feb 19 04:27:52.431: INFO: Pod "downwardapi-volume-b644120a-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:27:52.433: INFO: Trying to get logs from node 172.26.0.15 pod downwardapi-volume-b644120a-33fe-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:27:52.450: INFO: Waiting for pod downwardapi-volume-b644120a-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:27:52.452: INFO: Pod downwardapi-volume-b644120a-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:27:52.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r9bkm" for this suite.
Feb 19 04:27:58.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:27:58.476: INFO: namespace: e2e-tests-downward-api-r9bkm, resource: bindings, ignored listing per whitelist
Feb 19 04:27:58.534: INFO: namespace e2e-tests-downward-api-r9bkm deletion completed in 6.07881954s

• [SLOW TEST:10.177 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:27:58.534: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 19 04:28:05.122: INFO: Successfully updated pod "pod-update-bc55c2a6-33fe-11e9-834e-0a58ac100103"
STEP: verifying the updated pod is in kubernetes
Feb 19 04:28:05.127: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:28:05.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-v5t5g" for this suite.
Feb 19 04:28:27.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:28:27.190: INFO: namespace: e2e-tests-pods-v5t5g, resource: bindings, ignored listing per whitelist
Feb 19 04:28:27.204: INFO: namespace e2e-tests-pods-v5t5g deletion completed in 22.074034665s

• [SLOW TEST:28.669 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:28:27.204: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-xsr5t/configmap-test-cd6ba2e1-33fe-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 04:28:27.270: INFO: Waiting up to 5m0s for pod "pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-xsr5t" to be "success or failure"
Feb 19 04:28:27.273: INFO: Pod "pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.409343ms
Feb 19 04:28:29.276: INFO: Pod "pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00654439s
Feb 19 04:28:31.279: INFO: Pod "pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009542341s
Feb 19 04:28:33.285: INFO: Pod "pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015444265s
STEP: Saw pod success
Feb 19 04:28:33.285: INFO: Pod "pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:28:33.287: INFO: Trying to get logs from node 172.26.0.15 pod pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103 container env-test: <nil>
STEP: delete the pod
Feb 19 04:28:33.306: INFO: Waiting for pod pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:28:33.308: INFO: Pod pod-configmaps-cd6c6609-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:28:33.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xsr5t" for this suite.
Feb 19 04:28:39.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:28:39.333: INFO: namespace: e2e-tests-configmap-xsr5t, resource: bindings, ignored listing per whitelist
Feb 19 04:28:39.386: INFO: namespace e2e-tests-configmap-xsr5t deletion completed in 6.07505847s

• [SLOW TEST:12.182 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:28:39.386: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:28:39.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-9zqqm" to be "success or failure"
Feb 19 04:28:39.458: INFO: Pod "downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.643686ms
Feb 19 04:28:41.461: INFO: Pod "downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008618147s
Feb 19 04:28:43.467: INFO: Pod "downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015006122s
Feb 19 04:28:45.470: INFO: Pod "downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017771443s
STEP: Saw pod success
Feb 19 04:28:45.470: INFO: Pod "downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:28:45.472: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:28:45.492: INFO: Waiting for pod downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103 to disappear
Feb 19 04:28:45.496: INFO: Pod downwardapi-volume-d4af156a-33fe-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:28:45.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9zqqm" for this suite.
Feb 19 04:28:51.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:28:51.556: INFO: namespace: e2e-tests-projected-9zqqm, resource: bindings, ignored listing per whitelist
Feb 19 04:28:51.573: INFO: namespace e2e-tests-projected-9zqqm deletion completed in 6.073480873s

• [SLOW TEST:12.187 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:28:51.573: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-dbf39355-33fe-11e9-834e-0a58ac100103
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-dbf39355-33fe-11e9-834e-0a58ac100103
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:30:13.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kbbdb" for this suite.
Feb 19 04:30:36.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:30:36.060: INFO: namespace: e2e-tests-projected-kbbdb, resource: bindings, ignored listing per whitelist
Feb 19 04:30:36.077: INFO: namespace e2e-tests-projected-kbbdb deletion completed in 22.078534895s

• [SLOW TEST:104.504 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:30:36.077: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-1a3bc4eb-33ff-11e9-834e-0a58ac100103
STEP: Creating secret with name secret-projected-all-test-volume-1a3bc4d3-33ff-11e9-834e-0a58ac100103
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 19 04:30:36.147: INFO: Waiting up to 5m0s for pod "projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-88h7n" to be "success or failure"
Feb 19 04:30:36.149: INFO: Pod "projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 1.705297ms
Feb 19 04:30:38.152: INFO: Pod "projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004747076s
Feb 19 04:30:40.155: INFO: Pod "projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007708915s
Feb 19 04:30:42.158: INFO: Pod "projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010812812s
STEP: Saw pod success
Feb 19 04:30:42.158: INFO: Pod "projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:30:42.160: INFO: Trying to get logs from node 172.26.0.5 pod projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 19 04:30:42.176: INFO: Waiting for pod projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103 to disappear
Feb 19 04:30:42.177: INFO: Pod projected-volume-1a3bc498-33ff-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:30:42.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-88h7n" for this suite.
Feb 19 04:30:48.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:30:48.212: INFO: namespace: e2e-tests-projected-88h7n, resource: bindings, ignored listing per whitelist
Feb 19 04:30:48.256: INFO: namespace e2e-tests-projected-88h7n deletion completed in 6.075603851s

• [SLOW TEST:12.179 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:30:48.256: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-pv5nc
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 19 04:30:48.334: INFO: Found 0 stateful pods, waiting for 3
Feb 19 04:30:58.341: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:30:58.341: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:30:58.341: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 04:31:08.337: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:31:08.337: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:31:08.337: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 19 04:31:08.363: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 19 04:31:18.393: INFO: Updating stateful set ss2
Feb 19 04:31:18.400: INFO: Waiting for Pod e2e-tests-statefulset-pv5nc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 19 04:31:28.440: INFO: Found 2 stateful pods, waiting for 3
Feb 19 04:31:38.447: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:31:38.447: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:31:38.447: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 19 04:31:38.470: INFO: Updating stateful set ss2
Feb 19 04:31:38.475: INFO: Waiting for Pod e2e-tests-statefulset-pv5nc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 04:31:48.502: INFO: Updating stateful set ss2
Feb 19 04:31:48.507: INFO: Waiting for StatefulSet e2e-tests-statefulset-pv5nc/ss2 to complete update
Feb 19 04:31:48.507: INFO: Waiting for Pod e2e-tests-statefulset-pv5nc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 04:31:58.516: INFO: Deleting all statefulset in ns e2e-tests-statefulset-pv5nc
Feb 19 04:31:58.518: INFO: Scaling statefulset ss2 to 0
Feb 19 04:32:28.533: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:32:28.535: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:32:28.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-pv5nc" for this suite.
Feb 19 04:32:34.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:32:34.596: INFO: namespace: e2e-tests-statefulset-pv5nc, resource: bindings, ignored listing per whitelist
Feb 19 04:32:34.630: INFO: namespace e2e-tests-statefulset-pv5nc deletion completed in 6.080154481s

• [SLOW TEST:106.374 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:32:34.631: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 19 04:32:34.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:35.162: INFO: stderr: ""
Feb 19 04:32:35.162: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 04:32:35.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:35.274: INFO: stderr: ""
Feb 19 04:32:35.274: INFO: stdout: "update-demo-nautilus-bcr4k update-demo-nautilus-tvv4r "
Feb 19 04:32:35.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-bcr4k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:35.354: INFO: stderr: ""
Feb 19 04:32:35.354: INFO: stdout: ""
Feb 19 04:32:35.354: INFO: update-demo-nautilus-bcr4k is created but not running
Feb 19 04:32:40.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:40.447: INFO: stderr: ""
Feb 19 04:32:40.448: INFO: stdout: "update-demo-nautilus-bcr4k update-demo-nautilus-tvv4r "
Feb 19 04:32:40.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-bcr4k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:40.533: INFO: stderr: ""
Feb 19 04:32:40.533: INFO: stdout: "true"
Feb 19 04:32:40.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-bcr4k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:40.612: INFO: stderr: ""
Feb 19 04:32:40.612: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 04:32:40.612: INFO: validating pod update-demo-nautilus-bcr4k
Feb 19 04:32:40.615: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 04:32:40.615: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 04:32:40.615: INFO: update-demo-nautilus-bcr4k is verified up and running
Feb 19 04:32:40.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-tvv4r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:40.696: INFO: stderr: ""
Feb 19 04:32:40.696: INFO: stdout: "true"
Feb 19 04:32:40.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods update-demo-nautilus-tvv4r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:40.773: INFO: stderr: ""
Feb 19 04:32:40.773: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 04:32:40.773: INFO: validating pod update-demo-nautilus-tvv4r
Feb 19 04:32:40.776: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 04:32:40.777: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 04:32:40.777: INFO: update-demo-nautilus-tvv4r is verified up and running
STEP: using delete to clean up resources
Feb 19 04:32:40.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:40.872: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 04:32:40.872: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 19 04:32:40.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-jf7rz'
Feb 19 04:32:40.974: INFO: stderr: "No resources found.\n"
Feb 19 04:32:40.974: INFO: stdout: ""
Feb 19 04:32:40.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 get pods -l name=update-demo --namespace=e2e-tests-kubectl-jf7rz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 04:32:41.062: INFO: stderr: ""
Feb 19 04:32:41.062: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:32:41.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jf7rz" for this suite.
Feb 19 04:33:03.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:33:03.116: INFO: namespace: e2e-tests-kubectl-jf7rz, resource: bindings, ignored listing per whitelist
Feb 19 04:33:03.148: INFO: namespace e2e-tests-kubectl-jf7rz deletion completed in 22.082442552s

• [SLOW TEST:28.517 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:33:03.148: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 19 04:33:03.215: INFO: Waiting up to 5m0s for pod "client-containers-71e628a8-33ff-11e9-834e-0a58ac100103" in namespace "e2e-tests-containers-knnrl" to be "success or failure"
Feb 19 04:33:03.219: INFO: Pod "client-containers-71e628a8-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.917644ms
Feb 19 04:33:05.222: INFO: Pod "client-containers-71e628a8-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007077298s
Feb 19 04:33:07.225: INFO: Pod "client-containers-71e628a8-33ff-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01018358s
STEP: Saw pod success
Feb 19 04:33:07.225: INFO: Pod "client-containers-71e628a8-33ff-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:33:07.227: INFO: Trying to get logs from node 172.26.0.15 pod client-containers-71e628a8-33ff-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 04:33:07.247: INFO: Waiting for pod client-containers-71e628a8-33ff-11e9-834e-0a58ac100103 to disappear
Feb 19 04:33:07.249: INFO: Pod client-containers-71e628a8-33ff-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:33:07.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-knnrl" for this suite.
Feb 19 04:33:13.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:33:13.287: INFO: namespace: e2e-tests-containers-knnrl, resource: bindings, ignored listing per whitelist
Feb 19 04:33:13.336: INFO: namespace e2e-tests-containers-knnrl deletion completed in 6.083617975s

• [SLOW TEST:10.188 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:33:13.336: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:33:13.397: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103" in namespace "e2e-tests-downward-api-8r95b" to be "success or failure"
Feb 19 04:33:13.400: INFO: Pod "downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.091331ms
Feb 19 04:33:15.402: INFO: Pod "downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005674375s
Feb 19 04:33:17.405: INFO: Pod "downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008550415s
Feb 19 04:33:19.408: INFO: Pod "downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011375804s
STEP: Saw pod success
Feb 19 04:33:19.408: INFO: Pod "downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:33:19.410: INFO: Trying to get logs from node 172.26.0.5 pod downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103 container client-container: <nil>
STEP: delete the pod
Feb 19 04:33:19.434: INFO: Waiting for pod downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103 to disappear
Feb 19 04:33:19.436: INFO: Pod downwardapi-volume-77f7cc77-33ff-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:33:19.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8r95b" for this suite.
Feb 19 04:33:25.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:33:25.514: INFO: namespace: e2e-tests-downward-api-8r95b, resource: bindings, ignored listing per whitelist
Feb 19 04:33:25.522: INFO: namespace e2e-tests-downward-api-8r95b deletion completed in 6.08322196s

• [SLOW TEST:12.186 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:33:25.522: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 19 04:33:25.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 --namespace=e2e-tests-kubectl-fjj67 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 19 04:33:30.255: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 19 04:33:30.255: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:33:32.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fjj67" for this suite.
Feb 19 04:33:38.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:33:38.320: INFO: namespace: e2e-tests-kubectl-fjj67, resource: bindings, ignored listing per whitelist
Feb 19 04:33:38.337: INFO: namespace e2e-tests-kubectl-fjj67 deletion completed in 6.074502933s

• [SLOW TEST:12.815 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:33:38.337: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 19 04:33:38.392: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 04:33:38.398: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 04:33:38.400: INFO: 
Logging pods the kubelet thinks is on node 172.26.0.15 before test
Feb 19 04:33:38.404: INFO: ip-masq-agent-2zl96 from kube-system started at 2019-02-19 02:50:22 +0000 UTC (1 container statuses recorded)
Feb 19 04:33:38.404: INFO: 	Container ip-masq-agent ready: true, restart count 0
Feb 19 04:33:38.404: INFO: kube-proxy-j44xh from kube-system started at 2019-02-19 02:50:22 +0000 UTC (1 container statuses recorded)
Feb 19 04:33:38.404: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 04:33:38.404: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-19 02:59:41 +0000 UTC (1 container statuses recorded)
Feb 19 04:33:38.404: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 19 04:33:38.404: INFO: sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-wqftk from heptio-sonobuoy started at 2019-02-19 02:59:58 +0000 UTC (2 container statuses recorded)
Feb 19 04:33:38.404: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 04:33:38.404: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 04:33:38.404: INFO: 
Logging pods the kubelet thinks is on node 172.26.0.5 before test
Feb 19 04:33:38.408: INFO: ip-masq-agent-rlxwg from kube-system started at 2019-02-19 02:56:46 +0000 UTC (1 container statuses recorded)
Feb 19 04:33:38.408: INFO: 	Container ip-masq-agent ready: true, restart count 0
Feb 19 04:33:38.408: INFO: kube-proxy-ddtdb from kube-system started at 2019-02-19 02:56:46 +0000 UTC (1 container statuses recorded)
Feb 19 04:33:38.408: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 04:33:38.408: INFO: sonobuoy-systemd-logs-daemon-set-4df9248b8e184971-7glg5 from heptio-sonobuoy started at 2019-02-19 02:59:58 +0000 UTC (2 container statuses recorded)
Feb 19 04:33:38.408: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 04:33:38.408: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8a78ad59-33ff-11e9-834e-0a58ac100103 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-8a78ad59-33ff-11e9-834e-0a58ac100103 off the node 172.26.0.5
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8a78ad59-33ff-11e9-834e-0a58ac100103
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:33:50.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4crv8" for this suite.
Feb 19 04:34:08.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:34:08.504: INFO: namespace: e2e-tests-sched-pred-4crv8, resource: bindings, ignored listing per whitelist
Feb 19 04:34:08.551: INFO: namespace e2e-tests-sched-pred-4crv8 deletion completed in 18.0743867s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:30.214 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:34:08.551: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-98e19c56-33ff-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:34:08.622: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-98e22f1e-33ff-11e9-834e-0a58ac100103" in namespace "e2e-tests-projected-jjn6j" to be "success or failure"
Feb 19 04:34:08.625: INFO: Pod "pod-projected-secrets-98e22f1e-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.276791ms
Feb 19 04:34:10.629: INFO: Pod "pod-projected-secrets-98e22f1e-33ff-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006662541s
Feb 19 04:34:12.631: INFO: Pod "pod-projected-secrets-98e22f1e-33ff-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00935772s
STEP: Saw pod success
Feb 19 04:34:12.631: INFO: Pod "pod-projected-secrets-98e22f1e-33ff-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:34:12.634: INFO: Trying to get logs from node 172.26.0.15 pod pod-projected-secrets-98e22f1e-33ff-11e9-834e-0a58ac100103 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:34:12.656: INFO: Waiting for pod pod-projected-secrets-98e22f1e-33ff-11e9-834e-0a58ac100103 to disappear
Feb 19 04:34:12.658: INFO: Pod pod-projected-secrets-98e22f1e-33ff-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:34:12.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jjn6j" for this suite.
Feb 19 04:34:18.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:34:18.734: INFO: namespace: e2e-tests-projected-jjn6j, resource: bindings, ignored listing per whitelist
Feb 19 04:34:18.742: INFO: namespace e2e-tests-projected-jjn6j deletion completed in 6.079393353s

• [SLOW TEST:10.190 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:34:18.742: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-6cnzb
Feb 19 04:34:24.814: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-6cnzb
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 04:34:24.816: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:38:25.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6cnzb" for this suite.
Feb 19 04:38:31.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:38:31.315: INFO: namespace: e2e-tests-container-probe-6cnzb, resource: bindings, ignored listing per whitelist
Feb 19 04:38:31.344: INFO: namespace e2e-tests-container-probe-6cnzb deletion completed in 6.0772774s

• [SLOW TEST:252.602 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:38:31.344: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-r496r
Feb 19 04:38:35.415: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-r496r
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 04:38:35.417: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:42:35.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-r496r" for this suite.
Feb 19 04:42:41.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:42:41.935: INFO: namespace: e2e-tests-container-probe-r496r, resource: bindings, ignored listing per whitelist
Feb 19 04:42:41.950: INFO: namespace e2e-tests-container-probe-r496r deletion completed in 6.084977736s

• [SLOW TEST:250.606 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:42:41.950: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 19 04:42:42.035: INFO: Waiting up to 5m0s for pod "pod-cae6d04d-3400-11e9-834e-0a58ac100103" in namespace "e2e-tests-emptydir-7lwq7" to be "success or failure"
Feb 19 04:42:42.037: INFO: Pod "pod-cae6d04d-3400-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060713ms
Feb 19 04:42:44.041: INFO: Pod "pod-cae6d04d-3400-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00558361s
Feb 19 04:42:46.044: INFO: Pod "pod-cae6d04d-3400-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008348969s
Feb 19 04:42:48.051: INFO: Pod "pod-cae6d04d-3400-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015806188s
STEP: Saw pod success
Feb 19 04:42:48.051: INFO: Pod "pod-cae6d04d-3400-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:42:48.053: INFO: Trying to get logs from node 172.26.0.5 pod pod-cae6d04d-3400-11e9-834e-0a58ac100103 container test-container: <nil>
STEP: delete the pod
Feb 19 04:42:48.079: INFO: Waiting for pod pod-cae6d04d-3400-11e9-834e-0a58ac100103 to disappear
Feb 19 04:42:48.081: INFO: Pod pod-cae6d04d-3400-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:42:48.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7lwq7" for this suite.
Feb 19 04:42:54.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:42:54.134: INFO: namespace: e2e-tests-emptydir-7lwq7, resource: bindings, ignored listing per whitelist
Feb 19 04:42:54.160: INFO: namespace e2e-tests-emptydir-7lwq7 deletion completed in 6.075991135s

• [SLOW TEST:12.210 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:42:54.160: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d22b141a-3400-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:42:54.229: INFO: Waiting up to 5m0s for pod "pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-94j9p" to be "success or failure"
Feb 19 04:42:54.233: INFO: Pod "pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.699989ms
Feb 19 04:42:56.236: INFO: Pod "pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00672155s
Feb 19 04:42:58.243: INFO: Pod "pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013954674s
Feb 19 04:43:00.245: INFO: Pod "pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016456525s
STEP: Saw pod success
Feb 19 04:43:00.245: INFO: Pod "pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:43:00.248: INFO: Trying to get logs from node 172.26.0.15 pod pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:43:00.265: INFO: Waiting for pod pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103 to disappear
Feb 19 04:43:00.267: INFO: Pod pod-secrets-d22bd0de-3400-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:43:00.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-94j9p" for this suite.
Feb 19 04:43:06.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:06.317: INFO: namespace: e2e-tests-secrets-94j9p, resource: bindings, ignored listing per whitelist
Feb 19 04:43:06.346: INFO: namespace e2e-tests-secrets-94j9p deletion completed in 6.075042349s

• [SLOW TEST:12.185 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:43:06.346: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:43:06.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-snfrs" for this suite.
Feb 19 04:43:28.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:28.478: INFO: namespace: e2e-tests-pods-snfrs, resource: bindings, ignored listing per whitelist
Feb 19 04:43:28.497: INFO: namespace e2e-tests-pods-snfrs deletion completed in 22.080053802s

• [SLOW TEST:22.151 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:43:28.497: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 19 04:43:28.575: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-28zlz,SelfLink:/api/v1/namespaces/e2e-tests-watch-28zlz/configmaps/e2e-watch-test-resource-version,UID:e6a1cf6e-3400-11e9-9859-5254000410cb,ResourceVersion:26692,Generation:0,CreationTimestamp:2019-02-19 04:43:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 04:43:28.575: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-28zlz,SelfLink:/api/v1/namespaces/e2e-tests-watch-28zlz/configmaps/e2e-watch-test-resource-version,UID:e6a1cf6e-3400-11e9-9859-5254000410cb,ResourceVersion:26693,Generation:0,CreationTimestamp:2019-02-19 04:43:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:43:28.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-28zlz" for this suite.
Feb 19 04:43:34.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:34.630: INFO: namespace: e2e-tests-watch-28zlz, resource: bindings, ignored listing per whitelist
Feb 19 04:43:34.654: INFO: namespace e2e-tests-watch-28zlz deletion completed in 6.074772194s

• [SLOW TEST:6.157 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:43:34.654: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-ea4cee40-3400-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume secrets
Feb 19 04:43:34.716: INFO: Waiting up to 5m0s for pod "pod-secrets-ea4d8d6f-3400-11e9-834e-0a58ac100103" in namespace "e2e-tests-secrets-dfvhd" to be "success or failure"
Feb 19 04:43:34.719: INFO: Pod "pod-secrets-ea4d8d6f-3400-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 3.696404ms
Feb 19 04:43:36.722: INFO: Pod "pod-secrets-ea4d8d6f-3400-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006651735s
Feb 19 04:43:38.726: INFO: Pod "pod-secrets-ea4d8d6f-3400-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009910139s
STEP: Saw pod success
Feb 19 04:43:38.726: INFO: Pod "pod-secrets-ea4d8d6f-3400-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:43:38.727: INFO: Trying to get logs from node 172.26.0.15 pod pod-secrets-ea4d8d6f-3400-11e9-834e-0a58ac100103 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:43:38.745: INFO: Waiting for pod pod-secrets-ea4d8d6f-3400-11e9-834e-0a58ac100103 to disappear
Feb 19 04:43:38.747: INFO: Pod pod-secrets-ea4d8d6f-3400-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:43:38.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dfvhd" for this suite.
Feb 19 04:43:44.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:44.811: INFO: namespace: e2e-tests-secrets-dfvhd, resource: bindings, ignored listing per whitelist
Feb 19 04:43:44.827: INFO: namespace e2e-tests-secrets-dfvhd deletion completed in 6.07696832s

• [SLOW TEST:10.173 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:43:44.827: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-55rmn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-55rmn to expose endpoints map[]
Feb 19 04:43:44.897: INFO: Get endpoints failed (2.416662ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 19 04:43:45.900: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-55rmn exposes endpoints map[] (1.005508082s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-55rmn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-55rmn to expose endpoints map[pod1:[80]]
Feb 19 04:43:49.933: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.027132344s elapsed, will retry)
Feb 19 04:43:50.942: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-55rmn exposes endpoints map[pod1:[80]] (5.035668456s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-55rmn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-55rmn to expose endpoints map[pod1:[80] pod2:[80]]
Feb 19 04:43:53.976: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-55rmn exposes endpoints map[pod1:[80] pod2:[80]] (3.029887122s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-55rmn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-55rmn to expose endpoints map[pod2:[80]]
Feb 19 04:43:54.992: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-55rmn exposes endpoints map[pod2:[80]] (1.010741082s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-55rmn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-55rmn to expose endpoints map[]
Feb 19 04:43:56.006: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-55rmn exposes endpoints map[] (1.006738746s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:43:56.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-55rmn" for this suite.
Feb 19 04:44:18.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:44:18.055: INFO: namespace: e2e-tests-services-55rmn, resource: bindings, ignored listing per whitelist
Feb 19 04:44:18.110: INFO: namespace e2e-tests-services-55rmn deletion completed in 22.079636591s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:33.283 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:44:18.110: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 19 04:44:18.166: INFO: namespace e2e-tests-kubectl-mw2jb
Feb 19 04:44:18.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 create -f - --namespace=e2e-tests-kubectl-mw2jb'
Feb 19 04:44:18.646: INFO: stderr: ""
Feb 19 04:44:18.647: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 04:44:19.650: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:44:19.650: INFO: Found 0 / 1
Feb 19 04:44:20.650: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:44:20.650: INFO: Found 0 / 1
Feb 19 04:44:21.651: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:44:21.651: INFO: Found 0 / 1
Feb 19 04:44:22.650: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:44:22.650: INFO: Found 1 / 1
Feb 19 04:44:22.650: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 04:44:22.652: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:44:22.652: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 04:44:22.652: INFO: wait on redis-master startup in e2e-tests-kubectl-mw2jb 
Feb 19 04:44:22.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 logs redis-master-77zc2 redis-master --namespace=e2e-tests-kubectl-mw2jb'
Feb 19 04:44:22.751: INFO: stderr: ""
Feb 19 04:44:22.752: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 04:44:21.377 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 04:44:21.377 # Server started, Redis version 3.2.12\n1:M 19 Feb 04:44:21.377 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 04:44:21.377 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 19 04:44:22.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-mw2jb'
Feb 19 04:44:22.857: INFO: stderr: ""
Feb 19 04:44:22.857: INFO: stdout: "service/rm2 exposed\n"
Feb 19 04:44:22.860: INFO: Service rm2 in namespace e2e-tests-kubectl-mw2jb found.
STEP: exposing service
Feb 19 04:44:24.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273970669 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-mw2jb'
Feb 19 04:44:24.982: INFO: stderr: ""
Feb 19 04:44:24.982: INFO: stdout: "service/rm3 exposed\n"
Feb 19 04:44:24.985: INFO: Service rm3 in namespace e2e-tests-kubectl-mw2jb found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:44:26.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mw2jb" for this suite.
Feb 19 04:44:49.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:44:49.009: INFO: namespace: e2e-tests-kubectl-mw2jb, resource: bindings, ignored listing per whitelist
Feb 19 04:44:49.071: INFO: namespace e2e-tests-kubectl-mw2jb deletion completed in 22.078262505s

• [SLOW TEST:30.962 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:44:49.072: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-gbbdt.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-gbbdt.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gbbdt.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-gbbdt.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-gbbdt.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gbbdt.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 04:45:05.205: INFO: DNS probes using e2e-tests-dns-gbbdt/dns-test-16a8d318-3401-11e9-834e-0a58ac100103 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:45:05.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-gbbdt" for this suite.
Feb 19 04:45:11.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:45:11.274: INFO: namespace: e2e-tests-dns-gbbdt, resource: bindings, ignored listing per whitelist
Feb 19 04:45:11.301: INFO: namespace e2e-tests-dns-gbbdt deletion completed in 6.080352468s

• [SLOW TEST:22.229 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:45:11.301: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wrzkp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 04:45:11.362: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 04:45:35.425: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.4.159:8080/dial?request=hostName&protocol=http&host=172.16.3.174&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-wrzkp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:45:35.425: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:45:35.498: INFO: Waiting for endpoints: map[]
Feb 19 04:45:35.501: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.4.159:8080/dial?request=hostName&protocol=http&host=172.16.4.158&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-wrzkp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:45:35.501: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
Feb 19 04:45:35.575: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:45:35.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wrzkp" for this suite.
Feb 19 04:45:57.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:45:57.629: INFO: namespace: e2e-tests-pod-network-test-wrzkp, resource: bindings, ignored listing per whitelist
Feb 19 04:45:57.655: INFO: namespace e2e-tests-pod-network-test-wrzkp deletion completed in 22.076301681s

• [SLOW TEST:46.353 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:45:57.655: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 19 04:45:57.712: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-273970669 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:45:57.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nwq77" for this suite.
Feb 19 04:46:03.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:46:03.820: INFO: namespace: e2e-tests-kubectl-nwq77, resource: bindings, ignored listing per whitelist
Feb 19 04:46:03.879: INFO: namespace e2e-tests-kubectl-nwq77 deletion completed in 6.080701244s

• [SLOW TEST:6.224 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:46:03.879: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-8dhcb in namespace e2e-tests-proxy-lh8ws
I0219 04:46:03.942959      17 runners.go:180] Created replication controller with name: proxy-service-8dhcb, namespace: e2e-tests-proxy-lh8ws, replica count: 1
I0219 04:46:04.993265      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:05.993430      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:06.993585      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:07.993777      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:08.993964      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:09.994123      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:10.994284      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:11.994426      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:12.994594      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:13.994758      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:14.994920      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:15.995102      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:16.995276      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:17.995417      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:18.995600      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:19.995767      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:20.995927      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:21.996137      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:22.996301      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:23.996459      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:24.996647      17 runners.go:180] proxy-service-8dhcb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 19 04:46:25.002: INFO: setup took 21.071640513s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 19 04:46:25.012: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 8.977569ms)
Feb 19 04:46:25.012: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.979297ms)
Feb 19 04:46:25.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 11.983645ms)
Feb 19 04:46:25.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 13.405287ms)
Feb 19 04:46:25.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 12.885041ms)
Feb 19 04:46:25.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 12.592857ms)
Feb 19 04:46:25.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 13.978793ms)
Feb 19 04:46:25.017: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 12.566521ms)
Feb 19 04:46:25.017: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 13.535471ms)
Feb 19 04:46:25.020: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 16.352507ms)
Feb 19 04:46:25.020: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 17.363304ms)
Feb 19 04:46:25.021: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 17.852085ms)
Feb 19 04:46:25.021: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 17.200202ms)
Feb 19 04:46:25.021: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 18.654235ms)
Feb 19 04:46:25.021: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 17.819192ms)
Feb 19 04:46:25.023: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 19.467626ms)
Feb 19 04:46:25.027: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 3.814278ms)
Feb 19 04:46:25.028: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 4.365592ms)
Feb 19 04:46:25.028: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 4.984943ms)
Feb 19 04:46:25.029: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 5.554631ms)
Feb 19 04:46:25.029: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.138577ms)
Feb 19 04:46:25.029: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 5.500636ms)
Feb 19 04:46:25.029: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.580225ms)
Feb 19 04:46:25.029: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 5.34341ms)
Feb 19 04:46:25.029: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.484348ms)
Feb 19 04:46:25.029: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.179592ms)
Feb 19 04:46:25.031: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 7.208041ms)
Feb 19 04:46:25.031: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 7.447105ms)
Feb 19 04:46:25.031: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 8.157427ms)
Feb 19 04:46:25.032: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 8.177138ms)
Feb 19 04:46:25.032: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 8.548599ms)
Feb 19 04:46:25.032: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 8.30988ms)
Feb 19 04:46:25.036: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 4.499222ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 4.527037ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 5.163867ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 4.754787ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 4.946292ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 4.891376ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.417606ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 4.575799ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 4.473778ms)
Feb 19 04:46:25.037: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 5.443717ms)
Feb 19 04:46:25.039: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 5.964267ms)
Feb 19 04:46:25.040: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 7.595838ms)
Feb 19 04:46:25.040: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 7.602301ms)
Feb 19 04:46:25.040: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 7.281906ms)
Feb 19 04:46:25.040: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 8.110399ms)
Feb 19 04:46:25.040: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 7.742324ms)
Feb 19 04:46:25.047: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 6.241436ms)
Feb 19 04:46:25.047: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.88613ms)
Feb 19 04:46:25.047: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.701788ms)
Feb 19 04:46:25.047: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 6.744832ms)
Feb 19 04:46:25.048: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 7.162193ms)
Feb 19 04:46:25.048: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 7.099164ms)
Feb 19 04:46:25.048: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.483478ms)
Feb 19 04:46:25.048: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 7.254949ms)
Feb 19 04:46:25.048: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 7.800383ms)
Feb 19 04:46:25.048: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 7.02061ms)
Feb 19 04:46:25.048: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 8.305282ms)
Feb 19 04:46:25.051: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 10.409987ms)
Feb 19 04:46:25.051: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 10.695491ms)
Feb 19 04:46:25.052: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 11.485061ms)
Feb 19 04:46:25.052: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 11.683114ms)
Feb 19 04:46:25.052: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 11.081603ms)
Feb 19 04:46:25.057: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 4.733935ms)
Feb 19 04:46:25.057: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 5.574986ms)
Feb 19 04:46:25.058: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.075494ms)
Feb 19 04:46:25.058: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 5.301211ms)
Feb 19 04:46:25.058: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 5.255752ms)
Feb 19 04:46:25.058: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 5.787247ms)
Feb 19 04:46:25.058: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 5.732314ms)
Feb 19 04:46:25.058: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.623127ms)
Feb 19 04:46:25.060: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 7.169287ms)
Feb 19 04:46:25.060: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 7.14921ms)
Feb 19 04:46:25.060: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 8.352688ms)
Feb 19 04:46:25.061: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 8.560005ms)
Feb 19 04:46:25.061: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 8.324885ms)
Feb 19 04:46:25.061: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 8.699363ms)
Feb 19 04:46:25.061: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 8.887676ms)
Feb 19 04:46:25.061: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 9.391685ms)
Feb 19 04:46:25.079: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 17.875057ms)
Feb 19 04:46:25.081: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 18.95973ms)
Feb 19 04:46:25.081: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 18.804183ms)
Feb 19 04:46:25.081: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 19.07351ms)
Feb 19 04:46:25.084: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 22.227599ms)
Feb 19 04:46:25.085: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 22.584012ms)
Feb 19 04:46:25.085: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 22.475204ms)
Feb 19 04:46:25.085: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 23.259938ms)
Feb 19 04:46:25.085: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 22.74531ms)
Feb 19 04:46:25.085: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 23.037002ms)
Feb 19 04:46:25.086: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 24.451636ms)
Feb 19 04:46:25.087: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 24.250552ms)
Feb 19 04:46:25.087: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 24.892489ms)
Feb 19 04:46:25.087: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 24.633256ms)
Feb 19 04:46:25.087: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 25.17642ms)
Feb 19 04:46:25.087: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 24.309795ms)
Feb 19 04:46:25.094: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 7.620453ms)
Feb 19 04:46:25.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.578943ms)
Feb 19 04:46:25.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 7.54601ms)
Feb 19 04:46:25.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 7.909056ms)
Feb 19 04:46:25.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 7.85005ms)
Feb 19 04:46:25.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 8.228665ms)
Feb 19 04:46:25.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 8.282962ms)
Feb 19 04:46:25.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 8.455318ms)
Feb 19 04:46:25.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 8.384423ms)
Feb 19 04:46:25.096: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 8.598646ms)
Feb 19 04:46:25.096: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 8.449402ms)
Feb 19 04:46:25.097: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 9.685393ms)
Feb 19 04:46:25.097: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 9.976819ms)
Feb 19 04:46:25.097: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 10.40809ms)
Feb 19 04:46:25.097: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 10.14557ms)
Feb 19 04:46:25.097: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 10.665114ms)
Feb 19 04:46:25.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.78524ms)
Feb 19 04:46:25.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.56193ms)
Feb 19 04:46:25.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.01999ms)
Feb 19 04:46:25.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 6.8623ms)
Feb 19 04:46:25.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 6.942671ms)
Feb 19 04:46:25.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 6.639361ms)
Feb 19 04:46:25.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 7.646034ms)
Feb 19 04:46:25.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 7.226797ms)
Feb 19 04:46:25.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 7.331172ms)
Feb 19 04:46:25.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 8.214962ms)
Feb 19 04:46:25.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 8.696857ms)
Feb 19 04:46:25.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 9.447779ms)
Feb 19 04:46:25.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 9.229271ms)
Feb 19 04:46:25.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 9.538314ms)
Feb 19 04:46:25.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 9.503217ms)
Feb 19 04:46:25.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 8.994495ms)
Feb 19 04:46:25.112: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 3.950231ms)
Feb 19 04:46:25.112: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 4.398501ms)
Feb 19 04:46:25.113: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 5.590666ms)
Feb 19 04:46:25.113: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 5.359407ms)
Feb 19 04:46:25.113: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 5.763406ms)
Feb 19 04:46:25.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 6.134317ms)
Feb 19 04:46:25.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.833811ms)
Feb 19 04:46:25.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.827262ms)
Feb 19 04:46:25.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.832501ms)
Feb 19 04:46:25.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 6.080154ms)
Feb 19 04:46:25.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 6.560055ms)
Feb 19 04:46:25.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.427036ms)
Feb 19 04:46:25.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 6.872962ms)
Feb 19 04:46:25.115: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.722567ms)
Feb 19 04:46:25.115: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 7.466139ms)
Feb 19 04:46:25.115: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 7.469913ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 7.31619ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 7.251987ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 7.053763ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 7.639994ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 7.162362ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 7.135247ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 7.264081ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 7.559069ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.663917ms)
Feb 19 04:46:25.123: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.479276ms)
Feb 19 04:46:25.124: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 8.167414ms)
Feb 19 04:46:25.125: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 9.401865ms)
Feb 19 04:46:25.126: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 10.376447ms)
Feb 19 04:46:25.126: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 10.259504ms)
Feb 19 04:46:25.126: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 10.371589ms)
Feb 19 04:46:25.126: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 10.323872ms)
Feb 19 04:46:25.130: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 3.743142ms)
Feb 19 04:46:25.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 4.330565ms)
Feb 19 04:46:25.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 4.237824ms)
Feb 19 04:46:25.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 4.622735ms)
Feb 19 04:46:25.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 5.084537ms)
Feb 19 04:46:25.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.193725ms)
Feb 19 04:46:25.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 5.052575ms)
Feb 19 04:46:25.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 4.652548ms)
Feb 19 04:46:25.132: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 5.191144ms)
Feb 19 04:46:25.132: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 5.096017ms)
Feb 19 04:46:25.132: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 5.107957ms)
Feb 19 04:46:25.133: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 6.63056ms)
Feb 19 04:46:25.134: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 7.259661ms)
Feb 19 04:46:25.134: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 7.176681ms)
Feb 19 04:46:25.134: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 7.451941ms)
Feb 19 04:46:25.134: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 7.597644ms)
Feb 19 04:46:25.141: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.455695ms)
Feb 19 04:46:25.141: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.173063ms)
Feb 19 04:46:25.141: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 6.638013ms)
Feb 19 04:46:25.141: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 6.728923ms)
Feb 19 04:46:25.141: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 6.81266ms)
Feb 19 04:46:25.142: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 6.885254ms)
Feb 19 04:46:25.142: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.855396ms)
Feb 19 04:46:25.142: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 7.501902ms)
Feb 19 04:46:25.142: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.050061ms)
Feb 19 04:46:25.142: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 7.652842ms)
Feb 19 04:46:25.142: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 7.045616ms)
Feb 19 04:46:25.143: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 8.300853ms)
Feb 19 04:46:25.143: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 8.602664ms)
Feb 19 04:46:25.143: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 8.58981ms)
Feb 19 04:46:25.144: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 8.965522ms)
Feb 19 04:46:25.144: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 9.503129ms)
Feb 19 04:46:25.148: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 4.396071ms)
Feb 19 04:46:25.148: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 4.505057ms)
Feb 19 04:46:25.148: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 4.716986ms)
Feb 19 04:46:25.150: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 5.659815ms)
Feb 19 04:46:25.151: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 5.854265ms)
Feb 19 04:46:25.151: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 6.185369ms)
Feb 19 04:46:25.151: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 6.182889ms)
Feb 19 04:46:25.151: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 7.017261ms)
Feb 19 04:46:25.151: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 6.762959ms)
Feb 19 04:46:25.152: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.99038ms)
Feb 19 04:46:25.152: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 7.222892ms)
Feb 19 04:46:25.152: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 8.087247ms)
Feb 19 04:46:25.152: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 7.78422ms)
Feb 19 04:46:25.152: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 7.90358ms)
Feb 19 04:46:25.152: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 7.996593ms)
Feb 19 04:46:25.154: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 9.031542ms)
Feb 19 04:46:25.157: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 2.861249ms)
Feb 19 04:46:25.158: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 4.230979ms)
Feb 19 04:46:25.159: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 5.336748ms)
Feb 19 04:46:25.160: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 5.750823ms)
Feb 19 04:46:25.160: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.670104ms)
Feb 19 04:46:25.160: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 5.868648ms)
Feb 19 04:46:25.161: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.005005ms)
Feb 19 04:46:25.161: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 6.646514ms)
Feb 19 04:46:25.161: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 7.157497ms)
Feb 19 04:46:25.161: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 7.156858ms)
Feb 19 04:46:25.161: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 7.389108ms)
Feb 19 04:46:25.161: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 7.305559ms)
Feb 19 04:46:25.161: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 7.19001ms)
Feb 19 04:46:25.161: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 7.601176ms)
Feb 19 04:46:25.162: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 7.596749ms)
Feb 19 04:46:25.162: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 7.680812ms)
Feb 19 04:46:25.167: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 4.828807ms)
Feb 19 04:46:25.167: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 5.531198ms)
Feb 19 04:46:25.167: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.094567ms)
Feb 19 04:46:25.167: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 5.390382ms)
Feb 19 04:46:25.169: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.727828ms)
Feb 19 04:46:25.169: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 6.644818ms)
Feb 19 04:46:25.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 6.492281ms)
Feb 19 04:46:25.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.913286ms)
Feb 19 04:46:25.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 8.13649ms)
Feb 19 04:46:25.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 8.449183ms)
Feb 19 04:46:25.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 7.259455ms)
Feb 19 04:46:25.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 7.177141ms)
Feb 19 04:46:25.171: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 8.384447ms)
Feb 19 04:46:25.171: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 8.432946ms)
Feb 19 04:46:25.171: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 7.966767ms)
Feb 19 04:46:25.171: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 8.861867ms)
Feb 19 04:46:25.176: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 3.871595ms)
Feb 19 04:46:25.177: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 4.280728ms)
Feb 19 04:46:25.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 5.065866ms)
Feb 19 04:46:25.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 5.563783ms)
Feb 19 04:46:25.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.337965ms)
Feb 19 04:46:25.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 5.277828ms)
Feb 19 04:46:25.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.220454ms)
Feb 19 04:46:25.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.990552ms)
Feb 19 04:46:25.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 6.582011ms)
Feb 19 04:46:25.179: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 5.747963ms)
Feb 19 04:46:25.179: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 6.455966ms)
Feb 19 04:46:25.179: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 5.541216ms)
Feb 19 04:46:25.179: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 6.993593ms)
Feb 19 04:46:25.179: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 6.713896ms)
Feb 19 04:46:25.179: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 7.10771ms)
Feb 19 04:46:25.179: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 6.308868ms)
Feb 19 04:46:25.185: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.170177ms)
Feb 19 04:46:25.185: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.143925ms)
Feb 19 04:46:25.185: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 5.444601ms)
Feb 19 04:46:25.185: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 5.257195ms)
Feb 19 04:46:25.186: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.819446ms)
Feb 19 04:46:25.186: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.587719ms)
Feb 19 04:46:25.186: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 5.93964ms)
Feb 19 04:46:25.186: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.551288ms)
Feb 19 04:46:25.187: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 6.240039ms)
Feb 19 04:46:25.187: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 6.5082ms)
Feb 19 04:46:25.187: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 7.877998ms)
Feb 19 04:46:25.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 7.923595ms)
Feb 19 04:46:25.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 8.197158ms)
Feb 19 04:46:25.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 7.540545ms)
Feb 19 04:46:25.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 7.929769ms)
Feb 19 04:46:25.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 7.432567ms)
Feb 19 04:46:25.193: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 4.610182ms)
Feb 19 04:46:25.193: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 5.377233ms)
Feb 19 04:46:25.194: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.28902ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.03736ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 6.130002ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 5.909582ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.778439ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.391986ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 5.994341ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.515093ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 6.10129ms)
Feb 19 04:46:25.195: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 7.34575ms)
Feb 19 04:46:25.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 7.946361ms)
Feb 19 04:46:25.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 7.424622ms)
Feb 19 04:46:25.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 7.600391ms)
Feb 19 04:46:25.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 8.146321ms)
Feb 19 04:46:25.201: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 4.07704ms)
Feb 19 04:46:25.201: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 3.808542ms)
Feb 19 04:46:25.201: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 4.128918ms)
Feb 19 04:46:25.202: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 4.090398ms)
Feb 19 04:46:25.202: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 5.125715ms)
Feb 19 04:46:25.202: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 4.941737ms)
Feb 19 04:46:25.202: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 5.274436ms)
Feb 19 04:46:25.202: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 5.814633ms)
Feb 19 04:46:25.203: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 4.925839ms)
Feb 19 04:46:25.203: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 4.963199ms)
Feb 19 04:46:25.203: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.071321ms)
Feb 19 04:46:25.204: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 6.94344ms)
Feb 19 04:46:25.204: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 6.894211ms)
Feb 19 04:46:25.205: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 7.511909ms)
Feb 19 04:46:25.205: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 7.209816ms)
Feb 19 04:46:25.205: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 7.707385ms)
Feb 19 04:46:25.211: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname2/proxy/: bar (200; 5.738575ms)
Feb 19 04:46:25.211: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k/proxy/rewriteme"... (200; 5.828321ms)
Feb 19 04:46:25.211: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 5.700378ms)
Feb 19 04:46:25.211: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:462/proxy/: tls qux (200; 6.027684ms)
Feb 19 04:46:25.212: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:1080/proxy/... (200; 6.300841ms)
Feb 19 04:46:25.212: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:460/proxy/: tls baz (200; 6.274037ms)
Feb 19 04:46:25.212: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:1080/proxy/rewri... (200; 6.184693ms)
Feb 19 04:46:25.212: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 6.065794ms)
Feb 19 04:46:25.212: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/proxy-service-8dhcb-7mz2k:160/proxy/: foo (200; 6.234591ms)
Feb 19 04:46:25.212: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/https:proxy-service-8dhcb-7mz2k:443/proxy/... (200; 6.392216ms)
Feb 19 04:46:25.212: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/pods/http:proxy-service-8dhcb-7mz2k:162/proxy/: bar (200; 7.008101ms)
Feb 19 04:46:25.213: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname2/proxy/: tls qux (200; 6.972994ms)
Feb 19 04:46:25.213: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname1/proxy/: foo (200; 7.62306ms)
Feb 19 04:46:25.213: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/http:proxy-service-8dhcb:portname1/proxy/: foo (200; 7.661533ms)
Feb 19 04:46:25.214: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/https:proxy-service-8dhcb:tlsportname1/proxy/: tls baz (200; 7.933504ms)
Feb 19 04:46:25.214: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lh8ws/services/proxy-service-8dhcb:portname2/proxy/: bar (200; 8.022287ms)
STEP: deleting { ReplicationController} proxy-service-8dhcb in namespace e2e-tests-proxy-lh8ws, will wait for the garbage collector to delete the pods
Feb 19 04:46:25.276: INFO: Deleting { ReplicationController} proxy-service-8dhcb took: 10.087612ms
Feb 19 04:46:25.376: INFO: Terminating { ReplicationController} proxy-service-8dhcb pods took: 100.178457ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:46:28.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-lh8ws" for this suite.
Feb 19 04:46:34.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:46:34.497: INFO: namespace: e2e-tests-proxy-lh8ws, resource: bindings, ignored listing per whitelist
Feb 19 04:46:34.555: INFO: namespace e2e-tests-proxy-lh8ws deletion completed in 6.075169331s

• [SLOW TEST:30.676 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:46:34.555: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 04:46:56.630: INFO: Container started at 2019-02-19 04:46:35 +0000 UTC, pod became ready at 2019-02-19 04:46:54 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:46:56.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n5sn2" for this suite.
Feb 19 04:47:18.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:47:18.672: INFO: namespace: e2e-tests-container-probe-n5sn2, resource: bindings, ignored listing per whitelist
Feb 19 04:47:18.709: INFO: namespace e2e-tests-container-probe-n5sn2 deletion completed in 22.076244463s

• [SLOW TEST:44.154 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 04:47:18.709: INFO: >>> kubeConfig: /tmp/kubeconfig-273970669
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-6fd9babe-3401-11e9-834e-0a58ac100103
STEP: Creating a pod to test consume configMaps
Feb 19 04:47:18.775: INFO: Waiting up to 5m0s for pod "pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103" in namespace "e2e-tests-configmap-7phc2" to be "success or failure"
Feb 19 04:47:18.781: INFO: Pod "pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.672255ms
Feb 19 04:47:20.787: INFO: Pod "pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012042659s
Feb 19 04:47:22.790: INFO: Pod "pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014863682s
Feb 19 04:47:24.792: INFO: Pod "pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017380272s
STEP: Saw pod success
Feb 19 04:47:24.792: INFO: Pod "pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103" satisfied condition "success or failure"
Feb 19 04:47:24.794: INFO: Trying to get logs from node 172.26.0.5 pod pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:47:24.813: INFO: Waiting for pod pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103 to disappear
Feb 19 04:47:24.815: INFO: Pod pod-configmaps-6fda4ba6-3401-11e9-834e-0a58ac100103 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 04:47:24.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7phc2" for this suite.
Feb 19 04:47:30.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:47:30.854: INFO: namespace: e2e-tests-configmap-7phc2, resource: bindings, ignored listing per whitelist
Feb 19 04:47:30.899: INFO: namespace e2e-tests-configmap-7phc2 deletion completed in 6.081176058s

• [SLOW TEST:12.190 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSFeb 19 04:47:30.899: INFO: Running AfterSuite actions on all node
Feb 19 04:47:30.899: INFO: Running AfterSuite actions on node 1
Feb 19 04:47:30.899: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 6227.530 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h43m48.267113852s
Test Suite Passed
