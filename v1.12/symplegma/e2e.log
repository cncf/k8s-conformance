Oct 29 13:18:42.521: INFO: Overriding default scale value of zero to 1
Oct 29 13:18:42.521: INFO: Overriding default milliseconds value of zero to 5000
I1029 13:18:42.983454      18 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-215229198
I1029 13:18:42.983662      18 e2e.go:304] Starting e2e run "2811eab1-db7d-11e8-94a0-9e8b538e2da3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1540819122 - Will randomize all specs
Will run 188 of 1814 specs

Oct 29 13:18:43.187: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 13:18:43.188: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 29 13:18:43.208: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 29 13:18:43.253: INFO: 24 / 24 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 29 13:18:43.253: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Oct 29 13:18:43.253: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 29 13:18:43.265: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 29 13:18:43.265: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 29 13:18:43.265: INFO: e2e test version: v1.12.1
Oct 29 13:18:43.266: INFO: kube-apiserver version: v1.12.2
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:18:43.266: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
Oct 29 13:18:43.335: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Oct 29 13:18:43.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-4rhsx'
Oct 29 13:18:43.698: INFO: stderr: ""
Oct 29 13:18:43.698: INFO: stdout: "pod/pause created\n"
Oct 29 13:18:43.698: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 29 13:18:43.698: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-4rhsx" to be "running and ready"
Oct 29 13:18:43.705: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.366306ms
Oct 29 13:18:45.709: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010402536s
Oct 29 13:18:45.709: INFO: Pod "pause" satisfied condition "running and ready"
Oct 29 13:18:45.709: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 29 13:18:45.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-4rhsx'
Oct 29 13:18:45.797: INFO: stderr: ""
Oct 29 13:18:45.797: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 29 13:18:45.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pod pause -L testing-label --namespace=e2e-tests-kubectl-4rhsx'
Oct 29 13:18:45.879: INFO: stderr: ""
Oct 29 13:18:45.879: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 29 13:18:45.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 label pods pause testing-label- --namespace=e2e-tests-kubectl-4rhsx'
Oct 29 13:18:45.966: INFO: stderr: ""
Oct 29 13:18:45.966: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 29 13:18:45.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pod pause -L testing-label --namespace=e2e-tests-kubectl-4rhsx'
Oct 29 13:18:46.048: INFO: stderr: ""
Oct 29 13:18:46.048: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Oct 29 13:18:46.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4rhsx'
Oct 29 13:18:46.148: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 13:18:46.148: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 29 13:18:46.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-4rhsx'
Oct 29 13:18:46.235: INFO: stderr: "No resources found.\n"
Oct 29 13:18:46.235: INFO: stdout: ""
Oct 29 13:18:46.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -l name=pause --namespace=e2e-tests-kubectl-4rhsx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 13:18:46.314: INFO: stderr: ""
Oct 29 13:18:46.314: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:18:46.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4rhsx" for this suite.
Oct 29 13:18:52.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:18:52.418: INFO: namespace: e2e-tests-kubectl-4rhsx, resource: bindings, ignored listing per whitelist
Oct 29 13:18:52.433: INFO: namespace e2e-tests-kubectl-4rhsx deletion completed in 6.114577748s

• [SLOW TEST:9.167 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:18:52.434: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 13:18:52.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xjb7g'
Oct 29 13:18:52.731: INFO: stderr: ""
Oct 29 13:18:52.731: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Oct 29 13:18:52.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xjb7g'
Oct 29 13:19:02.894: INFO: stderr: ""
Oct 29 13:19:02.894: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:19:02.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xjb7g" for this suite.
Oct 29 13:19:08.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:19:08.990: INFO: namespace: e2e-tests-kubectl-xjb7g, resource: bindings, ignored listing per whitelist
Oct 29 13:19:09.029: INFO: namespace e2e-tests-kubectl-xjb7g deletion completed in 6.124719477s

• [SLOW TEST:16.595 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:19:09.029: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1029 13:19:39.639519      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 13:19:39.639: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:19:39.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-f5lcn" for this suite.
Oct 29 13:19:45.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:19:45.688: INFO: namespace: e2e-tests-gc-f5lcn, resource: bindings, ignored listing per whitelist
Oct 29 13:19:45.758: INFO: namespace e2e-tests-gc-f5lcn deletion completed in 6.115722389s

• [SLOW TEST:36.729 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:19:45.759: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4dd8c65e-db7d-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:19:45.836: INFO: Waiting up to 5m0s for pod "pod-secrets-4dd96e6a-db7d-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-k467b" to be "success or failure"
Oct 29 13:19:45.842: INFO: Pod "pod-secrets-4dd96e6a-db7d-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010054ms
Oct 29 13:19:47.846: INFO: Pod "pod-secrets-4dd96e6a-db7d-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010066343s
STEP: Saw pod success
Oct 29 13:19:47.846: INFO: Pod "pod-secrets-4dd96e6a-db7d-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:19:47.850: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-secrets-4dd96e6a-db7d-11e8-94a0-9e8b538e2da3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:19:47.882: INFO: Waiting for pod pod-secrets-4dd96e6a-db7d-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:19:47.885: INFO: Pod pod-secrets-4dd96e6a-db7d-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:19:47.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-k467b" for this suite.
Oct 29 13:19:53.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:19:53.992: INFO: namespace: e2e-tests-secrets-k467b, resource: bindings, ignored listing per whitelist
Oct 29 13:19:54.003: INFO: namespace e2e-tests-secrets-k467b deletion completed in 6.113979681s

• [SLOW TEST:8.244 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:19:54.004: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Oct 29 13:19:54.071: INFO: Waiting up to 5m0s for pod "client-containers-52c1fa55-db7d-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-containers-25v98" to be "success or failure"
Oct 29 13:19:54.076: INFO: Pod "client-containers-52c1fa55-db7d-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.632464ms
Oct 29 13:19:56.080: INFO: Pod "client-containers-52c1fa55-db7d-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00971028s
STEP: Saw pod success
Oct 29 13:19:56.081: INFO: Pod "client-containers-52c1fa55-db7d-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:19:56.084: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod client-containers-52c1fa55-db7d-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:19:56.116: INFO: Waiting for pod client-containers-52c1fa55-db7d-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:19:56.123: INFO: Pod client-containers-52c1fa55-db7d-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:19:56.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-25v98" for this suite.
Oct 29 13:20:02.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:20:02.242: INFO: namespace: e2e-tests-containers-25v98, resource: bindings, ignored listing per whitelist
Oct 29 13:20:02.243: INFO: namespace e2e-tests-containers-25v98 deletion completed in 6.114380207s

• [SLOW TEST:8.239 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:20:02.243: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Oct 29 13:20:02.309: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-215229198 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:20:02.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-67l9f" for this suite.
Oct 29 13:20:08.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:20:08.475: INFO: namespace: e2e-tests-kubectl-67l9f, resource: bindings, ignored listing per whitelist
Oct 29 13:20:08.501: INFO: namespace e2e-tests-kubectl-67l9f deletion completed in 6.11542884s

• [SLOW TEST:6.258 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:20:08.502: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 29 13:20:08.570: INFO: Waiting up to 5m0s for pod "pod-5b663a1d-db7d-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-pwb4v" to be "success or failure"
Oct 29 13:20:08.577: INFO: Pod "pod-5b663a1d-db7d-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.984678ms
Oct 29 13:20:10.586: INFO: Pod "pod-5b663a1d-db7d-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016876009s
STEP: Saw pod success
Oct 29 13:20:10.587: INFO: Pod "pod-5b663a1d-db7d-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:20:10.590: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-5b663a1d-db7d-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:20:10.616: INFO: Waiting for pod pod-5b663a1d-db7d-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:20:10.620: INFO: Pod pod-5b663a1d-db7d-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:20:10.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pwb4v" for this suite.
Oct 29 13:20:16.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:20:16.664: INFO: namespace: e2e-tests-emptydir-pwb4v, resource: bindings, ignored listing per whitelist
Oct 29 13:20:16.740: INFO: namespace e2e-tests-emptydir-pwb4v deletion completed in 6.116654671s

• [SLOW TEST:8.239 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:20:16.740: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 29 13:20:16.813: INFO: Waiting up to 5m0s for pod "pod-604fe853-db7d-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-gfjp9" to be "success or failure"
Oct 29 13:20:16.818: INFO: Pod "pod-604fe853-db7d-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.425147ms
Oct 29 13:20:18.823: INFO: Pod "pod-604fe853-db7d-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009637334s
STEP: Saw pod success
Oct 29 13:20:18.823: INFO: Pod "pod-604fe853-db7d-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:20:18.826: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-604fe853-db7d-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:20:18.855: INFO: Waiting for pod pod-604fe853-db7d-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:20:18.862: INFO: Pod pod-604fe853-db7d-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:20:18.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gfjp9" for this suite.
Oct 29 13:20:24.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:20:24.999: INFO: namespace: e2e-tests-emptydir-gfjp9, resource: bindings, ignored listing per whitelist
Oct 29 13:20:25.001: INFO: namespace e2e-tests-emptydir-gfjp9 deletion completed in 6.128800699s

• [SLOW TEST:8.261 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:20:25.002: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:20:25.070: INFO: Waiting up to 5m0s for pod "downwardapi-volume-653be49b-db7d-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-8zghw" to be "success or failure"
Oct 29 13:20:25.076: INFO: Pod "downwardapi-volume-653be49b-db7d-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.741037ms
Oct 29 13:20:27.080: INFO: Pod "downwardapi-volume-653be49b-db7d-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00998499s
STEP: Saw pod success
Oct 29 13:20:27.080: INFO: Pod "downwardapi-volume-653be49b-db7d-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:20:27.083: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-653be49b-db7d-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:20:27.106: INFO: Waiting for pod downwardapi-volume-653be49b-db7d-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:20:27.109: INFO: Pod downwardapi-volume-653be49b-db7d-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:20:27.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8zghw" for this suite.
Oct 29 13:20:33.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:20:33.166: INFO: namespace: e2e-tests-downward-api-8zghw, resource: bindings, ignored listing per whitelist
Oct 29 13:20:33.230: INFO: namespace e2e-tests-downward-api-8zghw deletion completed in 6.11665779s

• [SLOW TEST:8.229 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:20:33.230: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 29 13:20:33.305: INFO: Waiting up to 5m0s for pod "downward-api-6a248e80-db7d-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-fcmh5" to be "success or failure"
Oct 29 13:20:33.310: INFO: Pod "downward-api-6a248e80-db7d-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.760406ms
Oct 29 13:20:35.314: INFO: Pod "downward-api-6a248e80-db7d-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008610319s
STEP: Saw pod success
Oct 29 13:20:35.314: INFO: Pod "downward-api-6a248e80-db7d-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:20:35.317: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downward-api-6a248e80-db7d-11e8-94a0-9e8b538e2da3 container dapi-container: <nil>
STEP: delete the pod
Oct 29 13:20:35.340: INFO: Waiting for pod downward-api-6a248e80-db7d-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:20:35.344: INFO: Pod downward-api-6a248e80-db7d-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:20:35.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fcmh5" for this suite.
Oct 29 13:20:41.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:20:41.423: INFO: namespace: e2e-tests-downward-api-fcmh5, resource: bindings, ignored listing per whitelist
Oct 29 13:20:41.530: INFO: namespace e2e-tests-downward-api-fcmh5 deletion completed in 6.18128278s

• [SLOW TEST:8.300 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:20:41.531: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-xm6x7
I1029 13:20:41.596862      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-xm6x7, replica count: 1
I1029 13:20:42.650670      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 13:20:43.650840      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 29 13:20:43.766: INFO: Created: latency-svc-h5mlz
Oct 29 13:20:43.782: INFO: Got endpoints: latency-svc-h5mlz [31.729022ms]
Oct 29 13:20:43.810: INFO: Created: latency-svc-zdlbh
Oct 29 13:20:43.814: INFO: Got endpoints: latency-svc-zdlbh [31.300342ms]
Oct 29 13:20:43.826: INFO: Created: latency-svc-hd4sq
Oct 29 13:20:43.834: INFO: Got endpoints: latency-svc-hd4sq [50.990901ms]
Oct 29 13:20:43.842: INFO: Created: latency-svc-v7rsh
Oct 29 13:20:43.846: INFO: Got endpoints: latency-svc-v7rsh [55.523925ms]
Oct 29 13:20:43.863: INFO: Created: latency-svc-ss5zc
Oct 29 13:20:43.864: INFO: Got endpoints: latency-svc-ss5zc [73.668761ms]
Oct 29 13:20:43.879: INFO: Created: latency-svc-ks8sd
Oct 29 13:20:43.886: INFO: Got endpoints: latency-svc-ks8sd [102.819755ms]
Oct 29 13:20:43.897: INFO: Created: latency-svc-b22mb
Oct 29 13:20:43.900: INFO: Got endpoints: latency-svc-b22mb [108.693365ms]
Oct 29 13:20:43.912: INFO: Created: latency-svc-fjn9r
Oct 29 13:20:43.920: INFO: Got endpoints: latency-svc-fjn9r [129.002802ms]
Oct 29 13:20:43.930: INFO: Created: latency-svc-2k5c5
Oct 29 13:20:43.937: INFO: Got endpoints: latency-svc-2k5c5 [145.45176ms]
Oct 29 13:20:43.956: INFO: Created: latency-svc-swcfz
Oct 29 13:20:43.963: INFO: Got endpoints: latency-svc-swcfz [171.076314ms]
Oct 29 13:20:43.976: INFO: Created: latency-svc-nx98l
Oct 29 13:20:43.981: INFO: Got endpoints: latency-svc-nx98l [189.343872ms]
Oct 29 13:20:43.998: INFO: Created: latency-svc-ljtgf
Oct 29 13:20:44.002: INFO: Got endpoints: latency-svc-ljtgf [211.050432ms]
Oct 29 13:20:44.031: INFO: Created: latency-svc-dqp58
Oct 29 13:20:44.032: INFO: Got endpoints: latency-svc-dqp58 [239.113671ms]
Oct 29 13:20:44.054: INFO: Created: latency-svc-bvgt4
Oct 29 13:20:44.063: INFO: Got endpoints: latency-svc-bvgt4 [269.162446ms]
Oct 29 13:20:44.073: INFO: Created: latency-svc-8p2jk
Oct 29 13:20:44.076: INFO: Got endpoints: latency-svc-8p2jk [282.91596ms]
Oct 29 13:20:44.091: INFO: Created: latency-svc-kw6gx
Oct 29 13:20:44.098: INFO: Got endpoints: latency-svc-kw6gx [314.32435ms]
Oct 29 13:20:44.110: INFO: Created: latency-svc-kwl9q
Oct 29 13:20:44.124: INFO: Got endpoints: latency-svc-kwl9q [310.402603ms]
Oct 29 13:20:44.130: INFO: Created: latency-svc-6l4qm
Oct 29 13:20:44.236: INFO: Got endpoints: latency-svc-6l4qm [402.529527ms]
Oct 29 13:20:44.252: INFO: Created: latency-svc-kbfbq
Oct 29 13:20:44.261: INFO: Got endpoints: latency-svc-kbfbq [414.441234ms]
Oct 29 13:20:44.278: INFO: Created: latency-svc-sdzvj
Oct 29 13:20:44.290: INFO: Got endpoints: latency-svc-sdzvj [425.560152ms]
Oct 29 13:20:44.327: INFO: Created: latency-svc-wmftg
Oct 29 13:20:44.336: INFO: Got endpoints: latency-svc-wmftg [450.255513ms]
Oct 29 13:20:44.376: INFO: Created: latency-svc-98rvv
Oct 29 13:20:44.389: INFO: Got endpoints: latency-svc-98rvv [489.310628ms]
Oct 29 13:20:44.404: INFO: Created: latency-svc-96c6m
Oct 29 13:20:44.408: INFO: Got endpoints: latency-svc-96c6m [487.981614ms]
Oct 29 13:20:44.422: INFO: Created: latency-svc-7jt4h
Oct 29 13:20:44.436: INFO: Got endpoints: latency-svc-7jt4h [498.678751ms]
Oct 29 13:20:44.445: INFO: Created: latency-svc-bmdmw
Oct 29 13:20:44.455: INFO: Got endpoints: latency-svc-bmdmw [491.862379ms]
Oct 29 13:20:44.461: INFO: Created: latency-svc-xcrzq
Oct 29 13:20:44.467: INFO: Got endpoints: latency-svc-xcrzq [486.288689ms]
Oct 29 13:20:44.485: INFO: Created: latency-svc-frnnw
Oct 29 13:20:44.493: INFO: Got endpoints: latency-svc-frnnw [491.196836ms]
Oct 29 13:20:44.515: INFO: Created: latency-svc-8jvk4
Oct 29 13:20:44.528: INFO: Got endpoints: latency-svc-8jvk4 [495.815093ms]
Oct 29 13:20:44.533: INFO: Created: latency-svc-7j4tx
Oct 29 13:20:44.539: INFO: Got endpoints: latency-svc-7j4tx [476.572509ms]
Oct 29 13:20:44.552: INFO: Created: latency-svc-jhq2p
Oct 29 13:20:44.665: INFO: Got endpoints: latency-svc-jhq2p [588.576542ms]
Oct 29 13:20:44.675: INFO: Created: latency-svc-p9mxq
Oct 29 13:20:44.681: INFO: Got endpoints: latency-svc-p9mxq [582.676833ms]
Oct 29 13:20:44.691: INFO: Created: latency-svc-6q95z
Oct 29 13:20:44.698: INFO: Got endpoints: latency-svc-6q95z [573.887164ms]
Oct 29 13:20:44.708: INFO: Created: latency-svc-brgsr
Oct 29 13:20:44.716: INFO: Got endpoints: latency-svc-brgsr [479.261536ms]
Oct 29 13:20:44.728: INFO: Created: latency-svc-4r5kt
Oct 29 13:20:44.736: INFO: Got endpoints: latency-svc-4r5kt [474.932957ms]
Oct 29 13:20:44.754: INFO: Created: latency-svc-5xstw
Oct 29 13:20:44.759: INFO: Got endpoints: latency-svc-5xstw [469.063029ms]
Oct 29 13:20:44.799: INFO: Created: latency-svc-djlnh
Oct 29 13:20:44.799: INFO: Got endpoints: latency-svc-djlnh [462.897926ms]
Oct 29 13:20:44.820: INFO: Created: latency-svc-r6vnv
Oct 29 13:20:44.824: INFO: Got endpoints: latency-svc-r6vnv [435.374757ms]
Oct 29 13:20:44.837: INFO: Created: latency-svc-cwjln
Oct 29 13:20:44.842: INFO: Got endpoints: latency-svc-cwjln [433.608778ms]
Oct 29 13:20:44.855: INFO: Created: latency-svc-nrh7q
Oct 29 13:20:44.869: INFO: Got endpoints: latency-svc-nrh7q [432.837531ms]
Oct 29 13:20:44.879: INFO: Created: latency-svc-7wj6x
Oct 29 13:20:44.885: INFO: Got endpoints: latency-svc-7wj6x [430.495186ms]
Oct 29 13:20:44.903: INFO: Created: latency-svc-s59fb
Oct 29 13:20:44.906: INFO: Got endpoints: latency-svc-s59fb [438.711273ms]
Oct 29 13:20:44.926: INFO: Created: latency-svc-t9fmt
Oct 29 13:20:44.931: INFO: Got endpoints: latency-svc-t9fmt [437.635958ms]
Oct 29 13:20:44.946: INFO: Created: latency-svc-p845v
Oct 29 13:20:44.960: INFO: Got endpoints: latency-svc-p845v [432.152388ms]
Oct 29 13:20:44.973: INFO: Created: latency-svc-zjhl7
Oct 29 13:20:44.981: INFO: Got endpoints: latency-svc-zjhl7 [441.008907ms]
Oct 29 13:20:44.984: INFO: Created: latency-svc-t7xsm
Oct 29 13:20:44.993: INFO: Got endpoints: latency-svc-t7xsm [327.891848ms]
Oct 29 13:20:45.008: INFO: Created: latency-svc-q6st8
Oct 29 13:20:45.014: INFO: Got endpoints: latency-svc-q6st8 [332.998375ms]
Oct 29 13:20:45.026: INFO: Created: latency-svc-bnmqd
Oct 29 13:20:45.033: INFO: Got endpoints: latency-svc-bnmqd [334.329947ms]
Oct 29 13:20:45.047: INFO: Created: latency-svc-66ftk
Oct 29 13:20:45.060: INFO: Got endpoints: latency-svc-66ftk [343.945405ms]
Oct 29 13:20:45.071: INFO: Created: latency-svc-shjrh
Oct 29 13:20:45.079: INFO: Got endpoints: latency-svc-shjrh [343.770668ms]
Oct 29 13:20:45.096: INFO: Created: latency-svc-wvn7r
Oct 29 13:20:45.103: INFO: Got endpoints: latency-svc-wvn7r [344.020294ms]
Oct 29 13:20:45.134: INFO: Created: latency-svc-llj6c
Oct 29 13:20:45.134: INFO: Got endpoints: latency-svc-llj6c [334.874585ms]
Oct 29 13:20:45.141: INFO: Created: latency-svc-2vzdr
Oct 29 13:20:45.148: INFO: Got endpoints: latency-svc-2vzdr [322.904133ms]
Oct 29 13:20:45.164: INFO: Created: latency-svc-g5cgr
Oct 29 13:20:45.194: INFO: Got endpoints: latency-svc-g5cgr [351.863846ms]
Oct 29 13:20:45.210: INFO: Created: latency-svc-57frc
Oct 29 13:20:45.220: INFO: Got endpoints: latency-svc-57frc [350.792726ms]
Oct 29 13:20:45.232: INFO: Created: latency-svc-dd8l5
Oct 29 13:20:45.234: INFO: Got endpoints: latency-svc-dd8l5 [348.673021ms]
Oct 29 13:20:45.250: INFO: Created: latency-svc-m8kxs
Oct 29 13:20:45.256: INFO: Got endpoints: latency-svc-m8kxs [350.771671ms]
Oct 29 13:20:45.273: INFO: Created: latency-svc-572wt
Oct 29 13:20:45.280: INFO: Got endpoints: latency-svc-572wt [348.24772ms]
Oct 29 13:20:45.293: INFO: Created: latency-svc-746bv
Oct 29 13:20:45.299: INFO: Got endpoints: latency-svc-746bv [338.722976ms]
Oct 29 13:20:45.311: INFO: Created: latency-svc-d98xc
Oct 29 13:20:45.326: INFO: Got endpoints: latency-svc-d98xc [345.467086ms]
Oct 29 13:20:45.331: INFO: Created: latency-svc-ht2sj
Oct 29 13:20:45.341: INFO: Got endpoints: latency-svc-ht2sj [347.468223ms]
Oct 29 13:20:45.373: INFO: Created: latency-svc-9wfq2
Oct 29 13:20:45.378: INFO: Got endpoints: latency-svc-9wfq2 [364.151759ms]
Oct 29 13:20:45.404: INFO: Created: latency-svc-rz54p
Oct 29 13:20:45.412: INFO: Got endpoints: latency-svc-rz54p [379.180077ms]
Oct 29 13:20:45.433: INFO: Created: latency-svc-mv7z6
Oct 29 13:20:45.434: INFO: Got endpoints: latency-svc-mv7z6 [374.514036ms]
Oct 29 13:20:45.452: INFO: Created: latency-svc-v4rgd
Oct 29 13:20:45.466: INFO: Created: latency-svc-mht42
Oct 29 13:20:45.476: INFO: Got endpoints: latency-svc-v4rgd [396.50385ms]
Oct 29 13:20:45.501: INFO: Created: latency-svc-c82xd
Oct 29 13:20:45.518: INFO: Created: latency-svc-lgnb7
Oct 29 13:20:45.522: INFO: Got endpoints: latency-svc-mht42 [419.068599ms]
Oct 29 13:20:45.541: INFO: Created: latency-svc-28ntx
Oct 29 13:20:45.560: INFO: Created: latency-svc-sh6jj
Oct 29 13:20:45.575: INFO: Got endpoints: latency-svc-c82xd [440.719688ms]
Oct 29 13:20:45.583: INFO: Created: latency-svc-nfzkp
Oct 29 13:20:45.602: INFO: Created: latency-svc-qk6sw
Oct 29 13:20:45.617: INFO: Created: latency-svc-bd8vj
Oct 29 13:20:45.623: INFO: Got endpoints: latency-svc-lgnb7 [474.852924ms]
Oct 29 13:20:45.636: INFO: Created: latency-svc-2872q
Oct 29 13:20:45.654: INFO: Created: latency-svc-cdzx6
Oct 29 13:20:45.779: INFO: Got endpoints: latency-svc-28ntx [584.384893ms]
Oct 29 13:20:45.781: INFO: Got endpoints: latency-svc-sh6jj [561.438063ms]
Oct 29 13:20:45.782: INFO: Got endpoints: latency-svc-nfzkp [547.347903ms]
Oct 29 13:20:45.788: INFO: Created: latency-svc-qq5gs
Oct 29 13:20:45.807: INFO: Created: latency-svc-74t4t
Oct 29 13:20:45.826: INFO: Got endpoints: latency-svc-qk6sw [569.375265ms]
Oct 29 13:20:45.830: INFO: Created: latency-svc-2j75q
Oct 29 13:20:45.848: INFO: Created: latency-svc-kr6vr
Oct 29 13:20:45.864: INFO: Created: latency-svc-zkljh
Oct 29 13:20:45.872: INFO: Got endpoints: latency-svc-bd8vj [592.512715ms]
Oct 29 13:20:45.882: INFO: Created: latency-svc-kqtmb
Oct 29 13:20:45.917: INFO: Created: latency-svc-kdpbt
Oct 29 13:20:45.926: INFO: Got endpoints: latency-svc-2872q [626.479703ms]
Oct 29 13:20:45.936: INFO: Created: latency-svc-h86nt
Oct 29 13:20:45.949: INFO: Created: latency-svc-gcz8d
Oct 29 13:20:45.973: INFO: Created: latency-svc-z4mkk
Oct 29 13:20:45.977: INFO: Got endpoints: latency-svc-cdzx6 [650.518197ms]
Oct 29 13:20:45.996: INFO: Created: latency-svc-5mgq4
Oct 29 13:20:46.018: INFO: Created: latency-svc-z7fjt
Oct 29 13:20:46.028: INFO: Got endpoints: latency-svc-qq5gs [687.760522ms]
Oct 29 13:20:46.046: INFO: Created: latency-svc-wmd4g
Oct 29 13:20:46.154: INFO: Got endpoints: latency-svc-2j75q [741.583115ms]
Oct 29 13:20:46.154: INFO: Got endpoints: latency-svc-74t4t [775.482836ms]
Oct 29 13:20:46.165: INFO: Created: latency-svc-dccfm
Oct 29 13:20:46.178: INFO: Got endpoints: latency-svc-kr6vr [743.942619ms]
Oct 29 13:20:46.189: INFO: Created: latency-svc-b6klh
Oct 29 13:20:46.208: INFO: Created: latency-svc-6hdjj
Oct 29 13:20:46.224: INFO: Got endpoints: latency-svc-zkljh [747.720988ms]
Oct 29 13:20:46.233: INFO: Created: latency-svc-787fc
Oct 29 13:20:46.262: INFO: Created: latency-svc-79qwq
Oct 29 13:20:46.275: INFO: Got endpoints: latency-svc-kqtmb [753.190606ms]
Oct 29 13:20:46.277: INFO: Created: latency-svc-7mwvb
Oct 29 13:20:46.306: INFO: Created: latency-svc-96bm5
Oct 29 13:20:46.323: INFO: Created: latency-svc-9vh4p
Oct 29 13:20:46.324: INFO: Got endpoints: latency-svc-kdpbt [749.184675ms]
Oct 29 13:20:46.349: INFO: Created: latency-svc-lcdgp
Oct 29 13:20:46.373: INFO: Got endpoints: latency-svc-h86nt [750.054099ms]
Oct 29 13:20:46.398: INFO: Created: latency-svc-564qz
Oct 29 13:20:46.425: INFO: Got endpoints: latency-svc-gcz8d [646.426993ms]
Oct 29 13:20:46.450: INFO: Created: latency-svc-k2nvd
Oct 29 13:20:46.475: INFO: Got endpoints: latency-svc-z4mkk [693.444766ms]
Oct 29 13:20:46.508: INFO: Created: latency-svc-c5g5h
Oct 29 13:20:46.524: INFO: Got endpoints: latency-svc-5mgq4 [741.777995ms]
Oct 29 13:20:46.555: INFO: Created: latency-svc-9xcdt
Oct 29 13:20:46.574: INFO: Got endpoints: latency-svc-z7fjt [747.68353ms]
Oct 29 13:20:46.598: INFO: Created: latency-svc-9m97j
Oct 29 13:20:46.624: INFO: Got endpoints: latency-svc-wmd4g [751.42092ms]
Oct 29 13:20:46.652: INFO: Created: latency-svc-q8t62
Oct 29 13:20:46.675: INFO: Got endpoints: latency-svc-dccfm [748.944659ms]
Oct 29 13:20:46.699: INFO: Created: latency-svc-52fg2
Oct 29 13:20:46.726: INFO: Got endpoints: latency-svc-b6klh [749.149457ms]
Oct 29 13:20:46.746: INFO: Created: latency-svc-v25kv
Oct 29 13:20:46.777: INFO: Got endpoints: latency-svc-6hdjj [748.115271ms]
Oct 29 13:20:46.799: INFO: Created: latency-svc-dz5qw
Oct 29 13:20:46.826: INFO: Got endpoints: latency-svc-787fc [671.379204ms]
Oct 29 13:20:46.848: INFO: Created: latency-svc-flwqn
Oct 29 13:20:46.874: INFO: Got endpoints: latency-svc-79qwq [720.24911ms]
Oct 29 13:20:46.904: INFO: Created: latency-svc-9cv2c
Oct 29 13:20:46.924: INFO: Got endpoints: latency-svc-7mwvb [745.251362ms]
Oct 29 13:20:46.944: INFO: Created: latency-svc-sxkgg
Oct 29 13:20:46.973: INFO: Got endpoints: latency-svc-96bm5 [749.654903ms]
Oct 29 13:20:46.998: INFO: Created: latency-svc-5fgh8
Oct 29 13:20:47.022: INFO: Got endpoints: latency-svc-9vh4p [746.922652ms]
Oct 29 13:20:47.041: INFO: Created: latency-svc-c4j5w
Oct 29 13:20:47.074: INFO: Got endpoints: latency-svc-lcdgp [750.053289ms]
Oct 29 13:20:47.099: INFO: Created: latency-svc-kh8cw
Oct 29 13:20:47.123: INFO: Got endpoints: latency-svc-564qz [750.128707ms]
Oct 29 13:20:47.146: INFO: Created: latency-svc-zsfm7
Oct 29 13:20:47.174: INFO: Got endpoints: latency-svc-k2nvd [749.093645ms]
Oct 29 13:20:47.208: INFO: Created: latency-svc-kvh46
Oct 29 13:20:47.230: INFO: Got endpoints: latency-svc-c5g5h [754.651921ms]
Oct 29 13:20:47.257: INFO: Created: latency-svc-pwjbk
Oct 29 13:20:47.273: INFO: Got endpoints: latency-svc-9xcdt [749.468144ms]
Oct 29 13:20:47.294: INFO: Created: latency-svc-9fn6g
Oct 29 13:20:47.323: INFO: Got endpoints: latency-svc-9m97j [748.973615ms]
Oct 29 13:20:47.346: INFO: Created: latency-svc-n2j6r
Oct 29 13:20:47.375: INFO: Got endpoints: latency-svc-q8t62 [750.777881ms]
Oct 29 13:20:47.396: INFO: Created: latency-svc-gt5qr
Oct 29 13:20:47.424: INFO: Got endpoints: latency-svc-52fg2 [748.658276ms]
Oct 29 13:20:47.449: INFO: Created: latency-svc-2zn8m
Oct 29 13:20:47.477: INFO: Got endpoints: latency-svc-v25kv [750.745519ms]
Oct 29 13:20:47.501: INFO: Created: latency-svc-qbvvd
Oct 29 13:20:47.523: INFO: Got endpoints: latency-svc-dz5qw [746.455573ms]
Oct 29 13:20:47.546: INFO: Created: latency-svc-7m68l
Oct 29 13:20:47.574: INFO: Got endpoints: latency-svc-flwqn [747.80874ms]
Oct 29 13:20:47.594: INFO: Created: latency-svc-cdcws
Oct 29 13:20:47.623: INFO: Got endpoints: latency-svc-9cv2c [748.675165ms]
Oct 29 13:20:47.646: INFO: Created: latency-svc-xr6mn
Oct 29 13:20:47.674: INFO: Got endpoints: latency-svc-sxkgg [749.652343ms]
Oct 29 13:20:47.694: INFO: Created: latency-svc-9sbt9
Oct 29 13:20:47.723: INFO: Got endpoints: latency-svc-5fgh8 [749.651691ms]
Oct 29 13:20:47.745: INFO: Created: latency-svc-h6b5q
Oct 29 13:20:47.772: INFO: Got endpoints: latency-svc-c4j5w [749.6696ms]
Oct 29 13:20:47.794: INFO: Created: latency-svc-fbfsn
Oct 29 13:20:47.824: INFO: Got endpoints: latency-svc-kh8cw [748.609041ms]
Oct 29 13:20:47.844: INFO: Created: latency-svc-6km9v
Oct 29 13:20:47.874: INFO: Got endpoints: latency-svc-zsfm7 [751.509757ms]
Oct 29 13:20:47.895: INFO: Created: latency-svc-bvz4q
Oct 29 13:20:47.923: INFO: Got endpoints: latency-svc-kvh46 [748.206061ms]
Oct 29 13:20:47.960: INFO: Created: latency-svc-j7n82
Oct 29 13:20:47.973: INFO: Got endpoints: latency-svc-pwjbk [743.229878ms]
Oct 29 13:20:48.010: INFO: Created: latency-svc-plwnx
Oct 29 13:20:48.023: INFO: Got endpoints: latency-svc-9fn6g [749.857778ms]
Oct 29 13:20:48.053: INFO: Created: latency-svc-mp48d
Oct 29 13:20:48.079: INFO: Got endpoints: latency-svc-n2j6r [756.622872ms]
Oct 29 13:20:48.106: INFO: Created: latency-svc-b4kgh
Oct 29 13:20:48.131: INFO: Got endpoints: latency-svc-gt5qr [756.036454ms]
Oct 29 13:20:48.153: INFO: Created: latency-svc-82mpb
Oct 29 13:20:48.174: INFO: Got endpoints: latency-svc-2zn8m [750.622094ms]
Oct 29 13:20:48.197: INFO: Created: latency-svc-hb8rp
Oct 29 13:20:48.223: INFO: Got endpoints: latency-svc-qbvvd [746.370489ms]
Oct 29 13:20:48.246: INFO: Created: latency-svc-8mkpd
Oct 29 13:20:48.274: INFO: Got endpoints: latency-svc-7m68l [750.116185ms]
Oct 29 13:20:48.298: INFO: Created: latency-svc-scpd4
Oct 29 13:20:48.323: INFO: Got endpoints: latency-svc-cdcws [749.345826ms]
Oct 29 13:20:48.346: INFO: Created: latency-svc-pz2k4
Oct 29 13:20:48.374: INFO: Got endpoints: latency-svc-xr6mn [751.388371ms]
Oct 29 13:20:48.394: INFO: Created: latency-svc-l4tql
Oct 29 13:20:48.424: INFO: Got endpoints: latency-svc-9sbt9 [750.003302ms]
Oct 29 13:20:48.445: INFO: Created: latency-svc-kxfbg
Oct 29 13:20:48.475: INFO: Got endpoints: latency-svc-h6b5q [751.257156ms]
Oct 29 13:20:48.502: INFO: Created: latency-svc-jdts7
Oct 29 13:20:48.524: INFO: Got endpoints: latency-svc-fbfsn [751.040067ms]
Oct 29 13:20:48.549: INFO: Created: latency-svc-k57q2
Oct 29 13:20:48.573: INFO: Got endpoints: latency-svc-6km9v [748.913384ms]
Oct 29 13:20:48.617: INFO: Created: latency-svc-nk2ck
Oct 29 13:20:48.623: INFO: Got endpoints: latency-svc-bvz4q [748.119273ms]
Oct 29 13:20:48.643: INFO: Created: latency-svc-m2rjw
Oct 29 13:20:48.674: INFO: Got endpoints: latency-svc-j7n82 [751.431302ms]
Oct 29 13:20:48.696: INFO: Created: latency-svc-wkf6j
Oct 29 13:20:48.723: INFO: Got endpoints: latency-svc-plwnx [750.192049ms]
Oct 29 13:20:48.745: INFO: Created: latency-svc-n2gk4
Oct 29 13:20:48.774: INFO: Got endpoints: latency-svc-mp48d [750.675543ms]
Oct 29 13:20:48.803: INFO: Created: latency-svc-f977k
Oct 29 13:20:48.824: INFO: Got endpoints: latency-svc-b4kgh [744.425796ms]
Oct 29 13:20:48.876: INFO: Created: latency-svc-l8sgv
Oct 29 13:20:48.886: INFO: Got endpoints: latency-svc-82mpb [754.799528ms]
Oct 29 13:20:48.928: INFO: Got endpoints: latency-svc-hb8rp [753.399831ms]
Oct 29 13:20:48.944: INFO: Created: latency-svc-f5nnt
Oct 29 13:20:48.960: INFO: Created: latency-svc-sg4fx
Oct 29 13:20:48.975: INFO: Got endpoints: latency-svc-8mkpd [751.446385ms]
Oct 29 13:20:48.998: INFO: Created: latency-svc-hqnwf
Oct 29 13:20:49.023: INFO: Got endpoints: latency-svc-scpd4 [749.334656ms]
Oct 29 13:20:49.049: INFO: Created: latency-svc-s45d6
Oct 29 13:20:49.073: INFO: Got endpoints: latency-svc-pz2k4 [750.123774ms]
Oct 29 13:20:49.096: INFO: Created: latency-svc-jfdxk
Oct 29 13:20:49.122: INFO: Got endpoints: latency-svc-l4tql [747.609894ms]
Oct 29 13:20:49.145: INFO: Created: latency-svc-jfk7g
Oct 29 13:20:49.173: INFO: Got endpoints: latency-svc-kxfbg [749.000405ms]
Oct 29 13:20:49.205: INFO: Created: latency-svc-jbvxd
Oct 29 13:20:49.223: INFO: Got endpoints: latency-svc-jdts7 [748.092577ms]
Oct 29 13:20:49.247: INFO: Created: latency-svc-5wxh9
Oct 29 13:20:49.273: INFO: Got endpoints: latency-svc-k57q2 [749.279017ms]
Oct 29 13:20:49.295: INFO: Created: latency-svc-7vjzg
Oct 29 13:20:49.323: INFO: Got endpoints: latency-svc-nk2ck [750.173934ms]
Oct 29 13:20:49.410: INFO: Got endpoints: latency-svc-m2rjw [786.922309ms]
Oct 29 13:20:49.426: INFO: Got endpoints: latency-svc-wkf6j [752.414866ms]
Oct 29 13:20:49.430: INFO: Created: latency-svc-s9ll6
Oct 29 13:20:49.444: INFO: Created: latency-svc-l65tg
Oct 29 13:20:49.460: INFO: Created: latency-svc-c8wl5
Oct 29 13:20:49.472: INFO: Got endpoints: latency-svc-n2gk4 [749.262359ms]
Oct 29 13:20:49.501: INFO: Created: latency-svc-rdf5c
Oct 29 13:20:49.528: INFO: Got endpoints: latency-svc-f977k [754.121183ms]
Oct 29 13:20:49.551: INFO: Created: latency-svc-sjgsf
Oct 29 13:20:49.572: INFO: Got endpoints: latency-svc-l8sgv [748.161587ms]
Oct 29 13:20:49.593: INFO: Created: latency-svc-hbx9v
Oct 29 13:20:49.624: INFO: Got endpoints: latency-svc-f5nnt [737.64824ms]
Oct 29 13:20:49.644: INFO: Created: latency-svc-ssrrk
Oct 29 13:20:49.674: INFO: Got endpoints: latency-svc-sg4fx [746.046759ms]
Oct 29 13:20:49.695: INFO: Created: latency-svc-m744k
Oct 29 13:20:49.727: INFO: Got endpoints: latency-svc-hqnwf [751.650294ms]
Oct 29 13:20:49.751: INFO: Created: latency-svc-dghzl
Oct 29 13:20:49.774: INFO: Got endpoints: latency-svc-s45d6 [750.905863ms]
Oct 29 13:20:49.800: INFO: Created: latency-svc-wd5tb
Oct 29 13:20:49.829: INFO: Got endpoints: latency-svc-jfdxk [756.260707ms]
Oct 29 13:20:49.856: INFO: Created: latency-svc-npvqv
Oct 29 13:20:49.878: INFO: Got endpoints: latency-svc-jfk7g [755.401644ms]
Oct 29 13:20:49.902: INFO: Created: latency-svc-rbxhh
Oct 29 13:20:49.928: INFO: Got endpoints: latency-svc-jbvxd [754.682617ms]
Oct 29 13:20:49.949: INFO: Created: latency-svc-lvcjq
Oct 29 13:20:49.975: INFO: Got endpoints: latency-svc-5wxh9 [751.450478ms]
Oct 29 13:20:49.995: INFO: Created: latency-svc-w48mr
Oct 29 13:20:50.024: INFO: Got endpoints: latency-svc-7vjzg [750.012724ms]
Oct 29 13:20:50.049: INFO: Created: latency-svc-sjfdt
Oct 29 13:20:50.074: INFO: Got endpoints: latency-svc-s9ll6 [750.540368ms]
Oct 29 13:20:50.118: INFO: Created: latency-svc-tmrwl
Oct 29 13:20:50.123: INFO: Got endpoints: latency-svc-l65tg [712.773371ms]
Oct 29 13:20:50.147: INFO: Created: latency-svc-l8nwk
Oct 29 13:20:50.173: INFO: Got endpoints: latency-svc-c8wl5 [746.546247ms]
Oct 29 13:20:50.196: INFO: Created: latency-svc-nt7gr
Oct 29 13:20:50.224: INFO: Got endpoints: latency-svc-rdf5c [750.890042ms]
Oct 29 13:20:50.250: INFO: Created: latency-svc-hvdgj
Oct 29 13:20:50.274: INFO: Got endpoints: latency-svc-sjgsf [745.431678ms]
Oct 29 13:20:50.294: INFO: Created: latency-svc-d5mcg
Oct 29 13:20:50.324: INFO: Got endpoints: latency-svc-hbx9v [751.787324ms]
Oct 29 13:20:50.352: INFO: Created: latency-svc-5gp4l
Oct 29 13:20:50.374: INFO: Got endpoints: latency-svc-ssrrk [750.41002ms]
Oct 29 13:20:50.397: INFO: Created: latency-svc-v9zk7
Oct 29 13:20:50.424: INFO: Got endpoints: latency-svc-m744k [749.899713ms]
Oct 29 13:20:50.447: INFO: Created: latency-svc-dsf4b
Oct 29 13:20:50.474: INFO: Got endpoints: latency-svc-dghzl [747.744075ms]
Oct 29 13:20:50.496: INFO: Created: latency-svc-s2wk8
Oct 29 13:20:50.523: INFO: Got endpoints: latency-svc-wd5tb [748.16226ms]
Oct 29 13:20:50.544: INFO: Created: latency-svc-tcqw4
Oct 29 13:20:50.574: INFO: Got endpoints: latency-svc-npvqv [744.716592ms]
Oct 29 13:20:50.595: INFO: Created: latency-svc-jts4j
Oct 29 13:20:50.625: INFO: Got endpoints: latency-svc-rbxhh [746.631317ms]
Oct 29 13:20:50.650: INFO: Created: latency-svc-bvwgf
Oct 29 13:20:50.767: INFO: Got endpoints: latency-svc-lvcjq [839.069143ms]
Oct 29 13:20:50.770: INFO: Got endpoints: latency-svc-w48mr [794.703211ms]
Oct 29 13:20:50.774: INFO: Got endpoints: latency-svc-sjfdt [750.364726ms]
Oct 29 13:20:50.792: INFO: Created: latency-svc-t766d
Oct 29 13:20:50.805: INFO: Created: latency-svc-4ts92
Oct 29 13:20:50.824: INFO: Got endpoints: latency-svc-tmrwl [749.909196ms]
Oct 29 13:20:50.827: INFO: Created: latency-svc-2r5gr
Oct 29 13:20:50.847: INFO: Created: latency-svc-zqlnj
Oct 29 13:20:50.874: INFO: Got endpoints: latency-svc-l8nwk [750.939655ms]
Oct 29 13:20:50.891: INFO: Created: latency-svc-nzhxw
Oct 29 13:20:50.925: INFO: Got endpoints: latency-svc-nt7gr [751.744586ms]
Oct 29 13:20:50.982: INFO: Got endpoints: latency-svc-hvdgj [758.014885ms]
Oct 29 13:20:50.993: INFO: Created: latency-svc-zhxb4
Oct 29 13:20:51.008: INFO: Created: latency-svc-mqp99
Oct 29 13:20:51.025: INFO: Got endpoints: latency-svc-d5mcg [750.954715ms]
Oct 29 13:20:51.049: INFO: Created: latency-svc-8l574
Oct 29 13:20:51.075: INFO: Got endpoints: latency-svc-5gp4l [750.68081ms]
Oct 29 13:20:51.102: INFO: Created: latency-svc-l9fg6
Oct 29 13:20:51.125: INFO: Got endpoints: latency-svc-v9zk7 [750.227585ms]
Oct 29 13:20:51.149: INFO: Created: latency-svc-wpx7v
Oct 29 13:20:51.174: INFO: Got endpoints: latency-svc-dsf4b [749.202552ms]
Oct 29 13:20:51.197: INFO: Created: latency-svc-2wgs4
Oct 29 13:20:51.225: INFO: Got endpoints: latency-svc-s2wk8 [750.107061ms]
Oct 29 13:20:51.247: INFO: Created: latency-svc-hzzpq
Oct 29 13:20:51.277: INFO: Got endpoints: latency-svc-tcqw4 [754.149868ms]
Oct 29 13:20:51.315: INFO: Created: latency-svc-vp4j2
Oct 29 13:20:51.322: INFO: Got endpoints: latency-svc-jts4j [747.740589ms]
Oct 29 13:20:51.348: INFO: Created: latency-svc-tkq6m
Oct 29 13:20:51.373: INFO: Got endpoints: latency-svc-bvwgf [748.712269ms]
Oct 29 13:20:51.400: INFO: Created: latency-svc-d9bt4
Oct 29 13:20:51.431: INFO: Got endpoints: latency-svc-t766d [664.542618ms]
Oct 29 13:20:51.477: INFO: Created: latency-svc-zbbh5
Oct 29 13:20:51.478: INFO: Got endpoints: latency-svc-4ts92 [708.488157ms]
Oct 29 13:20:51.524: INFO: Created: latency-svc-5dv52
Oct 29 13:20:51.525: INFO: Got endpoints: latency-svc-2r5gr [751.424949ms]
Oct 29 13:20:51.566: INFO: Created: latency-svc-xthmx
Oct 29 13:20:51.573: INFO: Got endpoints: latency-svc-zqlnj [749.569217ms]
Oct 29 13:20:51.599: INFO: Created: latency-svc-9k9pk
Oct 29 13:20:51.628: INFO: Got endpoints: latency-svc-nzhxw [754.499568ms]
Oct 29 13:20:51.673: INFO: Got endpoints: latency-svc-zhxb4 [747.3089ms]
Oct 29 13:20:51.724: INFO: Got endpoints: latency-svc-mqp99 [742.646201ms]
Oct 29 13:20:51.776: INFO: Got endpoints: latency-svc-8l574 [750.705839ms]
Oct 29 13:20:51.824: INFO: Got endpoints: latency-svc-l9fg6 [748.849898ms]
Oct 29 13:20:51.881: INFO: Got endpoints: latency-svc-wpx7v [756.721082ms]
Oct 29 13:20:51.923: INFO: Got endpoints: latency-svc-2wgs4 [748.785652ms]
Oct 29 13:20:51.974: INFO: Got endpoints: latency-svc-hzzpq [749.164919ms]
Oct 29 13:20:52.031: INFO: Got endpoints: latency-svc-vp4j2 [753.546483ms]
Oct 29 13:20:52.074: INFO: Got endpoints: latency-svc-tkq6m [751.675635ms]
Oct 29 13:20:52.133: INFO: Got endpoints: latency-svc-d9bt4 [759.728449ms]
Oct 29 13:20:52.174: INFO: Got endpoints: latency-svc-zbbh5 [742.307397ms]
Oct 29 13:20:52.223: INFO: Got endpoints: latency-svc-5dv52 [744.788655ms]
Oct 29 13:20:52.273: INFO: Got endpoints: latency-svc-xthmx [747.721138ms]
Oct 29 13:20:52.323: INFO: Got endpoints: latency-svc-9k9pk [750.099631ms]
Oct 29 13:20:52.324: INFO: Latencies: [31.300342ms 50.990901ms 55.523925ms 73.668761ms 102.819755ms 108.693365ms 129.002802ms 145.45176ms 171.076314ms 189.343872ms 211.050432ms 239.113671ms 269.162446ms 282.91596ms 310.402603ms 314.32435ms 322.904133ms 327.891848ms 332.998375ms 334.329947ms 334.874585ms 338.722976ms 343.770668ms 343.945405ms 344.020294ms 345.467086ms 347.468223ms 348.24772ms 348.673021ms 350.771671ms 350.792726ms 351.863846ms 364.151759ms 374.514036ms 379.180077ms 396.50385ms 402.529527ms 414.441234ms 419.068599ms 425.560152ms 430.495186ms 432.152388ms 432.837531ms 433.608778ms 435.374757ms 437.635958ms 438.711273ms 440.719688ms 441.008907ms 450.255513ms 462.897926ms 469.063029ms 474.852924ms 474.932957ms 476.572509ms 479.261536ms 486.288689ms 487.981614ms 489.310628ms 491.196836ms 491.862379ms 495.815093ms 498.678751ms 547.347903ms 561.438063ms 569.375265ms 573.887164ms 582.676833ms 584.384893ms 588.576542ms 592.512715ms 626.479703ms 646.426993ms 650.518197ms 664.542618ms 671.379204ms 687.760522ms 693.444766ms 708.488157ms 712.773371ms 720.24911ms 737.64824ms 741.583115ms 741.777995ms 742.307397ms 742.646201ms 743.229878ms 743.942619ms 744.425796ms 744.716592ms 744.788655ms 745.251362ms 745.431678ms 746.046759ms 746.370489ms 746.455573ms 746.546247ms 746.631317ms 746.922652ms 747.3089ms 747.609894ms 747.68353ms 747.720988ms 747.721138ms 747.740589ms 747.744075ms 747.80874ms 748.092577ms 748.115271ms 748.119273ms 748.161587ms 748.16226ms 748.206061ms 748.609041ms 748.658276ms 748.675165ms 748.712269ms 748.785652ms 748.849898ms 748.913384ms 748.944659ms 748.973615ms 749.000405ms 749.093645ms 749.149457ms 749.164919ms 749.184675ms 749.202552ms 749.262359ms 749.279017ms 749.334656ms 749.345826ms 749.468144ms 749.569217ms 749.651691ms 749.652343ms 749.654903ms 749.6696ms 749.857778ms 749.899713ms 749.909196ms 750.003302ms 750.012724ms 750.053289ms 750.054099ms 750.099631ms 750.107061ms 750.116185ms 750.123774ms 750.128707ms 750.173934ms 750.192049ms 750.227585ms 750.364726ms 750.41002ms 750.540368ms 750.622094ms 750.675543ms 750.68081ms 750.705839ms 750.745519ms 750.777881ms 750.890042ms 750.905863ms 750.939655ms 750.954715ms 751.040067ms 751.257156ms 751.388371ms 751.42092ms 751.424949ms 751.431302ms 751.446385ms 751.450478ms 751.509757ms 751.650294ms 751.675635ms 751.744586ms 751.787324ms 752.414866ms 753.190606ms 753.399831ms 753.546483ms 754.121183ms 754.149868ms 754.499568ms 754.651921ms 754.682617ms 754.799528ms 755.401644ms 756.036454ms 756.260707ms 756.622872ms 756.721082ms 758.014885ms 759.728449ms 775.482836ms 786.922309ms 794.703211ms 839.069143ms]
Oct 29 13:20:52.324: INFO: 50 %ile: 747.609894ms
Oct 29 13:20:52.324: INFO: 90 %ile: 753.190606ms
Oct 29 13:20:52.324: INFO: 99 %ile: 794.703211ms
Oct 29 13:20:52.324: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:20:52.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-xm6x7" for this suite.
Oct 29 13:21:12.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:21:12.422: INFO: namespace: e2e-tests-svc-latency-xm6x7, resource: bindings, ignored listing per whitelist
Oct 29 13:21:12.471: INFO: namespace e2e-tests-svc-latency-xm6x7 deletion completed in 20.138868766s

• [SLOW TEST:30.941 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:21:12.472: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 29 13:21:12.544: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-a,UID:8188a215-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471460,Generation:0,CreationTimestamp:2018-10-29 13:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 13:21:12.545: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-a,UID:8188a215-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471460,Generation:0,CreationTimestamp:2018-10-29 13:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 29 13:21:22.559: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-a,UID:8188a215-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471479,Generation:0,CreationTimestamp:2018-10-29 13:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 29 13:21:22.559: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-a,UID:8188a215-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471479,Generation:0,CreationTimestamp:2018-10-29 13:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 29 13:21:32.573: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-a,UID:8188a215-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471498,Generation:0,CreationTimestamp:2018-10-29 13:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 13:21:32.573: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-a,UID:8188a215-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471498,Generation:0,CreationTimestamp:2018-10-29 13:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 29 13:21:42.587: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-a,UID:8188a215-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471517,Generation:0,CreationTimestamp:2018-10-29 13:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 13:21:42.587: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-a,UID:8188a215-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471517,Generation:0,CreationTimestamp:2018-10-29 13:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 29 13:21:52.600: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-b,UID:9968574e-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471536,Generation:0,CreationTimestamp:2018-10-29 13:21:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 13:21:52.600: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-b,UID:9968574e-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471536,Generation:0,CreationTimestamp:2018-10-29 13:21:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 29 13:22:02.615: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-b,UID:9968574e-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471555,Generation:0,CreationTimestamp:2018-10-29 13:21:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 13:22:02.615: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t65fb,SelfLink:/api/v1/namespaces/e2e-tests-watch-t65fb/configmaps/e2e-watch-test-configmap-b,UID:9968574e-db7d-11e8-84e8-0a8bfd2d149c,ResourceVersion:471555,Generation:0,CreationTimestamp:2018-10-29 13:21:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:22:12.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-t65fb" for this suite.
Oct 29 13:22:18.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:22:18.654: INFO: namespace: e2e-tests-watch-t65fb, resource: bindings, ignored listing per whitelist
Oct 29 13:22:18.738: INFO: namespace e2e-tests-watch-t65fb deletion completed in 6.11325063s

• [SLOW TEST:66.266 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:22:18.738: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:22:18.823: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a90865ab-db7d-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-w6gcv" to be "success or failure"
Oct 29 13:22:18.831: INFO: Pod "downwardapi-volume-a90865ab-db7d-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.139472ms
Oct 29 13:22:20.835: INFO: Pod "downwardapi-volume-a90865ab-db7d-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012349031s
STEP: Saw pod success
Oct 29 13:22:20.835: INFO: Pod "downwardapi-volume-a90865ab-db7d-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:22:20.839: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downwardapi-volume-a90865ab-db7d-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:22:20.862: INFO: Waiting for pod downwardapi-volume-a90865ab-db7d-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:22:20.866: INFO: Pod downwardapi-volume-a90865ab-db7d-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:22:20.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w6gcv" for this suite.
Oct 29 13:22:26.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:22:26.947: INFO: namespace: e2e-tests-projected-w6gcv, resource: bindings, ignored listing per whitelist
Oct 29 13:22:26.981: INFO: namespace e2e-tests-projected-w6gcv deletion completed in 6.111494555s

• [SLOW TEST:8.243 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:22:26.981: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-9wpxn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9wpxn to expose endpoints map[]
Oct 29 13:22:27.062: INFO: Get endpoints failed (6.375143ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct 29 13:22:28.066: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9wpxn exposes endpoints map[] (1.010595639s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9wpxn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9wpxn to expose endpoints map[pod1:[80]]
Oct 29 13:22:30.095: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9wpxn exposes endpoints map[pod1:[80]] (2.021140356s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9wpxn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9wpxn to expose endpoints map[pod1:[80] pod2:[80]]
Oct 29 13:22:31.122: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9wpxn exposes endpoints map[pod1:[80] pod2:[80]] (1.021228364s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9wpxn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9wpxn to expose endpoints map[pod2:[80]]
Oct 29 13:22:32.150: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9wpxn exposes endpoints map[pod2:[80]] (1.019280232s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9wpxn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9wpxn to expose endpoints map[]
Oct 29 13:22:33.242: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9wpxn exposes endpoints map[] (1.084967646s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:22:33.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9wpxn" for this suite.
Oct 29 13:22:55.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:22:55.440: INFO: namespace: e2e-tests-services-9wpxn, resource: bindings, ignored listing per whitelist
Oct 29 13:22:55.460: INFO: namespace e2e-tests-services-9wpxn deletion completed in 22.176815652s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:28.479 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:22:55.460: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Oct 29 13:22:55.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 api-versions'
Oct 29 13:22:55.612: INFO: stderr: ""
Oct 29 13:22:55.612: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:22:55.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k7m69" for this suite.
Oct 29 13:23:01.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:23:01.753: INFO: namespace: e2e-tests-kubectl-k7m69, resource: bindings, ignored listing per whitelist
Oct 29 13:23:01.760: INFO: namespace e2e-tests-kubectl-k7m69 deletion completed in 6.14306473s

• [SLOW TEST:6.300 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:23:01.760: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c2abf233-db7d-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 13:23:01.839: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2acd0c5-db7d-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-v76h7" to be "success or failure"
Oct 29 13:23:01.845: INFO: Pod "pod-configmaps-c2acd0c5-db7d-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.603462ms
Oct 29 13:23:03.849: INFO: Pod "pod-configmaps-c2acd0c5-db7d-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009751119s
STEP: Saw pod success
Oct 29 13:23:03.849: INFO: Pod "pod-configmaps-c2acd0c5-db7d-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:23:03.852: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-configmaps-c2acd0c5-db7d-11e8-94a0-9e8b538e2da3 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 13:23:03.874: INFO: Waiting for pod pod-configmaps-c2acd0c5-db7d-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:23:03.877: INFO: Pod pod-configmaps-c2acd0c5-db7d-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:23:03.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v76h7" for this suite.
Oct 29 13:23:09.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:23:09.910: INFO: namespace: e2e-tests-configmap-v76h7, resource: bindings, ignored listing per whitelist
Oct 29 13:23:10.022: INFO: namespace e2e-tests-configmap-v76h7 deletion completed in 6.141583601s

• [SLOW TEST:8.262 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:23:10.023: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dt95w
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-dt95w
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-dt95w
Oct 29 13:23:10.123: INFO: Found 0 stateful pods, waiting for 1
Oct 29 13:23:20.133: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 29 13:23:20.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:23:20.355: INFO: stderr: ""
Oct 29 13:23:20.355: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:23:20.355: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:23:20.359: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 29 13:23:30.369: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 13:23:30.369: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 13:23:30.387: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct 29 13:23:30.387: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:30.387: INFO: 
Oct 29 13:23:30.387: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 29 13:23:31.392: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994351514s
Oct 29 13:23:32.397: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989941933s
Oct 29 13:23:33.401: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985287576s
Oct 29 13:23:34.405: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980852726s
Oct 29 13:23:35.411: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976373999s
Oct 29 13:23:36.415: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971046052s
Oct 29 13:23:37.420: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966575621s
Oct 29 13:23:38.424: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962123402s
Oct 29 13:23:39.429: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.759347ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-dt95w
Oct 29 13:23:40.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:23:40.653: INFO: stderr: ""
Oct 29 13:23:40.653: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:23:40.653: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:23:40.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:23:40.890: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Oct 29 13:23:40.891: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:23:40.891: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:23:40.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:23:41.097: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Oct 29 13:23:41.097: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:23:41.097: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:23:41.101: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 13:23:41.101: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 13:23:41.101: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 29 13:23:41.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:23:41.304: INFO: stderr: ""
Oct 29 13:23:41.304: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:23:41.304: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:23:41.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:23:41.510: INFO: stderr: ""
Oct 29 13:23:41.510: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:23:41.510: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:23:41.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:23:41.709: INFO: stderr: ""
Oct 29 13:23:41.709: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:23:41.709: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:23:41.709: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 13:23:41.713: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 29 13:23:51.726: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 13:23:51.726: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 13:23:51.727: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 13:23:51.738: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:51.738: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:51.738: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:51.738: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:51.738: INFO: 
Oct 29 13:23:51.738: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:23:52.742: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:52.742: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:52.743: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:52.743: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:52.743: INFO: 
Oct 29 13:23:52.743: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:23:53.747: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:53.747: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:53.747: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:53.747: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:53.747: INFO: 
Oct 29 13:23:53.747: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:23:54.759: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:54.759: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:54.759: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:54.759: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:54.759: INFO: 
Oct 29 13:23:54.759: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:23:55.763: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:55.763: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:55.763: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:55.763: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:55.764: INFO: 
Oct 29 13:23:55.764: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:23:56.768: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:56.768: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:56.768: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:56.768: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:56.768: INFO: 
Oct 29 13:23:56.768: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:23:57.773: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:57.773: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:57.773: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:57.773: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:57.773: INFO: 
Oct 29 13:23:57.773: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:23:58.777: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:58.777: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:58.777: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:58.777: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:58.777: INFO: 
Oct 29 13:23:58.777: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:23:59.782: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:23:59.782: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:23:59.782: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:59.782: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:23:59.782: INFO: 
Oct 29 13:23:59.782: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 13:24:00.786: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Oct 29 13:24:00.786: INFO: ss-0  ip-10-0-2-47.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:10 +0000 UTC  }]
Oct 29 13:24:00.786: INFO: ss-1  ip-10-0-1-140.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:24:00.786: INFO: ss-2  ip-10-0-1-140.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:23:30 +0000 UTC  }]
Oct 29 13:24:00.786: INFO: 
Oct 29 13:24:00.786: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-dt95w
Oct 29 13:24:01.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:24:01.916: INFO: rc: 1
Oct 29 13:24:01.916: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc421bad980 exit status 1 <nil> <nil> true [0xc4219a6d68 0xc4219a6d80 0xc4219a6d98] [0xc4219a6d68 0xc4219a6d80 0xc4219a6d98] [0xc4219a6d78 0xc4219a6d90] [0x8fd520 0x8fd520] 0xc4215bca20 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Oct 29 13:24:11.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:24:12.041: INFO: rc: 1
Oct 29 13:24:12.041: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f24150 exit status 1 <nil> <nil> true [0xc4219a6da0 0xc4219a6db8 0xc4219a6dd0] [0xc4219a6da0 0xc4219a6db8 0xc4219a6dd0] [0xc4219a6db0 0xc4219a6dc8] [0x8fd520 0x8fd520] 0xc4215bcc00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:24:22.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:24:22.123: INFO: rc: 1
Oct 29 13:24:22.123: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421a0db30 exit status 1 <nil> <nil> true [0xc420321810 0xc420321828 0xc420321840] [0xc420321810 0xc420321828 0xc420321840] [0xc420321820 0xc420321838] [0x8fd520 0x8fd520] 0xc421b3ad80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:24:32.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:24:32.202: INFO: rc: 1
Oct 29 13:24:32.202: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421a0def0 exit status 1 <nil> <nil> true [0xc420321848 0xc420321860 0xc420321878] [0xc420321848 0xc420321860 0xc420321878] [0xc420321858 0xc420321870] [0x8fd520 0x8fd520] 0xc421b3aea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:24:42.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:24:42.286: INFO: rc: 1
Oct 29 13:24:42.286: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f46300 exit status 1 <nil> <nil> true [0xc420321880 0xc420321898 0xc4203218b0] [0xc420321880 0xc420321898 0xc4203218b0] [0xc420321890 0xc4203218a8] [0x8fd520 0x8fd520] 0xc421b3afc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:24:52.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:24:52.362: INFO: rc: 1
Oct 29 13:24:52.362: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bac3c0 exit status 1 <nil> <nil> true [0xc420990038 0xc4209900a8 0xc4209900f8] [0xc420990038 0xc4209900a8 0xc4209900f8] [0xc420990098 0xc4209900c0] [0x8fd520 0x8fd520] 0xc42129e060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:25:02.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:25:02.445: INFO: rc: 1
Oct 29 13:25:02.445: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f003c0 exit status 1 <nil> <nil> true [0xc42000e010 0xc4200ca138 0xc4200ca258] [0xc42000e010 0xc4200ca138 0xc4200ca258] [0xc4200ca080 0xc4200ca248] [0x8fd520 0x8fd520] 0xc420cc00c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:25:12.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:25:12.534: INFO: rc: 1
Oct 29 13:25:12.534: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f00780 exit status 1 <nil> <nil> true [0xc4200ca278 0xc4200ca4a0 0xc4200ca548] [0xc4200ca278 0xc4200ca4a0 0xc4200ca548] [0xc4200ca450 0xc4200ca4f0] [0x8fd520 0x8fd520] 0xc420cc01e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:25:22.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:25:22.616: INFO: rc: 1
Oct 29 13:25:22.616: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f00b40 exit status 1 <nil> <nil> true [0xc4200ca5b0 0xc4200ca6f0 0xc4200ca790] [0xc4200ca5b0 0xc4200ca6f0 0xc4200ca790] [0xc4200ca6c8 0xc4200ca738] [0x8fd520 0x8fd520] 0xc420cc0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:25:32.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:25:32.696: INFO: rc: 1
Oct 29 13:25:32.696: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f00f00 exit status 1 <nil> <nil> true [0xc4200cbc78 0xc4200cbcf0 0xc4200cbd08] [0xc4200cbc78 0xc4200cbcf0 0xc4200cbd08] [0xc4200cbcd0 0xc4200cbd00] [0x8fd520 0x8fd520] 0xc420cc0420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:25:42.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:25:42.778: INFO: rc: 1
Oct 29 13:25:42.778: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bac810 exit status 1 <nil> <nil> true [0xc420990158 0xc4209901f0 0xc420990290] [0xc420990158 0xc4209901f0 0xc420990290] [0xc4209901e8 0xc420990268] [0x8fd520 0x8fd520] 0xc42129e180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:25:52.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:25:52.866: INFO: rc: 1
Oct 29 13:25:52.866: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f012f0 exit status 1 <nil> <nil> true [0xc4200cbd18 0xc4200cbd58 0xc4200cbd80] [0xc4200cbd18 0xc4200cbd58 0xc4200cbd80] [0xc4200cbd48 0xc4200cbd70] [0x8fd520 0x8fd520] 0xc420cc0540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:26:02.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:26:02.950: INFO: rc: 1
Oct 29 13:26:02.951: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bacc00 exit status 1 <nil> <nil> true [0xc4209902a8 0xc4209902f8 0xc420990348] [0xc4209902a8 0xc4209902f8 0xc420990348] [0xc4209902c8 0xc420990318] [0x8fd520 0x8fd520] 0xc42129e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:26:12.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:26:13.025: INFO: rc: 1
Oct 29 13:26:13.025: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f016e0 exit status 1 <nil> <nil> true [0xc4200cbd90 0xc4200cbdf0 0xc4200cbe10] [0xc4200cbd90 0xc4200cbdf0 0xc4200cbe10] [0xc4200cbdd8 0xc4200cbe08] [0x8fd520 0x8fd520] 0xc420cc0660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:26:23.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:26:23.106: INFO: rc: 1
Oct 29 13:26:23.106: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f01aa0 exit status 1 <nil> <nil> true [0xc4200cbe28 0xc4200cbe98 0xc4200cbf10] [0xc4200cbe28 0xc4200cbe98 0xc4200cbf10] [0xc4200cbe50 0xc4200cbee8] [0x8fd520 0x8fd520] 0xc420cc0780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:26:33.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:26:33.185: INFO: rc: 1
Oct 29 13:26:33.185: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f01e90 exit status 1 <nil> <nil> true [0xc4200cbf30 0xc4200cbf70 0xc4209b8450] [0xc4200cbf30 0xc4200cbf70 0xc4209b8450] [0xc4200cbf68 0xc4209b8448] [0x8fd520 0x8fd520] 0xc420cc0960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:26:43.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:26:43.267: INFO: rc: 1
Oct 29 13:26:43.267: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bad020 exit status 1 <nil> <nil> true [0xc420990368 0xc420990390 0xc4209903e0] [0xc420990368 0xc420990390 0xc4209903e0] [0xc420990388 0xc4209903c0] [0x8fd520 0x8fd520] 0xc42129e3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:26:53.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:26:53.345: INFO: rc: 1
Oct 29 13:26:53.345: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bac3f0 exit status 1 <nil> <nil> true [0xc4200ca138 0xc4200ca258 0xc4200ca450] [0xc4200ca138 0xc4200ca258 0xc4200ca450] [0xc4200ca248 0xc4200ca308] [0x8fd520 0x8fd520] 0xc42129e060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:27:03.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:27:03.429: INFO: rc: 1
Oct 29 13:27:03.429: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f003f0 exit status 1 <nil> <nil> true [0xc42000e010 0xc420990038 0xc4209900a8] [0xc42000e010 0xc420990038 0xc4209900a8] [0xc420990010 0xc420990098] [0x8fd520 0x8fd520] 0xc420cc00c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:27:13.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:27:13.509: INFO: rc: 1
Oct 29 13:27:13.509: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f00810 exit status 1 <nil> <nil> true [0xc4209900b8 0xc420990158 0xc4209901f0] [0xc4209900b8 0xc420990158 0xc4209901f0] [0xc4209900f8 0xc4209901e8] [0x8fd520 0x8fd520] 0xc420cc01e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:27:23.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:27:23.590: INFO: rc: 1
Oct 29 13:27:23.590: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bac7e0 exit status 1 <nil> <nil> true [0xc4200ca4a0 0xc4200ca548 0xc4200ca6c8] [0xc4200ca4a0 0xc4200ca548 0xc4200ca6c8] [0xc4200ca4f0 0xc4200ca650] [0x8fd520 0x8fd520] 0xc42129e180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:27:33.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:27:33.682: INFO: rc: 1
Oct 29 13:27:33.682: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bacbd0 exit status 1 <nil> <nil> true [0xc4200ca6f0 0xc4200ca790 0xc4200cbcd0] [0xc4200ca6f0 0xc4200ca790 0xc4200cbcd0] [0xc4200ca738 0xc4200cbc90] [0x8fd520 0x8fd520] 0xc42129e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:27:43.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:27:43.759: INFO: rc: 1
Oct 29 13:27:43.759: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f00c60 exit status 1 <nil> <nil> true [0xc420990240 0xc4209902a8 0xc4209902f8] [0xc420990240 0xc4209902a8 0xc4209902f8] [0xc420990290 0xc4209902c8] [0x8fd520 0x8fd520] 0xc420cc0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:27:53.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:27:53.839: INFO: rc: 1
Oct 29 13:27:53.839: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f01050 exit status 1 <nil> <nil> true [0xc420990300 0xc420990368 0xc420990390] [0xc420990300 0xc420990368 0xc420990390] [0xc420990348 0xc420990388] [0x8fd520 0x8fd520] 0xc420cc0420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:28:03.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:28:03.923: INFO: rc: 1
Oct 29 13:28:03.923: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bad050 exit status 1 <nil> <nil> true [0xc4200cbcf0 0xc4200cbd08 0xc4200cbd48] [0xc4200cbcf0 0xc4200cbd08 0xc4200cbd48] [0xc4200cbd00 0xc4200cbd40] [0x8fd520 0x8fd520] 0xc42129e3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:28:13.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:28:14.000: INFO: rc: 1
Oct 29 13:28:14.001: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bad5f0 exit status 1 <nil> <nil> true [0xc4200cbd58 0xc4200cbd80 0xc4200cbdd8] [0xc4200cbd58 0xc4200cbd80 0xc4200cbdd8] [0xc4200cbd70 0xc4200cbdc8] [0x8fd520 0x8fd520] 0xc42129e4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:28:24.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:28:24.084: INFO: rc: 1
Oct 29 13:28:24.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421bad9e0 exit status 1 <nil> <nil> true [0xc4200cbdf0 0xc4200cbe10 0xc4200cbe50] [0xc4200cbdf0 0xc4200cbe10 0xc4200cbe50] [0xc4200cbe08 0xc4200cbe40] [0x8fd520 0x8fd520] 0xc42129e600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:28:34.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:28:34.166: INFO: rc: 1
Oct 29 13:28:34.166: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421baddd0 exit status 1 <nil> <nil> true [0xc4200cbe98 0xc4200cbf10 0xc4200cbf68] [0xc4200cbe98 0xc4200cbf10 0xc4200cbf68] [0xc4200cbee8 0xc4200cbf40] [0x8fd520 0x8fd520] 0xc42129e720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:28:44.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:28:44.254: INFO: rc: 1
Oct 29 13:28:44.254: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f014a0 exit status 1 <nil> <nil> true [0xc4209903b0 0xc4209903f0 0xc420990428] [0xc4209903b0 0xc4209903f0 0xc420990428] [0xc4209903e0 0xc420990410] [0x8fd520 0x8fd520] 0xc420cc0540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:28:54.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:28:54.344: INFO: rc: 1
Oct 29 13:28:54.344: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f01890 exit status 1 <nil> <nil> true [0xc420990448 0xc4209904a0 0xc4209904c0] [0xc420990448 0xc4209904a0 0xc4209904c0] [0xc420990498 0xc4209904b8] [0x8fd520 0x8fd520] 0xc420cc0600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Oct 29 13:29:04.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-dt95w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:29:04.494: INFO: rc: 1
Oct 29 13:29:04.494: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Oct 29 13:29:04.494: INFO: Scaling statefulset ss to 0
Oct 29 13:29:04.510: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 29 13:29:04.513: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dt95w
Oct 29 13:29:04.517: INFO: Scaling statefulset ss to 0
Oct 29 13:29:04.527: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 13:29:04.530: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:29:04.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dt95w" for this suite.
Oct 29 13:29:10.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:29:10.636: INFO: namespace: e2e-tests-statefulset-dt95w, resource: bindings, ignored listing per whitelist
Oct 29 13:29:10.670: INFO: namespace e2e-tests-statefulset-dt95w deletion completed in 6.121437406s

• [SLOW TEST:360.648 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:29:10.670: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 13:29:10.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-65h6z'
Oct 29 13:29:11.002: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Oct 29 13:29:11.002: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct 29 13:29:11.008: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Oct 29 13:29:11.014: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 29 13:29:11.032: INFO: scanned /root for discovery docs: <nil>
Oct 29 13:29:11.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-65h6z'
Oct 29 13:29:26.841: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 29 13:29:26.841: INFO: stdout: "Created e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc\nScaling up e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 29 13:29:26.841: INFO: stdout: "Created e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc\nScaling up e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 29 13:29:26.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-65h6z'
Oct 29 13:29:26.942: INFO: stderr: ""
Oct 29 13:29:26.942: INFO: stdout: "e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc-ssr8z "
Oct 29 13:29:26.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc-ssr8z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-65h6z'
Oct 29 13:29:27.034: INFO: stderr: ""
Oct 29 13:29:27.034: INFO: stdout: "true"
Oct 29 13:29:27.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc-ssr8z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-65h6z'
Oct 29 13:29:27.138: INFO: stderr: ""
Oct 29 13:29:27.138: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 29 13:29:27.138: INFO: e2e-test-nginx-rc-4b2f275b8764a967f0fd7aa27dde50bc-ssr8z is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Oct 29 13:29:27.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-65h6z'
Oct 29 13:29:27.231: INFO: stderr: ""
Oct 29 13:29:27.231: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:29:27.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-65h6z" for this suite.
Oct 29 13:29:33.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:29:33.288: INFO: namespace: e2e-tests-kubectl-65h6z, resource: bindings, ignored listing per whitelist
Oct 29 13:29:33.353: INFO: namespace e2e-tests-kubectl-65h6z deletion completed in 6.117192226s

• [SLOW TEST:22.682 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:29:33.353: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Oct 29 13:29:33.447: INFO: Waiting up to 5m0s for pod "var-expansion-ac1603af-db7e-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-var-expansion-zc298" to be "success or failure"
Oct 29 13:29:33.457: INFO: Pod "var-expansion-ac1603af-db7e-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.284598ms
Oct 29 13:29:35.461: INFO: Pod "var-expansion-ac1603af-db7e-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014328511s
STEP: Saw pod success
Oct 29 13:29:35.461: INFO: Pod "var-expansion-ac1603af-db7e-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:29:35.465: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod var-expansion-ac1603af-db7e-11e8-94a0-9e8b538e2da3 container dapi-container: <nil>
STEP: delete the pod
Oct 29 13:29:35.493: INFO: Waiting for pod var-expansion-ac1603af-db7e-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:29:35.497: INFO: Pod var-expansion-ac1603af-db7e-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:29:35.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-zc298" for this suite.
Oct 29 13:29:41.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:29:41.533: INFO: namespace: e2e-tests-var-expansion-zc298, resource: bindings, ignored listing per whitelist
Oct 29 13:29:41.625: INFO: namespace e2e-tests-var-expansion-zc298 deletion completed in 6.123051645s

• [SLOW TEST:8.272 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:29:41.625: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:29:41.723: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b104db0c-db7e-11e8-84e8-0a8bfd2d149c", Controller:(*bool)(0xc4227e9762), BlockOwnerDeletion:(*bool)(0xc4227e9763)}}
Oct 29 13:29:41.739: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b1033026-db7e-11e8-84e8-0a8bfd2d149c", Controller:(*bool)(0xc420f04dd6), BlockOwnerDeletion:(*bool)(0xc420f04dd7)}}
Oct 29 13:29:41.750: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b103e0e6-db7e-11e8-84e8-0a8bfd2d149c", Controller:(*bool)(0xc4227e9942), BlockOwnerDeletion:(*bool)(0xc4227e9943)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:29:46.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bj55x" for this suite.
Oct 29 13:29:52.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:29:52.832: INFO: namespace: e2e-tests-gc-bj55x, resource: bindings, ignored listing per whitelist
Oct 29 13:29:52.880: INFO: namespace e2e-tests-gc-bj55x deletion completed in 6.115092049s

• [SLOW TEST:11.254 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:29:52.880: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Oct 29 13:29:52.953: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-4qhcp" to be "success or failure"
Oct 29 13:29:52.957: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.813696ms
Oct 29 13:29:54.961: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.007844298s
Oct 29 13:29:56.965: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012275158s
STEP: Saw pod success
Oct 29 13:29:56.965: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 29 13:29:56.968: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 29 13:29:57.031: INFO: Waiting for pod pod-host-path-test to disappear
Oct 29 13:29:57.034: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:29:57.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-4qhcp" for this suite.
Oct 29 13:30:03.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:30:03.128: INFO: namespace: e2e-tests-hostpath-4qhcp, resource: bindings, ignored listing per whitelist
Oct 29 13:30:03.157: INFO: namespace e2e-tests-hostpath-4qhcp deletion completed in 6.118532957s

• [SLOW TEST:10.278 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:30:03.160: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-bdd9d0d0-db7e-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:30:03.247: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bddab469-db7e-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-wz5tq" to be "success or failure"
Oct 29 13:30:03.252: INFO: Pod "pod-projected-secrets-bddab469-db7e-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.340943ms
Oct 29 13:30:05.256: INFO: Pod "pod-projected-secrets-bddab469-db7e-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008394451s
STEP: Saw pod success
Oct 29 13:30:05.256: INFO: Pod "pod-projected-secrets-bddab469-db7e-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:30:05.259: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-projected-secrets-bddab469-db7e-11e8-94a0-9e8b538e2da3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:30:05.280: INFO: Waiting for pod pod-projected-secrets-bddab469-db7e-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:30:05.288: INFO: Pod pod-projected-secrets-bddab469-db7e-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:30:05.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wz5tq" for this suite.
Oct 29 13:30:11.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:30:11.380: INFO: namespace: e2e-tests-projected-wz5tq, resource: bindings, ignored listing per whitelist
Oct 29 13:30:11.414: INFO: namespace e2e-tests-projected-wz5tq deletion completed in 6.121700972s

• [SLOW TEST:8.254 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:30:11.414: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:30:11.537: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2c9a8af-db7e-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-xjdds" to be "success or failure"
Oct 29 13:30:11.543: INFO: Pod "downwardapi-volume-c2c9a8af-db7e-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.844173ms
Oct 29 13:30:13.547: INFO: Pod "downwardapi-volume-c2c9a8af-db7e-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009250469s
STEP: Saw pod success
Oct 29 13:30:13.547: INFO: Pod "downwardapi-volume-c2c9a8af-db7e-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:30:13.550: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-c2c9a8af-db7e-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:30:13.570: INFO: Waiting for pod downwardapi-volume-c2c9a8af-db7e-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:30:13.573: INFO: Pod downwardapi-volume-c2c9a8af-db7e-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:30:13.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xjdds" for this suite.
Oct 29 13:30:19.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:30:19.641: INFO: namespace: e2e-tests-projected-xjdds, resource: bindings, ignored listing per whitelist
Oct 29 13:30:19.701: INFO: namespace e2e-tests-projected-xjdds deletion completed in 6.1241272s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:30:19.702: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:30:19.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-td6b9" for this suite.
Oct 29 13:30:41.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:30:41.870: INFO: namespace: e2e-tests-pods-td6b9, resource: bindings, ignored listing per whitelist
Oct 29 13:30:41.910: INFO: namespace e2e-tests-pods-td6b9 deletion completed in 22.121080685s

• [SLOW TEST:22.208 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:30:41.910: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d4f23140-db7e-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 13:30:41.991: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d4f2dd0d-db7e-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-46wgm" to be "success or failure"
Oct 29 13:30:42.004: INFO: Pod "pod-projected-configmaps-d4f2dd0d-db7e-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.900056ms
Oct 29 13:30:44.009: INFO: Pod "pod-projected-configmaps-d4f2dd0d-db7e-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017106355s
STEP: Saw pod success
Oct 29 13:30:44.009: INFO: Pod "pod-projected-configmaps-d4f2dd0d-db7e-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:30:44.012: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-projected-configmaps-d4f2dd0d-db7e-11e8-94a0-9e8b538e2da3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 13:30:44.032: INFO: Waiting for pod pod-projected-configmaps-d4f2dd0d-db7e-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:30:44.035: INFO: Pod pod-projected-configmaps-d4f2dd0d-db7e-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:30:44.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-46wgm" for this suite.
Oct 29 13:30:50.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:30:50.093: INFO: namespace: e2e-tests-projected-46wgm, resource: bindings, ignored listing per whitelist
Oct 29 13:30:50.158: INFO: namespace e2e-tests-projected-46wgm deletion completed in 6.119255237s

• [SLOW TEST:8.248 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:30:50.159: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-b8cm4
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-b8cm4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-b8cm4
Oct 29 13:30:50.237: INFO: Found 0 stateful pods, waiting for 1
Oct 29 13:31:00.248: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 29 13:31:00.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-b8cm4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:31:00.464: INFO: stderr: ""
Oct 29 13:31:00.465: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:31:00.465: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:31:00.474: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 29 13:31:10.484: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 13:31:10.484: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 13:31:10.499: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999704s
Oct 29 13:31:11.515: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988164952s
Oct 29 13:31:12.519: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.980342286s
Oct 29 13:31:13.524: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.975864673s
Oct 29 13:31:14.528: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.971575047s
Oct 29 13:31:15.533: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.967197754s
Oct 29 13:31:16.537: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.962688219s
Oct 29 13:31:17.542: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.958544035s
Oct 29 13:31:18.546: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.953826339s
Oct 29 13:31:19.551: INFO: Verifying statefulset ss doesn't scale past 1 for another 949.427082ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-b8cm4
Oct 29 13:31:20.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-b8cm4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:31:20.775: INFO: stderr: ""
Oct 29 13:31:20.775: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:31:20.775: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:31:20.779: INFO: Found 1 stateful pods, waiting for 3
Oct 29 13:31:30.789: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 13:31:30.789: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 13:31:30.789: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 29 13:31:30.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-b8cm4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:31:31.009: INFO: stderr: ""
Oct 29 13:31:31.009: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:31:31.009: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:31:31.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-b8cm4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:31:31.257: INFO: stderr: ""
Oct 29 13:31:31.257: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:31:31.257: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:31:31.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-b8cm4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:31:31.456: INFO: stderr: ""
Oct 29 13:31:31.456: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:31:31.456: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:31:31.456: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 13:31:31.472: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Oct 29 13:31:41.503: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 13:31:41.503: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 13:31:41.503: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 13:31:41.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999477s
Oct 29 13:31:42.533: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995378569s
Oct 29 13:31:43.537: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990156355s
Oct 29 13:31:44.542: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985621362s
Oct 29 13:31:45.546: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981062534s
Oct 29 13:31:46.551: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976461874s
Oct 29 13:31:47.555: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97201856s
Oct 29 13:31:48.560: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967579365s
Oct 29 13:31:49.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962948192s
Oct 29 13:31:50.569: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.198008ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-b8cm4
Oct 29 13:31:51.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-b8cm4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:31:51.833: INFO: stderr: ""
Oct 29 13:31:51.833: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:31:51.833: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:31:51.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-b8cm4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:31:52.044: INFO: stderr: ""
Oct 29 13:31:52.044: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:31:52.044: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:31:52.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-b8cm4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:31:52.275: INFO: stderr: ""
Oct 29 13:31:52.275: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:31:52.275: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:31:52.275: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 29 13:32:12.304: INFO: Deleting all statefulset in ns e2e-tests-statefulset-b8cm4
Oct 29 13:32:12.315: INFO: Scaling statefulset ss to 0
Oct 29 13:32:12.329: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 13:32:12.332: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:32:12.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-b8cm4" for this suite.
Oct 29 13:32:18.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:32:18.386: INFO: namespace: e2e-tests-statefulset-b8cm4, resource: bindings, ignored listing per whitelist
Oct 29 13:32:18.467: INFO: namespace e2e-tests-statefulset-b8cm4 deletion completed in 6.115518291s

• [SLOW TEST:88.309 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:32:18.467: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Oct 29 13:32:18.542: INFO: Waiting up to 5m0s for pod "var-expansion-0e7f0c67-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-var-expansion-nprqq" to be "success or failure"
Oct 29 13:32:18.547: INFO: Pod "var-expansion-0e7f0c67-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.741524ms
Oct 29 13:32:20.552: INFO: Pod "var-expansion-0e7f0c67-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00985685s
STEP: Saw pod success
Oct 29 13:32:20.552: INFO: Pod "var-expansion-0e7f0c67-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:32:20.555: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod var-expansion-0e7f0c67-db7f-11e8-94a0-9e8b538e2da3 container dapi-container: <nil>
STEP: delete the pod
Oct 29 13:32:20.576: INFO: Waiting for pod var-expansion-0e7f0c67-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:32:20.579: INFO: Pod var-expansion-0e7f0c67-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:32:20.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-nprqq" for this suite.
Oct 29 13:32:26.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:32:26.645: INFO: namespace: e2e-tests-var-expansion-nprqq, resource: bindings, ignored listing per whitelist
Oct 29 13:32:26.697: INFO: namespace e2e-tests-var-expansion-nprqq deletion completed in 6.112434438s

• [SLOW TEST:8.230 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:32:26.697: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 29 13:32:26.766: INFO: Waiting up to 5m0s for pod "pod-1365fd54-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-gj44x" to be "success or failure"
Oct 29 13:32:26.778: INFO: Pod "pod-1365fd54-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.765568ms
Oct 29 13:32:28.783: INFO: Pod "pod-1365fd54-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0171465s
STEP: Saw pod success
Oct 29 13:32:28.783: INFO: Pod "pod-1365fd54-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:32:28.786: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-1365fd54-db7f-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:32:28.816: INFO: Waiting for pod pod-1365fd54-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:32:28.820: INFO: Pod pod-1365fd54-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:32:28.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gj44x" for this suite.
Oct 29 13:32:34.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:32:34.901: INFO: namespace: e2e-tests-emptydir-gj44x, resource: bindings, ignored listing per whitelist
Oct 29 13:32:34.960: INFO: namespace e2e-tests-emptydir-gj44x deletion completed in 6.135706479s

• [SLOW TEST:8.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:32:34.961: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 29 13:32:35.045: INFO: Waiting up to 5m0s for pod "pod-18550f98-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-cnwg6" to be "success or failure"
Oct 29 13:32:35.049: INFO: Pod "pod-18550f98-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.982355ms
Oct 29 13:32:37.053: INFO: Pod "pod-18550f98-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008153137s
Oct 29 13:32:39.057: INFO: Pod "pod-18550f98-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012442003s
STEP: Saw pod success
Oct 29 13:32:39.057: INFO: Pod "pod-18550f98-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:32:39.063: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-18550f98-db7f-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:32:39.082: INFO: Waiting for pod pod-18550f98-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:32:39.088: INFO: Pod pod-18550f98-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:32:39.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cnwg6" for this suite.
Oct 29 13:32:45.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:32:45.201: INFO: namespace: e2e-tests-emptydir-cnwg6, resource: bindings, ignored listing per whitelist
Oct 29 13:32:45.204: INFO: namespace e2e-tests-emptydir-cnwg6 deletion completed in 6.112341612s

• [SLOW TEST:10.244 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:32:45.205: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:33:05.297: INFO: Container started at 2018-10-29 13:32:46 +0000 UTC, pod became ready at 2018-10-29 13:33:03 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:33:05.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nwb6z" for this suite.
Oct 29 13:33:27.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:33:27.393: INFO: namespace: e2e-tests-container-probe-nwb6z, resource: bindings, ignored listing per whitelist
Oct 29 13:33:27.445: INFO: namespace e2e-tests-container-probe-nwb6z deletion completed in 22.143588626s

• [SLOW TEST:42.240 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:33:27.445: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:33:27.525: INFO: Waiting up to 5m0s for pod "downwardapi-volume-379d1dc6-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-f5h4j" to be "success or failure"
Oct 29 13:33:27.531: INFO: Pod "downwardapi-volume-379d1dc6-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.984639ms
Oct 29 13:33:29.535: INFO: Pod "downwardapi-volume-379d1dc6-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009961524s
STEP: Saw pod success
Oct 29 13:33:29.535: INFO: Pod "downwardapi-volume-379d1dc6-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:33:29.538: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-379d1dc6-db7f-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:33:29.563: INFO: Waiting for pod downwardapi-volume-379d1dc6-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:33:29.566: INFO: Pod downwardapi-volume-379d1dc6-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:33:29.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f5h4j" for this suite.
Oct 29 13:33:35.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:33:35.612: INFO: namespace: e2e-tests-downward-api-f5h4j, resource: bindings, ignored listing per whitelist
Oct 29 13:33:35.681: INFO: namespace e2e-tests-downward-api-f5h4j deletion completed in 6.111474314s

• [SLOW TEST:8.236 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:33:35.682: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wnsnh
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 29 13:33:35.794: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 29 13:33:57.889: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.3.105:8080/dial?request=hostName&protocol=udp&host=192.168.4.6&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-wnsnh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 13:33:57.889: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 13:33:58.010: INFO: Waiting for endpoints: map[]
Oct 29 13:33:58.014: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.3.105:8080/dial?request=hostName&protocol=udp&host=192.168.3.104&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-wnsnh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 13:33:58.015: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 13:33:58.214: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:33:58.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wnsnh" for this suite.
Oct 29 13:34:20.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:34:20.310: INFO: namespace: e2e-tests-pod-network-test-wnsnh, resource: bindings, ignored listing per whitelist
Oct 29 13:34:20.331: INFO: namespace e2e-tests-pod-network-test-wnsnh deletion completed in 22.113143666s

• [SLOW TEST:44.650 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:34:20.332: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:34:20.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-wmxcs" for this suite.
Oct 29 13:34:26.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:34:26.502: INFO: namespace: e2e-tests-services-wmxcs, resource: bindings, ignored listing per whitelist
Oct 29 13:34:26.521: INFO: namespace e2e-tests-services-wmxcs deletion completed in 6.115544284s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.189 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:34:26.521: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5ad1862a-db7f-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 13:34:26.593: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5ad2333d-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-djqk2" to be "success or failure"
Oct 29 13:34:26.599: INFO: Pod "pod-projected-configmaps-5ad2333d-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.471164ms
Oct 29 13:34:28.603: INFO: Pod "pod-projected-configmaps-5ad2333d-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00938826s
STEP: Saw pod success
Oct 29 13:34:28.603: INFO: Pod "pod-projected-configmaps-5ad2333d-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:34:28.606: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-projected-configmaps-5ad2333d-db7f-11e8-94a0-9e8b538e2da3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 13:34:28.631: INFO: Waiting for pod pod-projected-configmaps-5ad2333d-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:34:28.636: INFO: Pod pod-projected-configmaps-5ad2333d-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:34:28.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-djqk2" for this suite.
Oct 29 13:34:34.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:34:34.662: INFO: namespace: e2e-tests-projected-djqk2, resource: bindings, ignored listing per whitelist
Oct 29 13:34:34.755: INFO: namespace e2e-tests-projected-djqk2 deletion completed in 6.114736083s

• [SLOW TEST:8.234 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:34:34.755: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:34:34.829: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5fbacced-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-64jkf" to be "success or failure"
Oct 29 13:34:34.834: INFO: Pod "downwardapi-volume-5fbacced-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.31413ms
Oct 29 13:34:36.838: INFO: Pod "downwardapi-volume-5fbacced-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009365702s
STEP: Saw pod success
Oct 29 13:34:36.838: INFO: Pod "downwardapi-volume-5fbacced-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:34:36.842: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downwardapi-volume-5fbacced-db7f-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:34:36.880: INFO: Waiting for pod downwardapi-volume-5fbacced-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:34:36.886: INFO: Pod downwardapi-volume-5fbacced-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:34:36.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-64jkf" for this suite.
Oct 29 13:34:42.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:34:42.967: INFO: namespace: e2e-tests-projected-64jkf, resource: bindings, ignored listing per whitelist
Oct 29 13:34:43.014: INFO: namespace e2e-tests-projected-64jkf deletion completed in 6.123546261s

• [SLOW TEST:8.259 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:34:43.014: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Oct 29 13:34:43.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:43.255: INFO: stderr: ""
Oct 29 13:34:43.255: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 13:34:43.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:43.353: INFO: stderr: ""
Oct 29 13:34:43.353: INFO: stdout: "update-demo-nautilus-6xcd4 update-demo-nautilus-tmpm7 "
Oct 29 13:34:43.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-6xcd4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:43.453: INFO: stderr: ""
Oct 29 13:34:43.453: INFO: stdout: ""
Oct 29 13:34:43.453: INFO: update-demo-nautilus-6xcd4 is created but not running
Oct 29 13:34:48.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:48.544: INFO: stderr: ""
Oct 29 13:34:48.544: INFO: stdout: "update-demo-nautilus-6xcd4 update-demo-nautilus-tmpm7 "
Oct 29 13:34:48.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-6xcd4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:48.630: INFO: stderr: ""
Oct 29 13:34:48.630: INFO: stdout: "true"
Oct 29 13:34:48.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-6xcd4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:48.719: INFO: stderr: ""
Oct 29 13:34:48.719: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 13:34:48.719: INFO: validating pod update-demo-nautilus-6xcd4
Oct 29 13:34:48.725: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 13:34:48.725: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 13:34:48.725: INFO: update-demo-nautilus-6xcd4 is verified up and running
Oct 29 13:34:48.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-tmpm7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:48.810: INFO: stderr: ""
Oct 29 13:34:48.810: INFO: stdout: "true"
Oct 29 13:34:48.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-tmpm7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:48.906: INFO: stderr: ""
Oct 29 13:34:48.906: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 13:34:48.906: INFO: validating pod update-demo-nautilus-tmpm7
Oct 29 13:34:48.912: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 13:34:48.912: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 13:34:48.912: INFO: update-demo-nautilus-tmpm7 is verified up and running
STEP: using delete to clean up resources
Oct 29 13:34:48.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:49.002: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 13:34:49.002: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 29 13:34:49.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-dv8sl'
Oct 29 13:34:49.184: INFO: stderr: "No resources found.\n"
Oct 29 13:34:49.184: INFO: stdout: ""
Oct 29 13:34:49.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -l name=update-demo --namespace=e2e-tests-kubectl-dv8sl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 13:34:49.395: INFO: stderr: ""
Oct 29 13:34:49.395: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:34:49.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dv8sl" for this suite.
Oct 29 13:35:11.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:35:11.554: INFO: namespace: e2e-tests-kubectl-dv8sl, resource: bindings, ignored listing per whitelist
Oct 29 13:35:11.579: INFO: namespace e2e-tests-kubectl-dv8sl deletion completed in 22.169636875s

• [SLOW TEST:28.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:35:11.580: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Oct 29 13:35:11.651: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 29 13:35:11.661: INFO: Waiting for terminating namespaces to be deleted...
Oct 29 13:35:11.664: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-140.eu-west-1.compute.internal before test
Oct 29 13:35:11.674: INFO: coredns-576cbf47c7-96r4w from kube-system started at 2018-10-26 14:32:12 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.674: INFO: 	Container coredns ready: true, restart count 0
Oct 29 13:35:11.674: INFO: coredns-576cbf47c7-m8lhm from kube-system started at 2018-10-26 14:32:12 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.674: INFO: 	Container coredns ready: true, restart count 0
Oct 29 13:35:11.674: INFO: kube-proxy-7msnt from kube-system started at 2018-10-29 13:05:22 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.674: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 13:35:11.674: INFO: sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-vmft4 from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 13:35:11.674: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Oct 29 13:35:11.675: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 13:35:11.675: INFO: nginx-6c94d899fd-w6mz2 from default started at 2018-10-29 13:16:08 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.675: INFO: 	Container nginx ready: true, restart count 0
Oct 29 13:35:11.675: INFO: calico-node-gqfq5 from kube-system started at 2018-10-26 14:32:29 +0000 UTC (2 container statuses recorded)
Oct 29 13:35:11.675: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 13:35:11.675: INFO: 	Container install-cni ready: true, restart count 0
Oct 29 13:35:11.675: INFO: nginx-6c94d899fd-6x4kg from default started at 2018-10-29 13:16:15 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.675: INFO: 	Container nginx ready: true, restart count 0
Oct 29 13:35:11.675: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-2-47.eu-west-1.compute.internal before test
Oct 29 13:35:11.685: INFO: kube-proxy-j9xc7 from kube-system started at 2018-10-29 13:05:42 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.685: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 13:35:11.685: INFO: calico-node-vn4pl from kube-system started at 2018-10-26 14:32:29 +0000 UTC (2 container statuses recorded)
Oct 29 13:35:11.685: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 13:35:11.685: INFO: 	Container install-cni ready: true, restart count 0
Oct 29 13:35:11.685: INFO: sonobuoy from heptio-sonobuoy started at 2018-10-29 13:18:08 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.685: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 29 13:35:11.685: INFO: sonobuoy-e2e-job-e29a3530d05d487d from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 13:35:11.685: INFO: 	Container e2e ready: true, restart count 0
Oct 29 13:35:11.685: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 13:35:11.685: INFO: nginx-6c94d899fd-xqcqp from default started at 2018-10-29 13:16:08 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.685: INFO: 	Container nginx ready: true, restart count 0
Oct 29 13:35:11.685: INFO: nginx-6c94d899fd-cgsx2 from default started at 2018-10-29 13:16:15 +0000 UTC (1 container statuses recorded)
Oct 29 13:35:11.685: INFO: 	Container nginx ready: true, restart count 0
Oct 29 13:35:11.685: INFO: sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-bhgjz from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 13:35:11.685: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Oct 29 13:35:11.685: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156217ba5d13d66c], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:35:12.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-sxqfc" for this suite.
Oct 29 13:35:18.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:35:18.776: INFO: namespace: e2e-tests-sched-pred-sxqfc, resource: bindings, ignored listing per whitelist
Oct 29 13:35:18.839: INFO: namespace e2e-tests-sched-pred-sxqfc deletion completed in 6.123877886s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.259 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:35:18.839: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 29 13:35:18.937: INFO: Waiting up to 5m0s for pod "pod-7a053bc3-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-stvjf" to be "success or failure"
Oct 29 13:35:18.940: INFO: Pod "pod-7a053bc3-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.030645ms
Oct 29 13:35:20.944: INFO: Pod "pod-7a053bc3-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007137388s
STEP: Saw pod success
Oct 29 13:35:20.944: INFO: Pod "pod-7a053bc3-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:35:20.947: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-7a053bc3-db7f-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:35:20.969: INFO: Waiting for pod pod-7a053bc3-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:35:20.973: INFO: Pod pod-7a053bc3-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:35:20.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-stvjf" for this suite.
Oct 29 13:35:26.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:35:27.067: INFO: namespace: e2e-tests-emptydir-stvjf, resource: bindings, ignored listing per whitelist
Oct 29 13:35:27.104: INFO: namespace e2e-tests-emptydir-stvjf deletion completed in 6.123871681s

• [SLOW TEST:8.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:35:27.104: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:35:27.177: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7eee61f0-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-pwbf2" to be "success or failure"
Oct 29 13:35:27.185: INFO: Pod "downwardapi-volume-7eee61f0-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.490335ms
Oct 29 13:35:29.189: INFO: Pod "downwardapi-volume-7eee61f0-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012667323s
STEP: Saw pod success
Oct 29 13:35:29.189: INFO: Pod "downwardapi-volume-7eee61f0-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:35:29.192: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-7eee61f0-db7f-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:35:29.212: INFO: Waiting for pod downwardapi-volume-7eee61f0-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:35:29.224: INFO: Pod downwardapi-volume-7eee61f0-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:35:29.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pwbf2" for this suite.
Oct 29 13:35:35.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:35:35.340: INFO: namespace: e2e-tests-downward-api-pwbf2, resource: bindings, ignored listing per whitelist
Oct 29 13:35:35.340: INFO: namespace e2e-tests-downward-api-pwbf2 deletion completed in 6.111981176s

• [SLOW TEST:8.236 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:35:35.340: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-83d71a05-db7f-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:35:35.452: INFO: Waiting up to 5m0s for pod "pod-secrets-83dd312b-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-g55jl" to be "success or failure"
Oct 29 13:35:35.465: INFO: Pod "pod-secrets-83dd312b-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.926234ms
Oct 29 13:35:37.476: INFO: Pod "pod-secrets-83dd312b-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02417878s
STEP: Saw pod success
Oct 29 13:35:37.476: INFO: Pod "pod-secrets-83dd312b-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:35:37.479: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-secrets-83dd312b-db7f-11e8-94a0-9e8b538e2da3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:35:37.501: INFO: Waiting for pod pod-secrets-83dd312b-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:35:37.507: INFO: Pod pod-secrets-83dd312b-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:35:37.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g55jl" for this suite.
Oct 29 13:35:43.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:35:43.557: INFO: namespace: e2e-tests-secrets-g55jl, resource: bindings, ignored listing per whitelist
Oct 29 13:35:43.627: INFO: namespace e2e-tests-secrets-g55jl deletion completed in 6.116305725s
STEP: Destroying namespace "e2e-tests-secret-namespace-ts46q" for this suite.
Oct 29 13:35:49.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:35:49.738: INFO: namespace: e2e-tests-secret-namespace-ts46q, resource: bindings, ignored listing per whitelist
Oct 29 13:35:49.741: INFO: namespace e2e-tests-secret-namespace-ts46q deletion completed in 6.113487566s

• [SLOW TEST:14.401 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:35:49.741: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-8c6cd911-db7f-11e8-94a0-9e8b538e2da3
Oct 29 13:35:49.818: INFO: Pod name my-hostname-basic-8c6cd911-db7f-11e8-94a0-9e8b538e2da3: Found 0 pods out of 1
Oct 29 13:35:54.822: INFO: Pod name my-hostname-basic-8c6cd911-db7f-11e8-94a0-9e8b538e2da3: Found 1 pods out of 1
Oct 29 13:35:54.822: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8c6cd911-db7f-11e8-94a0-9e8b538e2da3" are running
Oct 29 13:35:54.825: INFO: Pod "my-hostname-basic-8c6cd911-db7f-11e8-94a0-9e8b538e2da3-b6gqx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-10-29 13:35:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-10-29 13:35:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-10-29 13:35:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-10-29 13:35:49 +0000 UTC Reason: Message:}])
Oct 29 13:35:54.825: INFO: Trying to dial the pod
Oct 29 13:35:59.845: INFO: Controller my-hostname-basic-8c6cd911-db7f-11e8-94a0-9e8b538e2da3: Got expected result from replica 1 [my-hostname-basic-8c6cd911-db7f-11e8-94a0-9e8b538e2da3-b6gqx]: "my-hostname-basic-8c6cd911-db7f-11e8-94a0-9e8b538e2da3-b6gqx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:35:59.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-t2csk" for this suite.
Oct 29 13:36:05.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:36:05.869: INFO: namespace: e2e-tests-replication-controller-t2csk, resource: bindings, ignored listing per whitelist
Oct 29 13:36:05.967: INFO: namespace e2e-tests-replication-controller-t2csk deletion completed in 6.118302853s

• [SLOW TEST:16.226 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:36:05.967: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 29 13:36:06.043: INFO: Waiting up to 5m0s for pod "pod-9618cf01-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-s659g" to be "success or failure"
Oct 29 13:36:06.049: INFO: Pod "pod-9618cf01-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.311059ms
Oct 29 13:36:08.053: INFO: Pod "pod-9618cf01-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010742996s
STEP: Saw pod success
Oct 29 13:36:08.053: INFO: Pod "pod-9618cf01-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:36:08.057: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-9618cf01-db7f-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:36:08.087: INFO: Waiting for pod pod-9618cf01-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:36:08.097: INFO: Pod pod-9618cf01-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:36:08.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s659g" for this suite.
Oct 29 13:36:14.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:36:14.163: INFO: namespace: e2e-tests-emptydir-s659g, resource: bindings, ignored listing per whitelist
Oct 29 13:36:14.231: INFO: namespace e2e-tests-emptydir-s659g deletion completed in 6.129888229s

• [SLOW TEST:8.264 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:36:14.232: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:36:14.326: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b072d06-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-vfk7d" to be "success or failure"
Oct 29 13:36:14.333: INFO: Pod "downwardapi-volume-9b072d06-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.315204ms
Oct 29 13:36:16.337: INFO: Pod "downwardapi-volume-9b072d06-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011562138s
STEP: Saw pod success
Oct 29 13:36:16.337: INFO: Pod "downwardapi-volume-9b072d06-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:36:16.341: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-9b072d06-db7f-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:36:16.367: INFO: Waiting for pod downwardapi-volume-9b072d06-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:36:16.372: INFO: Pod downwardapi-volume-9b072d06-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:36:16.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vfk7d" for this suite.
Oct 29 13:36:22.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:36:22.465: INFO: namespace: e2e-tests-projected-vfk7d, resource: bindings, ignored listing per whitelist
Oct 29 13:36:22.491: INFO: namespace e2e-tests-projected-vfk7d deletion completed in 6.115442138s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:36:22.491: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9ff32273-db7f-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 13:36:22.576: INFO: Waiting up to 5m0s for pod "pod-configmaps-9ff3c8cf-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-9nxf9" to be "success or failure"
Oct 29 13:36:22.580: INFO: Pod "pod-configmaps-9ff3c8cf-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.863738ms
Oct 29 13:36:24.584: INFO: Pod "pod-configmaps-9ff3c8cf-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007950085s
STEP: Saw pod success
Oct 29 13:36:24.584: INFO: Pod "pod-configmaps-9ff3c8cf-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:36:24.587: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-configmaps-9ff3c8cf-db7f-11e8-94a0-9e8b538e2da3 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 13:36:24.612: INFO: Waiting for pod pod-configmaps-9ff3c8cf-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:36:24.615: INFO: Pod pod-configmaps-9ff3c8cf-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:36:24.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9nxf9" for this suite.
Oct 29 13:36:30.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:36:30.720: INFO: namespace: e2e-tests-configmap-9nxf9, resource: bindings, ignored listing per whitelist
Oct 29 13:36:30.742: INFO: namespace e2e-tests-configmap-9nxf9 deletion completed in 6.122464993s

• [SLOW TEST:8.251 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:36:30.743: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:36:30.818: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Oct 29 13:36:30.828: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-p769h/daemonsets","resourceVersion":"474425"},"items":null}

Oct 29 13:36:30.831: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-p769h/pods","resourceVersion":"474425"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:36:30.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-p769h" for this suite.
Oct 29 13:36:36.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:36:36.957: INFO: namespace: e2e-tests-daemonsets-p769h, resource: bindings, ignored listing per whitelist
Oct 29 13:36:36.966: INFO: namespace e2e-tests-daemonsets-p769h deletion completed in 6.121212117s

S [SKIPPING] [6.223 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Oct 29 13:36:30.818: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:36:36.966: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 29 13:36:41.083: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 13:36:41.092: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 13:36:43.092: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 13:36:43.096: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 13:36:45.092: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 13:36:45.097: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 13:36:47.092: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 13:36:47.097: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 13:36:49.092: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 13:36:49.097: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 13:36:51.092: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 13:36:51.102: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 13:36:53.093: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 13:36:53.097: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:36:53.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mpzfg" for this suite.
Oct 29 13:37:15.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:37:15.134: INFO: namespace: e2e-tests-container-lifecycle-hook-mpzfg, resource: bindings, ignored listing per whitelist
Oct 29 13:37:15.220: INFO: namespace e2e-tests-container-lifecycle-hook-mpzfg deletion completed in 22.111844946s

• [SLOW TEST:38.254 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:37:15.220: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:37:15.286: INFO: Creating deployment "nginx-deployment"
Oct 29 13:37:15.291: INFO: Waiting for observed generation 1
Oct 29 13:37:17.298: INFO: Waiting for all required pods to come up
Oct 29 13:37:17.302: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 29 13:37:19.315: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 29 13:37:19.322: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 29 13:37:19.330: INFO: Updating deployment nginx-deployment
Oct 29 13:37:19.330: INFO: Waiting for observed generation 2
Oct 29 13:37:21.338: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 29 13:37:21.341: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 29 13:37:21.344: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 29 13:37:21.355: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 29 13:37:21.355: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 29 13:37:21.358: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 29 13:37:21.364: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 29 13:37:21.364: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 29 13:37:21.372: INFO: Updating deployment nginx-deployment
Oct 29 13:37:21.372: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 29 13:37:21.387: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 29 13:37:21.392: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 29 13:37:21.468: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-gltbs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gltbs/deployments/nginx-deployment,UID:bf600c5f-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474783,Generation:3,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2018-10-29 13:37:19 +0000 UTC 2018-10-29 13:37:15 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2018-10-29 13:37:21 +0000 UTC 2018-10-29 13:37:21 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct 29 13:37:21.550: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-gltbs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gltbs/replicasets/nginx-deployment-7dc8f79789,UID:c1c92beb-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474769,Generation:3,CreationTimestamp:2018-10-29 13:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bf600c5f-db7f-11e8-84e8-0a8bfd2d149c 0xc422b6dd17 0xc422b6dd18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 13:37:21.550: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 29 13:37:21.550: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-gltbs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gltbs/replicasets/nginx-deployment-7f9675fb8b,UID:bf61d673-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474766,Generation:3,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bf600c5f-db7f-11e8-84e8-0a8bfd2d149c 0xc422b6e097 0xc422b6e098}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct 29 13:37:21.612: INFO: Pod "nginx-deployment-7dc8f79789-25szg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-25szg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-25szg,UID:c30a924f-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474817,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422d337f7 0xc422d337f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422d338d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422d338f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.613: INFO: Pod "nginx-deployment-7dc8f79789-28hjv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-28hjv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-28hjv,UID:c30a2d62-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474816,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422d33960 0xc422d33961}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422d339e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422d33a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.613: INFO: Pod "nginx-deployment-7dc8f79789-4ht8c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4ht8c,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-4ht8c,UID:c1cb9ea1-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474795,Generation:0,CreationTimestamp:2018-10-29 13:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.117/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422d33b10 0xc422d33b11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422d33b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422d33c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.117,StartTime:2018-10-29 13:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.613: INFO: Pod "nginx-deployment-7dc8f79789-bj9xg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bj9xg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-bj9xg,UID:c30aa1d5-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474815,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422d33d40 0xc422d33d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422d33db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422d33dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.614: INFO: Pod "nginx-deployment-7dc8f79789-dv7s8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dv7s8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-dv7s8,UID:c3055942-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474822,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422d33e50 0xc422d33e51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422d33ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422d33ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:,StartTime:2018-10-29 13:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.614: INFO: Pod "nginx-deployment-7dc8f79789-fgh8n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fgh8n,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-fgh8n,UID:c30ab24e-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474823,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422d33fc0 0xc422d33fc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edc6c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edc6e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.614: INFO: Pod "nginx-deployment-7dc8f79789-hdsgw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hdsgw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-hdsgw,UID:c3033c9c-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474799,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422edc750 0xc422edc751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edc7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edc7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:,StartTime:2018-10-29 13:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.614: INFO: Pod "nginx-deployment-7dc8f79789-j676x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-j676x,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-j676x,UID:c30549f8-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474800,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422edc8a0 0xc422edc8a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edc910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edc930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 13:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.614: INFO: Pod "nginx-deployment-7dc8f79789-k86tz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-k86tz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-k86tz,UID:c1d35fd5-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474756,Generation:0,CreationTimestamp:2018-10-29 13:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.22/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422edca00 0xc422edca01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edca70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edca90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 13:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.614: INFO: Pod "nginx-deployment-7dc8f79789-l956p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-l956p,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-l956p,UID:c1cb7653-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474752,Generation:0,CreationTimestamp:2018-10-29 13:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.20/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422edcb60 0xc422edcb61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edcbd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edcbf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 13:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.615: INFO: Pod "nginx-deployment-7dc8f79789-mtxrb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mtxrb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-mtxrb,UID:c1ca1483-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474778,Generation:0,CreationTimestamp:2018-10-29 13:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.116/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422edccc0 0xc422edccc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edcd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edcd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.116,StartTime:2018-10-29 13:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.615: INFO: Pod "nginx-deployment-7dc8f79789-vrnbh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vrnbh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-vrnbh,UID:c1d1d302-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474755,Generation:0,CreationTimestamp:2018-10-29 13:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.21/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422edce40 0xc422edce41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edceb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edced0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 13:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.615: INFO: Pod "nginx-deployment-7dc8f79789-vzc4n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vzc4n,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7dc8f79789-vzc4n,UID:c3164305-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474842,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c1c92beb-db7f-11e8-84e8-0a8bfd2d149c 0xc422edcf90 0xc422edcf91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.615: INFO: Pod "nginx-deployment-7f9675fb8b-28cj4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-28cj4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-28cj4,UID:c307864a-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474829,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edd090 0xc422edd091}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd0f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 13:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.616: INFO: Pod "nginx-deployment-7f9675fb8b-45nkz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-45nkz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-45nkz,UID:c30741dd-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474824,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edd1c0 0xc422edd1c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 13:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.616: INFO: Pod "nginx-deployment-7f9675fb8b-7vsmj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7vsmj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-7vsmj,UID:c30426c6-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474796,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edd2f0 0xc422edd2f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 13:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.616: INFO: Pod "nginx-deployment-7f9675fb8b-bdhmx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bdhmx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-bdhmx,UID:bf66b01b-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474663,Generation:0,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.16/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edd430 0xc422edd431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:192.168.4.16,StartTime:2018-10-29 13:37:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-10-29 13:37:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf containerd://e9f907622552903a6d748a253e8a43e6007857bd0a07f054cff73641aa1fa9fe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.616: INFO: Pod "nginx-deployment-7f9675fb8b-bmqp8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bmqp8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-bmqp8,UID:bf66c987-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474674,Generation:0,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.113/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edd580 0xc422edd581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.113,StartTime:2018-10-29 13:37:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-10-29 13:37:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf containerd://e52d4b38c8629fed975dbad89b3f96c7f4396e99263f23b3f987c1e83428798e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.616: INFO: Pod "nginx-deployment-7f9675fb8b-c2phc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-c2phc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-c2phc,UID:c314df5d-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474843,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edd6c0 0xc422edd6c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.616: INFO: Pod "nginx-deployment-7f9675fb8b-ccczw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ccczw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-ccczw,UID:bf65854f-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474671,Generation:0,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.112/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edd7c0 0xc422edd7c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.112,StartTime:2018-10-29 13:37:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-10-29 13:37:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf containerd://4a7b7c14531565bbb56cfe8b1e2e77962b5ac3ab95080363810edd3b8f15faf8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.616: INFO: Pod "nginx-deployment-7f9675fb8b-dsljh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dsljh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-dsljh,UID:c3043dc5-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474811,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edd900 0xc422edd901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edd960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edd980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:,StartTime:2018-10-29 13:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.616: INFO: Pod "nginx-deployment-7f9675fb8b-gg9sl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gg9sl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-gg9sl,UID:bf644698-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474679,Generation:0,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.111/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edda40 0xc422edda41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422eddaa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422eddac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.111,StartTime:2018-10-29 13:37:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-10-29 13:37:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf containerd://95cb3f8ae34dfd269a7bc3e4e2cde0ba28f9c95d82cd24bbc021f09d29897f62}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.617: INFO: Pod "nginx-deployment-7f9675fb8b-hjvhp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hjvhp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-hjvhp,UID:bf6adfad-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474658,Generation:0,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.18/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422eddb90 0xc422eddb91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422eddbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422eddc10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:192.168.4.18,StartTime:2018-10-29 13:37:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-10-29 13:37:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf containerd://1ef195faf5899e6ab4edd81bc77d0aade7e1f741c2d9c8e79411a57c82838664}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.617: INFO: Pod "nginx-deployment-7f9675fb8b-kgbrw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kgbrw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-kgbrw,UID:c307906b-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474814,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422eddcd0 0xc422eddcd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422eddd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422eddd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.617: INFO: Pod "nginx-deployment-7f9675fb8b-ltrb9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ltrb9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-ltrb9,UID:bf66de7c-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474683,Generation:0,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.114/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422edddd0 0xc422edddd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422edde30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422edde50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.114,StartTime:2018-10-29 13:37:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-10-29 13:37:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf containerd://136df2a0f217ea8ddd01c75fee7a47a3bb0afc061e67d37b181e33356ff38b67}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.617: INFO: Pod "nginx-deployment-7f9675fb8b-mtr2t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mtr2t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-mtr2t,UID:c315957f-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474841,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422eddf10 0xc422eddf11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422eddf70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422eddf90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.617: INFO: Pod "nginx-deployment-7f9675fb8b-mxfxj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mxfxj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-mxfxj,UID:c313621b-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474838,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422e42000 0xc422e42001}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e42080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e420a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.619: INFO: Pod "nginx-deployment-7f9675fb8b-q8g6g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-q8g6g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-q8g6g,UID:c3019b5b-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474788,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422e42110 0xc422e42111}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e421a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e421c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 13:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.624: INFO: Pod "nginx-deployment-7f9675fb8b-rhsbl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rhsbl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-rhsbl,UID:bf6af79e-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474676,Generation:0,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.115/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422e422b0 0xc422e422b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e42330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e42350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.115,StartTime:2018-10-29 13:37:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-10-29 13:37:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf containerd://437a9d242a3b9dd18de8f54b4f0bbda6ffb13f86b7afaaa4a1351f1a5af0dfe0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.625: INFO: Pod "nginx-deployment-7f9675fb8b-t2tnh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-t2tnh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-t2tnh,UID:c307857a-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474812,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422e42460 0xc422e42461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e424c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e424f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.626: INFO: Pod "nginx-deployment-7f9675fb8b-v9grt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-v9grt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-v9grt,UID:bf6573e0-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474661,Generation:0,CreationTimestamp:2018-10-29 13:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.15/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422e42590 0xc422e42591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e425f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e42910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:192.168.4.15,StartTime:2018-10-29 13:37:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-10-29 13:37:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf containerd://a44ee9c65e8f2dccab197120b68064f46db88a3f010ae1657284f078ec762f5b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.628: INFO: Pod "nginx-deployment-7f9675fb8b-wz6vm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wz6vm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-wz6vm,UID:c3143db6-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474839,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422e42a50 0xc422e42a51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e42d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e43890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 13:37:21.632: INFO: Pod "nginx-deployment-7f9675fb8b-z6xgr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z6xgr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gltbs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gltbs/pods/nginx-deployment-7f9675fb8b-z6xgr,UID:c314ab68-db7f-11e8-84e8-0a8bfd2d149c,ResourceVersion:474840,Generation:0,CreationTimestamp:2018-10-29 13:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b bf61d673-db7f-11e8-84e8-0a8bfd2d149c 0xc422e43900 0xc422e43901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hwpvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwpvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hwpvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e43960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e43980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 13:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:37:21.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gltbs" for this suite.
Oct 29 13:37:29.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:37:29.955: INFO: namespace: e2e-tests-deployment-gltbs, resource: bindings, ignored listing per whitelist
Oct 29 13:37:30.078: INFO: namespace e2e-tests-deployment-gltbs deletion completed in 8.429455291s

• [SLOW TEST:14.858 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:37:30.083: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zfwkv
Oct 29 13:37:34.420: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zfwkv
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 13:37:34.423: INFO: Initial restart count of pod liveness-exec is 0
Oct 29 13:38:20.551: INFO: Restart count of pod e2e-tests-container-probe-zfwkv/liveness-exec is now 1 (46.128384086s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:38:20.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zfwkv" for this suite.
Oct 29 13:38:26.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:38:26.604: INFO: namespace: e2e-tests-container-probe-zfwkv, resource: bindings, ignored listing per whitelist
Oct 29 13:38:26.699: INFO: namespace e2e-tests-container-probe-zfwkv deletion completed in 6.126396631s

• [SLOW TEST:56.619 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:38:26.699: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-e9fb80d2-db7f-11e8-94a0-9e8b538e2da3
STEP: Creating configMap with name cm-test-opt-upd-e9fb811b-db7f-11e8-94a0-9e8b538e2da3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e9fb80d2-db7f-11e8-94a0-9e8b538e2da3
STEP: Updating configmap cm-test-opt-upd-e9fb811b-db7f-11e8-94a0-9e8b538e2da3
STEP: Creating configMap with name cm-test-opt-create-e9fb8133-db7f-11e8-94a0-9e8b538e2da3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:38:32.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4cggh" for this suite.
Oct 29 13:38:54.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:38:54.931: INFO: namespace: e2e-tests-projected-4cggh, resource: bindings, ignored listing per whitelist
Oct 29 13:38:55.027: INFO: namespace e2e-tests-projected-4cggh deletion completed in 22.128358817s

• [SLOW TEST:28.328 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:38:55.028: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fadd9e69-db7f-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:38:55.110: INFO: Waiting up to 5m0s for pod "pod-secrets-fade45c5-db7f-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-wmdsb" to be "success or failure"
Oct 29 13:38:55.114: INFO: Pod "pod-secrets-fade45c5-db7f-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072116ms
Oct 29 13:38:57.124: INFO: Pod "pod-secrets-fade45c5-db7f-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014506012s
STEP: Saw pod success
Oct 29 13:38:57.124: INFO: Pod "pod-secrets-fade45c5-db7f-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:38:57.128: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-secrets-fade45c5-db7f-11e8-94a0-9e8b538e2da3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:38:57.148: INFO: Waiting for pod pod-secrets-fade45c5-db7f-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:38:57.158: INFO: Pod pod-secrets-fade45c5-db7f-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:38:57.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wmdsb" for this suite.
Oct 29 13:39:03.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:39:03.215: INFO: namespace: e2e-tests-secrets-wmdsb, resource: bindings, ignored listing per whitelist
Oct 29 13:39:03.285: INFO: namespace e2e-tests-secrets-wmdsb deletion completed in 6.116251713s

• [SLOW TEST:8.257 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:39:03.285: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:39:05.392: INFO: Waiting up to 5m0s for pod "client-envvars-00ffa962-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-pods-5v2nc" to be "success or failure"
Oct 29 13:39:05.400: INFO: Pod "client-envvars-00ffa962-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.145203ms
Oct 29 13:39:07.409: INFO: Pod "client-envvars-00ffa962-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017069916s
STEP: Saw pod success
Oct 29 13:39:07.409: INFO: Pod "client-envvars-00ffa962-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:39:07.413: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod client-envvars-00ffa962-db80-11e8-94a0-9e8b538e2da3 container env3cont: <nil>
STEP: delete the pod
Oct 29 13:39:07.435: INFO: Waiting for pod client-envvars-00ffa962-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:39:07.438: INFO: Pod client-envvars-00ffa962-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:39:07.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5v2nc" for this suite.
Oct 29 13:39:53.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:39:53.534: INFO: namespace: e2e-tests-pods-5v2nc, resource: bindings, ignored listing per whitelist
Oct 29 13:39:53.608: INFO: namespace e2e-tests-pods-5v2nc deletion completed in 46.165881938s

• [SLOW TEST:50.323 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:39:53.608: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-b6q2x in namespace e2e-tests-proxy-j2n9k
I1029 13:39:53.695720      18 runners.go:180] Created replication controller with name: proxy-service-b6q2x, namespace: e2e-tests-proxy-j2n9k, replica count: 1
I1029 13:39:54.746259      18 runners.go:180] proxy-service-b6q2x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 13:39:55.746448      18 runners.go:180] proxy-service-b6q2x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 13:39:56.746639      18 runners.go:180] proxy-service-b6q2x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 13:39:57.746824      18 runners.go:180] proxy-service-b6q2x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 13:39:58.747047      18 runners.go:180] proxy-service-b6q2x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 13:39:59.747218      18 runners.go:180] proxy-service-b6q2x Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 29 13:39:59.751: INFO: setup took 6.077832078s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 29 13:39:59.771: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 19.566457ms)
Oct 29 13:39:59.771: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 19.651472ms)
Oct 29 13:39:59.773: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 21.4065ms)
Oct 29 13:39:59.773: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 21.724606ms)
Oct 29 13:39:59.774: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 22.807629ms)
Oct 29 13:39:59.774: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 22.607827ms)
Oct 29 13:39:59.777: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 25.3248ms)
Oct 29 13:39:59.777: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 25.563665ms)
Oct 29 13:39:59.777: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 25.696491ms)
Oct 29 13:39:59.777: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 25.615354ms)
Oct 29 13:39:59.777: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 25.761426ms)
Oct 29 13:39:59.779: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 27.928546ms)
Oct 29 13:39:59.780: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 28.598245ms)
Oct 29 13:39:59.781: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 29.479736ms)
Oct 29 13:39:59.781: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 30.337608ms)
Oct 29 13:39:59.783: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 31.614928ms)
Oct 29 13:39:59.792: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 9.086546ms)
Oct 29 13:39:59.792: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 8.931671ms)
Oct 29 13:39:59.792: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.038841ms)
Oct 29 13:39:59.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 10.56444ms)
Oct 29 13:39:59.796: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 12.538244ms)
Oct 29 13:39:59.796: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 12.623637ms)
Oct 29 13:39:59.796: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 13.067626ms)
Oct 29 13:39:59.796: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 13.249784ms)
Oct 29 13:39:59.797: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 13.604719ms)
Oct 29 13:39:59.797: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 14.03439ms)
Oct 29 13:39:59.797: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 13.863277ms)
Oct 29 13:39:59.797: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 13.793867ms)
Oct 29 13:39:59.798: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 14.509864ms)
Oct 29 13:39:59.798: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 14.517186ms)
Oct 29 13:39:59.798: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 14.691672ms)
Oct 29 13:39:59.798: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 14.936532ms)
Oct 29 13:39:59.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 8.662908ms)
Oct 29 13:39:59.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 9.115415ms)
Oct 29 13:39:59.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 9.717994ms)
Oct 29 13:39:59.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 9.893493ms)
Oct 29 13:39:59.809: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 9.449261ms)
Oct 29 13:39:59.809: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 9.988942ms)
Oct 29 13:39:59.809: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 10.229665ms)
Oct 29 13:39:59.809: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 10.108454ms)
Oct 29 13:39:59.809: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 10.359526ms)
Oct 29 13:39:59.809: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 10.600413ms)
Oct 29 13:39:59.811: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 11.532902ms)
Oct 29 13:39:59.811: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 12.287148ms)
Oct 29 13:39:59.811: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 12.446956ms)
Oct 29 13:39:59.813: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 14.448816ms)
Oct 29 13:39:59.814: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 14.813213ms)
Oct 29 13:39:59.814: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 14.820044ms)
Oct 29 13:39:59.822: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 7.61943ms)
Oct 29 13:39:59.822: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 8.053223ms)
Oct 29 13:39:59.822: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 8.141143ms)
Oct 29 13:39:59.822: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 8.437831ms)
Oct 29 13:39:59.823: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 8.794597ms)
Oct 29 13:39:59.823: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 9.45241ms)
Oct 29 13:39:59.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 10.120614ms)
Oct 29 13:39:59.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 10.236454ms)
Oct 29 13:39:59.825: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 10.592516ms)
Oct 29 13:39:59.825: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 10.694527ms)
Oct 29 13:39:59.825: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 11.20517ms)
Oct 29 13:39:59.826: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 12.242612ms)
Oct 29 13:39:59.827: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 12.482653ms)
Oct 29 13:39:59.827: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 12.556312ms)
Oct 29 13:39:59.827: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 12.765296ms)
Oct 29 13:39:59.828: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 13.804628ms)
Oct 29 13:39:59.837: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 9.18116ms)
Oct 29 13:39:59.838: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 9.464889ms)
Oct 29 13:39:59.838: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 10.108077ms)
Oct 29 13:39:59.838: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.92824ms)
Oct 29 13:39:59.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 10.070936ms)
Oct 29 13:39:59.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 10.559704ms)
Oct 29 13:39:59.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 10.305162ms)
Oct 29 13:39:59.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 10.649885ms)
Oct 29 13:39:59.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 10.595561ms)
Oct 29 13:39:59.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 10.88315ms)
Oct 29 13:39:59.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 11.005206ms)
Oct 29 13:39:59.842: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 13.890749ms)
Oct 29 13:39:59.844: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 15.569973ms)
Oct 29 13:39:59.844: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 15.898874ms)
Oct 29 13:39:59.844: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 15.769631ms)
Oct 29 13:39:59.844: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 16.018659ms)
Oct 29 13:39:59.850: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 5.559338ms)
Oct 29 13:39:59.851: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 7.024516ms)
Oct 29 13:39:59.854: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.590129ms)
Oct 29 13:39:59.855: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 9.610947ms)
Oct 29 13:39:59.855: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 10.842278ms)
Oct 29 13:39:59.856: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 10.96151ms)
Oct 29 13:39:59.856: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 11.035687ms)
Oct 29 13:39:59.856: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 11.31286ms)
Oct 29 13:39:59.856: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 11.356511ms)
Oct 29 13:39:59.857: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 11.962422ms)
Oct 29 13:39:59.857: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 11.948796ms)
Oct 29 13:39:59.857: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 12.361213ms)
Oct 29 13:39:59.858: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 13.625016ms)
Oct 29 13:39:59.858: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 13.78078ms)
Oct 29 13:39:59.859: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 13.63736ms)
Oct 29 13:39:59.860: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 15.280472ms)
Oct 29 13:39:59.868: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 8.114542ms)
Oct 29 13:39:59.869: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 8.750872ms)
Oct 29 13:39:59.874: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 13.460182ms)
Oct 29 13:39:59.874: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 13.413437ms)
Oct 29 13:39:59.874: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 13.695722ms)
Oct 29 13:39:59.874: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 13.63167ms)
Oct 29 13:39:59.874: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 13.930165ms)
Oct 29 13:39:59.874: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 13.969876ms)
Oct 29 13:39:59.875: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 14.054575ms)
Oct 29 13:39:59.875: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 14.51025ms)
Oct 29 13:39:59.875: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 14.415572ms)
Oct 29 13:39:59.875: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 14.658751ms)
Oct 29 13:39:59.875: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 14.562955ms)
Oct 29 13:39:59.875: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 14.950124ms)
Oct 29 13:39:59.883: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 22.487467ms)
Oct 29 13:39:59.883: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 22.640925ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 9.189496ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 9.793658ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 9.52239ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 10.530162ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 9.709394ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 9.114586ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 9.272266ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.186777ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 9.508923ms)
Oct 29 13:39:59.894: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.594084ms)
Oct 29 13:39:59.896: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 11.171338ms)
Oct 29 13:39:59.896: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 11.220224ms)
Oct 29 13:39:59.897: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 12.777383ms)
Oct 29 13:39:59.898: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 13.031518ms)
Oct 29 13:39:59.899: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 13.900299ms)
Oct 29 13:39:59.899: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 14.018663ms)
Oct 29 13:39:59.909: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 8.406201ms)
Oct 29 13:39:59.909: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 9.805929ms)
Oct 29 13:39:59.909: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 10.025183ms)
Oct 29 13:39:59.911: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 11.814092ms)
Oct 29 13:39:59.912: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 12.034236ms)
Oct 29 13:39:59.912: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 11.804061ms)
Oct 29 13:39:59.912: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 11.37361ms)
Oct 29 13:39:59.912: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 11.505846ms)
Oct 29 13:39:59.912: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 12.398419ms)
Oct 29 13:39:59.912: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 12.278051ms)
Oct 29 13:39:59.912: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 11.865651ms)
Oct 29 13:39:59.912: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 11.907892ms)
Oct 29 13:39:59.913: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 13.342176ms)
Oct 29 13:39:59.913: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 13.315042ms)
Oct 29 13:39:59.913: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 13.424587ms)
Oct 29 13:39:59.913: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 13.37898ms)
Oct 29 13:39:59.925: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 7.9543ms)
Oct 29 13:39:59.925: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 11.276134ms)
Oct 29 13:39:59.925: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 11.058753ms)
Oct 29 13:39:59.925: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 11.582843ms)
Oct 29 13:39:59.925: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 11.782543ms)
Oct 29 13:39:59.925: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 8.577631ms)
Oct 29 13:39:59.925: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 11.546411ms)
Oct 29 13:39:59.926: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 12.016069ms)
Oct 29 13:39:59.926: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 12.525923ms)
Oct 29 13:39:59.926: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.538113ms)
Oct 29 13:39:59.926: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 12.269186ms)
Oct 29 13:39:59.927: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 10.522894ms)
Oct 29 13:39:59.929: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 14.335828ms)
Oct 29 13:39:59.929: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 14.299024ms)
Oct 29 13:39:59.929: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 11.801024ms)
Oct 29 13:39:59.929: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 12.317972ms)
Oct 29 13:39:59.936: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 6.841213ms)
Oct 29 13:39:59.936: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 6.445544ms)
Oct 29 13:39:59.936: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 7.46285ms)
Oct 29 13:39:59.936: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 7.392517ms)
Oct 29 13:39:59.936: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 7.093829ms)
Oct 29 13:39:59.936: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 7.019231ms)
Oct 29 13:39:59.939: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 9.658928ms)
Oct 29 13:39:59.939: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 8.742204ms)
Oct 29 13:39:59.940: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 9.702006ms)
Oct 29 13:39:59.940: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 10.057732ms)
Oct 29 13:39:59.940: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 10.520839ms)
Oct 29 13:39:59.940: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.935427ms)
Oct 29 13:39:59.942: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 12.697286ms)
Oct 29 13:39:59.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 14.716455ms)
Oct 29 13:39:59.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 14.836835ms)
Oct 29 13:39:59.945: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 15.270124ms)
Oct 29 13:39:59.964: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 18.15374ms)
Oct 29 13:39:59.964: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 18.269078ms)
Oct 29 13:39:59.964: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 18.538964ms)
Oct 29 13:39:59.964: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 18.202104ms)
Oct 29 13:39:59.964: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 18.378216ms)
Oct 29 13:39:59.964: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 18.147388ms)
Oct 29 13:39:59.964: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 19.028664ms)
Oct 29 13:39:59.965: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 18.205157ms)
Oct 29 13:39:59.965: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 19.062204ms)
Oct 29 13:39:59.965: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 18.82867ms)
Oct 29 13:39:59.965: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 20.081246ms)
Oct 29 13:39:59.965: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 20.009026ms)
Oct 29 13:39:59.965: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 18.890432ms)
Oct 29 13:39:59.965: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 19.392112ms)
Oct 29 13:39:59.965: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 20.190545ms)
Oct 29 13:39:59.966: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 19.810341ms)
Oct 29 13:39:59.977: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.050415ms)
Oct 29 13:39:59.979: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 11.910423ms)
Oct 29 13:39:59.979: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 11.326777ms)
Oct 29 13:39:59.979: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 12.320825ms)
Oct 29 13:39:59.980: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 12.729013ms)
Oct 29 13:39:59.980: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 12.14591ms)
Oct 29 13:39:59.980: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 12.923506ms)
Oct 29 13:39:59.980: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 13.608004ms)
Oct 29 13:39:59.980: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 13.278746ms)
Oct 29 13:39:59.980: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 13.88223ms)
Oct 29 13:39:59.981: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 13.773309ms)
Oct 29 13:39:59.981: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 13.386068ms)
Oct 29 13:39:59.983: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 15.009598ms)
Oct 29 13:39:59.983: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 16.212954ms)
Oct 29 13:39:59.983: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 15.81333ms)
Oct 29 13:39:59.983: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 16.513592ms)
Oct 29 13:39:59.992: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 8.965578ms)
Oct 29 13:39:59.993: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 9.183157ms)
Oct 29 13:39:59.993: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 9.366743ms)
Oct 29 13:39:59.993: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 9.317012ms)
Oct 29 13:39:59.993: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 8.900529ms)
Oct 29 13:39:59.993: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 9.29292ms)
Oct 29 13:39:59.994: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.498456ms)
Oct 29 13:39:59.994: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 10.259859ms)
Oct 29 13:39:59.994: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 10.015895ms)
Oct 29 13:39:59.994: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 10.097639ms)
Oct 29 13:39:59.996: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 12.05832ms)
Oct 29 13:40:00.001: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 17.163033ms)
Oct 29 13:40:00.001: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 16.95119ms)
Oct 29 13:40:00.001: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 17.108949ms)
Oct 29 13:40:00.001: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 17.100296ms)
Oct 29 13:40:00.001: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 16.814754ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 10.848179ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 10.756043ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 10.2316ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 11.108738ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 10.880287ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 10.040915ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 10.769203ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 10.134995ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 10.708262ms)
Oct 29 13:40:00.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 10.585107ms)
Oct 29 13:40:00.018: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 11.281772ms)
Oct 29 13:40:00.020: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 13.688834ms)
Oct 29 13:40:00.022: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 15.597608ms)
Oct 29 13:40:00.022: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 15.301486ms)
Oct 29 13:40:00.022: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 15.526345ms)
Oct 29 13:40:00.022: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 15.90553ms)
Oct 29 13:40:00.029: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 6.617548ms)
Oct 29 13:40:00.031: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 8.573751ms)
Oct 29 13:40:00.031: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 8.621854ms)
Oct 29 13:40:00.031: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.267994ms)
Oct 29 13:40:00.031: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 9.213841ms)
Oct 29 13:40:00.031: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 9.121455ms)
Oct 29 13:40:00.032: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 9.137273ms)
Oct 29 13:40:00.032: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.451912ms)
Oct 29 13:40:00.032: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 9.685943ms)
Oct 29 13:40:00.032: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 9.677808ms)
Oct 29 13:40:00.036: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 13.341848ms)
Oct 29 13:40:00.037: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 15.02772ms)
Oct 29 13:40:00.037: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 15.208439ms)
Oct 29 13:40:00.037: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 15.218663ms)
Oct 29 13:40:00.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 15.523945ms)
Oct 29 13:40:00.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 15.471562ms)
Oct 29 13:40:00.045: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 7.19613ms)
Oct 29 13:40:00.049: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 11.162722ms)
Oct 29 13:40:00.049: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 11.061649ms)
Oct 29 13:40:00.049: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 11.310659ms)
Oct 29 13:40:00.050: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 11.531379ms)
Oct 29 13:40:00.050: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 11.722924ms)
Oct 29 13:40:00.050: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 12.045296ms)
Oct 29 13:40:00.050: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 12.323978ms)
Oct 29 13:40:00.051: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 12.70535ms)
Oct 29 13:40:00.051: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 13.035538ms)
Oct 29 13:40:00.051: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 13.405632ms)
Oct 29 13:40:00.053: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 14.853375ms)
Oct 29 13:40:00.053: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 14.5818ms)
Oct 29 13:40:00.053: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 15.168601ms)
Oct 29 13:40:00.053: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 15.411354ms)
Oct 29 13:40:00.053: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 15.312061ms)
Oct 29 13:40:00.060: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 6.453523ms)
Oct 29 13:40:00.065: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 11.251018ms)
Oct 29 13:40:00.065: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 11.839008ms)
Oct 29 13:40:00.066: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 12.028546ms)
Oct 29 13:40:00.066: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 12.008749ms)
Oct 29 13:40:00.066: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 12.256032ms)
Oct 29 13:40:00.066: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 12.504966ms)
Oct 29 13:40:00.067: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 12.865957ms)
Oct 29 13:40:00.067: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 13.209874ms)
Oct 29 13:40:00.067: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 13.504708ms)
Oct 29 13:40:00.068: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 13.919426ms)
Oct 29 13:40:00.068: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 14.936731ms)
Oct 29 13:40:00.068: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 14.773336ms)
Oct 29 13:40:00.068: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 14.733705ms)
Oct 29 13:40:00.069: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 15.252872ms)
Oct 29 13:40:00.069: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 15.41326ms)
Oct 29 13:40:00.078: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 9.264595ms)
Oct 29 13:40:00.079: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 9.238068ms)
Oct 29 13:40:00.079: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 9.039625ms)
Oct 29 13:40:00.079: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 9.560869ms)
Oct 29 13:40:00.079: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 9.431858ms)
Oct 29 13:40:00.079: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 9.971101ms)
Oct 29 13:40:00.080: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 10.51547ms)
Oct 29 13:40:00.080: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 10.386692ms)
Oct 29 13:40:00.080: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 10.476489ms)
Oct 29 13:40:00.080: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 10.393194ms)
Oct 29 13:40:00.081: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 11.870034ms)
Oct 29 13:40:00.081: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 11.757855ms)
Oct 29 13:40:00.084: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 14.404987ms)
Oct 29 13:40:00.086: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 16.043838ms)
Oct 29 13:40:00.086: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 16.073822ms)
Oct 29 13:40:00.086: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 15.980041ms)
Oct 29 13:40:00.090: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:1080/proxy/... (200; 4.571664ms)
Oct 29 13:40:00.093: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 7.207637ms)
Oct 29 13:40:00.093: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:460/proxy/: tls baz (200; 7.431956ms)
Oct 29 13:40:00.093: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 7.29137ms)
Oct 29 13:40:00.094: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:462/proxy/: tls qux (200; 8.091879ms)
Oct 29 13:40:00.095: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx/proxy/rewriteme"... (200; 8.717174ms)
Oct 29 13:40:00.095: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:162/proxy/: bar (200; 8.884796ms)
Oct 29 13:40:00.097: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/http:proxy-service-b6q2x-f79sx:160/proxy/: foo (200; 10.735226ms)
Oct 29 13:40:00.097: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/https:proxy-service-b6q2x-f79sx:443/proxy/... (200; 11.333648ms)
Oct 29 13:40:00.098: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname1/proxy/: foo (200; 11.813625ms)
Oct 29 13:40:00.098: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j2n9k/pods/proxy-service-b6q2x-f79sx:1080/proxy/rewri... (200; 11.656566ms)
Oct 29 13:40:00.100: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname2/proxy/: bar (200; 13.153024ms)
Oct 29 13:40:00.100: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/http:proxy-service-b6q2x:portname1/proxy/: foo (200; 13.49672ms)
Oct 29 13:40:00.100: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname1/proxy/: tls baz (200; 13.36291ms)
Oct 29 13:40:00.100: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/proxy-service-b6q2x:portname2/proxy/: bar (200; 13.707256ms)
Oct 29 13:40:00.100: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j2n9k/services/https:proxy-service-b6q2x:tlsportname2/proxy/: tls qux (200; 13.869603ms)
STEP: deleting { ReplicationController} proxy-service-b6q2x in namespace e2e-tests-proxy-j2n9k, will wait for the garbage collector to delete the pods
Oct 29 13:40:00.163: INFO: Deleting { ReplicationController} proxy-service-b6q2x took: 9.602524ms
Oct 29 13:40:00.263: INFO: Terminating { ReplicationController} proxy-service-b6q2x pods took: 100.201807ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:40:11.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j2n9k" for this suite.
Oct 29 13:40:17.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:40:18.100: INFO: namespace: e2e-tests-proxy-j2n9k, resource: bindings, ignored listing per whitelist
Oct 29 13:40:18.135: INFO: namespace e2e-tests-proxy-j2n9k deletion completed in 6.21844957s

• [SLOW TEST:24.527 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:40:18.135: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-2c66d6ae-db80-11e8-94a0-9e8b538e2da3
STEP: Creating secret with name secret-projected-all-test-volume-2c66d696-db80-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 29 13:40:18.219: INFO: Waiting up to 5m0s for pod "projected-volume-2c66d4f9-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-lzvq8" to be "success or failure"
Oct 29 13:40:18.223: INFO: Pod "projected-volume-2c66d4f9-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.254043ms
Oct 29 13:40:20.227: INFO: Pod "projected-volume-2c66d4f9-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007665497s
STEP: Saw pod success
Oct 29 13:40:20.227: INFO: Pod "projected-volume-2c66d4f9-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:40:20.230: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod projected-volume-2c66d4f9-db80-11e8-94a0-9e8b538e2da3 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 29 13:40:20.258: INFO: Waiting for pod projected-volume-2c66d4f9-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:40:20.269: INFO: Pod projected-volume-2c66d4f9-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:40:20.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lzvq8" for this suite.
Oct 29 13:40:26.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:40:26.382: INFO: namespace: e2e-tests-projected-lzvq8, resource: bindings, ignored listing per whitelist
Oct 29 13:40:26.399: INFO: namespace e2e-tests-projected-lzvq8 deletion completed in 6.125980023s

• [SLOW TEST:8.264 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:40:26.400: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-315b10d2-db80-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:40:26.526: INFO: Waiting up to 5m0s for pod "pod-secrets-315bc41b-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-mpnlg" to be "success or failure"
Oct 29 13:40:26.532: INFO: Pod "pod-secrets-315bc41b-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.216069ms
Oct 29 13:40:28.536: INFO: Pod "pod-secrets-315bc41b-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009342102s
STEP: Saw pod success
Oct 29 13:40:28.536: INFO: Pod "pod-secrets-315bc41b-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:40:28.539: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-secrets-315bc41b-db80-11e8-94a0-9e8b538e2da3 container secret-env-test: <nil>
STEP: delete the pod
Oct 29 13:40:28.566: INFO: Waiting for pod pod-secrets-315bc41b-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:40:28.569: INFO: Pod pod-secrets-315bc41b-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:40:28.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mpnlg" for this suite.
Oct 29 13:40:34.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:40:34.642: INFO: namespace: e2e-tests-secrets-mpnlg, resource: bindings, ignored listing per whitelist
Oct 29 13:40:34.689: INFO: namespace e2e-tests-secrets-mpnlg deletion completed in 6.115579344s

• [SLOW TEST:8.289 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:40:34.689: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-6d75l
Oct 29 13:40:40.811: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-6d75l
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 13:40:40.814: INFO: Initial restart count of pod liveness-http is 0
Oct 29 13:41:04.892: INFO: Restart count of pod e2e-tests-container-probe-6d75l/liveness-http is now 1 (24.077794317s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:41:04.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6d75l" for this suite.
Oct 29 13:41:10.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:41:11.015: INFO: namespace: e2e-tests-container-probe-6d75l, resource: bindings, ignored listing per whitelist
Oct 29 13:41:11.023: INFO: namespace e2e-tests-container-probe-6d75l deletion completed in 6.113633466s

• [SLOW TEST:36.334 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:41:11.023: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-4bed839a-db80-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:41:11.107: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4bee31a5-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-dzcc4" to be "success or failure"
Oct 29 13:41:11.112: INFO: Pod "pod-projected-secrets-4bee31a5-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.052838ms
Oct 29 13:41:13.122: INFO: Pod "pod-projected-secrets-4bee31a5-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014674588s
STEP: Saw pod success
Oct 29 13:41:13.122: INFO: Pod "pod-projected-secrets-4bee31a5-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:41:13.125: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-projected-secrets-4bee31a5-db80-11e8-94a0-9e8b538e2da3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:41:13.147: INFO: Waiting for pod pod-projected-secrets-4bee31a5-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:41:13.150: INFO: Pod pod-projected-secrets-4bee31a5-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:41:13.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dzcc4" for this suite.
Oct 29 13:41:19.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:41:19.225: INFO: namespace: e2e-tests-projected-dzcc4, resource: bindings, ignored listing per whitelist
Oct 29 13:41:19.269: INFO: namespace e2e-tests-projected-dzcc4 deletion completed in 6.113597746s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:41:19.269: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 29 13:41:19.337: INFO: Waiting up to 5m0s for pod "pod-50d5fbf6-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-kmrtc" to be "success or failure"
Oct 29 13:41:19.340: INFO: Pod "pod-50d5fbf6-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.392297ms
Oct 29 13:41:21.344: INFO: Pod "pod-50d5fbf6-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007451993s
STEP: Saw pod success
Oct 29 13:41:21.344: INFO: Pod "pod-50d5fbf6-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:41:21.348: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-50d5fbf6-db80-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:41:21.382: INFO: Waiting for pod pod-50d5fbf6-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:41:21.386: INFO: Pod pod-50d5fbf6-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:41:21.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kmrtc" for this suite.
Oct 29 13:41:27.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:41:27.498: INFO: namespace: e2e-tests-emptydir-kmrtc, resource: bindings, ignored listing per whitelist
Oct 29 13:41:27.504: INFO: namespace e2e-tests-emptydir-kmrtc deletion completed in 6.113651646s

• [SLOW TEST:8.234 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:41:27.504: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:41:27.578: INFO: (0) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.684177ms)
Oct 29 13:41:27.583: INFO: (1) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.012413ms)
Oct 29 13:41:27.587: INFO: (2) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.019813ms)
Oct 29 13:41:27.591: INFO: (3) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.964492ms)
Oct 29 13:41:27.595: INFO: (4) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.921468ms)
Oct 29 13:41:27.599: INFO: (5) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.827131ms)
Oct 29 13:41:27.602: INFO: (6) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.851903ms)
Oct 29 13:41:27.606: INFO: (7) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.914064ms)
Oct 29 13:41:27.610: INFO: (8) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.747857ms)
Oct 29 13:41:27.614: INFO: (9) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.975054ms)
Oct 29 13:41:27.618: INFO: (10) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.957758ms)
Oct 29 13:41:27.622: INFO: (11) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.991884ms)
Oct 29 13:41:27.626: INFO: (12) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.811649ms)
Oct 29 13:41:27.630: INFO: (13) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.860117ms)
Oct 29 13:41:27.634: INFO: (14) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.039677ms)
Oct 29 13:41:27.638: INFO: (15) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.095369ms)
Oct 29 13:41:27.642: INFO: (16) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.837217ms)
Oct 29 13:41:27.646: INFO: (17) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.207036ms)
Oct 29 13:41:27.650: INFO: (18) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.831028ms)
Oct 29 13:41:27.654: INFO: (19) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.954689ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:41:27.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wr2wv" for this suite.
Oct 29 13:41:33.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:41:33.730: INFO: namespace: e2e-tests-proxy-wr2wv, resource: bindings, ignored listing per whitelist
Oct 29 13:41:33.775: INFO: namespace e2e-tests-proxy-wr2wv deletion completed in 6.11679334s

• [SLOW TEST:6.271 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:41:33.775: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Oct 29 13:41:35.903: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:41:59.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-c2qvb" for this suite.
Oct 29 13:42:06.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:42:06.070: INFO: namespace: e2e-tests-namespaces-c2qvb, resource: bindings, ignored listing per whitelist
Oct 29 13:42:06.124: INFO: namespace e2e-tests-namespaces-c2qvb deletion completed in 6.144055185s
STEP: Destroying namespace "e2e-tests-nsdeletetest-49l24" for this suite.
Oct 29 13:42:06.128: INFO: Namespace e2e-tests-nsdeletetest-49l24 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-rv7cs" for this suite.
Oct 29 13:42:12.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:42:12.227: INFO: namespace: e2e-tests-nsdeletetest-rv7cs, resource: bindings, ignored listing per whitelist
Oct 29 13:42:12.252: INFO: namespace e2e-tests-nsdeletetest-rv7cs deletion completed in 6.124591082s

• [SLOW TEST:38.477 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:42:12.252: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:42:12.326: INFO: Waiting up to 5m0s for pod "downwardapi-volume-706b4668-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-jbchd" to be "success or failure"
Oct 29 13:42:12.332: INFO: Pod "downwardapi-volume-706b4668-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.047375ms
Oct 29 13:42:14.338: INFO: Pod "downwardapi-volume-706b4668-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011373071s
STEP: Saw pod success
Oct 29 13:42:14.338: INFO: Pod "downwardapi-volume-706b4668-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:42:14.342: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-706b4668-db80-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:42:14.373: INFO: Waiting for pod downwardapi-volume-706b4668-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:42:14.376: INFO: Pod downwardapi-volume-706b4668-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:42:14.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jbchd" for this suite.
Oct 29 13:42:20.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:42:20.484: INFO: namespace: e2e-tests-projected-jbchd, resource: bindings, ignored listing per whitelist
Oct 29 13:42:20.493: INFO: namespace e2e-tests-projected-jbchd deletion completed in 6.112282565s

• [SLOW TEST:8.240 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:42:20.493: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 29 13:42:24.614: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:24.619: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:26.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:26.629: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:28.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:28.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:30.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:30.626: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:32.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:32.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:34.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:34.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:36.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:36.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:38.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:38.629: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:40.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:40.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:42.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:42.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:44.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:44.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:46.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:46.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:48.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:48.623: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:50.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:50.629: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 13:42:52.619: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 13:42:52.623: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:42:52.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7xbmv" for this suite.
Oct 29 13:43:14.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:43:14.724: INFO: namespace: e2e-tests-container-lifecycle-hook-7xbmv, resource: bindings, ignored listing per whitelist
Oct 29 13:43:14.741: INFO: namespace e2e-tests-container-lifecycle-hook-7xbmv deletion completed in 22.113917745s

• [SLOW TEST:54.248 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:43:14.741: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2fwlj
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-2fwlj
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-2fwlj
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-2fwlj
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-2fwlj
Oct 29 13:43:16.944: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2fwlj, name: ss-0, uid: 9675e083-db80-11e8-84e8-0a8bfd2d149c, status phase: Pending. Waiting for statefulset controller to delete.
Oct 29 13:43:17.123: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2fwlj, name: ss-0, uid: 9675e083-db80-11e8-84e8-0a8bfd2d149c, status phase: Failed. Waiting for statefulset controller to delete.
Oct 29 13:43:17.139: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2fwlj, name: ss-0, uid: 9675e083-db80-11e8-84e8-0a8bfd2d149c, status phase: Failed. Waiting for statefulset controller to delete.
Oct 29 13:43:17.140: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-2fwlj
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-2fwlj
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-2fwlj and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 29 13:43:19.171: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2fwlj
Oct 29 13:43:19.174: INFO: Scaling statefulset ss to 0
Oct 29 13:43:39.191: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 13:43:39.195: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:43:39.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2fwlj" for this suite.
Oct 29 13:43:45.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:43:45.288: INFO: namespace: e2e-tests-statefulset-2fwlj, resource: bindings, ignored listing per whitelist
Oct 29 13:43:45.343: INFO: namespace e2e-tests-statefulset-2fwlj deletion completed in 6.117758314s

• [SLOW TEST:30.602 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:43:45.344: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a7e96be5-db80-11e8-94a0-9e8b538e2da3
STEP: Creating secret with name s-test-opt-upd-a7e96c31-db80-11e8-94a0-9e8b538e2da3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a7e96be5-db80-11e8-94a0-9e8b538e2da3
STEP: Updating secret s-test-opt-upd-a7e96c31-db80-11e8-94a0-9e8b538e2da3
STEP: Creating secret with name s-test-opt-create-a7e96c4c-db80-11e8-94a0-9e8b538e2da3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:43:51.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6fxqw" for this suite.
Oct 29 13:44:13.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:44:13.669: INFO: namespace: e2e-tests-projected-6fxqw, resource: bindings, ignored listing per whitelist
Oct 29 13:44:13.708: INFO: namespace e2e-tests-projected-6fxqw deletion completed in 22.119637956s

• [SLOW TEST:28.365 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:44:13.709: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 29 13:44:13.780: INFO: Waiting up to 5m0s for pod "pod-b8cff548-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-dt664" to be "success or failure"
Oct 29 13:44:13.786: INFO: Pod "pod-b8cff548-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.128828ms
Oct 29 13:44:15.790: INFO: Pod "pod-b8cff548-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009905668s
STEP: Saw pod success
Oct 29 13:44:15.790: INFO: Pod "pod-b8cff548-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:44:15.793: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-b8cff548-db80-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:44:15.815: INFO: Waiting for pod pod-b8cff548-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:44:15.818: INFO: Pod pod-b8cff548-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:44:15.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dt664" for this suite.
Oct 29 13:44:21.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:44:21.854: INFO: namespace: e2e-tests-emptydir-dt664, resource: bindings, ignored listing per whitelist
Oct 29 13:44:21.947: INFO: namespace e2e-tests-emptydir-dt664 deletion completed in 6.124634986s

• [SLOW TEST:8.238 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:44:21.947: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 29 13:44:22.014: INFO: Waiting up to 5m0s for pod "downward-api-bdb842a5-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-t4s7v" to be "success or failure"
Oct 29 13:44:22.017: INFO: Pod "downward-api-bdb842a5-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.113341ms
Oct 29 13:44:24.021: INFO: Pod "downward-api-bdb842a5-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007234091s
STEP: Saw pod success
Oct 29 13:44:24.021: INFO: Pod "downward-api-bdb842a5-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:44:24.025: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downward-api-bdb842a5-db80-11e8-94a0-9e8b538e2da3 container dapi-container: <nil>
STEP: delete the pod
Oct 29 13:44:24.050: INFO: Waiting for pod downward-api-bdb842a5-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:44:24.054: INFO: Pod downward-api-bdb842a5-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:44:24.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t4s7v" for this suite.
Oct 29 13:44:30.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:44:30.140: INFO: namespace: e2e-tests-downward-api-t4s7v, resource: bindings, ignored listing per whitelist
Oct 29 13:44:30.179: INFO: namespace e2e-tests-downward-api-t4s7v deletion completed in 6.121659602s

• [SLOW TEST:8.232 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:44:30.180: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 29 13:44:32.781: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c2a1257b-db80-11e8-94a0-9e8b538e2da3"
Oct 29 13:44:32.781: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c2a1257b-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-pods-cz4np" to be "terminated due to deadline exceeded"
Oct 29 13:44:32.784: INFO: Pod "pod-update-activedeadlineseconds-c2a1257b-db80-11e8-94a0-9e8b538e2da3": Phase="Running", Reason="", readiness=true. Elapsed: 3.236898ms
Oct 29 13:44:34.788: INFO: Pod "pod-update-activedeadlineseconds-c2a1257b-db80-11e8-94a0-9e8b538e2da3": Phase="Running", Reason="", readiness=true. Elapsed: 2.007741482s
Oct 29 13:44:36.793: INFO: Pod "pod-update-activedeadlineseconds-c2a1257b-db80-11e8-94a0-9e8b538e2da3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.012047233s
Oct 29 13:44:36.793: INFO: Pod "pod-update-activedeadlineseconds-c2a1257b-db80-11e8-94a0-9e8b538e2da3" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:44:36.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cz4np" for this suite.
Oct 29 13:44:42.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:44:42.880: INFO: namespace: e2e-tests-pods-cz4np, resource: bindings, ignored listing per whitelist
Oct 29 13:44:42.923: INFO: namespace e2e-tests-pods-cz4np deletion completed in 6.125728523s

• [SLOW TEST:12.743 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:44:42.924: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Oct 29 13:44:43.006: INFO: Waiting up to 5m0s for pod "client-containers-ca3b19a5-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-containers-zdxb7" to be "success or failure"
Oct 29 13:44:43.010: INFO: Pod "client-containers-ca3b19a5-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.660581ms
Oct 29 13:44:45.014: INFO: Pod "client-containers-ca3b19a5-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008629226s
STEP: Saw pod success
Oct 29 13:44:45.014: INFO: Pod "client-containers-ca3b19a5-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:44:45.017: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod client-containers-ca3b19a5-db80-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:44:45.047: INFO: Waiting for pod client-containers-ca3b19a5-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:44:45.051: INFO: Pod client-containers-ca3b19a5-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:44:45.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zdxb7" for this suite.
Oct 29 13:44:51.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:44:51.178: INFO: namespace: e2e-tests-containers-zdxb7, resource: bindings, ignored listing per whitelist
Oct 29 13:44:51.184: INFO: namespace e2e-tests-containers-zdxb7 deletion completed in 6.126349889s

• [SLOW TEST:8.260 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:44:51.184: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-lc2gq/configmap-test-cf26251a-db80-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 13:44:51.259: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf26d1e1-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-lc2gq" to be "success or failure"
Oct 29 13:44:51.265: INFO: Pod "pod-configmaps-cf26d1e1-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.456303ms
Oct 29 13:44:53.274: INFO: Pod "pod-configmaps-cf26d1e1-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015396459s
STEP: Saw pod success
Oct 29 13:44:53.275: INFO: Pod "pod-configmaps-cf26d1e1-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:44:53.277: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-configmaps-cf26d1e1-db80-11e8-94a0-9e8b538e2da3 container env-test: <nil>
STEP: delete the pod
Oct 29 13:44:53.299: INFO: Waiting for pod pod-configmaps-cf26d1e1-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:44:53.302: INFO: Pod pod-configmaps-cf26d1e1-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:44:53.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lc2gq" for this suite.
Oct 29 13:44:59.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:44:59.409: INFO: namespace: e2e-tests-configmap-lc2gq, resource: bindings, ignored listing per whitelist
Oct 29 13:44:59.418: INFO: namespace e2e-tests-configmap-lc2gq deletion completed in 6.112103281s

• [SLOW TEST:8.234 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:44:59.418: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d40ebc85-db80-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 13:44:59.502: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d4101bcc-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-hh6kr" to be "success or failure"
Oct 29 13:44:59.508: INFO: Pod "pod-projected-configmaps-d4101bcc-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.830423ms
Oct 29 13:45:01.524: INFO: Pod "pod-projected-configmaps-d4101bcc-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021631781s
STEP: Saw pod success
Oct 29 13:45:01.524: INFO: Pod "pod-projected-configmaps-d4101bcc-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:45:01.529: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-projected-configmaps-d4101bcc-db80-11e8-94a0-9e8b538e2da3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 13:45:01.562: INFO: Waiting for pod pod-projected-configmaps-d4101bcc-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:45:01.566: INFO: Pod pod-projected-configmaps-d4101bcc-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:45:01.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hh6kr" for this suite.
Oct 29 13:45:07.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:45:07.612: INFO: namespace: e2e-tests-projected-hh6kr, resource: bindings, ignored listing per whitelist
Oct 29 13:45:07.699: INFO: namespace e2e-tests-projected-hh6kr deletion completed in 6.128111936s

• [SLOW TEST:8.281 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:45:07.700: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d8ff9761-db80-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 13:45:07.786: INFO: Waiting up to 5m0s for pod "pod-configmaps-d9008bff-db80-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-69j8l" to be "success or failure"
Oct 29 13:45:07.790: INFO: Pod "pod-configmaps-d9008bff-db80-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.653342ms
Oct 29 13:45:09.794: INFO: Pod "pod-configmaps-d9008bff-db80-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007827103s
STEP: Saw pod success
Oct 29 13:45:09.794: INFO: Pod "pod-configmaps-d9008bff-db80-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:45:09.797: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-configmaps-d9008bff-db80-11e8-94a0-9e8b538e2da3 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 13:45:09.818: INFO: Waiting for pod pod-configmaps-d9008bff-db80-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:45:09.821: INFO: Pod pod-configmaps-d9008bff-db80-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:45:09.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-69j8l" for this suite.
Oct 29 13:45:15.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:45:15.938: INFO: namespace: e2e-tests-configmap-69j8l, resource: bindings, ignored listing per whitelist
Oct 29 13:45:15.941: INFO: namespace e2e-tests-configmap-69j8l deletion completed in 6.115542022s

• [SLOW TEST:8.242 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:45:15.942: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Oct 29 13:45:16.007: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 29 13:45:16.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:45:16.342: INFO: stderr: ""
Oct 29 13:45:16.342: INFO: stdout: "service/redis-slave created\n"
Oct 29 13:45:16.342: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 29 13:45:16.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:45:16.565: INFO: stderr: ""
Oct 29 13:45:16.565: INFO: stdout: "service/redis-master created\n"
Oct 29 13:45:16.565: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 29 13:45:16.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:45:16.771: INFO: stderr: ""
Oct 29 13:45:16.771: INFO: stdout: "service/frontend created\n"
Oct 29 13:45:16.771: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 29 13:45:16.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:45:16.983: INFO: stderr: ""
Oct 29 13:45:16.983: INFO: stdout: "deployment.extensions/frontend created\n"
Oct 29 13:45:16.983: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 29 13:45:16.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:45:17.176: INFO: stderr: ""
Oct 29 13:45:17.176: INFO: stdout: "deployment.extensions/redis-master created\n"
Oct 29 13:45:17.176: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 29 13:45:17.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:45:17.399: INFO: stderr: ""
Oct 29 13:45:17.399: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Oct 29 13:45:17.399: INFO: Waiting for all frontend pods to be Running.
Oct 29 13:45:22.450: INFO: Waiting for frontend to serve content.
Oct 29 13:45:22.465: INFO: Trying to add a new entry to the guestbook.
Oct 29 13:45:22.477: INFO: Verifying that added entry can be retrieved.
Oct 29 13:45:22.490: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:45:27.511: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:45:32.525: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:45:37.545: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:45:42.558: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:45:47.578: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:45:52.592: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:45:57.613: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:46:02.627: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:46:07.647: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:46:12.663: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 29 13:46:17.682: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Oct 29 13:46:22.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:46:22.812: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 13:46:22.812: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 13:46:22.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:46:22.943: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 13:46:22.943: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 13:46:22.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:46:23.065: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 13:46:23.065: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 13:46:23.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:46:23.164: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 13:46:23.164: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 13:46:23.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:46:23.371: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 13:46:23.371: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 13:46:23.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-267z7'
Oct 29 13:46:23.667: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 13:46:23.667: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:46:23.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-267z7" for this suite.
Oct 29 13:47:03.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:47:03.755: INFO: namespace: e2e-tests-kubectl-267z7, resource: bindings, ignored listing per whitelist
Oct 29 13:47:03.807: INFO: namespace e2e-tests-kubectl-267z7 deletion completed in 40.132728398s

• [SLOW TEST:107.866 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:47:03.808: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-x6nrn/secret-test-1e331928-db81-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:47:03.886: INFO: Waiting up to 5m0s for pod "pod-configmaps-1e33dab7-db81-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-x6nrn" to be "success or failure"
Oct 29 13:47:03.900: INFO: Pod "pod-configmaps-1e33dab7-db81-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.485456ms
Oct 29 13:47:05.904: INFO: Pod "pod-configmaps-1e33dab7-db81-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017651487s
STEP: Saw pod success
Oct 29 13:47:05.904: INFO: Pod "pod-configmaps-1e33dab7-db81-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:47:05.907: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-configmaps-1e33dab7-db81-11e8-94a0-9e8b538e2da3 container env-test: <nil>
STEP: delete the pod
Oct 29 13:47:05.939: INFO: Waiting for pod pod-configmaps-1e33dab7-db81-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:47:05.948: INFO: Pod pod-configmaps-1e33dab7-db81-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:47:05.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x6nrn" for this suite.
Oct 29 13:47:11.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:47:12.063: INFO: namespace: e2e-tests-secrets-x6nrn, resource: bindings, ignored listing per whitelist
Oct 29 13:47:12.080: INFO: namespace e2e-tests-secrets-x6nrn deletion completed in 6.127660946s

• [SLOW TEST:8.273 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:47:12.080: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-23208e26-db81-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:47:12.153: INFO: Waiting up to 5m0s for pod "pod-secrets-2321589b-db81-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-p2d4b" to be "success or failure"
Oct 29 13:47:12.158: INFO: Pod "pod-secrets-2321589b-db81-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.850214ms
Oct 29 13:47:14.169: INFO: Pod "pod-secrets-2321589b-db81-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015242493s
STEP: Saw pod success
Oct 29 13:47:14.169: INFO: Pod "pod-secrets-2321589b-db81-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:47:14.172: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-secrets-2321589b-db81-11e8-94a0-9e8b538e2da3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:47:14.198: INFO: Waiting for pod pod-secrets-2321589b-db81-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:47:14.202: INFO: Pod pod-secrets-2321589b-db81-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:47:14.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p2d4b" for this suite.
Oct 29 13:47:20.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:47:20.259: INFO: namespace: e2e-tests-secrets-p2d4b, resource: bindings, ignored listing per whitelist
Oct 29 13:47:20.328: INFO: namespace e2e-tests-secrets-p2d4b deletion completed in 6.117949676s

• [SLOW TEST:8.247 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:47:20.328: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:47:20.405: INFO: Waiting up to 5m0s for pod "downwardapi-volume-280c4ee6-db81-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-6qfhz" to be "success or failure"
Oct 29 13:47:20.412: INFO: Pod "downwardapi-volume-280c4ee6-db81-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.236725ms
Oct 29 13:47:22.417: INFO: Pod "downwardapi-volume-280c4ee6-db81-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011460899s
STEP: Saw pod success
Oct 29 13:47:22.417: INFO: Pod "downwardapi-volume-280c4ee6-db81-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:47:22.420: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downwardapi-volume-280c4ee6-db81-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:47:22.442: INFO: Waiting for pod downwardapi-volume-280c4ee6-db81-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:47:22.452: INFO: Pod downwardapi-volume-280c4ee6-db81-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:47:22.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6qfhz" for this suite.
Oct 29 13:47:28.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:47:28.564: INFO: namespace: e2e-tests-downward-api-6qfhz, resource: bindings, ignored listing per whitelist
Oct 29 13:47:28.574: INFO: namespace e2e-tests-downward-api-6qfhz deletion completed in 6.112999265s

• [SLOW TEST:8.246 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:47:28.575: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Oct 29 13:47:31.177: INFO: Successfully updated pod "labelsupdate2cf600d1-db81-11e8-94a0-9e8b538e2da3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:47:35.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r2zvc" for this suite.
Oct 29 13:47:57.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:47:57.297: INFO: namespace: e2e-tests-projected-r2zvc, resource: bindings, ignored listing per whitelist
Oct 29 13:47:57.334: INFO: namespace e2e-tests-projected-r2zvc deletion completed in 22.121621934s

• [SLOW TEST:28.759 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:47:57.334: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 13:47:57.408: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3e1aa493-db81-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-rjrbj" to be "success or failure"
Oct 29 13:47:57.413: INFO: Pod "downwardapi-volume-3e1aa493-db81-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.55493ms
Oct 29 13:47:59.417: INFO: Pod "downwardapi-volume-3e1aa493-db81-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008561356s
STEP: Saw pod success
Oct 29 13:47:59.417: INFO: Pod "downwardapi-volume-3e1aa493-db81-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:47:59.420: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downwardapi-volume-3e1aa493-db81-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 13:47:59.443: INFO: Waiting for pod downwardapi-volume-3e1aa493-db81-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:47:59.450: INFO: Pod downwardapi-volume-3e1aa493-db81-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:47:59.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rjrbj" for this suite.
Oct 29 13:48:05.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:48:05.478: INFO: namespace: e2e-tests-projected-rjrbj, resource: bindings, ignored listing per whitelist
Oct 29 13:48:05.574: INFO: namespace e2e-tests-projected-rjrbj deletion completed in 6.117866365s

• [SLOW TEST:8.239 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:48:05.574: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Oct 29 13:48:08.184: INFO: Successfully updated pod "annotationupdate43032ee9-db81-11e8-94a0-9e8b538e2da3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:48:12.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5jbq7" for this suite.
Oct 29 13:48:34.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:48:34.278: INFO: namespace: e2e-tests-projected-5jbq7, resource: bindings, ignored listing per whitelist
Oct 29 13:48:34.381: INFO: namespace e2e-tests-projected-5jbq7 deletion completed in 22.169501036s

• [SLOW TEST:28.807 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:48:34.381: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-c8nqz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 29 13:48:34.457: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 29 13:48:56.531: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.3.150:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-c8nqz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 13:48:56.531: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 13:48:56.667: INFO: Found all expected endpoints: [netserver-0]
Oct 29 13:48:56.671: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.4.49:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-c8nqz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 13:48:56.671: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 13:48:56.792: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:48:56.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-c8nqz" for this suite.
Oct 29 13:49:18.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:49:18.931: INFO: namespace: e2e-tests-pod-network-test-c8nqz, resource: bindings, ignored listing per whitelist
Oct 29 13:49:18.983: INFO: namespace e2e-tests-pod-network-test-c8nqz deletion completed in 22.186158858s

• [SLOW TEST:44.602 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:49:18.984: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qfzd4
Oct 29 13:49:21.064: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qfzd4
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 13:49:21.068: INFO: Initial restart count of pod liveness-http is 0
Oct 29 13:49:41.123: INFO: Restart count of pod e2e-tests-container-probe-qfzd4/liveness-http is now 1 (20.055277746s elapsed)
Oct 29 13:50:01.176: INFO: Restart count of pod e2e-tests-container-probe-qfzd4/liveness-http is now 2 (40.107777181s elapsed)
Oct 29 13:50:21.228: INFO: Restart count of pod e2e-tests-container-probe-qfzd4/liveness-http is now 3 (1m0.159852922s elapsed)
Oct 29 13:50:41.292: INFO: Restart count of pod e2e-tests-container-probe-qfzd4/liveness-http is now 4 (1m20.223842515s elapsed)
Oct 29 13:51:55.520: INFO: Restart count of pod e2e-tests-container-probe-qfzd4/liveness-http is now 5 (2m34.45211808s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:51:55.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qfzd4" for this suite.
Oct 29 13:52:01.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:52:01.645: INFO: namespace: e2e-tests-container-probe-qfzd4, resource: bindings, ignored listing per whitelist
Oct 29 13:52:02.015: INFO: namespace e2e-tests-container-probe-qfzd4 deletion completed in 6.465106993s

• [SLOW TEST:163.032 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:52:02.016: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 13:52:02.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-pstdv'
Oct 29 13:52:02.345: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Oct 29 13:52:02.345: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 29 13:52:04.420: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-cx49f]
Oct 29 13:52:04.420: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-cx49f" in namespace "e2e-tests-kubectl-pstdv" to be "running and ready"
Oct 29 13:52:04.423: INFO: Pod "e2e-test-nginx-rc-cx49f": Phase="Running", Reason="", readiness=true. Elapsed: 3.293221ms
Oct 29 13:52:04.423: INFO: Pod "e2e-test-nginx-rc-cx49f" satisfied condition "running and ready"
Oct 29 13:52:04.423: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-cx49f]
Oct 29 13:52:04.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pstdv'
Oct 29 13:52:04.533: INFO: stderr: ""
Oct 29 13:52:04.534: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Oct 29 13:52:04.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pstdv'
Oct 29 13:52:04.635: INFO: stderr: ""
Oct 29 13:52:04.635: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:52:04.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pstdv" for this suite.
Oct 29 13:52:26.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:52:26.682: INFO: namespace: e2e-tests-kubectl-pstdv, resource: bindings, ignored listing per whitelist
Oct 29 13:52:26.760: INFO: namespace e2e-tests-kubectl-pstdv deletion completed in 22.119926608s

• [SLOW TEST:24.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:52:26.760: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-deb244f7-db81-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:52:26.842: INFO: Waiting up to 5m0s for pod "pod-secrets-deb2ff0e-db81-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-zhcpp" to be "success or failure"
Oct 29 13:52:26.847: INFO: Pod "pod-secrets-deb2ff0e-db81-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.595541ms
Oct 29 13:52:28.873: INFO: Pod "pod-secrets-deb2ff0e-db81-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030185935s
STEP: Saw pod success
Oct 29 13:52:28.873: INFO: Pod "pod-secrets-deb2ff0e-db81-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:52:28.880: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-secrets-deb2ff0e-db81-11e8-94a0-9e8b538e2da3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:52:28.915: INFO: Waiting for pod pod-secrets-deb2ff0e-db81-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:52:28.918: INFO: Pod pod-secrets-deb2ff0e-db81-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:52:28.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zhcpp" for this suite.
Oct 29 13:52:34.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:52:34.991: INFO: namespace: e2e-tests-secrets-zhcpp, resource: bindings, ignored listing per whitelist
Oct 29 13:52:35.046: INFO: namespace e2e-tests-secrets-zhcpp deletion completed in 6.115084482s

• [SLOW TEST:8.286 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:52:35.046: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-e3a20a93-db81-11e8-94a0-9e8b538e2da3
STEP: Creating configMap with name cm-test-opt-upd-e3a20ad4-db81-11e8-94a0-9e8b538e2da3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e3a20a93-db81-11e8-94a0-9e8b538e2da3
STEP: Updating configmap cm-test-opt-upd-e3a20ad4-db81-11e8-94a0-9e8b538e2da3
STEP: Creating configMap with name cm-test-opt-create-e3a20aee-db81-11e8-94a0-9e8b538e2da3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:52:39.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5s2fv" for this suite.
Oct 29 13:52:59.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:52:59.297: INFO: namespace: e2e-tests-configmap-5s2fv, resource: bindings, ignored listing per whitelist
Oct 29 13:52:59.348: INFO: namespace e2e-tests-configmap-5s2fv deletion completed in 20.116614885s

• [SLOW TEST:24.302 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:52:59.348: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:52:59.412: INFO: Creating ReplicaSet my-hostname-basic-f21e1f96-db81-11e8-94a0-9e8b538e2da3
Oct 29 13:52:59.420: INFO: Pod name my-hostname-basic-f21e1f96-db81-11e8-94a0-9e8b538e2da3: Found 0 pods out of 1
Oct 29 13:53:04.424: INFO: Pod name my-hostname-basic-f21e1f96-db81-11e8-94a0-9e8b538e2da3: Found 1 pods out of 1
Oct 29 13:53:04.424: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f21e1f96-db81-11e8-94a0-9e8b538e2da3" is running
Oct 29 13:53:04.427: INFO: Pod "my-hostname-basic-f21e1f96-db81-11e8-94a0-9e8b538e2da3-ps4n6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-10-29 13:52:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-10-29 13:53:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-10-29 13:53:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-10-29 13:52:59 +0000 UTC Reason: Message:}])
Oct 29 13:53:04.428: INFO: Trying to dial the pod
Oct 29 13:53:09.446: INFO: Controller my-hostname-basic-f21e1f96-db81-11e8-94a0-9e8b538e2da3: Got expected result from replica 1 [my-hostname-basic-f21e1f96-db81-11e8-94a0-9e8b538e2da3-ps4n6]: "my-hostname-basic-f21e1f96-db81-11e8-94a0-9e8b538e2da3-ps4n6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:53:09.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-kxn9w" for this suite.
Oct 29 13:53:15.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:53:15.542: INFO: namespace: e2e-tests-replicaset-kxn9w, resource: bindings, ignored listing per whitelist
Oct 29 13:53:15.565: INFO: namespace e2e-tests-replicaset-kxn9w deletion completed in 6.11546296s

• [SLOW TEST:16.217 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:53:15.565: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hp4sl A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-hp4sl;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hp4sl A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-hp4sl;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hp4sl.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hp4sl.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hp4sl.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hp4sl.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-hp4sl.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hp4sl.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 213.46.111.10.in-addr.arpa. PTR)" && echo OK > /results/10.111.46.213_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 213.46.111.10.in-addr.arpa. PTR)" && echo OK > /results/10.111.46.213_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hp4sl A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-hp4sl;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hp4sl A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-hp4sl;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hp4sl.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hp4sl.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hp4sl.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-hp4sl.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hp4sl.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-hp4sl.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hp4sl.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 213.46.111.10.in-addr.arpa. PTR)" && echo OK > /results/10.111.46.213_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 213.46.111.10.in-addr.arpa. PTR)" && echo OK > /results/10.111.46.213_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 29 13:53:41.765: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:41.769: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:41.773: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-hp4sl from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:41.777: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-hp4sl from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:41.781: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-hp4sl.svc from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:41.784: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-hp4sl.svc from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:41.789: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:41.792: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:41.815: INFO: Lookups using e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-hp4sl jessie_tcp@dns-test-service.e2e-tests-dns-hp4sl jessie_udp@dns-test-service.e2e-tests-dns-hp4sl.svc jessie_tcp@dns-test-service.e2e-tests-dns-hp4sl.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc]

Oct 29 13:53:51.789: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:51.793: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc from pod e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3: the server could not find the requested resource (get pods dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3)
Oct 29 13:53:51.816: INFO: Lookups using e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3 failed for: [jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hp4sl.svc]

Oct 29 13:54:01.819: INFO: DNS probes using e2e-tests-dns-hp4sl/dns-test-fbcdbfcb-db81-11e8-94a0-9e8b538e2da3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:54:01.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-hp4sl" for this suite.
Oct 29 13:54:07.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:54:08.010: INFO: namespace: e2e-tests-dns-hp4sl, resource: bindings, ignored listing per whitelist
Oct 29 13:54:08.047: INFO: namespace e2e-tests-dns-hp4sl deletion completed in 6.141856275s

• [SLOW TEST:52.482 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:54:08.048: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Oct 29 13:54:08.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 --namespace=e2e-tests-kubectl-5pwb7 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 29 13:54:09.193: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 29 13:54:09.193: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:54:11.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5pwb7" for this suite.
Oct 29 13:54:17.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:54:17.284: INFO: namespace: e2e-tests-kubectl-5pwb7, resource: bindings, ignored listing per whitelist
Oct 29 13:54:17.327: INFO: namespace e2e-tests-kubectl-5pwb7 deletion completed in 6.122119789s

• [SLOW TEST:9.280 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:54:17.328: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-20984240-db82-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:54:17.400: INFO: Waiting up to 5m0s for pod "pod-secrets-2098f5f1-db82-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-s4jqc" to be "success or failure"
Oct 29 13:54:17.406: INFO: Pod "pod-secrets-2098f5f1-db82-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.785637ms
Oct 29 13:54:19.410: INFO: Pod "pod-secrets-2098f5f1-db82-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00979549s
STEP: Saw pod success
Oct 29 13:54:19.410: INFO: Pod "pod-secrets-2098f5f1-db82-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:54:19.413: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-secrets-2098f5f1-db82-11e8-94a0-9e8b538e2da3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:54:19.435: INFO: Waiting for pod pod-secrets-2098f5f1-db82-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:54:19.438: INFO: Pod pod-secrets-2098f5f1-db82-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:54:19.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s4jqc" for this suite.
Oct 29 13:54:25.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:54:25.519: INFO: namespace: e2e-tests-secrets-s4jqc, resource: bindings, ignored listing per whitelist
Oct 29 13:54:25.558: INFO: namespace e2e-tests-secrets-s4jqc deletion completed in 6.115143791s

• [SLOW TEST:8.230 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:54:25.558: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 29 13:54:25.632: INFO: Waiting up to 5m0s for pod "pod-2580f8e5-db82-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-rkqdw" to be "success or failure"
Oct 29 13:54:25.637: INFO: Pod "pod-2580f8e5-db82-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.881932ms
Oct 29 13:54:27.641: INFO: Pod "pod-2580f8e5-db82-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009333508s
STEP: Saw pod success
Oct 29 13:54:27.642: INFO: Pod "pod-2580f8e5-db82-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:54:27.646: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-2580f8e5-db82-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 13:54:27.670: INFO: Waiting for pod pod-2580f8e5-db82-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:54:27.674: INFO: Pod pod-2580f8e5-db82-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:54:27.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rkqdw" for this suite.
Oct 29 13:54:33.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:54:33.791: INFO: namespace: e2e-tests-emptydir-rkqdw, resource: bindings, ignored listing per whitelist
Oct 29 13:54:33.800: INFO: namespace e2e-tests-emptydir-rkqdw deletion completed in 6.120937146s

• [SLOW TEST:8.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:54:33.800: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1029 13:54:34.915777      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 13:54:34.915: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:54:34.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-dsmdm" for this suite.
Oct 29 13:54:40.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:54:41.029: INFO: namespace: e2e-tests-gc-dsmdm, resource: bindings, ignored listing per whitelist
Oct 29 13:54:41.042: INFO: namespace e2e-tests-gc-dsmdm deletion completed in 6.122509857s

• [SLOW TEST:7.242 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:54:41.042: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:55:41.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4k7q8" for this suite.
Oct 29 13:56:03.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:56:03.161: INFO: namespace: e2e-tests-container-probe-4k7q8, resource: bindings, ignored listing per whitelist
Oct 29 13:56:03.240: INFO: namespace e2e-tests-container-probe-4k7q8 deletion completed in 22.113325314s

• [SLOW TEST:82.198 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:56:03.240: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 29 13:56:03.319: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6whkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-6whkc/configmaps/e2e-watch-test-watch-closed,UID:5fba65db-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:478806,Generation:0,CreationTimestamp:2018-10-29 13:56:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 13:56:03.319: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6whkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-6whkc/configmaps/e2e-watch-test-watch-closed,UID:5fba65db-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:478807,Generation:0,CreationTimestamp:2018-10-29 13:56:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 29 13:56:03.337: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6whkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-6whkc/configmaps/e2e-watch-test-watch-closed,UID:5fba65db-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:478808,Generation:0,CreationTimestamp:2018-10-29 13:56:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 13:56:03.337: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6whkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-6whkc/configmaps/e2e-watch-test-watch-closed,UID:5fba65db-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:478809,Generation:0,CreationTimestamp:2018-10-29 13:56:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:56:03.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6whkc" for this suite.
Oct 29 13:56:09.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:56:09.415: INFO: namespace: e2e-tests-watch-6whkc, resource: bindings, ignored listing per whitelist
Oct 29 13:56:09.455: INFO: namespace e2e-tests-watch-6whkc deletion completed in 6.113676873s

• [SLOW TEST:6.214 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:56:09.455: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 13:56:09.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-mvhrm'
Oct 29 13:56:09.829: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Oct 29 13:56:09.829: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Oct 29 13:56:09.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-mvhrm'
Oct 29 13:56:10.028: INFO: stderr: ""
Oct 29 13:56:10.028: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:56:10.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mvhrm" for this suite.
Oct 29 13:56:16.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:56:16.153: INFO: namespace: e2e-tests-kubectl-mvhrm, resource: bindings, ignored listing per whitelist
Oct 29 13:56:16.164: INFO: namespace e2e-tests-kubectl-mvhrm deletion completed in 6.131598715s

• [SLOW TEST:6.709 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:56:16.164: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:56:16.242: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 29 13:56:21.252: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 29 13:56:21.252: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 29 13:56:21.289: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-cpxjt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cpxjt/deployments/test-cleanup-deployment,UID:6a6d556d-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:478893,Generation:1,CreationTimestamp:2018-10-29 13:56:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Oct 29 13:56:21.296: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:56:21.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cpxjt" for this suite.
Oct 29 13:56:27.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:56:27.360: INFO: namespace: e2e-tests-deployment-cpxjt, resource: bindings, ignored listing per whitelist
Oct 29 13:56:27.451: INFO: namespace e2e-tests-deployment-cpxjt deletion completed in 6.135161333s

• [SLOW TEST:11.287 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:56:27.451: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-6e29533d-db82-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 13:56:27.535: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6e2a03f0-db82-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-kc6fh" to be "success or failure"
Oct 29 13:56:27.542: INFO: Pod "pod-projected-secrets-6e2a03f0-db82-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.939055ms
Oct 29 13:56:29.546: INFO: Pod "pod-projected-secrets-6e2a03f0-db82-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010829272s
STEP: Saw pod success
Oct 29 13:56:29.546: INFO: Pod "pod-projected-secrets-6e2a03f0-db82-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 13:56:29.549: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-projected-secrets-6e2a03f0-db82-11e8-94a0-9e8b538e2da3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 13:56:29.569: INFO: Waiting for pod pod-projected-secrets-6e2a03f0-db82-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 13:56:29.573: INFO: Pod pod-projected-secrets-6e2a03f0-db82-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:56:29.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kc6fh" for this suite.
Oct 29 13:56:35.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:56:35.617: INFO: namespace: e2e-tests-projected-kc6fh, resource: bindings, ignored listing per whitelist
Oct 29 13:56:35.704: INFO: namespace e2e-tests-projected-kc6fh deletion completed in 6.127616638s

• [SLOW TEST:8.253 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:56:35.704: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 13:56:35.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-x669l'
Oct 29 13:56:35.917: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Oct 29 13:56:35.917: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Oct 29 13:56:37.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-x669l'
Oct 29 13:56:38.024: INFO: stderr: ""
Oct 29 13:56:38.024: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:56:38.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x669l" for this suite.
Oct 29 13:56:44.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:56:44.137: INFO: namespace: e2e-tests-kubectl-x669l, resource: bindings, ignored listing per whitelist
Oct 29 13:56:44.163: INFO: namespace e2e-tests-kubectl-x669l deletion completed in 6.126799591s

• [SLOW TEST:8.458 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:56:44.163: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Oct 29 13:56:46.251: INFO: Pod pod-hostip-781e723b-db82-11e8-94a0-9e8b538e2da3 has hostIP: 10.0.1.140
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:56:46.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-h4w6q" for this suite.
Oct 29 13:57:08.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:57:08.298: INFO: namespace: e2e-tests-pods-h4w6q, resource: bindings, ignored listing per whitelist
Oct 29 13:57:08.367: INFO: namespace e2e-tests-pods-h4w6q deletion completed in 22.112356895s

• [SLOW TEST:24.204 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:57:08.367: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Oct 29 13:57:08.435: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 29 13:57:08.443: INFO: Waiting for terminating namespaces to be deleted...
Oct 29 13:57:08.446: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-140.eu-west-1.compute.internal before test
Oct 29 13:57:08.452: INFO: sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-vmft4 from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 13:57:08.452: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Oct 29 13:57:08.452: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 13:57:08.452: INFO: calico-node-gqfq5 from kube-system started at 2018-10-26 14:32:29 +0000 UTC (2 container statuses recorded)
Oct 29 13:57:08.452: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 13:57:08.452: INFO: 	Container install-cni ready: true, restart count 0
Oct 29 13:57:08.452: INFO: nginx-6c94d899fd-6x4kg from default started at 2018-10-29 13:16:15 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.452: INFO: 	Container nginx ready: true, restart count 0
Oct 29 13:57:08.452: INFO: coredns-576cbf47c7-96r4w from kube-system started at 2018-10-26 14:32:12 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.452: INFO: 	Container coredns ready: true, restart count 0
Oct 29 13:57:08.452: INFO: coredns-576cbf47c7-m8lhm from kube-system started at 2018-10-26 14:32:12 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.452: INFO: 	Container coredns ready: true, restart count 0
Oct 29 13:57:08.452: INFO: kube-proxy-7msnt from kube-system started at 2018-10-29 13:05:22 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.452: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 13:57:08.452: INFO: nginx-6c94d899fd-w6mz2 from default started at 2018-10-29 13:16:08 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.452: INFO: 	Container nginx ready: true, restart count 0
Oct 29 13:57:08.452: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-2-47.eu-west-1.compute.internal before test
Oct 29 13:57:08.458: INFO: nginx-6c94d899fd-xqcqp from default started at 2018-10-29 13:16:08 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.458: INFO: 	Container nginx ready: true, restart count 0
Oct 29 13:57:08.458: INFO: kube-proxy-j9xc7 from kube-system started at 2018-10-29 13:05:42 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.458: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 13:57:08.458: INFO: calico-node-vn4pl from kube-system started at 2018-10-26 14:32:29 +0000 UTC (2 container statuses recorded)
Oct 29 13:57:08.458: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 13:57:08.458: INFO: 	Container install-cni ready: true, restart count 0
Oct 29 13:57:08.458: INFO: nginx-6c94d899fd-cgsx2 from default started at 2018-10-29 13:16:15 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.458: INFO: 	Container nginx ready: true, restart count 0
Oct 29 13:57:08.458: INFO: sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-bhgjz from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 13:57:08.458: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Oct 29 13:57:08.458: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 13:57:08.458: INFO: sonobuoy from heptio-sonobuoy started at 2018-10-29 13:18:08 +0000 UTC (1 container statuses recorded)
Oct 29 13:57:08.458: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 29 13:57:08.458: INFO: sonobuoy-e2e-job-e29a3530d05d487d from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 13:57:08.458: INFO: 	Container e2e ready: true, restart count 0
Oct 29 13:57:08.458: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-10-0-1-140.eu-west-1.compute.internal
STEP: verifying the node has the label node ip-10-0-2-47.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod nginx-6c94d899fd-6x4kg requesting resource cpu=0m on Node ip-10-0-1-140.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod nginx-6c94d899fd-cgsx2 requesting resource cpu=0m on Node ip-10-0-2-47.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod nginx-6c94d899fd-w6mz2 requesting resource cpu=0m on Node ip-10-0-1-140.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod nginx-6c94d899fd-xqcqp requesting resource cpu=0m on Node ip-10-0-2-47.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-2-47.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod sonobuoy-e2e-job-e29a3530d05d487d requesting resource cpu=0m on Node ip-10-0-2-47.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-bhgjz requesting resource cpu=0m on Node ip-10-0-2-47.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-vmft4 requesting resource cpu=0m on Node ip-10-0-1-140.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod calico-node-gqfq5 requesting resource cpu=250m on Node ip-10-0-1-140.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod calico-node-vn4pl requesting resource cpu=250m on Node ip-10-0-2-47.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod coredns-576cbf47c7-96r4w requesting resource cpu=100m on Node ip-10-0-1-140.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod coredns-576cbf47c7-m8lhm requesting resource cpu=100m on Node ip-10-0-1-140.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod kube-proxy-7msnt requesting resource cpu=0m on Node ip-10-0-1-140.eu-west-1.compute.internal
Oct 29 13:57:08.500: INFO: Pod kube-proxy-j9xc7 requesting resource cpu=0m on Node ip-10-0-2-47.eu-west-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8695ed0a-db82-11e8-94a0-9e8b538e2da3.156218ecf4cc5319], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4lssz/filler-pod-8695ed0a-db82-11e8-94a0-9e8b538e2da3 to ip-10-0-1-140.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8695ed0a-db82-11e8-94a0-9e8b538e2da3.156218ed1fc71510], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8695ed0a-db82-11e8-94a0-9e8b538e2da3.156218ed237de5d6], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8695ed0a-db82-11e8-94a0-9e8b538e2da3.156218ed28e29692], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-86971b34-db82-11e8-94a0-9e8b538e2da3.156218ecf5496c1c], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4lssz/filler-pod-86971b34-db82-11e8-94a0-9e8b538e2da3 to ip-10-0-2-47.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-86971b34-db82-11e8-94a0-9e8b538e2da3.156218ed1e8fb561], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-86971b34-db82-11e8-94a0-9e8b538e2da3.156218ed22758d6f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-86971b34-db82-11e8-94a0-9e8b538e2da3.156218ed27eb4c16], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156218ed6d8d4968], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node ip-10-0-1-140.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-2-47.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:57:11.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4lssz" for this suite.
Oct 29 13:57:17.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:57:17.666: INFO: namespace: e2e-tests-sched-pred-4lssz, resource: bindings, ignored listing per whitelist
Oct 29 13:57:17.695: INFO: namespace e2e-tests-sched-pred-4lssz deletion completed in 6.109842242s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.328 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:57:17.695: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zkdb8
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Oct 29 13:57:17.770: INFO: Found 0 stateful pods, waiting for 3
Oct 29 13:57:27.780: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 13:57:27.780: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 13:57:27.780: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 13:57:27.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-zkdb8 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:57:28.001: INFO: stderr: ""
Oct 29 13:57:28.001: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:57:28.001: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 29 13:57:38.049: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 29 13:57:48.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-zkdb8 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:57:48.279: INFO: stderr: ""
Oct 29 13:57:48.279: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:57:48.279: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:57:58.305: INFO: Waiting for StatefulSet e2e-tests-statefulset-zkdb8/ss2 to complete update
Oct 29 13:57:58.305: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 29 13:57:58.305: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 29 13:57:58.305: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 29 13:58:08.319: INFO: Waiting for StatefulSet e2e-tests-statefulset-zkdb8/ss2 to complete update
Oct 29 13:58:08.319: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 29 13:58:08.319: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 29 13:58:18.313: INFO: Waiting for StatefulSet e2e-tests-statefulset-zkdb8/ss2 to complete update
Oct 29 13:58:18.313: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Oct 29 13:58:28.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-zkdb8 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 13:58:28.534: INFO: stderr: ""
Oct 29 13:58:28.534: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 13:58:28.534: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 13:58:38.574: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 29 13:58:48.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 exec --namespace=e2e-tests-statefulset-zkdb8 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 13:58:48.800: INFO: stderr: ""
Oct 29 13:58:48.800: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 13:58:48.800: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 13:58:58.829: INFO: Waiting for StatefulSet e2e-tests-statefulset-zkdb8/ss2 to complete update
Oct 29 13:58:58.829: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Oct 29 13:58:58.829: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Oct 29 13:58:58.829: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Oct 29 13:59:08.852: INFO: Waiting for StatefulSet e2e-tests-statefulset-zkdb8/ss2 to complete update
Oct 29 13:59:08.852: INFO: Waiting for Pod e2e-tests-statefulset-zkdb8/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 29 13:59:18.864: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zkdb8
Oct 29 13:59:18.867: INFO: Scaling statefulset ss2 to 0
Oct 29 13:59:48.904: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 13:59:48.907: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 13:59:48.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zkdb8" for this suite.
Oct 29 13:59:54.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 13:59:55.006: INFO: namespace: e2e-tests-statefulset-zkdb8, resource: bindings, ignored listing per whitelist
Oct 29 13:59:55.047: INFO: namespace e2e-tests-statefulset-zkdb8 deletion completed in 6.121346814s

• [SLOW TEST:157.352 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 13:59:55.048: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 13:59:55.112: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 29 13:59:55.120: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 29 14:00:00.130: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 29 14:00:00.130: INFO: Creating deployment "test-rolling-update-deployment"
Oct 29 14:00:00.135: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 29 14:00:00.142: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 29 14:00:02.150: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 29 14:00:02.154: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 29 14:00:02.163: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-9t554,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9t554/deployments/test-rolling-update-deployment,UID:ece2dae9-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479878,Generation:1,CreationTimestamp:2018-10-29 14:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-10-29 14:00:00 +0000 UTC 2018-10-29 14:00:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-10-29 14:00:01 +0000 UTC 2018-10-29 14:00:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 29 14:00:02.167: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-9t554,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9t554/replicasets/test-rolling-update-deployment-65b7695dcf,UID:ece65645-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479869,Generation:1,CreationTimestamp:2018-10-29 14:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ece2dae9-db82-11e8-84e8-0a8bfd2d149c 0xc42122da37 0xc42122da38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 29 14:00:02.167: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 29 14:00:02.167: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-9t554,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9t554/replicasets/test-rolling-update-controller,UID:e9e521d5-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479877,Generation:2,CreationTimestamp:2018-10-29 13:59:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ece2dae9-db82-11e8-84e8-0a8bfd2d149c 0xc42122d96e 0xc42122d96f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 14:00:02.172: INFO: Pod "test-rolling-update-deployment-65b7695dcf-4wjbh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-4wjbh,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-9t554,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9t554/pods/test-rolling-update-deployment-65b7695dcf-4wjbh,UID:ece7126a-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479868,Generation:0,CreationTimestamp:2018-10-29 14:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.62/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf ece65645-db82-11e8-84e8-0a8bfd2d149c 0xc421d162e7 0xc421d162e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64cc5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64cc5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-64cc5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d16350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d16370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:00:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:00:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:00:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:00:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:192.168.4.62,StartTime:2018-10-29 14:00:00 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-10-29 14:00:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://2883a44d02d966685785061499818b8ed6756faf48034cb5146b756eb2186c85}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:00:02.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9t554" for this suite.
Oct 29 14:00:08.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:00:08.288: INFO: namespace: e2e-tests-deployment-9t554, resource: bindings, ignored listing per whitelist
Oct 29 14:00:08.288: INFO: namespace e2e-tests-deployment-9t554 deletion completed in 6.11288335s

• [SLOW TEST:13.241 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:00:08.289: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Oct 29 14:00:08.362: INFO: Waiting up to 5m0s for pod "client-containers-f1c94f12-db82-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-containers-9k45z" to be "success or failure"
Oct 29 14:00:08.366: INFO: Pod "client-containers-f1c94f12-db82-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128178ms
Oct 29 14:00:10.377: INFO: Pod "client-containers-f1c94f12-db82-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014793278s
Oct 29 14:00:12.381: INFO: Pod "client-containers-f1c94f12-db82-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018632524s
STEP: Saw pod success
Oct 29 14:00:12.381: INFO: Pod "client-containers-f1c94f12-db82-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:00:12.385: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod client-containers-f1c94f12-db82-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 14:00:12.407: INFO: Waiting for pod client-containers-f1c94f12-db82-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:00:12.411: INFO: Pod client-containers-f1c94f12-db82-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:00:12.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9k45z" for this suite.
Oct 29 14:00:18.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:00:18.499: INFO: namespace: e2e-tests-containers-9k45z, resource: bindings, ignored listing per whitelist
Oct 29 14:00:18.531: INFO: namespace e2e-tests-containers-9k45z deletion completed in 6.115918026s

• [SLOW TEST:10.242 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:00:18.531: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 29 14:00:18.616: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qdzdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdzdl/configmaps/e2e-watch-test-label-changed,UID:f7e4b2e5-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479969,Generation:0,CreationTimestamp:2018-10-29 14:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 14:00:18.616: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qdzdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdzdl/configmaps/e2e-watch-test-label-changed,UID:f7e4b2e5-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479970,Generation:0,CreationTimestamp:2018-10-29 14:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 29 14:00:18.616: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qdzdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdzdl/configmaps/e2e-watch-test-label-changed,UID:f7e4b2e5-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479971,Generation:0,CreationTimestamp:2018-10-29 14:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 29 14:00:28.653: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qdzdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdzdl/configmaps/e2e-watch-test-label-changed,UID:f7e4b2e5-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479991,Generation:0,CreationTimestamp:2018-10-29 14:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 14:00:28.653: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qdzdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdzdl/configmaps/e2e-watch-test-label-changed,UID:f7e4b2e5-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479992,Generation:0,CreationTimestamp:2018-10-29 14:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 29 14:00:28.653: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qdzdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdzdl/configmaps/e2e-watch-test-label-changed,UID:f7e4b2e5-db82-11e8-84e8-0a8bfd2d149c,ResourceVersion:479993,Generation:0,CreationTimestamp:2018-10-29 14:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:00:28.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qdzdl" for this suite.
Oct 29 14:00:34.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:00:34.733: INFO: namespace: e2e-tests-watch-qdzdl, resource: bindings, ignored listing per whitelist
Oct 29 14:00:34.773: INFO: namespace e2e-tests-watch-qdzdl deletion completed in 6.116515619s

• [SLOW TEST:16.243 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:00:34.774: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 14:00:34.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-jrmzp'
Oct 29 14:00:34.968: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Oct 29 14:00:34.968: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Oct 29 14:00:38.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jrmzp'
Oct 29 14:00:39.093: INFO: stderr: ""
Oct 29 14:00:39.093: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:00:39.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jrmzp" for this suite.
Oct 29 14:00:45.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:00:45.190: INFO: namespace: e2e-tests-kubectl-jrmzp, resource: bindings, ignored listing per whitelist
Oct 29 14:00:45.230: INFO: namespace e2e-tests-kubectl-jrmzp deletion completed in 6.12478595s

• [SLOW TEST:10.456 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:00:45.230: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:00:45.306: INFO: Waiting up to 5m0s for pod "downwardapi-volume-07ce8a6b-db83-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-2xt7c" to be "success or failure"
Oct 29 14:00:45.313: INFO: Pod "downwardapi-volume-07ce8a6b-db83-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.617628ms
Oct 29 14:00:47.318: INFO: Pod "downwardapi-volume-07ce8a6b-db83-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011902053s
STEP: Saw pod success
Oct 29 14:00:47.318: INFO: Pod "downwardapi-volume-07ce8a6b-db83-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:00:47.321: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-07ce8a6b-db83-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 14:00:47.348: INFO: Waiting for pod downwardapi-volume-07ce8a6b-db83-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:00:47.351: INFO: Pod downwardapi-volume-07ce8a6b-db83-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:00:47.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2xt7c" for this suite.
Oct 29 14:00:53.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:00:53.450: INFO: namespace: e2e-tests-projected-2xt7c, resource: bindings, ignored listing per whitelist
Oct 29 14:00:53.467: INFO: namespace e2e-tests-projected-2xt7c deletion completed in 6.112119303s

• [SLOW TEST:8.237 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:00:53.467: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Oct 29 14:00:53.531: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-215229198 proxy --unix-socket=/tmp/kubectl-proxy-unix956645141/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:00:53.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j5kxt" for this suite.
Oct 29 14:00:59.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:00:59.667: INFO: namespace: e2e-tests-kubectl-j5kxt, resource: bindings, ignored listing per whitelist
Oct 29 14:00:59.720: INFO: namespace e2e-tests-kubectl-j5kxt deletion completed in 6.11954507s

• [SLOW TEST:6.252 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:00:59.720: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 14:00:59.797: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 29 14:00:59.806: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:00:59.806: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:00:59.806: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:00:59.810: INFO: Number of nodes with available pods: 0
Oct 29 14:00:59.810: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:01:00.820: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:00.820: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:00.820: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:00.824: INFO: Number of nodes with available pods: 0
Oct 29 14:01:00.824: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:01:01.815: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:01.815: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:01.815: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:01.819: INFO: Number of nodes with available pods: 2
Oct 29 14:01:01.819: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 29 14:01:01.843: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:01.844: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:01.848: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:01.848: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:01.848: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:02.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:02.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:02.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:02.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:02.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:03.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:03.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:03.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:03.856: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:03.856: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:04.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:04.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:04.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:04.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:04.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:05.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:05.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:05.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:05.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:05.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:06.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:06.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:06.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:06.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:06.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:07.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:07.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:07.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:07.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:07.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:08.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:08.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:08.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:08.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:08.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:09.858: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:09.858: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:09.862: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:09.862: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:09.862: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:10.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:10.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:10.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:10.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:10.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:11.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:11.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:11.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:11.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:11.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:12.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:12.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:12.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:12.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:12.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:13.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:13.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:13.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:13.856: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:13.856: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:14.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:14.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:14.863: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:14.863: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:14.863: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:15.854: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:15.854: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:15.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:15.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:15.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:16.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:16.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:16.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:16.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:16.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:17.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:17.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:17.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:17.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:17.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:18.864: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:18.864: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:18.868: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:18.868: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:18.868: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:19.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:19.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:19.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:19.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:19.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:20.862: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:20.862: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:20.867: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:20.867: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:20.867: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:21.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:21.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:21.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:21.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:21.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:22.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:22.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:22.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:22.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:22.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:23.856: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:23.856: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:23.861: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:23.863: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:23.863: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:24.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:24.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:24.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:24.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:24.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:25.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:25.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:25.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:25.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:25.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:26.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:26.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:26.862: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:26.862: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:26.862: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:27.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:27.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:27.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:27.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:27.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:28.855: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:28.855: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:28.865: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:28.865: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:28.865: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:29.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:29.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:29.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:29.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:29.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:30.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:30.853: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:30.863: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:30.863: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:30.863: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:31.859: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:31.859: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:31.863: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:31.863: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:31.863: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:32.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:32.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:32.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:32.856: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:32.856: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:33.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:33.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:33.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:33.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:33.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:34.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:34.852: INFO: Wrong image for pod: daemon-set-wjmzl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:34.852: INFO: Pod daemon-set-wjmzl is not available
Oct 29 14:01:34.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:34.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:34.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:35.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:35.853: INFO: Pod daemon-set-mwlxj is not available
Oct 29 14:01:35.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:35.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:35.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:36.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:36.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:36.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:36.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:37.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:37.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:37.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:37.858: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:38.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:38.863: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:38.863: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:38.863: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:39.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:39.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:39.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:39.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:40.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:40.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:40.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:40.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:41.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:41.882: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:41.882: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:41.882: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:42.862: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:42.866: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:42.866: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:42.866: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:43.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:43.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:43.856: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:43.856: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:44.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:44.858: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:44.858: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:44.858: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:45.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:45.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:45.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:45.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:46.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:46.858: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:46.858: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:46.858: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:47.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:47.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:47.856: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:47.856: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:48.856: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:48.865: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:48.865: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:48.865: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:49.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:49.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:49.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:49.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:50.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:50.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:50.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:50.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:51.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:51.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:51.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:51.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:52.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:52.862: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:52.862: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:52.862: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:53.858: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:53.862: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:53.862: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:53.862: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:54.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:54.862: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:54.862: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:54.862: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:55.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:55.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:55.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:55.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:56.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:56.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:56.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:56.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:57.856: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:57.860: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:57.860: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:57.861: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:58.855: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:58.865: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:58.865: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:58.865: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:59.854: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:01:59.858: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:59.858: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:01:59.858: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:00.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:02:00.856: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:00.856: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:00.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:01.856: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:02:01.860: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:01.861: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:01.861: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:02.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:02:02.862: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:02.862: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:02.862: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:03.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:02:03.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:03.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:03.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:04.858: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:02:04.864: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:04.864: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:04.864: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:05.853: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:02:05.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:05.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:05.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:06.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:02:06.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:06.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:06.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:07.852: INFO: Wrong image for pod: daemon-set-h7p99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 29 14:02:07.852: INFO: Pod daemon-set-h7p99 is not available
Oct 29 14:02:07.857: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:07.857: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:07.857: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:08.854: INFO: Pod daemon-set-kbdht is not available
Oct 29 14:02:08.863: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:08.863: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:08.863: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 29 14:02:08.873: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:08.873: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:08.873: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:08.883: INFO: Number of nodes with available pods: 1
Oct 29 14:02:08.883: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:02:09.888: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:09.888: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:09.888: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:02:09.892: INFO: Number of nodes with available pods: 2
Oct 29 14:02:09.892: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-cmjmh, will wait for the garbage collector to delete the pods
Oct 29 14:02:09.977: INFO: Deleting {extensions DaemonSet} daemon-set took: 9.459333ms
Oct 29 14:02:10.077: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.192728ms
Oct 29 14:02:22.986: INFO: Number of nodes with available pods: 0
Oct 29 14:02:22.986: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 14:02:22.989: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cmjmh/daemonsets","resourceVersion":"480365"},"items":null}

Oct 29 14:02:22.992: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cmjmh/pods","resourceVersion":"480365"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:02:23.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cmjmh" for this suite.
Oct 29 14:02:29.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:02:29.063: INFO: namespace: e2e-tests-daemonsets-cmjmh, resource: bindings, ignored listing per whitelist
Oct 29 14:02:29.121: INFO: namespace e2e-tests-daemonsets-cmjmh deletion completed in 6.114973534s

• [SLOW TEST:89.401 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:02:29.121: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Oct 29 14:02:29.186: INFO: namespace e2e-tests-kubectl-x8rjb
Oct 29 14:02:29.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-x8rjb'
Oct 29 14:02:29.355: INFO: stderr: ""
Oct 29 14:02:29.355: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 29 14:02:30.359: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:02:30.359: INFO: Found 0 / 1
Oct 29 14:02:31.360: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:02:31.360: INFO: Found 1 / 1
Oct 29 14:02:31.360: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 29 14:02:31.363: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:02:31.363: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 29 14:02:31.363: INFO: wait on redis-master startup in e2e-tests-kubectl-x8rjb 
Oct 29 14:02:31.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 logs redis-master-j9b4m redis-master --namespace=e2e-tests-kubectl-x8rjb'
Oct 29 14:02:31.470: INFO: stderr: ""
Oct 29 14:02:31.470: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Oct 14:02:30.233 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Oct 14:02:30.233 # Server started, Redis version 3.2.12\n1:M 29 Oct 14:02:30.233 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Oct 14:02:30.233 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 29 14:02:31.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-x8rjb'
Oct 29 14:02:31.581: INFO: stderr: ""
Oct 29 14:02:31.581: INFO: stdout: "service/rm2 exposed\n"
Oct 29 14:02:31.585: INFO: Service rm2 in namespace e2e-tests-kubectl-x8rjb found.
STEP: exposing service
Oct 29 14:02:33.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-x8rjb'
Oct 29 14:02:33.702: INFO: stderr: ""
Oct 29 14:02:33.702: INFO: stdout: "service/rm3 exposed\n"
Oct 29 14:02:33.709: INFO: Service rm3 in namespace e2e-tests-kubectl-x8rjb found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:02:35.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x8rjb" for this suite.
Oct 29 14:02:57.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:02:57.810: INFO: namespace: e2e-tests-kubectl-x8rjb, resource: bindings, ignored listing per whitelist
Oct 29 14:02:57.834: INFO: namespace e2e-tests-kubectl-x8rjb deletion completed in 22.114273211s

• [SLOW TEST:28.713 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:02:57.834: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 29 14:02:57.912: INFO: Waiting up to 5m0s for pod "downward-api-56d89732-db83-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-j7xrw" to be "success or failure"
Oct 29 14:02:57.919: INFO: Pod "downward-api-56d89732-db83-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.828686ms
Oct 29 14:02:59.923: INFO: Pod "downward-api-56d89732-db83-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011234783s
STEP: Saw pod success
Oct 29 14:02:59.923: INFO: Pod "downward-api-56d89732-db83-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:02:59.927: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downward-api-56d89732-db83-11e8-94a0-9e8b538e2da3 container dapi-container: <nil>
STEP: delete the pod
Oct 29 14:02:59.950: INFO: Waiting for pod downward-api-56d89732-db83-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:02:59.953: INFO: Pod downward-api-56d89732-db83-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:02:59.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j7xrw" for this suite.
Oct 29 14:03:05.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:03:06.040: INFO: namespace: e2e-tests-downward-api-j7xrw, resource: bindings, ignored listing per whitelist
Oct 29 14:03:06.091: INFO: namespace e2e-tests-downward-api-j7xrw deletion completed in 6.133376381s

• [SLOW TEST:8.257 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:03:06.091: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5bc428db-db83-11e8-94a0-9e8b538e2da3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5bc428db-db83-11e8-94a0-9e8b538e2da3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:03:10.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wtwf5" for this suite.
Oct 29 14:03:32.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:03:32.328: INFO: namespace: e2e-tests-projected-wtwf5, resource: bindings, ignored listing per whitelist
Oct 29 14:03:32.346: INFO: namespace e2e-tests-projected-wtwf5 deletion completed in 22.128947116s

• [SLOW TEST:26.255 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:03:32.347: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Oct 29 14:03:32.935: INFO: Waiting up to 5m0s for pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-tpcp4" in namespace "e2e-tests-svcaccounts-4tbtk" to be "success or failure"
Oct 29 14:03:32.940: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-tpcp4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.641248ms
Oct 29 14:03:34.945: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-tpcp4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009123071s
STEP: Saw pod success
Oct 29 14:03:34.945: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-tpcp4" satisfied condition "success or failure"
Oct 29 14:03:34.948: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-tpcp4 container token-test: <nil>
STEP: delete the pod
Oct 29 14:03:34.971: INFO: Waiting for pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-tpcp4 to disappear
Oct 29 14:03:34.974: INFO: Pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-tpcp4 no longer exists
STEP: Creating a pod to test consume service account root CA
Oct 29 14:03:34.981: INFO: Waiting up to 5m0s for pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-8sxhg" in namespace "e2e-tests-svcaccounts-4tbtk" to be "success or failure"
Oct 29 14:03:34.986: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-8sxhg": Phase="Pending", Reason="", readiness=false. Elapsed: 5.387163ms
Oct 29 14:03:36.991: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-8sxhg": Phase="Running", Reason="", readiness=false. Elapsed: 2.010054484s
Oct 29 14:03:39.001: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-8sxhg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020141816s
STEP: Saw pod success
Oct 29 14:03:39.001: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-8sxhg" satisfied condition "success or failure"
Oct 29 14:03:39.004: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-8sxhg container root-ca-test: <nil>
STEP: delete the pod
Oct 29 14:03:39.029: INFO: Waiting for pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-8sxhg to disappear
Oct 29 14:03:39.034: INFO: Pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-8sxhg no longer exists
STEP: Creating a pod to test consume service account namespace
Oct 29 14:03:39.039: INFO: Waiting up to 5m0s for pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-vdhlq" in namespace "e2e-tests-svcaccounts-4tbtk" to be "success or failure"
Oct 29 14:03:39.044: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-vdhlq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.571411ms
Oct 29 14:03:41.048: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-vdhlq": Phase="Running", Reason="", readiness=false. Elapsed: 2.008945179s
Oct 29 14:03:43.052: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-vdhlq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013077604s
STEP: Saw pod success
Oct 29 14:03:43.052: INFO: Pod "pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-vdhlq" satisfied condition "success or failure"
Oct 29 14:03:43.055: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-vdhlq container namespace-test: <nil>
STEP: delete the pod
Oct 29 14:03:43.078: INFO: Waiting for pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-vdhlq to disappear
Oct 29 14:03:43.082: INFO: Pod pod-service-account-6bb8a0f0-db83-11e8-94a0-9e8b538e2da3-vdhlq no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:03:43.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-4tbtk" for this suite.
Oct 29 14:03:49.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:03:49.163: INFO: namespace: e2e-tests-svcaccounts-4tbtk, resource: bindings, ignored listing per whitelist
Oct 29 14:03:49.204: INFO: namespace e2e-tests-svcaccounts-4tbtk deletion completed in 6.118652507s

• [SLOW TEST:16.857 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:03:49.204: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 29 14:03:49.284: INFO: Waiting up to 5m0s for pod "downward-api-7576933c-db83-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-khszv" to be "success or failure"
Oct 29 14:03:49.288: INFO: Pod "downward-api-7576933c-db83-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058258ms
Oct 29 14:03:51.294: INFO: Pod "downward-api-7576933c-db83-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0097836s
STEP: Saw pod success
Oct 29 14:03:51.294: INFO: Pod "downward-api-7576933c-db83-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:03:51.300: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downward-api-7576933c-db83-11e8-94a0-9e8b538e2da3 container dapi-container: <nil>
STEP: delete the pod
Oct 29 14:03:51.334: INFO: Waiting for pod downward-api-7576933c-db83-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:03:51.340: INFO: Pod downward-api-7576933c-db83-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:03:51.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-khszv" for this suite.
Oct 29 14:03:57.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:03:57.421: INFO: namespace: e2e-tests-downward-api-khszv, resource: bindings, ignored listing per whitelist
Oct 29 14:03:57.463: INFO: namespace e2e-tests-downward-api-khszv deletion completed in 6.116625371s

• [SLOW TEST:8.259 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:03:57.464: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1029 14:04:03.576131      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 14:04:03.576: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:04:03.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hrmkk" for this suite.
Oct 29 14:04:09.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:04:09.654: INFO: namespace: e2e-tests-gc-hrmkk, resource: bindings, ignored listing per whitelist
Oct 29 14:04:09.710: INFO: namespace e2e-tests-gc-hrmkk deletion completed in 6.11881609s

• [SLOW TEST:12.247 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:04:09.711: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-81afbafc-db83-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:04:09.793: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-81b09caa-db83-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-hqsc2" to be "success or failure"
Oct 29 14:04:09.797: INFO: Pod "pod-projected-configmaps-81b09caa-db83-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.798607ms
Oct 29 14:04:11.802: INFO: Pod "pod-projected-configmaps-81b09caa-db83-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009018639s
STEP: Saw pod success
Oct 29 14:04:11.802: INFO: Pod "pod-projected-configmaps-81b09caa-db83-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:04:11.810: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-projected-configmaps-81b09caa-db83-11e8-94a0-9e8b538e2da3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:04:11.832: INFO: Waiting for pod pod-projected-configmaps-81b09caa-db83-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:04:11.835: INFO: Pod pod-projected-configmaps-81b09caa-db83-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:04:11.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hqsc2" for this suite.
Oct 29 14:04:17.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:04:17.942: INFO: namespace: e2e-tests-projected-hqsc2, resource: bindings, ignored listing per whitelist
Oct 29 14:04:17.953: INFO: namespace e2e-tests-projected-hqsc2 deletion completed in 6.113732455s

• [SLOW TEST:8.243 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:04:17.954: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-869ab94d-db83-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 14:04:18.052: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-869b6fdf-db83-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-zjfwf" to be "success or failure"
Oct 29 14:04:18.064: INFO: Pod "pod-projected-secrets-869b6fdf-db83-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.172993ms
Oct 29 14:04:20.073: INFO: Pod "pod-projected-secrets-869b6fdf-db83-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020556115s
STEP: Saw pod success
Oct 29 14:04:20.073: INFO: Pod "pod-projected-secrets-869b6fdf-db83-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:04:20.077: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-projected-secrets-869b6fdf-db83-11e8-94a0-9e8b538e2da3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:04:20.109: INFO: Waiting for pod pod-projected-secrets-869b6fdf-db83-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:04:20.114: INFO: Pod pod-projected-secrets-869b6fdf-db83-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:04:20.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjfwf" for this suite.
Oct 29 14:04:26.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:04:26.160: INFO: namespace: e2e-tests-projected-zjfwf, resource: bindings, ignored listing per whitelist
Oct 29 14:04:26.243: INFO: namespace e2e-tests-projected-zjfwf deletion completed in 6.113050907s

• [SLOW TEST:8.290 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:04:26.244: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 14:04:26.309: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:04:27.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-9nm8k" for this suite.
Oct 29 14:04:33.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:04:33.407: INFO: namespace: e2e-tests-custom-resource-definition-9nm8k, resource: bindings, ignored listing per whitelist
Oct 29 14:04:33.484: INFO: namespace e2e-tests-custom-resource-definition-9nm8k deletion completed in 6.111201703s

• [SLOW TEST:7.241 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:04:33.484: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 14:04:33.553: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 29 14:04:33.562: INFO: Number of nodes with available pods: 0
Oct 29 14:04:33.562: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 29 14:04:33.586: INFO: Number of nodes with available pods: 0
Oct 29 14:04:33.586: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:34.595: INFO: Number of nodes with available pods: 0
Oct 29 14:04:34.595: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:35.590: INFO: Number of nodes with available pods: 1
Oct 29 14:04:35.590: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 29 14:04:35.611: INFO: Number of nodes with available pods: 1
Oct 29 14:04:35.611: INFO: Number of running nodes: 0, number of available pods: 1
Oct 29 14:04:36.615: INFO: Number of nodes with available pods: 0
Oct 29 14:04:36.615: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 29 14:04:36.624: INFO: Number of nodes with available pods: 0
Oct 29 14:04:36.624: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:37.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:37.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:38.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:38.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:39.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:39.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:40.627: INFO: Number of nodes with available pods: 0
Oct 29 14:04:40.627: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:41.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:41.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:42.630: INFO: Number of nodes with available pods: 0
Oct 29 14:04:42.630: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:43.627: INFO: Number of nodes with available pods: 0
Oct 29 14:04:43.627: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:44.633: INFO: Number of nodes with available pods: 0
Oct 29 14:04:44.633: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:45.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:45.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:46.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:46.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:47.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:47.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:48.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:48.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:49.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:49.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:50.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:50.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:51.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:51.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:52.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:52.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:53.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:53.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:54.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:54.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:55.633: INFO: Number of nodes with available pods: 0
Oct 29 14:04:55.633: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:56.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:56.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:57.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:57.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:58.628: INFO: Number of nodes with available pods: 0
Oct 29 14:04:58.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:04:59.627: INFO: Number of nodes with available pods: 0
Oct 29 14:04:59.627: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:00.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:00.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:01.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:01.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:02.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:02.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:03.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:03.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:04.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:04.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:05.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:05.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:06.634: INFO: Number of nodes with available pods: 0
Oct 29 14:05:06.634: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:07.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:07.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:08.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:08.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:09.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:09.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:10.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:10.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:11.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:11.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:12.628: INFO: Number of nodes with available pods: 0
Oct 29 14:05:12.628: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:05:13.627: INFO: Number of nodes with available pods: 1
Oct 29 14:05:13.627: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-5jzkr, will wait for the garbage collector to delete the pods
Oct 29 14:05:13.695: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.735199ms
Oct 29 14:05:13.796: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.152239ms
Oct 29 14:05:51.805: INFO: Number of nodes with available pods: 0
Oct 29 14:05:51.805: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 14:05:51.808: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-5jzkr/daemonsets","resourceVersion":"481356"},"items":null}

Oct 29 14:05:51.811: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-5jzkr/pods","resourceVersion":"481356"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:05:51.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-5jzkr" for this suite.
Oct 29 14:05:57.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:05:57.878: INFO: namespace: e2e-tests-daemonsets-5jzkr, resource: bindings, ignored listing per whitelist
Oct 29 14:05:57.946: INFO: namespace e2e-tests-daemonsets-5jzkr deletion completed in 6.111112471s

• [SLOW TEST:84.462 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:05:57.946: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-nnfrw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nnfrw to expose endpoints map[]
Oct 29 14:05:58.063: INFO: Get endpoints failed (6.778903ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct 29 14:05:59.067: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nnfrw exposes endpoints map[] (1.010549199s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-nnfrw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nnfrw to expose endpoints map[pod1:[100]]
Oct 29 14:06:01.096: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nnfrw exposes endpoints map[pod1:[100]] (2.021557598s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-nnfrw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nnfrw to expose endpoints map[pod2:[101] pod1:[100]]
Oct 29 14:06:02.152: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nnfrw exposes endpoints map[pod1:[100] pod2:[101]] (1.043562701s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-nnfrw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nnfrw to expose endpoints map[pod2:[101]]
Oct 29 14:06:03.178: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nnfrw exposes endpoints map[pod2:[101]] (1.01697333s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-nnfrw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nnfrw to expose endpoints map[]
Oct 29 14:06:04.194: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nnfrw exposes endpoints map[] (1.007738953s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:06:04.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nnfrw" for this suite.
Oct 29 14:06:10.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:06:10.314: INFO: namespace: e2e-tests-services-nnfrw, resource: bindings, ignored listing per whitelist
Oct 29 14:06:10.377: INFO: namespace e2e-tests-services-nnfrw deletion completed in 6.145172649s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:12.431 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:06:10.378: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Oct 29 14:06:10.974: INFO: created pod pod-service-account-defaultsa
Oct 29 14:06:10.974: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 29 14:06:10.987: INFO: created pod pod-service-account-mountsa
Oct 29 14:06:10.988: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 29 14:06:11.005: INFO: created pod pod-service-account-nomountsa
Oct 29 14:06:11.005: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 29 14:06:11.013: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 29 14:06:11.013: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 29 14:06:11.022: INFO: created pod pod-service-account-mountsa-mountspec
Oct 29 14:06:11.022: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 29 14:06:11.032: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 29 14:06:11.032: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 29 14:06:11.041: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 29 14:06:11.041: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 29 14:06:11.050: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 29 14:06:11.050: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 29 14:06:11.060: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 29 14:06:11.060: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:06:11.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-gzhc4" for this suite.
Oct 29 14:06:17.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:06:17.124: INFO: namespace: e2e-tests-svcaccounts-gzhc4, resource: bindings, ignored listing per whitelist
Oct 29 14:06:17.188: INFO: namespace e2e-tests-svcaccounts-gzhc4 deletion completed in 6.121564767s

• [SLOW TEST:6.810 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:06:17.189: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 14:06:17.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 version'
Oct 29 14:06:17.332: INFO: stderr: ""
Oct 29 14:06:17.332: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.2\", GitCommit:\"17c77c7898218073f14c8d573582e8d2313dc740\", GitTreeState:\"clean\", BuildDate:\"2018-10-24T06:43:59Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:06:17.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kb6mt" for this suite.
Oct 29 14:06:23.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:06:23.382: INFO: namespace: e2e-tests-kubectl-kb6mt, resource: bindings, ignored listing per whitelist
Oct 29 14:06:23.463: INFO: namespace e2e-tests-kubectl-kb6mt deletion completed in 6.126436365s

• [SLOW TEST:6.274 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:06:23.464: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:06:23.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1699e5a-db83-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-7wqcs" to be "success or failure"
Oct 29 14:06:23.550: INFO: Pod "downwardapi-volume-d1699e5a-db83-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.878511ms
Oct 29 14:06:25.554: INFO: Pod "downwardapi-volume-d1699e5a-db83-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009067654s
STEP: Saw pod success
Oct 29 14:06:25.554: INFO: Pod "downwardapi-volume-d1699e5a-db83-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:06:25.557: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downwardapi-volume-d1699e5a-db83-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 14:06:25.587: INFO: Waiting for pod downwardapi-volume-d1699e5a-db83-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:06:25.600: INFO: Pod downwardapi-volume-d1699e5a-db83-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:06:25.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7wqcs" for this suite.
Oct 29 14:06:31.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:06:31.641: INFO: namespace: e2e-tests-downward-api-7wqcs, resource: bindings, ignored listing per whitelist
Oct 29 14:06:31.721: INFO: namespace e2e-tests-downward-api-7wqcs deletion completed in 6.115520761s

• [SLOW TEST:8.257 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:06:31.721: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d653e8d3-db83-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:06:31.796: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d654ab81-db83-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-6hrq2" to be "success or failure"
Oct 29 14:06:31.801: INFO: Pod "pod-projected-configmaps-d654ab81-db83-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.292701ms
Oct 29 14:06:33.811: INFO: Pod "pod-projected-configmaps-d654ab81-db83-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014882351s
STEP: Saw pod success
Oct 29 14:06:33.811: INFO: Pod "pod-projected-configmaps-d654ab81-db83-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:06:33.814: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-projected-configmaps-d654ab81-db83-11e8-94a0-9e8b538e2da3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:06:33.836: INFO: Waiting for pod pod-projected-configmaps-d654ab81-db83-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:06:33.839: INFO: Pod pod-projected-configmaps-d654ab81-db83-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:06:33.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6hrq2" for this suite.
Oct 29 14:06:39.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:06:39.887: INFO: namespace: e2e-tests-projected-6hrq2, resource: bindings, ignored listing per whitelist
Oct 29 14:06:39.972: INFO: namespace e2e-tests-projected-6hrq2 deletion completed in 6.12825056s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:06:39.972: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 29 14:06:40.080: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-znkq7,SelfLink:/api/v1/namespaces/e2e-tests-watch-znkq7/configmaps/e2e-watch-test-resource-version,UID:db423599-db83-11e8-84e8-0a8bfd2d149c,ResourceVersion:481697,Generation:0,CreationTimestamp:2018-10-29 14:06:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 14:06:40.081: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-znkq7,SelfLink:/api/v1/namespaces/e2e-tests-watch-znkq7/configmaps/e2e-watch-test-resource-version,UID:db423599-db83-11e8-84e8-0a8bfd2d149c,ResourceVersion:481698,Generation:0,CreationTimestamp:2018-10-29 14:06:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:06:40.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-znkq7" for this suite.
Oct 29 14:06:46.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:06:46.148: INFO: namespace: e2e-tests-watch-znkq7, resource: bindings, ignored listing per whitelist
Oct 29 14:06:46.201: INFO: namespace e2e-tests-watch-znkq7 deletion completed in 6.116909573s

• [SLOW TEST:6.229 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:06:46.201: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-jtlpp.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-jtlpp.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jtlpp.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-jtlpp.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-jtlpp.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jtlpp.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 29 14:06:58.378: INFO: DNS probes using e2e-tests-dns-jtlpp/dns-test-def5fa42-db83-11e8-94a0-9e8b538e2da3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:06:58.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-jtlpp" for this suite.
Oct 29 14:07:04.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:07:04.497: INFO: namespace: e2e-tests-dns-jtlpp, resource: bindings, ignored listing per whitelist
Oct 29 14:07:04.511: INFO: namespace e2e-tests-dns-jtlpp deletion completed in 6.112657938s

• [SLOW TEST:18.310 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:07:04.511: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 14:07:04.578: INFO: Creating deployment "test-recreate-deployment"
Oct 29 14:07:04.583: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 29 14:07:04.592: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Oct 29 14:07:06.599: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 29 14:07:06.602: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 29 14:07:06.611: INFO: Updating deployment test-recreate-deployment
Oct 29 14:07:06.611: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 29 14:07:06.689: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-lln89,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lln89/deployments/test-recreate-deployment,UID:e9e06816-db83-11e8-84e8-0a8bfd2d149c,ResourceVersion:481833,Generation:2,CreationTimestamp:2018-10-29 14:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-10-29 14:07:06 +0000 UTC 2018-10-29 14:07:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-10-29 14:07:06 +0000 UTC 2018-10-29 14:07:04 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 29 14:07:06.693: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-lln89,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lln89/replicasets/test-recreate-deployment-7cf749666b,UID:eb1c20e1-db83-11e8-84e8-0a8bfd2d149c,ResourceVersion:481830,Generation:1,CreationTimestamp:2018-10-29 14:07:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment e9e06816-db83-11e8-84e8-0a8bfd2d149c 0xc421b5edf7 0xc421b5edf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 14:07:06.693: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 29 14:07:06.693: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-lln89,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lln89/replicasets/test-recreate-deployment-79f694ff59,UID:e9e22b67-db83-11e8-84e8-0a8bfd2d149c,ResourceVersion:481821,Generation:2,CreationTimestamp:2018-10-29 14:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment e9e06816-db83-11e8-84e8-0a8bfd2d149c 0xc421b5e567 0xc421b5e568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 14:07:06.697: INFO: Pod "test-recreate-deployment-7cf749666b-zvf8g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-zvf8g,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-lln89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lln89/pods/test-recreate-deployment-7cf749666b-zvf8g,UID:eb1d0d34-db83-11e8-84e8-0a8bfd2d149c,ResourceVersion:481832,Generation:0,CreationTimestamp:2018-10-29 14:07:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b eb1c20e1-db83-11e8-84e8-0a8bfd2d149c 0xc421fbe0b7 0xc421fbe0b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pp5x5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pp5x5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pp5x5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-47.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fbe120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fbe140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:07:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:07:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:07:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:07:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.47,PodIP:,StartTime:2018-10-29 14:07:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:07:06.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lln89" for this suite.
Oct 29 14:07:12.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:07:12.774: INFO: namespace: e2e-tests-deployment-lln89, resource: bindings, ignored listing per whitelist
Oct 29 14:07:12.813: INFO: namespace e2e-tests-deployment-lln89 deletion completed in 6.112847103s

• [SLOW TEST:8.302 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:07:12.814: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-eed2dbd6-db83-11e8-94a0-9e8b538e2da3
STEP: Creating secret with name s-test-opt-upd-eed2dc23-db83-11e8-94a0-9e8b538e2da3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-eed2dbd6-db83-11e8-94a0-9e8b538e2da3
STEP: Updating secret s-test-opt-upd-eed2dc23-db83-11e8-94a0-9e8b538e2da3
STEP: Creating secret with name s-test-opt-create-eed2dc41-db83-11e8-94a0-9e8b538e2da3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:07:16.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fzjhz" for this suite.
Oct 29 14:07:38.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:07:39.046: INFO: namespace: e2e-tests-secrets-fzjhz, resource: bindings, ignored listing per whitelist
Oct 29 14:07:39.092: INFO: namespace e2e-tests-secrets-fzjhz deletion completed in 22.115393395s

• [SLOW TEST:26.279 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:07:39.093: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 29 14:07:39.166: INFO: Waiting up to 5m0s for pod "pod-fe7ca3ee-db83-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-c5fjl" to be "success or failure"
Oct 29 14:07:39.171: INFO: Pod "pod-fe7ca3ee-db83-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.042993ms
Oct 29 14:07:41.181: INFO: Pod "pod-fe7ca3ee-db83-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015703358s
STEP: Saw pod success
Oct 29 14:07:41.181: INFO: Pod "pod-fe7ca3ee-db83-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:07:41.184: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-fe7ca3ee-db83-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 14:07:41.207: INFO: Waiting for pod pod-fe7ca3ee-db83-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:07:41.210: INFO: Pod pod-fe7ca3ee-db83-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:07:41.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c5fjl" for this suite.
Oct 29 14:07:47.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:07:47.264: INFO: namespace: e2e-tests-emptydir-c5fjl, resource: bindings, ignored listing per whitelist
Oct 29 14:07:47.385: INFO: namespace e2e-tests-emptydir-c5fjl deletion completed in 6.167776637s

• [SLOW TEST:8.292 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:07:47.385: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 29 14:07:49.981: INFO: Successfully updated pod "pod-update-036d4c1d-db84-11e8-94a0-9e8b538e2da3"
STEP: verifying the updated pod is in kubernetes
Oct 29 14:07:49.988: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:07:49.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8ppv4" for this suite.
Oct 29 14:08:12.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:08:12.097: INFO: namespace: e2e-tests-pods-8ppv4, resource: bindings, ignored listing per whitelist
Oct 29 14:08:12.106: INFO: namespace e2e-tests-pods-8ppv4 deletion completed in 22.113631798s

• [SLOW TEST:24.721 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:08:12.106: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Oct 29 14:08:12.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-5dz8k'
Oct 29 14:08:12.500: INFO: stderr: ""
Oct 29 14:08:12.500: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 29 14:08:13.504: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:08:13.504: INFO: Found 0 / 1
Oct 29 14:08:14.509: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:08:14.509: INFO: Found 1 / 1
Oct 29 14:08:14.509: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 29 14:08:14.513: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:08:14.513: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 29 14:08:14.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 patch pod redis-master-8zzgh --namespace=e2e-tests-kubectl-5dz8k -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 29 14:08:14.609: INFO: stderr: ""
Oct 29 14:08:14.609: INFO: stdout: "pod/redis-master-8zzgh patched\n"
STEP: checking annotations
Oct 29 14:08:14.613: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:08:14.613: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:08:14.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5dz8k" for this suite.
Oct 29 14:08:36.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:08:36.737: INFO: namespace: e2e-tests-kubectl-5dz8k, resource: bindings, ignored listing per whitelist
Oct 29 14:08:36.746: INFO: namespace e2e-tests-kubectl-5dz8k deletion completed in 22.128672567s

• [SLOW TEST:24.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:08:36.746: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-20dbadc1-db84-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:08:36.840: INFO: Waiting up to 5m0s for pod "pod-configmaps-20dc61eb-db84-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-rxp7p" to be "success or failure"
Oct 29 14:08:36.845: INFO: Pod "pod-configmaps-20dc61eb-db84-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.745274ms
Oct 29 14:08:38.862: INFO: Pod "pod-configmaps-20dc61eb-db84-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022089452s
STEP: Saw pod success
Oct 29 14:08:38.862: INFO: Pod "pod-configmaps-20dc61eb-db84-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:08:38.870: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-configmaps-20dc61eb-db84-11e8-94a0-9e8b538e2da3 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:08:38.914: INFO: Waiting for pod pod-configmaps-20dc61eb-db84-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:08:38.917: INFO: Pod pod-configmaps-20dc61eb-db84-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:08:38.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rxp7p" for this suite.
Oct 29 14:08:44.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:08:45.012: INFO: namespace: e2e-tests-configmap-rxp7p, resource: bindings, ignored listing per whitelist
Oct 29 14:08:45.037: INFO: namespace e2e-tests-configmap-rxp7p deletion completed in 6.115153834s

• [SLOW TEST:8.290 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:08:45.037: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-k646m
Oct 29 14:08:47.117: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-k646m
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 14:08:47.120: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:12:47.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-k646m" for this suite.
Oct 29 14:12:53.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:12:53.931: INFO: namespace: e2e-tests-container-probe-k646m, resource: bindings, ignored listing per whitelist
Oct 29 14:12:53.937: INFO: namespace e2e-tests-container-probe-k646m deletion completed in 6.118088335s

• [SLOW TEST:248.900 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:12:53.937: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ba264d0a-db84-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 14:12:54.016: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ba26ef60-db84-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-w2jhp" to be "success or failure"
Oct 29 14:12:54.022: INFO: Pod "pod-projected-secrets-ba26ef60-db84-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.21141ms
Oct 29 14:12:56.027: INFO: Pod "pod-projected-secrets-ba26ef60-db84-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010610073s
STEP: Saw pod success
Oct 29 14:12:56.027: INFO: Pod "pod-projected-secrets-ba26ef60-db84-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:12:56.030: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-projected-secrets-ba26ef60-db84-11e8-94a0-9e8b538e2da3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:12:56.059: INFO: Waiting for pod pod-projected-secrets-ba26ef60-db84-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:12:56.062: INFO: Pod pod-projected-secrets-ba26ef60-db84-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:12:56.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w2jhp" for this suite.
Oct 29 14:13:02.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:13:02.172: INFO: namespace: e2e-tests-projected-w2jhp, resource: bindings, ignored listing per whitelist
Oct 29 14:13:02.182: INFO: namespace e2e-tests-projected-w2jhp deletion completed in 6.115174137s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:13:02.182: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 29 14:13:02.254: INFO: Waiting up to 5m0s for pod "pod-bf0fcf00-db84-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-jjkmw" to be "success or failure"
Oct 29 14:13:02.259: INFO: Pod "pod-bf0fcf00-db84-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.53592ms
Oct 29 14:13:04.264: INFO: Pod "pod-bf0fcf00-db84-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009560548s
STEP: Saw pod success
Oct 29 14:13:04.264: INFO: Pod "pod-bf0fcf00-db84-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:13:04.268: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-bf0fcf00-db84-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 14:13:04.316: INFO: Waiting for pod pod-bf0fcf00-db84-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:13:04.329: INFO: Pod pod-bf0fcf00-db84-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:13:04.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jjkmw" for this suite.
Oct 29 14:13:10.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:13:10.464: INFO: namespace: e2e-tests-emptydir-jjkmw, resource: bindings, ignored listing per whitelist
Oct 29 14:13:10.467: INFO: namespace e2e-tests-emptydir-jjkmw deletion completed in 6.131705271s

• [SLOW TEST:8.285 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:13:10.468: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 14:13:10.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mmwjc'
Oct 29 14:13:10.637: INFO: stderr: ""
Oct 29 14:13:10.637: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 29 14:13:15.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mmwjc -o json'
Oct 29 14:13:15.772: INFO: stderr: ""
Oct 29 14:13:15.772: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.3.199/32\"\n        },\n        \"creationTimestamp\": \"2018-10-29T14:13:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-mmwjc\",\n        \"resourceVersion\": \"482769\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-mmwjc/pods/e2e-test-nginx-pod\",\n        \"uid\": \"c40e77b8-db84-11e8-84ce-06e69adc25c2\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-v6jgg\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"ip-10-0-1-140.eu-west-1.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-v6jgg\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-v6jgg\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-10-29T14:13:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-10-29T14:13:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-10-29T14:13:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-10-29T14:13:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://51867116855d14bd2b01217398db27e98eaa23f6d613c77884c31c5ed288060f\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-10-29T14:13:11Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.1.140\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.3.199\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-10-29T14:13:10Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 29 14:13:15.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 replace -f - --namespace=e2e-tests-kubectl-mmwjc'
Oct 29 14:13:15.949: INFO: stderr: ""
Oct 29 14:13:15.949: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Oct 29 14:13:15.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mmwjc'
Oct 29 14:13:18.354: INFO: stderr: ""
Oct 29 14:13:18.354: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:13:18.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mmwjc" for this suite.
Oct 29 14:13:24.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:13:24.397: INFO: namespace: e2e-tests-kubectl-mmwjc, resource: bindings, ignored listing per whitelist
Oct 29 14:13:24.472: INFO: namespace e2e-tests-kubectl-mmwjc deletion completed in 6.113356212s

• [SLOW TEST:14.005 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:13:24.472: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:13:24.548: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc59bd67-db84-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-f29s9" to be "success or failure"
Oct 29 14:13:24.553: INFO: Pod "downwardapi-volume-cc59bd67-db84-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.559021ms
Oct 29 14:13:26.557: INFO: Pod "downwardapi-volume-cc59bd67-db84-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008796153s
STEP: Saw pod success
Oct 29 14:13:26.557: INFO: Pod "downwardapi-volume-cc59bd67-db84-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:13:26.560: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downwardapi-volume-cc59bd67-db84-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 14:13:26.581: INFO: Waiting for pod downwardapi-volume-cc59bd67-db84-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:13:26.585: INFO: Pod downwardapi-volume-cc59bd67-db84-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:13:26.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f29s9" for this suite.
Oct 29 14:13:32.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:13:32.657: INFO: namespace: e2e-tests-projected-f29s9, resource: bindings, ignored listing per whitelist
Oct 29 14:13:32.711: INFO: namespace e2e-tests-projected-f29s9 deletion completed in 6.119661531s

• [SLOW TEST:8.238 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:13:32.711: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Oct 29 14:13:34.801: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-d141ddea-db84-11e8-94a0-9e8b538e2da3", GenerateName:"", Namespace:"e2e-tests-pods-dp244", SelfLink:"/api/v1/namespaces/e2e-tests-pods-dp244/pods/pod-submit-remove-d141ddea-db84-11e8-94a0-9e8b538e2da3", UID:"d1431225-db84-11e8-84e8-0a8bfd2d149c", ResourceVersion:"482870", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63676419212, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"772098106", "name":"foo"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.3.200/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-ml6lb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422a56200), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ml6lb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421e595e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-1-140.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421dd8c00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421e59620)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421e59640)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421e59648), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419212, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419214, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419214, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419212, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.1.140", PodIP:"192.168.3.200", StartTime:(*v1.Time)(0xc422ab8a00), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc422ab8a20), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf", ContainerID:"containerd://3db478b1d4b5435be59b47a955ced1a3294838960629e1d6987de3fc1a1251dd"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 29 14:13:39.816: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:13:39.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dp244" for this suite.
Oct 29 14:13:45.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:13:45.926: INFO: namespace: e2e-tests-pods-dp244, resource: bindings, ignored listing per whitelist
Oct 29 14:13:45.938: INFO: namespace e2e-tests-pods-dp244 deletion completed in 6.113989733s

• [SLOW TEST:13.227 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:13:45.939: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-gh88
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 14:13:46.022: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-gh88" in namespace "e2e-tests-subpath-9wmwf" to be "success or failure"
Oct 29 14:13:46.029: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Pending", Reason="", readiness=false. Elapsed: 6.092554ms
Oct 29 14:13:48.033: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010525042s
Oct 29 14:13:50.037: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 4.01461872s
Oct 29 14:13:52.047: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 6.024695652s
Oct 29 14:13:54.052: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 8.028997538s
Oct 29 14:13:56.056: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 10.033400048s
Oct 29 14:13:58.060: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 12.03756924s
Oct 29 14:14:00.064: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 14.041876791s
Oct 29 14:14:02.075: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 16.052146749s
Oct 29 14:14:04.079: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 18.056223049s
Oct 29 14:14:06.083: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 20.060223101s
Oct 29 14:14:08.087: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Running", Reason="", readiness=false. Elapsed: 22.064460527s
Oct 29 14:14:10.091: INFO: Pod "pod-subpath-test-projected-gh88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.068620097s
STEP: Saw pod success
Oct 29 14:14:10.091: INFO: Pod "pod-subpath-test-projected-gh88" satisfied condition "success or failure"
Oct 29 14:14:10.095: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-subpath-test-projected-gh88 container test-container-subpath-projected-gh88: <nil>
STEP: delete the pod
Oct 29 14:14:10.118: INFO: Waiting for pod pod-subpath-test-projected-gh88 to disappear
Oct 29 14:14:10.121: INFO: Pod pod-subpath-test-projected-gh88 no longer exists
STEP: Deleting pod pod-subpath-test-projected-gh88
Oct 29 14:14:10.121: INFO: Deleting pod "pod-subpath-test-projected-gh88" in namespace "e2e-tests-subpath-9wmwf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:14:10.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9wmwf" for this suite.
Oct 29 14:14:16.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:14:16.208: INFO: namespace: e2e-tests-subpath-9wmwf, resource: bindings, ignored listing per whitelist
Oct 29 14:14:16.247: INFO: namespace e2e-tests-subpath-9wmwf deletion completed in 6.118849768s

• [SLOW TEST:30.308 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:14:16.247: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:14:16.334: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb378a57-db84-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-72lj7" to be "success or failure"
Oct 29 14:14:16.339: INFO: Pod "downwardapi-volume-eb378a57-db84-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.639664ms
Oct 29 14:14:18.343: INFO: Pod "downwardapi-volume-eb378a57-db84-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009005253s
STEP: Saw pod success
Oct 29 14:14:18.343: INFO: Pod "downwardapi-volume-eb378a57-db84-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:14:18.346: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-eb378a57-db84-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 14:14:18.366: INFO: Waiting for pod downwardapi-volume-eb378a57-db84-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:14:18.370: INFO: Pod downwardapi-volume-eb378a57-db84-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:14:18.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-72lj7" for this suite.
Oct 29 14:14:24.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:14:24.476: INFO: namespace: e2e-tests-downward-api-72lj7, resource: bindings, ignored listing per whitelist
Oct 29 14:14:24.491: INFO: namespace e2e-tests-downward-api-72lj7 deletion completed in 6.116271812s

• [SLOW TEST:8.243 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:14:24.491: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Oct 29 14:14:24.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 cluster-info'
Oct 29 14:14:24.639: INFO: stderr: ""
Oct 29 14:14:24.639: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:14:24.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d9zmb" for this suite.
Oct 29 14:14:30.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:14:30.757: INFO: namespace: e2e-tests-kubectl-d9zmb, resource: bindings, ignored listing per whitelist
Oct 29 14:14:30.762: INFO: namespace e2e-tests-kubectl-d9zmb deletion completed in 6.118611604s

• [SLOW TEST:6.272 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:14:30.763: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:14:30.840: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f3dcd4cd-db84-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-7f6vk" to be "success or failure"
Oct 29 14:14:30.848: INFO: Pod "downwardapi-volume-f3dcd4cd-db84-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.806964ms
Oct 29 14:14:32.866: INFO: Pod "downwardapi-volume-f3dcd4cd-db84-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026073082s
STEP: Saw pod success
Oct 29 14:14:32.866: INFO: Pod "downwardapi-volume-f3dcd4cd-db84-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:14:32.869: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downwardapi-volume-f3dcd4cd-db84-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 14:14:32.891: INFO: Waiting for pod downwardapi-volume-f3dcd4cd-db84-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:14:32.896: INFO: Pod downwardapi-volume-f3dcd4cd-db84-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:14:32.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7f6vk" for this suite.
Oct 29 14:14:38.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:14:38.970: INFO: namespace: e2e-tests-downward-api-7f6vk, resource: bindings, ignored listing per whitelist
Oct 29 14:14:39.030: INFO: namespace e2e-tests-downward-api-7f6vk deletion completed in 6.128827864s

• [SLOW TEST:8.267 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:14:39.030: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:14:39.103: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8c9d2f6-db84-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-fsqqb" to be "success or failure"
Oct 29 14:14:39.108: INFO: Pod "downwardapi-volume-f8c9d2f6-db84-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.393147ms
Oct 29 14:14:41.112: INFO: Pod "downwardapi-volume-f8c9d2f6-db84-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009325489s
STEP: Saw pod success
Oct 29 14:14:41.112: INFO: Pod "downwardapi-volume-f8c9d2f6-db84-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:14:41.116: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-f8c9d2f6-db84-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 14:14:41.136: INFO: Waiting for pod downwardapi-volume-f8c9d2f6-db84-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:14:41.139: INFO: Pod downwardapi-volume-f8c9d2f6-db84-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:14:41.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fsqqb" for this suite.
Oct 29 14:14:47.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:14:47.198: INFO: namespace: e2e-tests-downward-api-fsqqb, resource: bindings, ignored listing per whitelist
Oct 29 14:14:47.257: INFO: namespace e2e-tests-downward-api-fsqqb deletion completed in 6.113791615s

• [SLOW TEST:8.227 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:14:47.257: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 29 14:14:47.344: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:47.344: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:47.345: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:47.348: INFO: Number of nodes with available pods: 0
Oct 29 14:14:47.348: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:48.355: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:48.355: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:48.355: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:48.359: INFO: Number of nodes with available pods: 1
Oct 29 14:14:48.359: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:49.354: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:49.354: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:49.354: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:49.357: INFO: Number of nodes with available pods: 2
Oct 29 14:14:49.357: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 29 14:14:49.379: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:49.379: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:49.379: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:49.383: INFO: Number of nodes with available pods: 1
Oct 29 14:14:49.383: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:50.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:50.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:50.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:50.391: INFO: Number of nodes with available pods: 1
Oct 29 14:14:50.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:51.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:51.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:51.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:51.393: INFO: Number of nodes with available pods: 1
Oct 29 14:14:51.393: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:52.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:52.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:52.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:52.391: INFO: Number of nodes with available pods: 1
Oct 29 14:14:52.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:53.394: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:53.394: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:53.394: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:53.397: INFO: Number of nodes with available pods: 1
Oct 29 14:14:53.397: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:54.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:54.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:54.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:54.392: INFO: Number of nodes with available pods: 1
Oct 29 14:14:54.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:55.417: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:55.417: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:55.417: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:55.435: INFO: Number of nodes with available pods: 1
Oct 29 14:14:55.435: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:56.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:56.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:56.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:56.392: INFO: Number of nodes with available pods: 1
Oct 29 14:14:56.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:57.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:57.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:57.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:57.391: INFO: Number of nodes with available pods: 1
Oct 29 14:14:57.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:58.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:58.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:58.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:58.391: INFO: Number of nodes with available pods: 1
Oct 29 14:14:58.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:14:59.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:59.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:59.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:14:59.391: INFO: Number of nodes with available pods: 1
Oct 29 14:14:59.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:00.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:00.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:00.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:00.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:00.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:01.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:01.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:01.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:01.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:01.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:02.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:02.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:02.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:02.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:02.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:03.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:03.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:03.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:03.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:03.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:04.394: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:04.394: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:04.394: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:04.397: INFO: Number of nodes with available pods: 1
Oct 29 14:15:04.397: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:05.417: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:05.417: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:05.417: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:05.425: INFO: Number of nodes with available pods: 1
Oct 29 14:15:05.425: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:06.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:06.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:06.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:06.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:06.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:07.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:07.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:07.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:07.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:07.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:08.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:08.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:08.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:08.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:08.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:09.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:09.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:09.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:09.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:09.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:10.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:10.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:10.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:10.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:10.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:11.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:11.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:11.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:11.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:11.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:12.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:12.389: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:12.389: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:12.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:12.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:13.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:13.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:13.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:13.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:13.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:14.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:14.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:14.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:14.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:14.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:15.402: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:15.402: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:15.402: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:15.407: INFO: Number of nodes with available pods: 1
Oct 29 14:15:15.407: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:16.464: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:16.464: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:16.464: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:16.468: INFO: Number of nodes with available pods: 1
Oct 29 14:15:16.468: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:17.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:17.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:17.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:17.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:17.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:18.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:18.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:18.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:18.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:18.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:19.387: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:19.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:19.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:19.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:19.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:20.390: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:20.390: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:20.390: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:20.394: INFO: Number of nodes with available pods: 1
Oct 29 14:15:20.394: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:21.393: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:21.393: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:21.393: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:21.398: INFO: Number of nodes with available pods: 1
Oct 29 14:15:21.398: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:22.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:22.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:22.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:22.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:22.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:23.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:23.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:23.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:23.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:23.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:24.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:24.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:24.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:24.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:24.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:25.397: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:25.397: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:25.398: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:25.403: INFO: Number of nodes with available pods: 1
Oct 29 14:15:25.403: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:26.394: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:26.394: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:26.394: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:26.397: INFO: Number of nodes with available pods: 1
Oct 29 14:15:26.397: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:27.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:27.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:27.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:27.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:27.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:28.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:28.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:28.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:28.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:28.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:29.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:29.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:29.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:29.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:29.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:30.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:30.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:30.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:30.391: INFO: Number of nodes with available pods: 1
Oct 29 14:15:30.391: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:31.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:31.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:31.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:31.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:31.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:32.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:32.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:32.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:32.392: INFO: Number of nodes with available pods: 1
Oct 29 14:15:32.392: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:33.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:33.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:33.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:33.394: INFO: Number of nodes with available pods: 1
Oct 29 14:15:33.394: INFO: Node ip-10-0-2-47.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:15:34.388: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:34.388: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:34.388: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:15:34.391: INFO: Number of nodes with available pods: 2
Oct 29 14:15:34.391: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-4bsb6, will wait for the garbage collector to delete the pods
Oct 29 14:15:34.457: INFO: Deleting {extensions DaemonSet} daemon-set took: 9.089483ms
Oct 29 14:15:34.557: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.164918ms
Oct 29 14:16:12.968: INFO: Number of nodes with available pods: 0
Oct 29 14:16:12.968: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 14:16:12.973: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4bsb6/daemonsets","resourceVersion":"483356"},"items":null}

Oct 29 14:16:12.976: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4bsb6/pods","resourceVersion":"483357"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:16:12.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4bsb6" for this suite.
Oct 29 14:16:19.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:16:19.022: INFO: namespace: e2e-tests-daemonsets-4bsb6, resource: bindings, ignored listing per whitelist
Oct 29 14:16:19.135: INFO: namespace e2e-tests-daemonsets-4bsb6 deletion completed in 6.144375486s

• [SLOW TEST:91.878 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:16:19.135: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1029 14:16:29.312926      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 14:16:29.312: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:16:29.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ns5qs" for this suite.
Oct 29 14:16:35.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:16:35.367: INFO: namespace: e2e-tests-gc-ns5qs, resource: bindings, ignored listing per whitelist
Oct 29 14:16:35.537: INFO: namespace e2e-tests-gc-ns5qs deletion completed in 6.220544542s

• [SLOW TEST:16.402 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:16:35.537: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Oct 29 14:16:35.623: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:16:39.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2ttcl" for this suite.
Oct 29 14:17:01.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:17:01.205: INFO: namespace: e2e-tests-init-container-2ttcl, resource: bindings, ignored listing per whitelist
Oct 29 14:17:01.224: INFO: namespace e2e-tests-init-container-2ttcl deletion completed in 22.136797076s

• [SLOW TEST:25.686 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:17:01.225: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-4d8b5cfa-db85-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 14:17:01.305: INFO: Waiting up to 5m0s for pod "pod-secrets-4d8c118e-db85-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-secrets-7wkn2" to be "success or failure"
Oct 29 14:17:01.308: INFO: Pod "pod-secrets-4d8c118e-db85-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.433104ms
Oct 29 14:17:03.312: INFO: Pod "pod-secrets-4d8c118e-db85-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007444786s
STEP: Saw pod success
Oct 29 14:17:03.312: INFO: Pod "pod-secrets-4d8c118e-db85-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:17:03.315: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-secrets-4d8c118e-db85-11e8-94a0-9e8b538e2da3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:17:03.337: INFO: Waiting for pod pod-secrets-4d8c118e-db85-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:17:03.340: INFO: Pod pod-secrets-4d8c118e-db85-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:17:03.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7wkn2" for this suite.
Oct 29 14:17:09.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:17:09.450: INFO: namespace: e2e-tests-secrets-7wkn2, resource: bindings, ignored listing per whitelist
Oct 29 14:17:09.465: INFO: namespace e2e-tests-secrets-7wkn2 deletion completed in 6.121166977s

• [SLOW TEST:8.241 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:17:09.466: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Oct 29 14:17:09.532: INFO: Waiting up to 5m0s for pod "client-containers-5273d507-db85-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-containers-ngx7d" to be "success or failure"
Oct 29 14:17:09.536: INFO: Pod "client-containers-5273d507-db85-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.359618ms
Oct 29 14:17:11.540: INFO: Pod "client-containers-5273d507-db85-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007188877s
STEP: Saw pod success
Oct 29 14:17:11.540: INFO: Pod "client-containers-5273d507-db85-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:17:11.543: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod client-containers-5273d507-db85-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 14:17:11.564: INFO: Waiting for pod client-containers-5273d507-db85-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:17:11.575: INFO: Pod client-containers-5273d507-db85-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:17:11.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ngx7d" for this suite.
Oct 29 14:17:17.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:17:17.611: INFO: namespace: e2e-tests-containers-ngx7d, resource: bindings, ignored listing per whitelist
Oct 29 14:17:17.691: INFO: namespace e2e-tests-containers-ngx7d deletion completed in 6.110680934s

• [SLOW TEST:8.225 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:17:17.691: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-575bc528-db85-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume secrets
Oct 29 14:17:17.769: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-575c7b09-db85-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-wmsgf" to be "success or failure"
Oct 29 14:17:17.774: INFO: Pod "pod-projected-secrets-575c7b09-db85-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.298689ms
Oct 29 14:17:19.783: INFO: Pod "pod-projected-secrets-575c7b09-db85-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013893227s
STEP: Saw pod success
Oct 29 14:17:19.783: INFO: Pod "pod-projected-secrets-575c7b09-db85-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:17:19.787: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-projected-secrets-575c7b09-db85-11e8-94a0-9e8b538e2da3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:17:19.808: INFO: Waiting for pod pod-projected-secrets-575c7b09-db85-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:17:19.811: INFO: Pod pod-projected-secrets-575c7b09-db85-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:17:19.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wmsgf" for this suite.
Oct 29 14:17:25.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:17:25.860: INFO: namespace: e2e-tests-projected-wmsgf, resource: bindings, ignored listing per whitelist
Oct 29 14:17:25.933: INFO: namespace e2e-tests-projected-wmsgf deletion completed in 6.11742501s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:17:25.934: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tgkjw
Oct 29 14:17:28.013: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tgkjw
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 14:17:28.016: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:21:28.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tgkjw" for this suite.
Oct 29 14:21:34.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:21:34.774: INFO: namespace: e2e-tests-container-probe-tgkjw, resource: bindings, ignored listing per whitelist
Oct 29 14:21:34.847: INFO: namespace e2e-tests-container-probe-tgkjw deletion completed in 6.120747797s

• [SLOW TEST:248.913 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:21:34.848: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 14:21:34.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 version --client'
Oct 29 14:21:34.989: INFO: stderr: ""
Oct 29 14:21:34.989: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Oct 29 14:21:34.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-tnrcl'
Oct 29 14:21:35.360: INFO: stderr: ""
Oct 29 14:21:35.360: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 29 14:21:35.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-tnrcl'
Oct 29 14:21:35.545: INFO: stderr: ""
Oct 29 14:21:35.545: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 29 14:21:36.554: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:21:36.554: INFO: Found 1 / 1
Oct 29 14:21:36.554: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 29 14:21:36.563: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:21:36.563: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 29 14:21:36.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 describe pod redis-master-tcbzn --namespace=e2e-tests-kubectl-tnrcl'
Oct 29 14:21:36.661: INFO: stderr: ""
Oct 29 14:21:36.661: INFO: stdout: "Name:               redis-master-tcbzn\nNamespace:          e2e-tests-kubectl-tnrcl\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-0-1-140.eu-west-1.compute.internal/10.0.1.140\nStart Time:         Mon, 29 Oct 2018 14:21:35 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 192.168.3.212/32\nStatus:             Running\nIP:                 192.168.3.212\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://747822c47d38775f4308ac86fba1a6aa4e60343a84cbde18c9af82672ce07eb6\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 29 Oct 2018 14:21:36 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-kqpld (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-kqpld:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-kqpld\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                               Message\n  ----    ------     ----  ----                                               -------\n  Normal  Scheduled  1s    default-scheduler                                  Successfully assigned e2e-tests-kubectl-tnrcl/redis-master-tcbzn to ip-10-0-1-140.eu-west-1.compute.internal\n  Normal  Pulled     0s    kubelet, ip-10-0-1-140.eu-west-1.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, ip-10-0-1-140.eu-west-1.compute.internal  Created container\n  Normal  Started    0s    kubelet, ip-10-0-1-140.eu-west-1.compute.internal  Started container\n"
Oct 29 14:21:36.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 describe rc redis-master --namespace=e2e-tests-kubectl-tnrcl'
Oct 29 14:21:36.784: INFO: stderr: ""
Oct 29 14:21:36.784: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-tnrcl\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-tcbzn\n"
Oct 29 14:21:36.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 describe service redis-master --namespace=e2e-tests-kubectl-tnrcl'
Oct 29 14:21:36.882: INFO: stderr: ""
Oct 29 14:21:36.882: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-tnrcl\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.103.22.161\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.3.212:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 29 14:21:36.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 describe node ip-10-0-1-140.eu-west-1.compute.internal'
Oct 29 14:21:37.000: INFO: stderr: ""
Oct 29 14:21:37.000: INFO: stdout: "Name:               ip-10-0-1-140.eu-west-1.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t3.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-west-1\n                    failure-domain.beta.kubernetes.io/zone=eu-west-1a\n                    kubernetes.io/hostname=ip-10-0-1-140.eu-west-1.compute.internal\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.1.140/24\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 26 Oct 2018 14:32:12 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Mon, 29 Oct 2018 14:21:29 +0000   Fri, 26 Oct 2018 14:32:12 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Mon, 29 Oct 2018 14:21:29 +0000   Fri, 26 Oct 2018 14:32:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 29 Oct 2018 14:21:29 +0000   Fri, 26 Oct 2018 14:32:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 29 Oct 2018 14:21:29 +0000   Fri, 26 Oct 2018 14:32:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 29 Oct 2018 14:21:29 +0000   Mon, 29 Oct 2018 12:55:12 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.0.1.140\n  InternalDNS:  ip-10-0-1-140.eu-west-1.compute.internal\n  Hostname:     ip-10-0-1-140.eu-west-1.compute.internal\nCapacity:\n attachable-volumes-aws-ebs:     25\n attachable-volumes-azure-disk:  16\n cpu:                            2\n ephemeral-storage:              48375392Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         8066816Ki\n pods:                           110\nAllocatable:\n attachable-volumes-aws-ebs:     25\n attachable-volumes-azure-disk:  16\n cpu:                            2\n ephemeral-storage:              44582761194\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7964416Ki\n pods:                           110\nSystem Info:\n Machine ID:                 ec2c53de1a22326cba553a3289531246\n System UUID:                EC2C53DE-1A22-326C-BA55-3A3289531246\n Boot ID:                    ff6cf9d8-eae9-4834-89b3-4236aab65033\n Kernel Version:             4.14.74-coreos\n OS Image:                   Container Linux by CoreOS 1855.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.1.4\n Kubelet Version:            v1.12.2\n Kube-Proxy Version:         v1.12.2\nPodCIDR:                     192.168.3.0/24\nProviderID:                  aws:///eu-west-1a/i-0824510f89ba163b7\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  default                    nginx-6c94d899fd-6x4kg                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  default                    nginx-6c94d899fd-w6mz2                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  e2e-tests-kubectl-tnrcl    redis-master-tcbzn                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-vmft4    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-gqfq5                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                coredns-576cbf47c7-96r4w                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)\n  kube-system                coredns-576cbf47c7-m8lhm                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)\n  kube-system                kube-proxy-7msnt                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests    Limits\n  --------                       --------    ------\n  cpu                            450m (22%)  0 (0%)\n  memory                         140Mi (1%)  340Mi (4%)\n  attachable-volumes-aws-ebs     0           0\n  attachable-volumes-azure-disk  0           0\nEvents:                          <none>\n"
Oct 29 14:21:37.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 describe namespace e2e-tests-kubectl-tnrcl'
Oct 29 14:21:37.100: INFO: stderr: ""
Oct 29 14:21:37.100: INFO: stdout: "Name:         e2e-tests-kubectl-tnrcl\nLabels:       e2e-framework=kubectl\n              e2e-run=2811eab1-db7d-11e8-94a0-9e8b538e2da3\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:21:37.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tnrcl" for this suite.
Oct 29 14:21:59.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:21:59.200: INFO: namespace: e2e-tests-kubectl-tnrcl, resource: bindings, ignored listing per whitelist
Oct 29 14:21:59.220: INFO: namespace e2e-tests-kubectl-tnrcl deletion completed in 22.115323064s

• [SLOW TEST:24.372 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:21:59.221: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:22:05.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-fql68" for this suite.
Oct 29 14:22:11.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:22:11.510: INFO: namespace: e2e-tests-namespaces-fql68, resource: bindings, ignored listing per whitelist
Oct 29 14:22:11.586: INFO: namespace e2e-tests-namespaces-fql68 deletion completed in 6.18375734s
STEP: Destroying namespace "e2e-tests-nsdeletetest-d9hl7" for this suite.
Oct 29 14:22:11.589: INFO: Namespace e2e-tests-nsdeletetest-d9hl7 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-fjql7" for this suite.
Oct 29 14:22:17.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:22:17.694: INFO: namespace: e2e-tests-nsdeletetest-fjql7, resource: bindings, ignored listing per whitelist
Oct 29 14:22:17.703: INFO: namespace e2e-tests-nsdeletetest-fjql7 deletion completed in 6.113469339s

• [SLOW TEST:18.482 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:22:17.703: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Oct 29 14:22:17.785: INFO: Waiting up to 5m0s for pod "var-expansion-0a2f2b60-db86-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-var-expansion-qch5w" to be "success or failure"
Oct 29 14:22:17.788: INFO: Pod "var-expansion-0a2f2b60-db86-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.668281ms
Oct 29 14:22:19.829: INFO: Pod "var-expansion-0a2f2b60-db86-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044521881s
STEP: Saw pod success
Oct 29 14:22:19.829: INFO: Pod "var-expansion-0a2f2b60-db86-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:22:19.833: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod var-expansion-0a2f2b60-db86-11e8-94a0-9e8b538e2da3 container dapi-container: <nil>
STEP: delete the pod
Oct 29 14:22:19.866: INFO: Waiting for pod var-expansion-0a2f2b60-db86-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:22:19.888: INFO: Pod var-expansion-0a2f2b60-db86-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:22:19.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qch5w" for this suite.
Oct 29 14:22:25.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:22:25.953: INFO: namespace: e2e-tests-var-expansion-qch5w, resource: bindings, ignored listing per whitelist
Oct 29 14:22:26.014: INFO: namespace e2e-tests-var-expansion-qch5w deletion completed in 6.117319045s

• [SLOW TEST:8.311 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:22:26.014: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 29 14:22:26.082: INFO: Waiting up to 5m0s for pod "downward-api-0f21656d-db86-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-wffr7" to be "success or failure"
Oct 29 14:22:26.085: INFO: Pod "downward-api-0f21656d-db86-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.31239ms
Oct 29 14:22:28.089: INFO: Pod "downward-api-0f21656d-db86-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007807661s
STEP: Saw pod success
Oct 29 14:22:28.089: INFO: Pod "downward-api-0f21656d-db86-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:22:28.093: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downward-api-0f21656d-db86-11e8-94a0-9e8b538e2da3 container dapi-container: <nil>
STEP: delete the pod
Oct 29 14:22:28.117: INFO: Waiting for pod downward-api-0f21656d-db86-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:22:28.121: INFO: Pod downward-api-0f21656d-db86-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:22:28.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wffr7" for this suite.
Oct 29 14:22:34.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:22:34.164: INFO: namespace: e2e-tests-downward-api-wffr7, resource: bindings, ignored listing per whitelist
Oct 29 14:22:34.245: INFO: namespace e2e-tests-downward-api-wffr7 deletion completed in 6.120387073s

• [SLOW TEST:8.231 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:22:34.245: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-140d7c0b-db86-11e8-94a0-9e8b538e2da3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-140d7c0b-db86-11e8-94a0-9e8b538e2da3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:22:38.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hntb4" for this suite.
Oct 29 14:22:58.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:22:58.521: INFO: namespace: e2e-tests-configmap-hntb4, resource: bindings, ignored listing per whitelist
Oct 29 14:22:58.547: INFO: namespace e2e-tests-configmap-hntb4 deletion completed in 20.114717969s

• [SLOW TEST:24.302 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:22:58.547: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-9922l/configmap-test-2286818b-db86-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:22:58.626: INFO: Waiting up to 5m0s for pod "pod-configmaps-228730b8-db86-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-9922l" to be "success or failure"
Oct 29 14:22:58.632: INFO: Pod "pod-configmaps-228730b8-db86-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.895947ms
Oct 29 14:23:00.637: INFO: Pod "pod-configmaps-228730b8-db86-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010283878s
STEP: Saw pod success
Oct 29 14:23:00.637: INFO: Pod "pod-configmaps-228730b8-db86-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:23:00.640: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-configmaps-228730b8-db86-11e8-94a0-9e8b538e2da3 container env-test: <nil>
STEP: delete the pod
Oct 29 14:23:00.662: INFO: Waiting for pod pod-configmaps-228730b8-db86-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:23:00.665: INFO: Pod pod-configmaps-228730b8-db86-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:23:00.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9922l" for this suite.
Oct 29 14:23:06.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:23:06.747: INFO: namespace: e2e-tests-configmap-9922l, resource: bindings, ignored listing per whitelist
Oct 29 14:23:06.803: INFO: namespace e2e-tests-configmap-9922l deletion completed in 6.134356316s

• [SLOW TEST:8.256 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:23:06.804: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 14:23:06.924: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 29 14:23:11.929: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 29 14:23:11.929: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 29 14:23:13.934: INFO: Creating deployment "test-rollover-deployment"
Oct 29 14:23:13.943: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 29 14:23:15.951: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 29 14:23:15.957: INFO: Ensure that both replica sets have 1 created replica
Oct 29 14:23:15.964: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 29 14:23:15.972: INFO: Updating deployment test-rollover-deployment
Oct 29 14:23:15.972: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 29 14:23:17.985: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 29 14:23:17.992: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 29 14:23:18.003: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 14:23:18.003: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419797, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 14:23:20.012: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 14:23:20.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419797, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 14:23:22.012: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 14:23:22.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419797, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 14:23:24.011: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 14:23:24.011: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419797, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 14:23:26.012: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 14:23:26.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419797, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419793, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 14:23:28.017: INFO: 
Oct 29 14:23:28.017: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 29 14:23:28.037: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-z2gz8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z2gz8/deployments/test-rollover-deployment,UID:2ba871db-db86-11e8-84e8-0a8bfd2d149c,ResourceVersion:484866,Generation:2,CreationTimestamp:2018-10-29 14:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-10-29 14:23:13 +0000 UTC 2018-10-29 14:23:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-10-29 14:23:27 +0000 UTC 2018-10-29 14:23:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 29 14:23:28.041: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-z2gz8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z2gz8/replicasets/test-rollover-deployment-5b76ff8c4,UID:2cdf6479-db86-11e8-84e8-0a8bfd2d149c,ResourceVersion:484857,Generation:2,CreationTimestamp:2018-10-29 14:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2ba871db-db86-11e8-84e8-0a8bfd2d149c 0xc422cfe487 0xc422cfe488}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 29 14:23:28.041: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 29 14:23:28.041: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-z2gz8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z2gz8/replicasets/test-rollover-controller,UID:277956ac-db86-11e8-84e8-0a8bfd2d149c,ResourceVersion:484865,Generation:2,CreationTimestamp:2018-10-29 14:23:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2ba871db-db86-11e8-84e8-0a8bfd2d149c 0xc422cfe3be 0xc422cfe3bf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 14:23:28.041: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-z2gz8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z2gz8/replicasets/test-rollover-deployment-6975f4fb87,UID:2babe658-db86-11e8-84e8-0a8bfd2d149c,ResourceVersion:484825,Generation:2,CreationTimestamp:2018-10-29 14:23:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2ba871db-db86-11e8-84e8-0a8bfd2d149c 0xc422cfe547 0xc422cfe548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 14:23:28.048: INFO: Pod "test-rollover-deployment-5b76ff8c4-8wbd6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-8wbd6,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-z2gz8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2gz8/pods/test-rollover-deployment-5b76ff8c4-8wbd6,UID:2ce4c826-db86-11e8-84e8-0a8bfd2d149c,ResourceVersion:484836,Generation:0,CreationTimestamp:2018-10-29 14:23:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.216/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 2cdf6479-db86-11e8-84e8-0a8bfd2d149c 0xc422cff140 0xc422cff141}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lw6ll {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lw6ll,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lw6ll true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422cff1c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422cff1f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:23:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:23:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:23:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:23:16 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.216,StartTime:2018-10-29 14:23:16 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-10-29 14:23:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://8f36d15b4b5916e0a16146e5dd2273b495a3b589e394cfae7e73dfde169ecacb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:23:28.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-z2gz8" for this suite.
Oct 29 14:23:34.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:23:34.157: INFO: namespace: e2e-tests-deployment-z2gz8, resource: bindings, ignored listing per whitelist
Oct 29 14:23:34.171: INFO: namespace e2e-tests-deployment-z2gz8 deletion completed in 6.119053477s

• [SLOW TEST:27.368 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:23:34.172: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-49kz
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 14:23:34.272: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-49kz" in namespace "e2e-tests-subpath-chkhd" to be "success or failure"
Oct 29 14:23:34.282: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Pending", Reason="", readiness=false. Elapsed: 10.808544ms
Oct 29 14:23:36.286: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014914317s
Oct 29 14:23:38.302: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 4.030246009s
Oct 29 14:23:40.305: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 6.03385256s
Oct 29 14:23:42.310: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 8.038095823s
Oct 29 14:23:44.316: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 10.044677174s
Oct 29 14:23:46.321: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 12.049013363s
Oct 29 14:23:48.344: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 14.072295539s
Oct 29 14:23:50.348: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 16.07619721s
Oct 29 14:23:52.352: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 18.080533241s
Oct 29 14:23:54.357: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 20.085316115s
Oct 29 14:23:56.361: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Running", Reason="", readiness=false. Elapsed: 22.089555883s
Oct 29 14:23:58.372: INFO: Pod "pod-subpath-test-configmap-49kz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.100046319s
STEP: Saw pod success
Oct 29 14:23:58.372: INFO: Pod "pod-subpath-test-configmap-49kz" satisfied condition "success or failure"
Oct 29 14:23:58.378: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-subpath-test-configmap-49kz container test-container-subpath-configmap-49kz: <nil>
STEP: delete the pod
Oct 29 14:23:58.416: INFO: Waiting for pod pod-subpath-test-configmap-49kz to disappear
Oct 29 14:23:58.421: INFO: Pod pod-subpath-test-configmap-49kz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-49kz
Oct 29 14:23:58.421: INFO: Deleting pod "pod-subpath-test-configmap-49kz" in namespace "e2e-tests-subpath-chkhd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:23:58.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-chkhd" for this suite.
Oct 29 14:24:04.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:24:04.505: INFO: namespace: e2e-tests-subpath-chkhd, resource: bindings, ignored listing per whitelist
Oct 29 14:24:04.550: INFO: namespace e2e-tests-subpath-chkhd deletion completed in 6.120511342s

• [SLOW TEST:30.379 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:24:04.550: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-6h6lh
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-6h6lh
STEP: Deleting pre-stop pod
Oct 29 14:24:13.682: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:24:13.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-6h6lh" for this suite.
Oct 29 14:24:53.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:24:53.818: INFO: namespace: e2e-tests-prestop-6h6lh, resource: bindings, ignored listing per whitelist
Oct 29 14:24:53.849: INFO: namespace e2e-tests-prestop-6h6lh deletion completed in 40.148962461s

• [SLOW TEST:49.299 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:24:53.849: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-cr8t
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 14:24:53.932: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-cr8t" in namespace "e2e-tests-subpath-hmhxs" to be "success or failure"
Oct 29 14:24:53.935: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Pending", Reason="", readiness=false. Elapsed: 3.016957ms
Oct 29 14:24:55.939: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007480126s
Oct 29 14:24:57.944: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 4.011824959s
Oct 29 14:24:59.950: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 6.017807089s
Oct 29 14:25:01.954: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 8.02220275s
Oct 29 14:25:03.964: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 10.032395968s
Oct 29 14:25:05.969: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 12.036716604s
Oct 29 14:25:07.975: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 14.043113055s
Oct 29 14:25:09.987: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 16.054690895s
Oct 29 14:25:11.991: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 18.058991341s
Oct 29 14:25:14.001: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 20.068837827s
Oct 29 14:25:16.005: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Running", Reason="", readiness=false. Elapsed: 22.073185577s
Oct 29 14:25:18.009: INFO: Pod "pod-subpath-test-secret-cr8t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.07743967s
STEP: Saw pod success
Oct 29 14:25:18.009: INFO: Pod "pod-subpath-test-secret-cr8t" satisfied condition "success or failure"
Oct 29 14:25:18.013: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-subpath-test-secret-cr8t container test-container-subpath-secret-cr8t: <nil>
STEP: delete the pod
Oct 29 14:25:18.050: INFO: Waiting for pod pod-subpath-test-secret-cr8t to disappear
Oct 29 14:25:18.058: INFO: Pod pod-subpath-test-secret-cr8t no longer exists
STEP: Deleting pod pod-subpath-test-secret-cr8t
Oct 29 14:25:18.058: INFO: Deleting pod "pod-subpath-test-secret-cr8t" in namespace "e2e-tests-subpath-hmhxs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:25:18.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hmhxs" for this suite.
Oct 29 14:25:24.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:25:24.151: INFO: namespace: e2e-tests-subpath-hmhxs, resource: bindings, ignored listing per whitelist
Oct 29 14:25:24.185: INFO: namespace e2e-tests-subpath-hmhxs deletion completed in 6.120210924s

• [SLOW TEST:30.336 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:25:24.186: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Oct 29 14:25:24.257: INFO: PodSpec: initContainers in spec.initContainers
Oct 29 14:26:12.049: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7955fa07-db86-11e8-94a0-9e8b538e2da3", GenerateName:"", Namespace:"e2e-tests-init-container-pcnvx", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-pcnvx/pods/pod-init-7955fa07-db86-11e8-94a0-9e8b538e2da3", UID:"7956d825-db86-11e8-84e8-0a8bfd2d149c", ResourceVersion:"485372", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63676419924, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"257848135", "name":"foo"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.3.220/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-lxpkr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42009c2c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lxpkr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lxpkr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lxpkr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4209bdcc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-1-140.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420ea2d20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4209bddd0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4209bde70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4209bde78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419924, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419924, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419924, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676419924, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.1.140", PodIP:"192.168.3.220", StartTime:(*v1.Time)(0xc4204cf860), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4211822a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421182310)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"containerd://b33ad270a1ffed773ce9b69a0bf8c3f78dcbeba0967c4b77cf19cf22c620bb5a"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4204cf8a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4204cf880), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:26:12.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pcnvx" for this suite.
Oct 29 14:26:34.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:26:34.090: INFO: namespace: e2e-tests-init-container-pcnvx, resource: bindings, ignored listing per whitelist
Oct 29 14:26:34.185: INFO: namespace e2e-tests-init-container-pcnvx deletion completed in 22.124012147s

• [SLOW TEST:69.999 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:26:34.186: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a30f0dbf-db86-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:26:34.273: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a30ff1d6-db86-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-qsv5k" to be "success or failure"
Oct 29 14:26:34.289: INFO: Pod "pod-projected-configmaps-a30ff1d6-db86-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.06545ms
Oct 29 14:26:36.294: INFO: Pod "pod-projected-configmaps-a30ff1d6-db86-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020984808s
STEP: Saw pod success
Oct 29 14:26:36.294: INFO: Pod "pod-projected-configmaps-a30ff1d6-db86-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:26:36.298: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-projected-configmaps-a30ff1d6-db86-11e8-94a0-9e8b538e2da3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:26:36.326: INFO: Waiting for pod pod-projected-configmaps-a30ff1d6-db86-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:26:36.332: INFO: Pod pod-projected-configmaps-a30ff1d6-db86-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:26:36.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qsv5k" for this suite.
Oct 29 14:26:42.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:26:42.444: INFO: namespace: e2e-tests-projected-qsv5k, resource: bindings, ignored listing per whitelist
Oct 29 14:26:42.452: INFO: namespace e2e-tests-projected-qsv5k deletion completed in 6.114575826s

• [SLOW TEST:8.267 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:26:42.453: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Oct 29 14:26:42.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-qtbv2'
Oct 29 14:26:42.686: INFO: stderr: ""
Oct 29 14:26:42.686: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Oct 29 14:26:43.691: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:26:43.691: INFO: Found 0 / 1
Oct 29 14:26:44.697: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:26:44.697: INFO: Found 1 / 1
Oct 29 14:26:44.697: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 29 14:26:44.700: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:26:44.700: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 29 14:26:44.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 logs redis-master-x5qzt redis-master --namespace=e2e-tests-kubectl-qtbv2'
Oct 29 14:26:44.803: INFO: stderr: ""
Oct 29 14:26:44.803: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Oct 14:26:43.504 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Oct 14:26:43.504 # Server started, Redis version 3.2.12\n1:M 29 Oct 14:26:43.504 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Oct 14:26:43.504 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 29 14:26:44.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 log redis-master-x5qzt redis-master --namespace=e2e-tests-kubectl-qtbv2 --tail=1'
Oct 29 14:26:44.913: INFO: stderr: ""
Oct 29 14:26:44.914: INFO: stdout: "1:M 29 Oct 14:26:43.504 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 29 14:26:44.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 log redis-master-x5qzt redis-master --namespace=e2e-tests-kubectl-qtbv2 --limit-bytes=1'
Oct 29 14:26:45.012: INFO: stderr: ""
Oct 29 14:26:45.012: INFO: stdout: " "
STEP: exposing timestamps
Oct 29 14:26:45.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 log redis-master-x5qzt redis-master --namespace=e2e-tests-kubectl-qtbv2 --tail=1 --timestamps'
Oct 29 14:26:45.106: INFO: stderr: ""
Oct 29 14:26:45.106: INFO: stdout: "2018-10-29T14:26:43.50503259Z 1:M 29 Oct 14:26:43.504 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 29 14:26:47.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 log redis-master-x5qzt redis-master --namespace=e2e-tests-kubectl-qtbv2 --since=1s'
Oct 29 14:26:47.699: INFO: stderr: ""
Oct 29 14:26:47.699: INFO: stdout: ""
Oct 29 14:26:47.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 log redis-master-x5qzt redis-master --namespace=e2e-tests-kubectl-qtbv2 --since=24h'
Oct 29 14:26:47.793: INFO: stderr: ""
Oct 29 14:26:47.793: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Oct 14:26:43.504 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Oct 14:26:43.504 # Server started, Redis version 3.2.12\n1:M 29 Oct 14:26:43.504 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Oct 14:26:43.504 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Oct 29 14:26:47.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qtbv2'
Oct 29 14:26:47.879: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 14:26:47.879: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 29 14:26:47.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-qtbv2'
Oct 29 14:26:47.966: INFO: stderr: "No resources found.\n"
Oct 29 14:26:47.966: INFO: stdout: ""
Oct 29 14:26:47.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -l name=nginx --namespace=e2e-tests-kubectl-qtbv2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 14:26:48.058: INFO: stderr: ""
Oct 29 14:26:48.058: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:26:48.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qtbv2" for this suite.
Oct 29 14:26:54.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:26:54.160: INFO: namespace: e2e-tests-kubectl-qtbv2, resource: bindings, ignored listing per whitelist
Oct 29 14:26:54.175: INFO: namespace e2e-tests-kubectl-qtbv2 deletion completed in 6.11332941s

• [SLOW TEST:11.723 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:26:54.176: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-lfdrg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 29 14:26:54.245: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 29 14:27:16.384: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.3.222 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-lfdrg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:27:16.384: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:27:17.496: INFO: Found all expected endpoints: [netserver-0]
Oct 29 14:27:17.500: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.4.105 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-lfdrg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:27:17.500: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:27:18.606: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:27:18.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-lfdrg" for this suite.
Oct 29 14:27:40.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:27:40.632: INFO: namespace: e2e-tests-pod-network-test-lfdrg, resource: bindings, ignored listing per whitelist
Oct 29 14:27:40.725: INFO: namespace e2e-tests-pod-network-test-lfdrg deletion completed in 22.114290163s

• [SLOW TEST:46.549 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:27:40.725: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8pdxm
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Oct 29 14:27:40.807: INFO: Found 0 stateful pods, waiting for 3
Oct 29 14:27:50.817: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 14:27:50.817: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 14:27:50.817: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 29 14:27:50.846: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 29 14:28:00.887: INFO: Updating stateful set ss2
Oct 29 14:28:00.894: INFO: Waiting for Pod e2e-tests-statefulset-8pdxm/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 29 14:28:10.907: INFO: Waiting for Pod e2e-tests-statefulset-8pdxm/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Oct 29 14:28:20.984: INFO: Found 2 stateful pods, waiting for 3
Oct 29 14:28:30.994: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 14:28:30.994: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 14:28:30.994: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 29 14:28:31.020: INFO: Updating stateful set ss2
Oct 29 14:28:31.029: INFO: Waiting for Pod e2e-tests-statefulset-8pdxm/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 29 14:28:41.042: INFO: Waiting for Pod e2e-tests-statefulset-8pdxm/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 29 14:28:51.061: INFO: Updating stateful set ss2
Oct 29 14:28:51.068: INFO: Waiting for StatefulSet e2e-tests-statefulset-8pdxm/ss2 to complete update
Oct 29 14:28:51.068: INFO: Waiting for Pod e2e-tests-statefulset-8pdxm/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 29 14:29:01.082: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8pdxm
Oct 29 14:29:01.086: INFO: Scaling statefulset ss2 to 0
Oct 29 14:29:31.109: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 14:29:31.112: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:29:31.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8pdxm" for this suite.
Oct 29 14:29:37.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:29:37.253: INFO: namespace: e2e-tests-statefulset-8pdxm, resource: bindings, ignored listing per whitelist
Oct 29 14:29:37.256: INFO: namespace e2e-tests-statefulset-8pdxm deletion completed in 6.120568859s

• [SLOW TEST:116.530 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:29:37.256: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Oct 29 14:29:39.864: INFO: Successfully updated pod "annotationupdate102c6e26-db87-11e8-94a0-9e8b538e2da3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:29:43.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6jb5g" for this suite.
Oct 29 14:30:05.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:30:05.982: INFO: namespace: e2e-tests-downward-api-6jb5g, resource: bindings, ignored listing per whitelist
Oct 29 14:30:06.032: INFO: namespace e2e-tests-downward-api-6jb5g deletion completed in 22.118054788s

• [SLOW TEST:28.776 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:30:06.032: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1029 14:30:16.135145      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 14:30:16.135: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:30:16.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zgt2b" for this suite.
Oct 29 14:30:22.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:30:22.238: INFO: namespace: e2e-tests-gc-zgt2b, resource: bindings, ignored listing per whitelist
Oct 29 14:30:22.256: INFO: namespace e2e-tests-gc-zgt2b deletion completed in 6.117111392s

• [SLOW TEST:16.224 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:30:22.256: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 29 14:30:24.361: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-2aff1383-db87-11e8-94a0-9e8b538e2da3,GenerateName:,Namespace:e2e-tests-events-nqd96,SelfLink:/api/v1/namespaces/e2e-tests-events-nqd96/pods/send-events-2aff1383-db87-11e8-94a0-9e8b538e2da3,UID:2b001b55-db87-11e8-84e8-0a8bfd2d149c,ResourceVersion:486339,Generation:0,CreationTimestamp:2018-10-29 14:30:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 322783348,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.230/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5gnbh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5gnbh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-5gnbh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-140.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d72c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d72c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:30:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:30:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:30:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-10-29 14:30:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.140,PodIP:192.168.3.230,StartTime:2018-10-29 14:30:22 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-10-29 14:30:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://46054473562b708dc3940b04a4270cb81e30cdc06a8222a546b7e275ff6e19bb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 29 14:30:26.372: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 29 14:30:28.377: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:30:28.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-nqd96" for this suite.
Oct 29 14:31:06.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:31:06.426: INFO: namespace: e2e-tests-events-nqd96, resource: bindings, ignored listing per whitelist
Oct 29 14:31:06.508: INFO: namespace e2e-tests-events-nqd96 deletion completed in 38.119412155s

• [SLOW TEST:44.252 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:31:06.508: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 29 14:31:06.594: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:06.594: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:06.594: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:06.598: INFO: Number of nodes with available pods: 0
Oct 29 14:31:06.598: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:31:07.603: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:07.603: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:07.603: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:07.607: INFO: Number of nodes with available pods: 1
Oct 29 14:31:07.607: INFO: Node ip-10-0-1-140.eu-west-1.compute.internal is running more than one daemon pod
Oct 29 14:31:08.603: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:08.603: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:08.603: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:08.606: INFO: Number of nodes with available pods: 2
Oct 29 14:31:08.606: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 29 14:31:08.622: INFO: DaemonSet pods can't tolerate node ip-10-0-1-22.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:08.622: INFO: DaemonSet pods can't tolerate node ip-10-0-2-8.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:08.622: INFO: DaemonSet pods can't tolerate node ip-10-0-3-123.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 14:31:08.626: INFO: Number of nodes with available pods: 2
Oct 29 14:31:08.626: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-xptc4, will wait for the garbage collector to delete the pods
Oct 29 14:31:09.706: INFO: Deleting {extensions DaemonSet} daemon-set took: 13.915163ms
Oct 29 14:31:09.806: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.186939ms
Oct 29 14:31:51.815: INFO: Number of nodes with available pods: 0
Oct 29 14:31:51.815: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 14:31:51.819: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-xptc4/daemonsets","resourceVersion":"486569"},"items":null}

Oct 29 14:31:51.822: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-xptc4/pods","resourceVersion":"486569"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:31:51.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-xptc4" for this suite.
Oct 29 14:31:57.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:31:57.923: INFO: namespace: e2e-tests-daemonsets-xptc4, resource: bindings, ignored listing per whitelist
Oct 29 14:31:57.951: INFO: namespace e2e-tests-daemonsets-xptc4 deletion completed in 6.114286398s

• [SLOW TEST:51.442 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:31:57.951: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:31:58.041: INFO: Waiting up to 5m0s for pod "downwardapi-volume-640b4ea2-db87-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-v8bk7" to be "success or failure"
Oct 29 14:31:58.045: INFO: Pod "downwardapi-volume-640b4ea2-db87-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.780315ms
Oct 29 14:32:00.049: INFO: Pod "downwardapi-volume-640b4ea2-db87-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008353861s
STEP: Saw pod success
Oct 29 14:32:00.049: INFO: Pod "downwardapi-volume-640b4ea2-db87-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:32:00.053: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod downwardapi-volume-640b4ea2-db87-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 14:32:00.089: INFO: Waiting for pod downwardapi-volume-640b4ea2-db87-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:32:00.093: INFO: Pod downwardapi-volume-640b4ea2-db87-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:32:00.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v8bk7" for this suite.
Oct 29 14:32:06.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:32:06.185: INFO: namespace: e2e-tests-projected-v8bk7, resource: bindings, ignored listing per whitelist
Oct 29 14:32:06.218: INFO: namespace e2e-tests-projected-v8bk7 deletion completed in 6.116443551s

• [SLOW TEST:8.267 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:32:06.218: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-68f5f24a-db87-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:32:06.296: INFO: Waiting up to 5m0s for pod "pod-configmaps-68f69ef4-db87-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-76t6x" to be "success or failure"
Oct 29 14:32:06.302: INFO: Pod "pod-configmaps-68f69ef4-db87-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.961702ms
Oct 29 14:32:08.307: INFO: Pod "pod-configmaps-68f69ef4-db87-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010496023s
STEP: Saw pod success
Oct 29 14:32:08.307: INFO: Pod "pod-configmaps-68f69ef4-db87-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:32:08.310: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-configmaps-68f69ef4-db87-11e8-94a0-9e8b538e2da3 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:32:08.347: INFO: Waiting for pod pod-configmaps-68f69ef4-db87-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:32:08.350: INFO: Pod pod-configmaps-68f69ef4-db87-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:32:08.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-76t6x" for this suite.
Oct 29 14:32:14.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:32:14.437: INFO: namespace: e2e-tests-configmap-76t6x, resource: bindings, ignored listing per whitelist
Oct 29 14:32:14.466: INFO: namespace e2e-tests-configmap-76t6x deletion completed in 6.111486211s

• [SLOW TEST:8.248 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:32:14.467: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 29 14:32:18.572: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:18.572: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:18.691: INFO: Exec stderr: ""
Oct 29 14:32:18.691: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:18.692: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:18.812: INFO: Exec stderr: ""
Oct 29 14:32:18.812: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:18.812: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:18.928: INFO: Exec stderr: ""
Oct 29 14:32:18.928: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:18.928: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:19.055: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 29 14:32:19.055: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:19.055: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:19.186: INFO: Exec stderr: ""
Oct 29 14:32:19.187: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:19.187: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:19.303: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 29 14:32:19.303: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:19.303: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:19.418: INFO: Exec stderr: ""
Oct 29 14:32:19.418: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:19.418: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:19.553: INFO: Exec stderr: ""
Oct 29 14:32:19.553: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:19.553: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:19.665: INFO: Exec stderr: ""
Oct 29 14:32:19.665: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jh5nn PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:32:19.665: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:32:19.789: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:32:19.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-jh5nn" for this suite.
Oct 29 14:33:05.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:33:05.814: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-jh5nn, resource: bindings, ignored listing per whitelist
Oct 29 14:33:05.908: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-jh5nn deletion completed in 46.114173959s

• [SLOW TEST:51.441 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:33:05.908: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Oct 29 14:33:05.992: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:33:08.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mrh5p" for this suite.
Oct 29 14:33:14.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:33:14.767: INFO: namespace: e2e-tests-init-container-mrh5p, resource: bindings, ignored listing per whitelist
Oct 29 14:33:14.879: INFO: namespace e2e-tests-init-container-mrh5p deletion completed in 6.133709646s

• [SLOW TEST:8.971 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:33:14.879: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:33:14.952: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91e320d5-db87-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-downward-api-rwxpz" to be "success or failure"
Oct 29 14:33:14.955: INFO: Pod "downwardapi-volume-91e320d5-db87-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.356289ms
Oct 29 14:33:16.959: INFO: Pod "downwardapi-volume-91e320d5-db87-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007403087s
STEP: Saw pod success
Oct 29 14:33:16.959: INFO: Pod "downwardapi-volume-91e320d5-db87-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:33:16.962: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod downwardapi-volume-91e320d5-db87-11e8-94a0-9e8b538e2da3 container client-container: <nil>
STEP: delete the pod
Oct 29 14:33:16.999: INFO: Waiting for pod downwardapi-volume-91e320d5-db87-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:33:17.003: INFO: Pod downwardapi-volume-91e320d5-db87-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:33:17.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rwxpz" for this suite.
Oct 29 14:33:23.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:33:23.070: INFO: namespace: e2e-tests-downward-api-rwxpz, resource: bindings, ignored listing per whitelist
Oct 29 14:33:23.122: INFO: namespace e2e-tests-downward-api-rwxpz deletion completed in 6.113667138s

• [SLOW TEST:8.242 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:33:23.123: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 29 14:33:23.197: INFO: Waiting up to 5m0s for pod "pod-96cd217c-db87-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-t4ghh" to be "success or failure"
Oct 29 14:33:23.201: INFO: Pod "pod-96cd217c-db87-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.4132ms
Oct 29 14:33:25.206: INFO: Pod "pod-96cd217c-db87-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009087856s
STEP: Saw pod success
Oct 29 14:33:25.206: INFO: Pod "pod-96cd217c-db87-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:33:25.209: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-96cd217c-db87-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 14:33:25.241: INFO: Waiting for pod pod-96cd217c-db87-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:33:25.252: INFO: Pod pod-96cd217c-db87-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:33:25.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t4ghh" for this suite.
Oct 29 14:33:31.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:33:31.283: INFO: namespace: e2e-tests-emptydir-t4ghh, resource: bindings, ignored listing per whitelist
Oct 29 14:33:31.376: INFO: namespace e2e-tests-emptydir-t4ghh deletion completed in 6.119500113s

• [SLOW TEST:8.253 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:33:31.376: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9bc12089-db87-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:33:31.533: INFO: Waiting up to 5m0s for pod "pod-configmaps-9bc47abb-db87-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-hdjqn" to be "success or failure"
Oct 29 14:33:31.537: INFO: Pod "pod-configmaps-9bc47abb-db87-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042751ms
Oct 29 14:33:33.542: INFO: Pod "pod-configmaps-9bc47abb-db87-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008414584s
STEP: Saw pod success
Oct 29 14:33:33.542: INFO: Pod "pod-configmaps-9bc47abb-db87-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:33:33.545: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-configmaps-9bc47abb-db87-11e8-94a0-9e8b538e2da3 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:33:33.576: INFO: Waiting for pod pod-configmaps-9bc47abb-db87-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:33:33.579: INFO: Pod pod-configmaps-9bc47abb-db87-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:33:33.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hdjqn" for this suite.
Oct 29 14:33:39.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:33:39.651: INFO: namespace: e2e-tests-configmap-hdjqn, resource: bindings, ignored listing per whitelist
Oct 29 14:33:39.697: INFO: namespace e2e-tests-configmap-hdjqn deletion completed in 6.113670736s

• [SLOW TEST:8.321 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:33:39.697: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1029 14:34:19.809169      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 14:34:19.809: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:34:19.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mfwbz" for this suite.
Oct 29 14:34:25.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:34:25.843: INFO: namespace: e2e-tests-gc-mfwbz, resource: bindings, ignored listing per whitelist
Oct 29 14:34:26.017: INFO: namespace e2e-tests-gc-mfwbz deletion completed in 6.20378773s

• [SLOW TEST:46.320 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:34:26.017: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Oct 29 14:34:26.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:27.123: INFO: stderr: ""
Oct 29 14:34:27.123: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 14:34:27.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:27.368: INFO: stderr: ""
Oct 29 14:34:27.368: INFO: stdout: "update-demo-nautilus-jshlf update-demo-nautilus-m9vl9 "
Oct 29 14:34:27.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-jshlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:27.471: INFO: stderr: ""
Oct 29 14:34:27.471: INFO: stdout: ""
Oct 29 14:34:27.471: INFO: update-demo-nautilus-jshlf is created but not running
Oct 29 14:34:32.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:32.559: INFO: stderr: ""
Oct 29 14:34:32.559: INFO: stdout: "update-demo-nautilus-jshlf update-demo-nautilus-m9vl9 "
Oct 29 14:34:32.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-jshlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:32.642: INFO: stderr: ""
Oct 29 14:34:32.642: INFO: stdout: "true"
Oct 29 14:34:32.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-jshlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:32.724: INFO: stderr: ""
Oct 29 14:34:32.724: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:34:32.724: INFO: validating pod update-demo-nautilus-jshlf
Oct 29 14:34:32.735: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:34:32.735: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:34:32.735: INFO: update-demo-nautilus-jshlf is verified up and running
Oct 29 14:34:32.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-m9vl9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:32.814: INFO: stderr: ""
Oct 29 14:34:32.814: INFO: stdout: "true"
Oct 29 14:34:32.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-m9vl9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:32.910: INFO: stderr: ""
Oct 29 14:34:32.910: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:34:32.910: INFO: validating pod update-demo-nautilus-m9vl9
Oct 29 14:34:32.916: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:34:32.916: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:34:32.916: INFO: update-demo-nautilus-m9vl9 is verified up and running
STEP: scaling down the replication controller
Oct 29 14:34:32.920: INFO: scanned /root for discovery docs: <nil>
Oct 29 14:34:32.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:34.035: INFO: stderr: ""
Oct 29 14:34:34.035: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 14:34:34.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:34.118: INFO: stderr: ""
Oct 29 14:34:34.118: INFO: stdout: "update-demo-nautilus-jshlf update-demo-nautilus-m9vl9 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 29 14:34:39.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:39.203: INFO: stderr: ""
Oct 29 14:34:39.203: INFO: stdout: "update-demo-nautilus-jshlf update-demo-nautilus-m9vl9 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 29 14:34:44.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:44.295: INFO: stderr: ""
Oct 29 14:34:44.295: INFO: stdout: "update-demo-nautilus-jshlf "
Oct 29 14:34:44.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-jshlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:44.379: INFO: stderr: ""
Oct 29 14:34:44.379: INFO: stdout: "true"
Oct 29 14:34:44.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-jshlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:44.461: INFO: stderr: ""
Oct 29 14:34:44.461: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:34:44.461: INFO: validating pod update-demo-nautilus-jshlf
Oct 29 14:34:44.466: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:34:44.466: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:34:44.466: INFO: update-demo-nautilus-jshlf is verified up and running
STEP: scaling up the replication controller
Oct 29 14:34:44.468: INFO: scanned /root for discovery docs: <nil>
Oct 29 14:34:44.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:45.588: INFO: stderr: ""
Oct 29 14:34:45.588: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 14:34:45.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:45.673: INFO: stderr: ""
Oct 29 14:34:45.673: INFO: stdout: "update-demo-nautilus-jshlf update-demo-nautilus-zfbfj "
Oct 29 14:34:45.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-jshlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:45.753: INFO: stderr: ""
Oct 29 14:34:45.753: INFO: stdout: "true"
Oct 29 14:34:45.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-jshlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:45.840: INFO: stderr: ""
Oct 29 14:34:45.840: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:34:45.840: INFO: validating pod update-demo-nautilus-jshlf
Oct 29 14:34:45.845: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:34:45.845: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:34:45.845: INFO: update-demo-nautilus-jshlf is verified up and running
Oct 29 14:34:45.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-zfbfj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:45.951: INFO: stderr: ""
Oct 29 14:34:45.952: INFO: stdout: "true"
Oct 29 14:34:45.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-zfbfj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:46.036: INFO: stderr: ""
Oct 29 14:34:46.036: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:34:46.036: INFO: validating pod update-demo-nautilus-zfbfj
Oct 29 14:34:46.043: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:34:46.043: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:34:46.043: INFO: update-demo-nautilus-zfbfj is verified up and running
STEP: using delete to clean up resources
Oct 29 14:34:46.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:46.130: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 14:34:46.130: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 29 14:34:46.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-64xs2'
Oct 29 14:34:46.296: INFO: stderr: "No resources found.\n"
Oct 29 14:34:46.296: INFO: stdout: ""
Oct 29 14:34:46.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -l name=update-demo --namespace=e2e-tests-kubectl-64xs2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 14:34:46.489: INFO: stderr: ""
Oct 29 14:34:46.489: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:34:46.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-64xs2" for this suite.
Oct 29 14:35:10.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:35:10.561: INFO: namespace: e2e-tests-kubectl-64xs2, resource: bindings, ignored listing per whitelist
Oct 29 14:35:10.613: INFO: namespace e2e-tests-kubectl-64xs2 deletion completed in 24.117639218s

• [SLOW TEST:44.596 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:35:10.614: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 29 14:35:10.701: INFO: (0) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.809797ms)
Oct 29 14:35:10.705: INFO: (1) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.379362ms)
Oct 29 14:35:10.709: INFO: (2) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.321994ms)
Oct 29 14:35:10.714: INFO: (3) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.21272ms)
Oct 29 14:35:10.718: INFO: (4) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.031592ms)
Oct 29 14:35:10.724: INFO: (5) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.440317ms)
Oct 29 14:35:10.730: INFO: (6) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.946228ms)
Oct 29 14:35:10.735: INFO: (7) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.454118ms)
Oct 29 14:35:10.739: INFO: (8) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.082687ms)
Oct 29 14:35:10.743: INFO: (9) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.977507ms)
Oct 29 14:35:10.747: INFO: (10) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.981337ms)
Oct 29 14:35:10.751: INFO: (11) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.910658ms)
Oct 29 14:35:10.755: INFO: (12) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.132032ms)
Oct 29 14:35:10.759: INFO: (13) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.196128ms)
Oct 29 14:35:10.764: INFO: (14) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.130263ms)
Oct 29 14:35:10.768: INFO: (15) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.08006ms)
Oct 29 14:35:10.772: INFO: (16) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.999622ms)
Oct 29 14:35:10.776: INFO: (17) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.026827ms)
Oct 29 14:35:10.780: INFO: (18) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.111172ms)
Oct 29 14:35:10.784: INFO: (19) /api/v1/nodes/ip-10-0-1-140.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.433456ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:35:10.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-dj87x" for this suite.
Oct 29 14:35:16.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:35:16.897: INFO: namespace: e2e-tests-proxy-dj87x, resource: bindings, ignored listing per whitelist
Oct 29 14:35:16.976: INFO: namespace e2e-tests-proxy-dj87x deletion completed in 6.186931521s

• [SLOW TEST:6.362 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:35:16.976: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 29 14:35:17.073: INFO: Waiting up to 5m0s for pod "pod-daac7fcc-db87-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-d7s2p" to be "success or failure"
Oct 29 14:35:17.079: INFO: Pod "pod-daac7fcc-db87-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.613318ms
Oct 29 14:35:19.085: INFO: Pod "pod-daac7fcc-db87-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012099607s
Oct 29 14:35:21.106: INFO: Pod "pod-daac7fcc-db87-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03293828s
STEP: Saw pod success
Oct 29 14:35:21.106: INFO: Pod "pod-daac7fcc-db87-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:35:21.115: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-daac7fcc-db87-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 14:35:21.188: INFO: Waiting for pod pod-daac7fcc-db87-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:35:21.197: INFO: Pod pod-daac7fcc-db87-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:35:21.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d7s2p" for this suite.
Oct 29 14:35:27.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:35:27.291: INFO: namespace: e2e-tests-emptydir-d7s2p, resource: bindings, ignored listing per whitelist
Oct 29 14:35:27.362: INFO: namespace e2e-tests-emptydir-d7s2p deletion completed in 6.153443419s

• [SLOW TEST:10.386 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:35:27.362: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-fbs9
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 14:35:27.446: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-fbs9" in namespace "e2e-tests-subpath-b54wl" to be "success or failure"
Oct 29 14:35:27.451: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.990125ms
Oct 29 14:35:29.455: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009411255s
Oct 29 14:35:31.461: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 4.015012081s
Oct 29 14:35:33.465: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 6.019356185s
Oct 29 14:35:35.469: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 8.023040231s
Oct 29 14:35:37.479: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 10.033821975s
Oct 29 14:35:39.484: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 12.037889846s
Oct 29 14:35:41.506: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 14.060688825s
Oct 29 14:35:43.511: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 16.065221457s
Oct 29 14:35:45.515: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 18.069332221s
Oct 29 14:35:47.525: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 20.078977372s
Oct 29 14:35:49.529: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Running", Reason="", readiness=false. Elapsed: 22.083360235s
Oct 29 14:35:51.534: INFO: Pod "pod-subpath-test-downwardapi-fbs9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.088059489s
STEP: Saw pod success
Oct 29 14:35:51.534: INFO: Pod "pod-subpath-test-downwardapi-fbs9" satisfied condition "success or failure"
Oct 29 14:35:51.537: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-subpath-test-downwardapi-fbs9 container test-container-subpath-downwardapi-fbs9: <nil>
STEP: delete the pod
Oct 29 14:35:51.566: INFO: Waiting for pod pod-subpath-test-downwardapi-fbs9 to disappear
Oct 29 14:35:51.570: INFO: Pod pod-subpath-test-downwardapi-fbs9 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-fbs9
Oct 29 14:35:51.570: INFO: Deleting pod "pod-subpath-test-downwardapi-fbs9" in namespace "e2e-tests-subpath-b54wl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:35:51.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-b54wl" for this suite.
Oct 29 14:35:57.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:35:57.607: INFO: namespace: e2e-tests-subpath-b54wl, resource: bindings, ignored listing per whitelist
Oct 29 14:35:57.696: INFO: namespace e2e-tests-subpath-b54wl deletion completed in 6.118825206s

• [SLOW TEST:30.334 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:35:57.697: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f2ef30bf-db87-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:35:57.775: INFO: Waiting up to 5m0s for pod "pod-configmaps-f2efde53-db87-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-configmap-gxzw8" to be "success or failure"
Oct 29 14:35:57.781: INFO: Pod "pod-configmaps-f2efde53-db87-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.06618ms
Oct 29 14:35:59.785: INFO: Pod "pod-configmaps-f2efde53-db87-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010474037s
STEP: Saw pod success
Oct 29 14:35:59.785: INFO: Pod "pod-configmaps-f2efde53-db87-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:35:59.789: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-configmaps-f2efde53-db87-11e8-94a0-9e8b538e2da3 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:35:59.814: INFO: Waiting for pod pod-configmaps-f2efde53-db87-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:35:59.817: INFO: Pod pod-configmaps-f2efde53-db87-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:35:59.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gxzw8" for this suite.
Oct 29 14:36:05.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:36:05.904: INFO: namespace: e2e-tests-configmap-gxzw8, resource: bindings, ignored listing per whitelist
Oct 29 14:36:05.941: INFO: namespace e2e-tests-configmap-gxzw8 deletion completed in 6.117420069s

• [SLOW TEST:8.244 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:36:05.941: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Oct 29 14:36:06.003: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 29 14:36:06.011: INFO: Waiting for terminating namespaces to be deleted...
Oct 29 14:36:06.015: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-140.eu-west-1.compute.internal before test
Oct 29 14:36:06.021: INFO: sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-vmft4 from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 14:36:06.021: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Oct 29 14:36:06.021: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 29 14:36:06.021: INFO: calico-node-gqfq5 from kube-system started at 2018-10-26 14:32:29 +0000 UTC (2 container statuses recorded)
Oct 29 14:36:06.021: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 14:36:06.021: INFO: 	Container install-cni ready: true, restart count 0
Oct 29 14:36:06.021: INFO: nginx-6c94d899fd-6x4kg from default started at 2018-10-29 13:16:15 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.021: INFO: 	Container nginx ready: true, restart count 0
Oct 29 14:36:06.021: INFO: kube-proxy-7msnt from kube-system started at 2018-10-29 13:05:22 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.021: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 14:36:06.021: INFO: nginx-6c94d899fd-w6mz2 from default started at 2018-10-29 13:16:08 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.021: INFO: 	Container nginx ready: true, restart count 0
Oct 29 14:36:06.021: INFO: coredns-576cbf47c7-96r4w from kube-system started at 2018-10-26 14:32:12 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.022: INFO: 	Container coredns ready: true, restart count 0
Oct 29 14:36:06.022: INFO: coredns-576cbf47c7-m8lhm from kube-system started at 2018-10-26 14:32:12 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.022: INFO: 	Container coredns ready: true, restart count 0
Oct 29 14:36:06.022: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-2-47.eu-west-1.compute.internal before test
Oct 29 14:36:06.029: INFO: nginx-6c94d899fd-xqcqp from default started at 2018-10-29 13:16:08 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.029: INFO: 	Container nginx ready: true, restart count 0
Oct 29 14:36:06.029: INFO: calico-node-vn4pl from kube-system started at 2018-10-26 14:32:29 +0000 UTC (2 container statuses recorded)
Oct 29 14:36:06.029: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 14:36:06.029: INFO: 	Container install-cni ready: true, restart count 0
Oct 29 14:36:06.029: INFO: nginx-6c94d899fd-cgsx2 from default started at 2018-10-29 13:16:15 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.029: INFO: 	Container nginx ready: true, restart count 0
Oct 29 14:36:06.029: INFO: sonobuoy-systemd-logs-daemon-set-89a796ff93214ab5-bhgjz from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 14:36:06.029: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Oct 29 14:36:06.029: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 29 14:36:06.029: INFO: kube-proxy-j9xc7 from kube-system started at 2018-10-29 13:05:42 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.029: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 14:36:06.030: INFO: sonobuoy-e2e-job-e29a3530d05d487d from heptio-sonobuoy started at 2018-10-29 13:18:14 +0000 UTC (2 container statuses recorded)
Oct 29 14:36:06.030: INFO: 	Container e2e ready: true, restart count 0
Oct 29 14:36:06.030: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 14:36:06.030: INFO: sonobuoy from heptio-sonobuoy started at 2018-10-29 13:18:08 +0000 UTC (1 container statuses recorded)
Oct 29 14:36:06.030: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f915c687-db87-11e8-94a0-9e8b538e2da3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f915c687-db87-11e8-94a0-9e8b538e2da3 off the node ip-10-0-2-47.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f915c687-db87-11e8-94a0-9e8b538e2da3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:36:10.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-nk5zk" for this suite.
Oct 29 14:36:24.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:36:24.171: INFO: namespace: e2e-tests-sched-pred-nk5zk, resource: bindings, ignored listing per whitelist
Oct 29 14:36:24.265: INFO: namespace e2e-tests-sched-pred-nk5zk deletion completed in 14.119064444s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:18.324 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:36:24.267: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-02c9009e-db88-11e8-94a0-9e8b538e2da3
STEP: Creating a pod to test consume configMaps
Oct 29 14:36:24.381: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-02caec97-db88-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-projected-xrhvd" to be "success or failure"
Oct 29 14:36:24.387: INFO: Pod "pod-projected-configmaps-02caec97-db88-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.489843ms
Oct 29 14:36:26.391: INFO: Pod "pod-projected-configmaps-02caec97-db88-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00966162s
STEP: Saw pod success
Oct 29 14:36:26.391: INFO: Pod "pod-projected-configmaps-02caec97-db88-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:36:26.395: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-projected-configmaps-02caec97-db88-11e8-94a0-9e8b538e2da3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:36:26.418: INFO: Waiting for pod pod-projected-configmaps-02caec97-db88-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:36:26.427: INFO: Pod pod-projected-configmaps-02caec97-db88-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:36:26.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xrhvd" for this suite.
Oct 29 14:36:32.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:36:32.518: INFO: namespace: e2e-tests-projected-xrhvd, resource: bindings, ignored listing per whitelist
Oct 29 14:36:32.546: INFO: namespace e2e-tests-projected-xrhvd deletion completed in 6.114886083s

• [SLOW TEST:8.279 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:36:32.546: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 29 14:36:32.625: INFO: Waiting up to 5m0s for pod "pod-07b5593d-db88-11e8-94a0-9e8b538e2da3" in namespace "e2e-tests-emptydir-kpcgf" to be "success or failure"
Oct 29 14:36:32.630: INFO: Pod "pod-07b5593d-db88-11e8-94a0-9e8b538e2da3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.854801ms
Oct 29 14:36:34.634: INFO: Pod "pod-07b5593d-db88-11e8-94a0-9e8b538e2da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009124398s
STEP: Saw pod success
Oct 29 14:36:34.634: INFO: Pod "pod-07b5593d-db88-11e8-94a0-9e8b538e2da3" satisfied condition "success or failure"
Oct 29 14:36:34.637: INFO: Trying to get logs from node ip-10-0-2-47.eu-west-1.compute.internal pod pod-07b5593d-db88-11e8-94a0-9e8b538e2da3 container test-container: <nil>
STEP: delete the pod
Oct 29 14:36:34.664: INFO: Waiting for pod pod-07b5593d-db88-11e8-94a0-9e8b538e2da3 to disappear
Oct 29 14:36:34.667: INFO: Pod pod-07b5593d-db88-11e8-94a0-9e8b538e2da3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:36:34.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kpcgf" for this suite.
Oct 29 14:36:40.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:36:40.772: INFO: namespace: e2e-tests-emptydir-kpcgf, resource: bindings, ignored listing per whitelist
Oct 29 14:36:40.793: INFO: namespace e2e-tests-emptydir-kpcgf deletion completed in 6.121190627s

• [SLOW TEST:8.247 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:36:40.793: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Oct 29 14:36:40.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 create -f - --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:36:41.037: INFO: stderr: ""
Oct 29 14:36:41.037: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 14:36:41.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:36:41.146: INFO: stderr: ""
Oct 29 14:36:41.146: INFO: stdout: "update-demo-nautilus-5twq5 update-demo-nautilus-x9v2c "
Oct 29 14:36:41.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-5twq5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:36:41.252: INFO: stderr: ""
Oct 29 14:36:41.252: INFO: stdout: ""
Oct 29 14:36:41.252: INFO: update-demo-nautilus-5twq5 is created but not running
Oct 29 14:36:46.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:36:46.340: INFO: stderr: ""
Oct 29 14:36:46.340: INFO: stdout: "update-demo-nautilus-5twq5 update-demo-nautilus-x9v2c "
Oct 29 14:36:46.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-5twq5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:36:46.425: INFO: stderr: ""
Oct 29 14:36:46.425: INFO: stdout: "true"
Oct 29 14:36:46.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-5twq5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:36:46.560: INFO: stderr: ""
Oct 29 14:36:46.560: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:36:46.560: INFO: validating pod update-demo-nautilus-5twq5
Oct 29 14:36:46.566: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:36:46.567: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:36:46.567: INFO: update-demo-nautilus-5twq5 is verified up and running
Oct 29 14:36:46.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-x9v2c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:36:46.654: INFO: stderr: ""
Oct 29 14:36:46.654: INFO: stdout: "true"
Oct 29 14:36:46.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-nautilus-x9v2c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:36:46.738: INFO: stderr: ""
Oct 29 14:36:46.738: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:36:46.738: INFO: validating pod update-demo-nautilus-x9v2c
Oct 29 14:36:46.744: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:36:46.744: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:36:46.744: INFO: update-demo-nautilus-x9v2c is verified up and running
STEP: rolling-update to new replication controller
Oct 29 14:36:46.745: INFO: scanned /root for discovery docs: <nil>
Oct 29 14:36:46.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:37:09.136: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 29 14:37:09.136: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 14:37:09.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:37:09.234: INFO: stderr: ""
Oct 29 14:37:09.234: INFO: stdout: "update-demo-kitten-9nnxp update-demo-kitten-nnpgh "
Oct 29 14:37:09.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-kitten-9nnxp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:37:09.320: INFO: stderr: ""
Oct 29 14:37:09.320: INFO: stdout: "true"
Oct 29 14:37:09.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-kitten-9nnxp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:37:09.413: INFO: stderr: ""
Oct 29 14:37:09.413: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 29 14:37:09.413: INFO: validating pod update-demo-kitten-9nnxp
Oct 29 14:37:09.418: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 29 14:37:09.418: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 29 14:37:09.418: INFO: update-demo-kitten-9nnxp is verified up and running
Oct 29 14:37:09.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-kitten-nnpgh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:37:09.508: INFO: stderr: ""
Oct 29 14:37:09.508: INFO: stdout: "true"
Oct 29 14:37:09.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-215229198 get pods update-demo-kitten-nnpgh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fth54'
Oct 29 14:37:09.594: INFO: stderr: ""
Oct 29 14:37:09.594: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 29 14:37:09.594: INFO: validating pod update-demo-kitten-nnpgh
Oct 29 14:37:09.599: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 29 14:37:09.599: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 29 14:37:09.599: INFO: update-demo-kitten-nnpgh is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:37:09.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fth54" for this suite.
Oct 29 14:37:31.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:37:31.705: INFO: namespace: e2e-tests-kubectl-fth54, resource: bindings, ignored listing per whitelist
Oct 29 14:37:31.732: INFO: namespace e2e-tests-kubectl-fth54 deletion completed in 22.128480594s

• [SLOW TEST:50.939 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:37:31.733: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-9sgc
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 14:37:31.850: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9sgc" in namespace "e2e-tests-subpath-vl4nn" to be "success or failure"
Oct 29 14:37:31.862: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Pending", Reason="", readiness=false. Elapsed: 11.427008ms
Oct 29 14:37:33.867: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016518745s
Oct 29 14:37:35.871: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 4.020763889s
Oct 29 14:37:37.876: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 6.025202098s
Oct 29 14:37:39.880: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 8.02933894s
Oct 29 14:37:41.890: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 10.039214195s
Oct 29 14:37:43.894: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 12.043270069s
Oct 29 14:37:45.898: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 14.047338683s
Oct 29 14:37:47.902: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 16.051590054s
Oct 29 14:37:49.906: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 18.05567971s
Oct 29 14:37:51.916: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 20.065890291s
Oct 29 14:37:53.921: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Running", Reason="", readiness=false. Elapsed: 22.070191854s
Oct 29 14:37:55.925: INFO: Pod "pod-subpath-test-configmap-9sgc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.074347635s
STEP: Saw pod success
Oct 29 14:37:55.925: INFO: Pod "pod-subpath-test-configmap-9sgc" satisfied condition "success or failure"
Oct 29 14:37:55.928: INFO: Trying to get logs from node ip-10-0-1-140.eu-west-1.compute.internal pod pod-subpath-test-configmap-9sgc container test-container-subpath-configmap-9sgc: <nil>
STEP: delete the pod
Oct 29 14:37:55.953: INFO: Waiting for pod pod-subpath-test-configmap-9sgc to disappear
Oct 29 14:37:55.960: INFO: Pod pod-subpath-test-configmap-9sgc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9sgc
Oct 29 14:37:55.960: INFO: Deleting pod "pod-subpath-test-configmap-9sgc" in namespace "e2e-tests-subpath-vl4nn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:37:55.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vl4nn" for this suite.
Oct 29 14:38:01.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:38:02.086: INFO: namespace: e2e-tests-subpath-vl4nn, resource: bindings, ignored listing per whitelist
Oct 29 14:38:02.112: INFO: namespace e2e-tests-subpath-vl4nn deletion completed in 6.14473755s

• [SLOW TEST:30.380 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:38:02.113: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Oct 29 14:38:04.720: INFO: Successfully updated pod "labelsupdate3d17e63e-db88-11e8-94a0-9e8b538e2da3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:38:08.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xq257" for this suite.
Oct 29 14:38:30.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:38:30.817: INFO: namespace: e2e-tests-downward-api-xq257, resource: bindings, ignored listing per whitelist
Oct 29 14:38:30.866: INFO: namespace e2e-tests-downward-api-xq257 deletion completed in 22.117918407s

• [SLOW TEST:28.754 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:38:30.867: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ht5jg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 29 14:38:30.940: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 29 14:38:47.031: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.3.252:8080/dial?request=hostName&protocol=http&host=192.168.4.127&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ht5jg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:38:47.031: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:38:47.160: INFO: Waiting for endpoints: map[]
Oct 29 14:38:47.164: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.3.252:8080/dial?request=hostName&protocol=http&host=192.168.3.251&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ht5jg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:38:47.164: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
Oct 29 14:38:47.299: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:38:47.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ht5jg" for this suite.
Oct 29 14:39:11.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:39:11.679: INFO: namespace: e2e-tests-pod-network-test-ht5jg, resource: bindings, ignored listing per whitelist
Oct 29 14:39:11.725: INFO: namespace e2e-tests-pod-network-test-ht5jg deletion completed in 24.421896221s

• [SLOW TEST:40.859 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:39:11.727: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 29 14:39:15.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 29 14:39:15.996: INFO: Pod pod-with-poststart-http-hook still exists
Oct 29 14:39:17.996: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 29 14:39:18.015: INFO: Pod pod-with-poststart-http-hook still exists
Oct 29 14:39:19.996: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 29 14:39:20.001: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:39:20.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-86sb9" for this suite.
Oct 29 14:39:42.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:39:42.082: INFO: namespace: e2e-tests-container-lifecycle-hook-86sb9, resource: bindings, ignored listing per whitelist
Oct 29 14:39:42.123: INFO: namespace e2e-tests-container-lifecycle-hook-86sb9 deletion completed in 22.116133591s

• [SLOW TEST:30.396 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:39:42.124: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 29 14:39:46.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:39:46.246: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:39:48.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:39:48.250: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:39:50.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:39:50.256: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:39:52.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:39:52.250: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:39:54.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:39:54.251: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:39:56.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:39:56.251: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:39:58.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:39:58.250: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:40:00.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:40:00.250: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:40:02.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:40:02.257: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:40:04.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:40:04.252: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:40:06.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:40:06.250: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:40:08.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:40:08.251: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:40:10.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:40:10.251: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:40:12.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:40:12.250: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 14:40:14.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 14:40:14.258: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:40:14.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-nb9dq" for this suite.
Oct 29 14:40:36.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:40:36.391: INFO: namespace: e2e-tests-container-lifecycle-hook-nb9dq, resource: bindings, ignored listing per whitelist
Oct 29 14:40:36.397: INFO: namespace e2e-tests-container-lifecycle-hook-nb9dq deletion completed in 22.122400895s

• [SLOW TEST:54.273 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:40:36.397: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Oct 29 14:40:36.469: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:40:40.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-d855n" for this suite.
Oct 29 14:40:46.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:40:46.227: INFO: namespace: e2e-tests-init-container-d855n, resource: bindings, ignored listing per whitelist
Oct 29 14:40:46.283: INFO: namespace e2e-tests-init-container-d855n deletion completed in 6.117944666s

• [SLOW TEST:9.885 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Oct 29 14:40:46.283: INFO: >>> kubeConfig: /tmp/kubeconfig-215229198
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-9ef323bf-db88-11e8-94a0-9e8b538e2da3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Oct 29 14:40:48.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xptlh" for this suite.
Oct 29 14:41:10.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:41:10.454: INFO: namespace: e2e-tests-configmap-xptlh, resource: bindings, ignored listing per whitelist
Oct 29 14:41:10.517: INFO: namespace e2e-tests-configmap-xptlh deletion completed in 22.114627923s

• [SLOW TEST:24.234 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSOct 29 14:41:10.517: INFO: Running AfterSuite actions on all node
Oct 29 14:41:10.517: INFO: Running AfterSuite actions on node 1
Oct 29 14:41:10.517: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 4947.331 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h22m28.190256952s
Test Suite Passed
