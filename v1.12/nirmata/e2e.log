Dec  8 22:02:53.664: INFO: Overriding default scale value of zero to 1
Dec  8 22:02:53.672: INFO: Overriding default milliseconds value of zero to 5000
I1208 22:02:54.320015      14 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-960662691
I1208 22:02:54.320333      14 e2e.go:304] Starting e2e run "02d4f9d4-fb35-11e8-8c59-ae6969886d1b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544306573 - Will randomize all specs
Will run 188 of 1814 specs

Dec  8 22:02:54.622: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 22:02:54.625: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  8 22:02:54.645: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  8 22:02:54.672: INFO: 3 / 3 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  8 22:02:54.672: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec  8 22:02:54.672: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  8 22:02:54.680: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Dec  8 22:02:54.680: INFO: e2e test version: v1.12.1
Dec  8 22:02:54.682: INFO: kube-apiserver version: v1.12.3
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:02:54.682: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pods
Dec  8 22:02:54.755: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:02:56.901: INFO: Waiting up to 5m0s for pod "client-envvars-04e74c5d-fb35-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-pods-dqg9x" to be "success or failure"
Dec  8 22:02:56.919: INFO: Pod "client-envvars-04e74c5d-fb35-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.04951ms
Dec  8 22:02:58.922: INFO: Pod "client-envvars-04e74c5d-fb35-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021425168s
Dec  8 22:03:00.936: INFO: Pod "client-envvars-04e74c5d-fb35-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034751211s
STEP: Saw pod success
Dec  8 22:03:00.936: INFO: Pod "client-envvars-04e74c5d-fb35-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:03:00.956: INFO: Trying to get logs from node compliancetest pod client-envvars-04e74c5d-fb35-11e8-8c59-ae6969886d1b container env3cont: <nil>
STEP: delete the pod
Dec  8 22:03:01.034: INFO: Waiting for pod client-envvars-04e74c5d-fb35-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:03:01.043: INFO: Pod client-envvars-04e74c5d-fb35-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:03:01.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dqg9x" for this suite.
Dec  8 22:03:47.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:03:47.175: INFO: namespace: e2e-tests-pods-dqg9x, resource: bindings, ignored listing per whitelist
Dec  8 22:03:47.219: INFO: namespace e2e-tests-pods-dqg9x deletion completed in 46.165329171s

• [SLOW TEST:52.537 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:03:47.220: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:03:47.298: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  8 22:03:47.308: INFO: Number of nodes with available pods: 0
Dec  8 22:03:47.308: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  8 22:03:47.335: INFO: Number of nodes with available pods: 0
Dec  8 22:03:47.335: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:48.339: INFO: Number of nodes with available pods: 1
Dec  8 22:03:48.339: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  8 22:03:48.362: INFO: Number of nodes with available pods: 1
Dec  8 22:03:48.362: INFO: Number of running nodes: 0, number of available pods: 1
Dec  8 22:03:49.366: INFO: Number of nodes with available pods: 0
Dec  8 22:03:49.366: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  8 22:03:49.387: INFO: Number of nodes with available pods: 0
Dec  8 22:03:49.387: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:50.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:50.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:51.393: INFO: Number of nodes with available pods: 0
Dec  8 22:03:51.393: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:52.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:52.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:53.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:53.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:54.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:54.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:55.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:55.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:56.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:56.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:57.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:57.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:58.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:58.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:03:59.391: INFO: Number of nodes with available pods: 0
Dec  8 22:03:59.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:00.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:00.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:01.396: INFO: Number of nodes with available pods: 0
Dec  8 22:04:01.396: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:02.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:02.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:03.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:03.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:04.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:04.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:05.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:05.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:06.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:06.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:07.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:07.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:08.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:08.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:09.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:09.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:10.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:10.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:11.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:11.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:12.404: INFO: Number of nodes with available pods: 0
Dec  8 22:04:12.404: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:13.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:13.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:14.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:14.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:15.390: INFO: Number of nodes with available pods: 0
Dec  8 22:04:15.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:16.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:16.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:17.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:17.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:18.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:18.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:19.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:19.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:20.390: INFO: Number of nodes with available pods: 0
Dec  8 22:04:20.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:21.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:21.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:22.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:22.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:23.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:23.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:24.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:24.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:25.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:25.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:26.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:26.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:27.390: INFO: Number of nodes with available pods: 0
Dec  8 22:04:27.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:28.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:28.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:29.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:29.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:30.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:30.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:31.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:31.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:32.390: INFO: Number of nodes with available pods: 0
Dec  8 22:04:32.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:33.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:33.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:34.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:34.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:35.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:35.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:36.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:36.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:37.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:37.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:38.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:38.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:39.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:39.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:40.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:40.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:41.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:41.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:42.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:42.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:43.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:43.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:44.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:44.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:45.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:45.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:46.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:46.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:47.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:47.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:48.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:48.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:49.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:49.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:50.392: INFO: Number of nodes with available pods: 0
Dec  8 22:04:50.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:51.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:51.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:52.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:52.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:53.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:53.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:54.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:54.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:55.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:55.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:56.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:56.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:57.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:57.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:58.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:58.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:04:59.391: INFO: Number of nodes with available pods: 0
Dec  8 22:04:59.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:00.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:00.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:01.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:01.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:02.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:02.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:03.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:03.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:04.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:04.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:05.392: INFO: Number of nodes with available pods: 0
Dec  8 22:05:05.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:06.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:06.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:07.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:07.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:08.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:08.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:09.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:09.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:10.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:10.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:11.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:11.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:12.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:12.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:13.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:13.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:14.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:14.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:15.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:15.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:16.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:16.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:17.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:17.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:18.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:18.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:19.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:19.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:20.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:20.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:21.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:21.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:22.390: INFO: Number of nodes with available pods: 0
Dec  8 22:05:22.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:23.390: INFO: Number of nodes with available pods: 0
Dec  8 22:05:23.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:24.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:24.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:25.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:25.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:26.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:26.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:27.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:27.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:28.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:28.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:29.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:29.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:30.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:30.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:31.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:31.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:32.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:32.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:33.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:33.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:34.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:34.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:35.390: INFO: Number of nodes with available pods: 0
Dec  8 22:05:35.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:36.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:36.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:37.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:37.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:38.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:38.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:39.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:39.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:40.390: INFO: Number of nodes with available pods: 0
Dec  8 22:05:40.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:41.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:41.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:42.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:42.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:43.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:43.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:44.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:44.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:45.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:45.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:46.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:46.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:47.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:47.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:48.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:48.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:49.452: INFO: Number of nodes with available pods: 0
Dec  8 22:05:49.453: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:50.470: INFO: Number of nodes with available pods: 0
Dec  8 22:05:50.470: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:51.452: INFO: Number of nodes with available pods: 0
Dec  8 22:05:51.453: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:52.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:52.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:53.390: INFO: Number of nodes with available pods: 0
Dec  8 22:05:53.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:54.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:54.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:55.390: INFO: Number of nodes with available pods: 0
Dec  8 22:05:55.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:56.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:56.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:57.391: INFO: Number of nodes with available pods: 0
Dec  8 22:05:57.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:58.392: INFO: Number of nodes with available pods: 0
Dec  8 22:05:58.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:05:59.390: INFO: Number of nodes with available pods: 0
Dec  8 22:05:59.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:00.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:00.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:01.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:01.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:02.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:02.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:03.409: INFO: Number of nodes with available pods: 0
Dec  8 22:06:03.409: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:04.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:04.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:05.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:05.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:06.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:06.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:07.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:07.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:08.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:08.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:09.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:09.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:10.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:10.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:11.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:11.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:12.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:12.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:13.392: INFO: Number of nodes with available pods: 0
Dec  8 22:06:13.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:14.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:14.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:15.390: INFO: Number of nodes with available pods: 0
Dec  8 22:06:15.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:16.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:16.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:17.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:17.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:18.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:18.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:19.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:19.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:20.390: INFO: Number of nodes with available pods: 0
Dec  8 22:06:20.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:21.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:21.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:22.391: INFO: Number of nodes with available pods: 0
Dec  8 22:06:22.391: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:23.390: INFO: Number of nodes with available pods: 0
Dec  8 22:06:23.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:24.390: INFO: Number of nodes with available pods: 0
Dec  8 22:06:24.390: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:25.392: INFO: Number of nodes with available pods: 0
Dec  8 22:06:25.393: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:26.392: INFO: Number of nodes with available pods: 0
Dec  8 22:06:26.392: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:06:27.413: INFO: Number of nodes with available pods: 1
Dec  8 22:06:27.413: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-kw8t2, will wait for the garbage collector to delete the pods
Dec  8 22:06:27.507: INFO: Deleting {extensions DaemonSet} daemon-set took: 18.840927ms
Dec  8 22:06:27.607: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.305ms
Dec  8 22:07:04.912: INFO: Number of nodes with available pods: 0
Dec  8 22:07:04.912: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 22:07:04.918: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kw8t2/daemonsets","resourceVersion":"19877"},"items":null}

Dec  8 22:07:04.922: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kw8t2/pods","resourceVersion":"19877"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:07:04.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kw8t2" for this suite.
Dec  8 22:07:10.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:07:10.995: INFO: namespace: e2e-tests-daemonsets-kw8t2, resource: bindings, ignored listing per whitelist
Dec  8 22:07:11.123: INFO: namespace e2e-tests-daemonsets-kw8t2 deletion completed in 6.178039036s

• [SLOW TEST:203.904 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:07:11.124: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 22:07:11.192: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:07:14.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-lrflm" for this suite.
Dec  8 22:07:20.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:07:20.337: INFO: namespace: e2e-tests-init-container-lrflm, resource: bindings, ignored listing per whitelist
Dec  8 22:07:20.371: INFO: namespace e2e-tests-init-container-lrflm deletion completed in 6.132108077s

• [SLOW TEST:9.247 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:07:20.372: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  8 22:07:20.506: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rcvjn,SelfLink:/api/v1/namespaces/e2e-tests-watch-rcvjn/configmaps/e2e-watch-test-label-changed,UID:a2044493-fb35-11e8-a35e-42010a800004,ResourceVersion:19952,Generation:0,CreationTimestamp:2018-12-08 22:07:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 22:07:20.506: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rcvjn,SelfLink:/api/v1/namespaces/e2e-tests-watch-rcvjn/configmaps/e2e-watch-test-label-changed,UID:a2044493-fb35-11e8-a35e-42010a800004,ResourceVersion:19953,Generation:0,CreationTimestamp:2018-12-08 22:07:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  8 22:07:20.506: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rcvjn,SelfLink:/api/v1/namespaces/e2e-tests-watch-rcvjn/configmaps/e2e-watch-test-label-changed,UID:a2044493-fb35-11e8-a35e-42010a800004,ResourceVersion:19954,Generation:0,CreationTimestamp:2018-12-08 22:07:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  8 22:07:30.546: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rcvjn,SelfLink:/api/v1/namespaces/e2e-tests-watch-rcvjn/configmaps/e2e-watch-test-label-changed,UID:a2044493-fb35-11e8-a35e-42010a800004,ResourceVersion:19959,Generation:0,CreationTimestamp:2018-12-08 22:07:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 22:07:30.546: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rcvjn,SelfLink:/api/v1/namespaces/e2e-tests-watch-rcvjn/configmaps/e2e-watch-test-label-changed,UID:a2044493-fb35-11e8-a35e-42010a800004,ResourceVersion:19960,Generation:0,CreationTimestamp:2018-12-08 22:07:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  8 22:07:30.546: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rcvjn,SelfLink:/api/v1/namespaces/e2e-tests-watch-rcvjn/configmaps/e2e-watch-test-label-changed,UID:a2044493-fb35-11e8-a35e-42010a800004,ResourceVersion:19961,Generation:0,CreationTimestamp:2018-12-08 22:07:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:07:30.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-rcvjn" for this suite.
Dec  8 22:07:36.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:07:36.663: INFO: namespace: e2e-tests-watch-rcvjn, resource: bindings, ignored listing per whitelist
Dec  8 22:07:36.742: INFO: namespace e2e-tests-watch-rcvjn deletion completed in 6.191997878s

• [SLOW TEST:16.371 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:07:36.743: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  8 22:07:36.854: INFO: namespace e2e-tests-kubectl-hrm8f
Dec  8 22:07:36.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-hrm8f'
Dec  8 22:07:39.155: INFO: stderr: ""
Dec  8 22:07:39.155: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 22:07:40.158: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:07:40.158: INFO: Found 0 / 1
Dec  8 22:07:41.159: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:07:41.160: INFO: Found 0 / 1
Dec  8 22:07:42.159: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:07:42.159: INFO: Found 1 / 1
Dec  8 22:07:42.159: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 22:07:42.162: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:07:42.162: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 22:07:42.162: INFO: wait on redis-master startup in e2e-tests-kubectl-hrm8f 
Dec  8 22:07:42.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 logs redis-master-tqdp9 redis-master --namespace=e2e-tests-kubectl-hrm8f'
Dec  8 22:07:42.325: INFO: stderr: ""
Dec  8 22:07:42.325: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 22:07:40.791 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 22:07:40.791 # Server started, Redis version 3.2.12\n1:M 08 Dec 22:07:40.791 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 22:07:40.791 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  8 22:07:42.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-hrm8f'
Dec  8 22:07:42.475: INFO: stderr: ""
Dec  8 22:07:42.475: INFO: stdout: "service/rm2 exposed\n"
Dec  8 22:07:42.480: INFO: Service rm2 in namespace e2e-tests-kubectl-hrm8f found.
STEP: exposing service
Dec  8 22:07:44.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-hrm8f'
Dec  8 22:07:44.663: INFO: stderr: ""
Dec  8 22:07:44.663: INFO: stdout: "service/rm3 exposed\n"
Dec  8 22:07:44.676: INFO: Service rm3 in namespace e2e-tests-kubectl-hrm8f found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:07:46.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hrm8f" for this suite.
Dec  8 22:08:08.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:08:08.806: INFO: namespace: e2e-tests-kubectl-hrm8f, resource: bindings, ignored listing per whitelist
Dec  8 22:08:08.844: INFO: namespace e2e-tests-kubectl-hrm8f deletion completed in 22.156549376s

• [SLOW TEST:32.101 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:08:08.844: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bee1908a-fb35-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:08:08.923: INFO: Waiting up to 5m0s for pod "pod-secrets-bee2440b-fb35-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-gjljc" to be "success or failure"
Dec  8 22:08:08.926: INFO: Pod "pod-secrets-bee2440b-fb35-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.84894ms
Dec  8 22:08:10.953: INFO: Pod "pod-secrets-bee2440b-fb35-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030102441s
Dec  8 22:08:12.958: INFO: Pod "pod-secrets-bee2440b-fb35-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035255257s
STEP: Saw pod success
Dec  8 22:08:12.958: INFO: Pod "pod-secrets-bee2440b-fb35-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:08:12.970: INFO: Trying to get logs from node compliancetest pod pod-secrets-bee2440b-fb35-11e8-8c59-ae6969886d1b container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:08:13.018: INFO: Waiting for pod pod-secrets-bee2440b-fb35-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:08:13.033: INFO: Pod pod-secrets-bee2440b-fb35-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:08:13.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gjljc" for this suite.
Dec  8 22:08:19.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:08:19.114: INFO: namespace: e2e-tests-secrets-gjljc, resource: bindings, ignored listing per whitelist
Dec  8 22:08:19.226: INFO: namespace e2e-tests-secrets-gjljc deletion completed in 6.186680826s

• [SLOW TEST:10.381 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:08:19.226: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-c514dd42-fb35-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:08:19.329: INFO: Waiting up to 5m0s for pod "pod-secrets-c515bd30-fb35-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-8zkh7" to be "success or failure"
Dec  8 22:08:19.336: INFO: Pod "pod-secrets-c515bd30-fb35-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.680281ms
Dec  8 22:08:21.341: INFO: Pod "pod-secrets-c515bd30-fb35-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011528969s
STEP: Saw pod success
Dec  8 22:08:21.341: INFO: Pod "pod-secrets-c515bd30-fb35-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:08:21.345: INFO: Trying to get logs from node compliancetest pod pod-secrets-c515bd30-fb35-11e8-8c59-ae6969886d1b container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:08:21.376: INFO: Waiting for pod pod-secrets-c515bd30-fb35-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:08:21.385: INFO: Pod pod-secrets-c515bd30-fb35-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:08:21.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8zkh7" for this suite.
Dec  8 22:08:27.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:08:27.476: INFO: namespace: e2e-tests-secrets-8zkh7, resource: bindings, ignored listing per whitelist
Dec  8 22:08:27.519: INFO: namespace e2e-tests-secrets-8zkh7 deletion completed in 6.13000467s

• [SLOW TEST:8.293 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:08:27.520: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hcpsj
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  8 22:08:27.613: INFO: Found 0 stateful pods, waiting for 3
Dec  8 22:08:37.620: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:08:37.620: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:08:37.620: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:08:37.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-hcpsj ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:08:37.898: INFO: stderr: ""
Dec  8 22:08:37.898: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:08:37.898: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  8 22:08:47.932: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  8 22:08:57.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-hcpsj ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:08:58.185: INFO: stderr: ""
Dec  8 22:08:58.185: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:08:58.185: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:09:18.257: INFO: Waiting for StatefulSet e2e-tests-statefulset-hcpsj/ss2 to complete update
Dec  8 22:09:18.257: INFO: Waiting for Pod e2e-tests-statefulset-hcpsj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Dec  8 22:09:28.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-hcpsj ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:09:28.460: INFO: stderr: ""
Dec  8 22:09:28.460: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:09:28.460: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:09:38.498: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  8 22:09:48.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-hcpsj ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:09:48.753: INFO: stderr: ""
Dec  8 22:09:48.753: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:09:48.753: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:10:08.801: INFO: Waiting for StatefulSet e2e-tests-statefulset-hcpsj/ss2 to complete update
Dec  8 22:10:08.801: INFO: Waiting for Pod e2e-tests-statefulset-hcpsj/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 22:10:18.811: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hcpsj
Dec  8 22:10:18.817: INFO: Scaling statefulset ss2 to 0
Dec  8 22:10:48.977: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 22:10:49.057: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:10:49.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hcpsj" for this suite.
Dec  8 22:10:55.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:10:55.726: INFO: namespace: e2e-tests-statefulset-hcpsj, resource: bindings, ignored listing per whitelist
Dec  8 22:10:55.749: INFO: namespace e2e-tests-statefulset-hcpsj deletion completed in 6.308624407s

• [SLOW TEST:148.230 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:10:55.750: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Dec  8 22:11:07.046: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:11:23.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-llzzb" for this suite.
Dec  8 22:11:29.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:11:30.035: INFO: namespace: e2e-tests-namespaces-llzzb, resource: bindings, ignored listing per whitelist
Dec  8 22:11:30.055: INFO: namespace e2e-tests-namespaces-llzzb deletion completed in 6.119907657s
STEP: Destroying namespace "e2e-tests-nsdeletetest-7vdht" for this suite.
Dec  8 22:11:30.058: INFO: Namespace e2e-tests-nsdeletetest-7vdht was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-kvg8b" for this suite.
Dec  8 22:11:36.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:11:36.153: INFO: namespace: e2e-tests-nsdeletetest-kvg8b, resource: bindings, ignored listing per whitelist
Dec  8 22:11:36.220: INFO: namespace e2e-tests-nsdeletetest-kvg8b deletion completed in 6.162414291s

• [SLOW TEST:40.470 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:11:36.221: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1208 22:12:16.343830      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 22:12:16.343: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:12:16.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7v5m9" for this suite.
Dec  8 22:12:26.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:12:26.442: INFO: namespace: e2e-tests-gc-7v5m9, resource: bindings, ignored listing per whitelist
Dec  8 22:12:26.504: INFO: namespace e2e-tests-gc-7v5m9 deletion completed in 10.157141999s

• [SLOW TEST:50.283 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:12:26.505: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Dec  8 22:12:33.111: INFO: 0 pods remaining
Dec  8 22:12:33.111: INFO: 0 pods has nil DeletionTimestamp
Dec  8 22:12:33.111: INFO: 
STEP: Gathering metrics
W1208 22:12:33.889035      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 22:12:33.889: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:12:33.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2htm2" for this suite.
Dec  8 22:12:39.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:12:39.976: INFO: namespace: e2e-tests-gc-2htm2, resource: bindings, ignored listing per whitelist
Dec  8 22:12:40.031: INFO: namespace e2e-tests-gc-2htm2 deletion completed in 6.137514135s

• [SLOW TEST:13.526 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:12:40.031: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-60865fd9-fb36-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:12:40.115: INFO: Waiting up to 5m0s for pod "pod-secrets-608708a6-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-865gf" to be "success or failure"
Dec  8 22:12:40.119: INFO: Pod "pod-secrets-608708a6-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.396225ms
Dec  8 22:12:42.123: INFO: Pod "pod-secrets-608708a6-fb36-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.008188966s
Dec  8 22:12:44.126: INFO: Pod "pod-secrets-608708a6-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011087714s
STEP: Saw pod success
Dec  8 22:12:44.126: INFO: Pod "pod-secrets-608708a6-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:12:44.138: INFO: Trying to get logs from node compliancetest pod pod-secrets-608708a6-fb36-11e8-8c59-ae6969886d1b container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:12:44.192: INFO: Waiting for pod pod-secrets-608708a6-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:12:44.213: INFO: Pod pod-secrets-608708a6-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:12:44.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-865gf" for this suite.
Dec  8 22:12:50.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:12:50.327: INFO: namespace: e2e-tests-secrets-865gf, resource: bindings, ignored listing per whitelist
Dec  8 22:12:50.371: INFO: namespace e2e-tests-secrets-865gf deletion completed in 6.152044501s

• [SLOW TEST:10.340 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:12:50.372: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-66afff36-fb36-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:12:50.456: INFO: Waiting up to 5m0s for pod "pod-secrets-66b0b996-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-cj8fv" to be "success or failure"
Dec  8 22:12:50.460: INFO: Pod "pod-secrets-66b0b996-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.586025ms
Dec  8 22:12:52.464: INFO: Pod "pod-secrets-66b0b996-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008375965s
STEP: Saw pod success
Dec  8 22:12:52.464: INFO: Pod "pod-secrets-66b0b996-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:12:52.468: INFO: Trying to get logs from node compliancetest pod pod-secrets-66b0b996-fb36-11e8-8c59-ae6969886d1b container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:12:52.491: INFO: Waiting for pod pod-secrets-66b0b996-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:12:52.499: INFO: Pod pod-secrets-66b0b996-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:12:52.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cj8fv" for this suite.
Dec  8 22:12:58.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:12:58.630: INFO: namespace: e2e-tests-secrets-cj8fv, resource: bindings, ignored listing per whitelist
Dec  8 22:12:58.630: INFO: namespace e2e-tests-secrets-cj8fv deletion completed in 6.126826145s

• [SLOW TEST:8.258 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:12:58.630: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-6b9a8364-fb36-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:12:58.702: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6b9b29a3-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-2xwnx" to be "success or failure"
Dec  8 22:12:58.706: INFO: Pod "pod-projected-secrets-6b9b29a3-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.617356ms
Dec  8 22:13:00.710: INFO: Pod "pod-projected-secrets-6b9b29a3-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008688198s
Dec  8 22:13:02.715: INFO: Pod "pod-projected-secrets-6b9b29a3-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012919302s
STEP: Saw pod success
Dec  8 22:13:02.715: INFO: Pod "pod-projected-secrets-6b9b29a3-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:13:02.718: INFO: Trying to get logs from node compliancetest pod pod-projected-secrets-6b9b29a3-fb36-11e8-8c59-ae6969886d1b container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:13:02.752: INFO: Waiting for pod pod-projected-secrets-6b9b29a3-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:13:02.762: INFO: Pod pod-projected-secrets-6b9b29a3-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:13:02.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2xwnx" for this suite.
Dec  8 22:13:08.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:13:08.847: INFO: namespace: e2e-tests-projected-2xwnx, resource: bindings, ignored listing per whitelist
Dec  8 22:13:08.920: INFO: namespace e2e-tests-projected-2xwnx deletion completed in 6.154798272s

• [SLOW TEST:10.290 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:13:08.920: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  8 22:13:11.016: INFO: Pod pod-hostip-71be80df-fb36-11e8-8c59-ae6969886d1b has hostIP: 10.128.0.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:13:11.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-96vt9" for this suite.
Dec  8 22:13:33.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:13:33.277: INFO: namespace: e2e-tests-pods-96vt9, resource: bindings, ignored listing per whitelist
Dec  8 22:13:33.336: INFO: namespace e2e-tests-pods-96vt9 deletion completed in 22.314826005s

• [SLOW TEST:24.416 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:13:33.336: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8zdln A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-8zdln;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8zdln A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-8zdln;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8zdln.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-8zdln.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8zdln.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-8zdln.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8zdln.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8zdln.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8zdln.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8zdln.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8zdln.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-8zdln.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8zdln.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-8zdln.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8zdln.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 68.116.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.116.68_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 68.116.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.116.68_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8zdln A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-8zdln;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8zdln A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-8zdln;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8zdln.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-8zdln.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8zdln.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-8zdln.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8zdln.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8zdln.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8zdln.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8zdln.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8zdln.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-8zdln.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8zdln.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-8zdln.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8zdln.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 68.116.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.116.68_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 68.116.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.116.68_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  8 22:13:59.869: INFO: DNS probes using e2e-tests-dns-8zdln/dns-test-80629641-fb36-11e8-8c59-ae6969886d1b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:14:00.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-8zdln" for this suite.
Dec  8 22:14:06.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:14:06.454: INFO: namespace: e2e-tests-dns-8zdln, resource: bindings, ignored listing per whitelist
Dec  8 22:14:06.521: INFO: namespace e2e-tests-dns-8zdln deletion completed in 6.148608479s

• [SLOW TEST:33.185 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:14:06.522: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-94135fae-fb36-11e8-8c59-ae6969886d1b
Dec  8 22:14:06.601: INFO: Pod name my-hostname-basic-94135fae-fb36-11e8-8c59-ae6969886d1b: Found 0 pods out of 1
Dec  8 22:14:11.605: INFO: Pod name my-hostname-basic-94135fae-fb36-11e8-8c59-ae6969886d1b: Found 1 pods out of 1
Dec  8 22:14:11.605: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-94135fae-fb36-11e8-8c59-ae6969886d1b" are running
Dec  8 22:14:11.609: INFO: Pod "my-hostname-basic-94135fae-fb36-11e8-8c59-ae6969886d1b-b9ktk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 22:14:06 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 22:14:08 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 22:14:08 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 22:14:06 +0000 UTC Reason: Message:}])
Dec  8 22:14:11.609: INFO: Trying to dial the pod
Dec  8 22:14:16.622: INFO: Controller my-hostname-basic-94135fae-fb36-11e8-8c59-ae6969886d1b: Got expected result from replica 1 [my-hostname-basic-94135fae-fb36-11e8-8c59-ae6969886d1b-b9ktk]: "my-hostname-basic-94135fae-fb36-11e8-8c59-ae6969886d1b-b9ktk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:14:16.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-wpmwm" for this suite.
Dec  8 22:14:22.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:14:22.719: INFO: namespace: e2e-tests-replication-controller-wpmwm, resource: bindings, ignored listing per whitelist
Dec  8 22:14:22.841: INFO: namespace e2e-tests-replication-controller-wpmwm deletion completed in 6.214264497s

• [SLOW TEST:16.319 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:14:22.842: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:14:22.939: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9dcfefa8-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-llr98" to be "success or failure"
Dec  8 22:14:22.945: INFO: Pod "downwardapi-volume-9dcfefa8-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.890512ms
Dec  8 22:14:24.949: INFO: Pod "downwardapi-volume-9dcfefa8-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010310736s
STEP: Saw pod success
Dec  8 22:14:24.950: INFO: Pod "downwardapi-volume-9dcfefa8-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:14:24.958: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-9dcfefa8-fb36-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:14:25.092: INFO: Waiting for pod downwardapi-volume-9dcfefa8-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:14:25.111: INFO: Pod downwardapi-volume-9dcfefa8-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:14:25.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-llr98" for this suite.
Dec  8 22:14:31.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:14:31.179: INFO: namespace: e2e-tests-downward-api-llr98, resource: bindings, ignored listing per whitelist
Dec  8 22:14:31.255: INFO: namespace e2e-tests-downward-api-llr98 deletion completed in 6.137789834s

• [SLOW TEST:8.413 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:14:31.256: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:14:31.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2d20263-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-7k82j" to be "success or failure"
Dec  8 22:14:31.343: INFO: Pod "downwardapi-volume-a2d20263-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.420314ms
Dec  8 22:14:33.348: INFO: Pod "downwardapi-volume-a2d20263-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009830649s
STEP: Saw pod success
Dec  8 22:14:33.348: INFO: Pod "downwardapi-volume-a2d20263-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:14:33.351: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-a2d20263-fb36-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:14:33.385: INFO: Waiting for pod downwardapi-volume-a2d20263-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:14:33.391: INFO: Pod downwardapi-volume-a2d20263-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:14:33.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7k82j" for this suite.
Dec  8 22:14:39.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:14:39.523: INFO: namespace: e2e-tests-downward-api-7k82j, resource: bindings, ignored listing per whitelist
Dec  8 22:14:39.537: INFO: namespace e2e-tests-downward-api-7k82j deletion completed in 6.142710396s

• [SLOW TEST:8.281 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:14:39.538: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:14:39.616: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7c15d27-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-sl22p" to be "success or failure"
Dec  8 22:14:39.621: INFO: Pod "downwardapi-volume-a7c15d27-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.55719ms
Dec  8 22:14:41.625: INFO: Pod "downwardapi-volume-a7c15d27-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008939518s
STEP: Saw pod success
Dec  8 22:14:41.625: INFO: Pod "downwardapi-volume-a7c15d27-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:14:41.629: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-a7c15d27-fb36-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:14:41.672: INFO: Waiting for pod downwardapi-volume-a7c15d27-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:14:41.681: INFO: Pod downwardapi-volume-a7c15d27-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:14:41.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sl22p" for this suite.
Dec  8 22:14:47.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:14:47.826: INFO: namespace: e2e-tests-downward-api-sl22p, resource: bindings, ignored listing per whitelist
Dec  8 22:14:47.826: INFO: namespace e2e-tests-downward-api-sl22p deletion completed in 6.140603155s

• [SLOW TEST:8.288 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:14:47.826: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  8 22:14:47.951: INFO: Waiting up to 5m0s for pod "pod-acb91f7b-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-dw5hj" to be "success or failure"
Dec  8 22:14:47.956: INFO: Pod "pod-acb91f7b-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.369433ms
Dec  8 22:14:49.960: INFO: Pod "pod-acb91f7b-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009085855s
STEP: Saw pod success
Dec  8 22:14:49.960: INFO: Pod "pod-acb91f7b-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:14:49.965: INFO: Trying to get logs from node compliancetest pod pod-acb91f7b-fb36-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:14:50.002: INFO: Waiting for pod pod-acb91f7b-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:14:50.013: INFO: Pod pod-acb91f7b-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:14:50.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dw5hj" for this suite.
Dec  8 22:14:56.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:14:56.068: INFO: namespace: e2e-tests-emptydir-dw5hj, resource: bindings, ignored listing per whitelist
Dec  8 22:14:56.243: INFO: namespace e2e-tests-emptydir-dw5hj deletion completed in 6.227165909s

• [SLOW TEST:8.417 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:14:56.244: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  8 22:14:56.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 --namespace=e2e-tests-kubectl-ld4t6 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  8 22:14:57.899: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  8 22:14:57.899: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:14:59.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ld4t6" for this suite.
Dec  8 22:15:05.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:15:06.016: INFO: namespace: e2e-tests-kubectl-ld4t6, resource: bindings, ignored listing per whitelist
Dec  8 22:15:06.038: INFO: namespace e2e-tests-kubectl-ld4t6 deletion completed in 6.128873732s

• [SLOW TEST:9.795 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:15:06.039: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1208 22:15:07.172214      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 22:15:07.172: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:15:07.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-f5t5j" for this suite.
Dec  8 22:15:13.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:15:13.262: INFO: namespace: e2e-tests-gc-f5t5j, resource: bindings, ignored listing per whitelist
Dec  8 22:15:13.308: INFO: namespace e2e-tests-gc-f5t5j deletion completed in 6.132691521s

• [SLOW TEST:7.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:15:13.309: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-4qzbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4qzbn to expose endpoints map[]
Dec  8 22:15:13.404: INFO: Get endpoints failed (13.423414ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  8 22:15:14.407: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4qzbn exposes endpoints map[] (1.017017029s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-4qzbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4qzbn to expose endpoints map[pod1:[80]]
Dec  8 22:15:16.500: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4qzbn exposes endpoints map[pod1:[80]] (2.052004876s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-4qzbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4qzbn to expose endpoints map[pod1:[80] pod2:[80]]
Dec  8 22:15:18.572: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4qzbn exposes endpoints map[pod1:[80] pod2:[80]] (2.063101057s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-4qzbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4qzbn to expose endpoints map[pod2:[80]]
Dec  8 22:15:18.662: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4qzbn exposes endpoints map[pod2:[80]] (52.454027ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-4qzbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4qzbn to expose endpoints map[]
Dec  8 22:15:19.742: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4qzbn exposes endpoints map[] (1.032192437s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:15:19.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-4qzbn" for this suite.
Dec  8 22:15:25.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:15:25.824: INFO: namespace: e2e-tests-services-4qzbn, resource: bindings, ignored listing per whitelist
Dec  8 22:15:25.924: INFO: namespace e2e-tests-services-4qzbn deletion completed in 6.144387304s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:12.615 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:15:25.925: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:15:26.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lr2xf" for this suite.
Dec  8 22:15:48.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:15:48.094: INFO: namespace: e2e-tests-pods-lr2xf, resource: bindings, ignored listing per whitelist
Dec  8 22:15:48.166: INFO: namespace e2e-tests-pods-lr2xf deletion completed in 22.143354882s

• [SLOW TEST:22.242 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:15:48.167: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  8 22:15:48.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-cgwm4'
Dec  8 22:15:48.656: INFO: stderr: ""
Dec  8 22:15:48.657: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 22:15:49.788: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:15:49.788: INFO: Found 0 / 1
Dec  8 22:15:50.700: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:15:50.700: INFO: Found 0 / 1
Dec  8 22:15:51.720: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:15:51.720: INFO: Found 1 / 1
Dec  8 22:15:51.720: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  8 22:15:51.801: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:15:51.801: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 22:15:51.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 patch pod redis-master-n7klb --namespace=e2e-tests-kubectl-cgwm4 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  8 22:15:52.173: INFO: stderr: ""
Dec  8 22:15:52.173: INFO: stdout: "pod/redis-master-n7klb patched\n"
STEP: checking annotations
Dec  8 22:15:52.249: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:15:52.249: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:15:52.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cgwm4" for this suite.
Dec  8 22:16:14.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:16:14.648: INFO: namespace: e2e-tests-kubectl-cgwm4, resource: bindings, ignored listing per whitelist
Dec  8 22:16:14.662: INFO: namespace e2e-tests-kubectl-cgwm4 deletion completed in 22.332804631s

• [SLOW TEST:26.495 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:16:14.665: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-mclmn/configmap-test-e075f9df-fb36-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:16:14.756: INFO: Waiting up to 5m0s for pod "pod-configmaps-e076a35a-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-mclmn" to be "success or failure"
Dec  8 22:16:14.762: INFO: Pod "pod-configmaps-e076a35a-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.105572ms
Dec  8 22:16:16.765: INFO: Pod "pod-configmaps-e076a35a-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008930383s
STEP: Saw pod success
Dec  8 22:16:16.765: INFO: Pod "pod-configmaps-e076a35a-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:16:16.768: INFO: Trying to get logs from node compliancetest pod pod-configmaps-e076a35a-fb36-11e8-8c59-ae6969886d1b container env-test: <nil>
STEP: delete the pod
Dec  8 22:16:16.800: INFO: Waiting for pod pod-configmaps-e076a35a-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:16:16.810: INFO: Pod pod-configmaps-e076a35a-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:16:16.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mclmn" for this suite.
Dec  8 22:16:22.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:16:22.901: INFO: namespace: e2e-tests-configmap-mclmn, resource: bindings, ignored listing per whitelist
Dec  8 22:16:22.975: INFO: namespace e2e-tests-configmap-mclmn deletion completed in 6.160190782s

• [SLOW TEST:8.311 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:16:22.976: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e568ff94-fb36-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:16:23.060: INFO: Waiting up to 5m0s for pod "pod-secrets-e569a7d1-fb36-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-h8jcw" to be "success or failure"
Dec  8 22:16:23.074: INFO: Pod "pod-secrets-e569a7d1-fb36-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.862703ms
Dec  8 22:16:25.078: INFO: Pod "pod-secrets-e569a7d1-fb36-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01787382s
STEP: Saw pod success
Dec  8 22:16:25.078: INFO: Pod "pod-secrets-e569a7d1-fb36-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:16:25.081: INFO: Trying to get logs from node compliancetest pod pod-secrets-e569a7d1-fb36-11e8-8c59-ae6969886d1b container secret-env-test: <nil>
STEP: delete the pod
Dec  8 22:16:25.111: INFO: Waiting for pod pod-secrets-e569a7d1-fb36-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:16:25.120: INFO: Pod pod-secrets-e569a7d1-fb36-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:16:25.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-h8jcw" for this suite.
Dec  8 22:16:31.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:16:31.206: INFO: namespace: e2e-tests-secrets-h8jcw, resource: bindings, ignored listing per whitelist
Dec  8 22:16:31.268: INFO: namespace e2e-tests-secrets-h8jcw deletion completed in 6.14492384s

• [SLOW TEST:8.292 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:16:31.268: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-7xr4n
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7xr4n to expose endpoints map[]
Dec  8 22:16:31.393: INFO: Get endpoints failed (12.663788ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  8 22:16:32.396: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7xr4n exposes endpoints map[] (1.016610813s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7xr4n
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7xr4n to expose endpoints map[pod1:[100]]
Dec  8 22:16:33.441: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7xr4n exposes endpoints map[pod1:[100]] (1.034111553s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7xr4n
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7xr4n to expose endpoints map[pod1:[100] pod2:[101]]
Dec  8 22:16:34.525: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7xr4n exposes endpoints map[pod2:[101] pod1:[100]] (1.073670211s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7xr4n
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7xr4n to expose endpoints map[pod2:[101]]
Dec  8 22:16:34.555: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7xr4n exposes endpoints map[pod2:[101]] (8.873386ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7xr4n
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7xr4n to expose endpoints map[]
Dec  8 22:16:34.582: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7xr4n exposes endpoints map[] (12.955232ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:16:34.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7xr4n" for this suite.
Dec  8 22:16:56.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:16:56.695: INFO: namespace: e2e-tests-services-7xr4n, resource: bindings, ignored listing per whitelist
Dec  8 22:16:56.798: INFO: namespace e2e-tests-services-7xr4n deletion completed in 22.18232505s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:25.530 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:16:56.799: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  8 22:16:56.895: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-2kn6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kn6n/configmaps/e2e-watch-test-watch-closed,UID:f994714b-fb36-11e8-a35e-42010a800004,ResourceVersion:21575,Generation:0,CreationTimestamp:2018-12-08 22:16:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 22:16:56.895: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-2kn6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kn6n/configmaps/e2e-watch-test-watch-closed,UID:f994714b-fb36-11e8-a35e-42010a800004,ResourceVersion:21576,Generation:0,CreationTimestamp:2018-12-08 22:16:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  8 22:16:56.911: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-2kn6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kn6n/configmaps/e2e-watch-test-watch-closed,UID:f994714b-fb36-11e8-a35e-42010a800004,ResourceVersion:21577,Generation:0,CreationTimestamp:2018-12-08 22:16:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 22:16:56.911: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-2kn6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kn6n/configmaps/e2e-watch-test-watch-closed,UID:f994714b-fb36-11e8-a35e-42010a800004,ResourceVersion:21578,Generation:0,CreationTimestamp:2018-12-08 22:16:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:16:56.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-2kn6n" for this suite.
Dec  8 22:17:02.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:17:03.058: INFO: namespace: e2e-tests-watch-2kn6n, resource: bindings, ignored listing per whitelist
Dec  8 22:17:03.071: INFO: namespace e2e-tests-watch-2kn6n deletion completed in 6.156731279s

• [SLOW TEST:6.273 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:17:03.072: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-x58c
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 22:17:03.158: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-x58c" in namespace "e2e-tests-subpath-4lqk5" to be "success or failure"
Dec  8 22:17:03.163: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.868199ms
Dec  8 22:17:05.168: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010230073s
Dec  8 22:17:07.173: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 4.015108906s
Dec  8 22:17:09.176: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 6.018626281s
Dec  8 22:17:11.181: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 8.023030251s
Dec  8 22:17:13.185: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 10.02699254s
Dec  8 22:17:15.188: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 12.030611886s
Dec  8 22:17:17.192: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 14.034907264s
Dec  8 22:17:19.196: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 16.038853858s
Dec  8 22:17:21.201: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 18.04323598s
Dec  8 22:17:23.205: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 20.047276589s
Dec  8 22:17:25.208: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Running", Reason="", readiness=false. Elapsed: 22.050614698s
Dec  8 22:17:27.212: INFO: Pod "pod-subpath-test-configmap-x58c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.054863006s
STEP: Saw pod success
Dec  8 22:17:27.212: INFO: Pod "pod-subpath-test-configmap-x58c" satisfied condition "success or failure"
Dec  8 22:17:27.219: INFO: Trying to get logs from node compliancetest pod pod-subpath-test-configmap-x58c container test-container-subpath-configmap-x58c: <nil>
STEP: delete the pod
Dec  8 22:17:27.253: INFO: Waiting for pod pod-subpath-test-configmap-x58c to disappear
Dec  8 22:17:27.258: INFO: Pod pod-subpath-test-configmap-x58c no longer exists
STEP: Deleting pod pod-subpath-test-configmap-x58c
Dec  8 22:17:27.258: INFO: Deleting pod "pod-subpath-test-configmap-x58c" in namespace "e2e-tests-subpath-4lqk5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:17:27.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4lqk5" for this suite.
Dec  8 22:17:33.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:17:33.366: INFO: namespace: e2e-tests-subpath-4lqk5, resource: bindings, ignored listing per whitelist
Dec  8 22:17:33.393: INFO: namespace e2e-tests-subpath-4lqk5 deletion completed in 6.128134701s

• [SLOW TEST:30.321 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:17:33.393: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-kjj2
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 22:17:33.477: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-kjj2" in namespace "e2e-tests-subpath-jq4tr" to be "success or failure"
Dec  8 22:17:33.482: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.164189ms
Dec  8 22:17:35.488: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010488602s
Dec  8 22:17:37.492: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 4.014516762s
Dec  8 22:17:39.496: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 6.01865245s
Dec  8 22:17:41.500: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 8.023076123s
Dec  8 22:17:43.505: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 10.027468347s
Dec  8 22:17:45.509: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 12.03147564s
Dec  8 22:17:47.513: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 14.036204621s
Dec  8 22:17:49.518: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 16.040873445s
Dec  8 22:17:51.522: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 18.045148618s
Dec  8 22:17:53.527: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 20.049331165s
Dec  8 22:17:55.531: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Running", Reason="", readiness=false. Elapsed: 22.053556151s
Dec  8 22:17:57.535: INFO: Pod "pod-subpath-test-projected-kjj2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057887702s
STEP: Saw pod success
Dec  8 22:17:57.535: INFO: Pod "pod-subpath-test-projected-kjj2" satisfied condition "success or failure"
Dec  8 22:17:57.539: INFO: Trying to get logs from node compliancetest pod pod-subpath-test-projected-kjj2 container test-container-subpath-projected-kjj2: <nil>
STEP: delete the pod
Dec  8 22:17:57.570: INFO: Waiting for pod pod-subpath-test-projected-kjj2 to disappear
Dec  8 22:17:57.575: INFO: Pod pod-subpath-test-projected-kjj2 no longer exists
STEP: Deleting pod pod-subpath-test-projected-kjj2
Dec  8 22:17:57.575: INFO: Deleting pod "pod-subpath-test-projected-kjj2" in namespace "e2e-tests-subpath-jq4tr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:17:57.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jq4tr" for this suite.
Dec  8 22:18:03.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:18:03.681: INFO: namespace: e2e-tests-subpath-jq4tr, resource: bindings, ignored listing per whitelist
Dec  8 22:18:03.753: INFO: namespace e2e-tests-subpath-jq4tr deletion completed in 6.172099139s

• [SLOW TEST:30.360 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:18:03.753: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:18:03.823: INFO: Creating deployment "nginx-deployment"
Dec  8 22:18:03.830: INFO: Waiting for observed generation 1
Dec  8 22:18:05.842: INFO: Waiting for all required pods to come up
Dec  8 22:18:05.853: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  8 22:18:13.925: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  8 22:18:13.931: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  8 22:18:13.941: INFO: Updating deployment nginx-deployment
Dec  8 22:18:13.941: INFO: Waiting for observed generation 2
Dec  8 22:18:15.948: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  8 22:18:15.953: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  8 22:18:15.960: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  8 22:18:15.976: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  8 22:18:15.976: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  8 22:18:15.980: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  8 22:18:15.991: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  8 22:18:15.991: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  8 22:18:16.007: INFO: Updating deployment nginx-deployment
Dec  8 22:18:16.007: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  8 22:18:16.057: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  8 22:18:16.146: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 22:18:16.589: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-l7hlx/deployments/nginx-deployment,UID:217a8288-fb37-11e8-a35e-42010a800004,ResourceVersion:21882,Generation:3,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2018-12-08 22:18:14 +0000 UTC 2018-12-08 22:18:03 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2018-12-08 22:18:16 +0000 UTC 2018-12-08 22:18:16 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  8 22:18:16.717: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-l7hlx/replicasets/nginx-deployment-7dc8f79789,UID:27838080-fb37-11e8-a35e-42010a800004,ResourceVersion:21873,Generation:3,CreationTimestamp:2018-12-08 22:18:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 217a8288-fb37-11e8-a35e-42010a800004 0xc421df9a67 0xc421df9a68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 22:18:16.717: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  8 22:18:16.717: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-l7hlx/replicasets/nginx-deployment-7f9675fb8b,UID:217ccee1-fb37-11e8-a35e-42010a800004,ResourceVersion:21870,Generation:3,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 217a8288-fb37-11e8-a35e-42010a800004 0xc421df9c67 0xc421df9c68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  8 22:18:16.773: INFO: Pod "nginx-deployment-7dc8f79789-4cwkr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4cwkr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-4cwkr,UID:28f25f04-fb37-11e8-a35e-42010a800004,ResourceVersion:21915,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc42195d187 0xc42195d188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42195d200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42195d220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.773: INFO: Pod "nginx-deployment-7dc8f79789-84rss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-84rss,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-84rss,UID:2790ffbf-fb37-11e8-a35e-42010a800004,ResourceVersion:21855,Generation:0,CreationTimestamp:2018-12-08 22:18:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc42195d320 0xc42195d321}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42195d3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42195d3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-08 22:18:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.774: INFO: Pod "nginx-deployment-7dc8f79789-8l2gd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8l2gd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-8l2gd,UID:28df7bc7-fb37-11e8-a35e-42010a800004,ResourceVersion:21905,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc42195d790 0xc42195d791}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42195d810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42195d830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.774: INFO: Pod "nginx-deployment-7dc8f79789-9q2hn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9q2hn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-9q2hn,UID:2789c8f2-fb37-11e8-a35e-42010a800004,ResourceVersion:21833,Generation:0,CreationTimestamp:2018-12-08 22:18:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc42195d8a0 0xc42195d8a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42195dbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42195dc10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-08 22:18:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.774: INFO: Pod "nginx-deployment-7dc8f79789-czktx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-czktx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-czktx,UID:27911c7d-fb37-11e8-a35e-42010a800004,ResourceVersion:21863,Generation:0,CreationTimestamp:2018-12-08 22:18:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc42195dcd0 0xc42195dcd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421204070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-08 22:18:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.775: INFO: Pod "nginx-deployment-7dc8f79789-gk87q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gk87q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-gk87q,UID:28f16598-fb37-11e8-a35e-42010a800004,ResourceVersion:21913,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc421204150 0xc421204151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421204250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.775: INFO: Pod "nginx-deployment-7dc8f79789-nkvpv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nkvpv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-nkvpv,UID:28f3a14e-fb37-11e8-a35e-42010a800004,ResourceVersion:21917,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc4212042e0 0xc4212042e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421204360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.775: INFO: Pod "nginx-deployment-7dc8f79789-q8t9x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-q8t9x,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-q8t9x,UID:27ceecaa-fb37-11e8-a35e-42010a800004,ResourceVersion:21924,Generation:0,CreationTimestamp:2018-12-08 22:18:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc4212044b0 0xc4212044b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421204530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-08 22:18:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.775: INFO: Pod "nginx-deployment-7dc8f79789-w2lgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-w2lgl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-w2lgl,UID:28dee59f-fb37-11e8-a35e-42010a800004,ResourceVersion:21904,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc421204750 0xc421204751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212047e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.776: INFO: Pod "nginx-deployment-7dc8f79789-wnh6s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wnh6s,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-wnh6s,UID:28f2d992-fb37-11e8-a35e-42010a800004,ResourceVersion:21916,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc4212049b0 0xc4212049b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421204a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.776: INFO: Pod "nginx-deployment-7dc8f79789-wrdqv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wrdqv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-wrdqv,UID:28ca8d10-fb37-11e8-a35e-42010a800004,ResourceVersion:21890,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc421204ad0 0xc421204ad1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421204bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.776: INFO: Pod "nginx-deployment-7dc8f79789-x6g7m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-x6g7m,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-x6g7m,UID:29116144-fb37-11e8-a35e-42010a800004,ResourceVersion:21921,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc421204c50 0xc421204c51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421204da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.776: INFO: Pod "nginx-deployment-7dc8f79789-zms8t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zms8t,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7dc8f79789-zms8t,UID:27c99e6a-fb37-11e8-a35e-42010a800004,ResourceVersion:21865,Generation:0,CreationTimestamp:2018-12-08 22:18:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 27838080-fb37-11e8-a35e-42010a800004 0xc421204e30 0xc421204e31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421204f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421204f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:14 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-08 22:18:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.777: INFO: Pod "nginx-deployment-7f9675fb8b-5ffgv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5ffgv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-5ffgv,UID:2191fee9-fb37-11e8-a35e-42010a800004,ResourceVersion:21801,Generation:0,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc421205030 0xc421205031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:04 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.85,StartTime:2018-12-08 22:18:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 22:18:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://84a50edbd61c533a6ff0d6d03c0c3109282b79ceab85e60f883dbc7a03977707}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.777: INFO: Pod "nginx-deployment-7f9675fb8b-65k65" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-65k65,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-65k65,UID:28f06b01-fb37-11e8-a35e-42010a800004,ResourceVersion:21910,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc4212051f0 0xc4212051f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212052e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.777: INFO: Pod "nginx-deployment-7f9675fb8b-6jgsg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6jgsg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-6jgsg,UID:28cd485e-fb37-11e8-a35e-42010a800004,ResourceVersion:21891,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc421205370 0xc421205371}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212053e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.777: INFO: Pod "nginx-deployment-7f9675fb8b-7pdgm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7pdgm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-7pdgm,UID:218320a7-fb37-11e8-a35e-42010a800004,ResourceVersion:21789,Generation:0,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc4212054e0 0xc4212054e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.81,StartTime:2018-12-08 22:18:03 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 22:18:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://6fae4dca37cc5523e3fddcbbf2de9658969e1c2328e5656729586eff96c9565c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.778: INFO: Pod "nginx-deployment-7f9675fb8b-8mvzv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8mvzv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-8mvzv,UID:28e100c7-fb37-11e8-a35e-42010a800004,ResourceVersion:21906,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc421205680 0xc421205681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212056f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.781: INFO: Pod "nginx-deployment-7f9675fb8b-b9676" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-b9676,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-b9676,UID:2182cdf0-fb37-11e8-a35e-42010a800004,ResourceVersion:21807,Generation:0,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc421205780 0xc421205781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.79,StartTime:2018-12-08 22:18:03 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 22:18:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://1d29c9ec05116b070701436218f3632af1432e72eed4dc3f22550c02ad0e5161}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.781: INFO: Pod "nginx-deployment-7f9675fb8b-c6m2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-c6m2h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-c6m2h,UID:28f63ee0-fb37-11e8-a35e-42010a800004,ResourceVersion:21923,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc4212058e0 0xc4212058e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.781: INFO: Pod "nginx-deployment-7f9675fb8b-f6cbk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f6cbk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-f6cbk,UID:2188bdff-fb37-11e8-a35e-42010a800004,ResourceVersion:21786,Generation:0,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc4212059f0 0xc4212059f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.82,StartTime:2018-12-08 22:18:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 22:18:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://c14023ea0cd67876803f270f5f842c5ec75c4da3b23f3d72037472f4e503b806}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.781: INFO: Pod "nginx-deployment-7f9675fb8b-g88rg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-g88rg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-g88rg,UID:28f41649-fb37-11e8-a35e-42010a800004,ResourceVersion:21912,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc421205b40 0xc421205b41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.782: INFO: Pod "nginx-deployment-7f9675fb8b-gvs68" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gvs68,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-gvs68,UID:21819ff2-fb37-11e8-a35e-42010a800004,ResourceVersion:21780,Generation:0,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc421205c40 0xc421205c41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.78,StartTime:2018-12-08 22:18:03 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 22:18:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://8263524a752b856312615827114ee77b7fba65539d9d792aca9329f20612680a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.782: INFO: Pod "nginx-deployment-7f9675fb8b-hk76k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hk76k,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-hk76k,UID:21890004-fb37-11e8-a35e-42010a800004,ResourceVersion:21804,Generation:0,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc421205dc0 0xc421205dc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205e60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.80,StartTime:2018-12-08 22:18:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 22:18:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://44da7c3fe747c04cf701754a91e1ec20234f08f868606329fdb2cde86f688d29}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.783: INFO: Pod "nginx-deployment-7f9675fb8b-jlqfr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jlqfr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-jlqfr,UID:28e04dbf-fb37-11e8-a35e-42010a800004,ResourceVersion:21908,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc421205f20 0xc421205f21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421205f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421205fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.783: INFO: Pod "nginx-deployment-7f9675fb8b-k6rgw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k6rgw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-k6rgw,UID:28f5a77a-fb37-11e8-a35e-42010a800004,ResourceVersion:21922,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc420c921f0 0xc420c921f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c92260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c92280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.783: INFO: Pod "nginx-deployment-7f9675fb8b-ngqf8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ngqf8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-ngqf8,UID:28cd9f25-fb37-11e8-a35e-42010a800004,ResourceVersion:21883,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc420c922f0 0xc420c922f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c92630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c92650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.783: INFO: Pod "nginx-deployment-7f9675fb8b-rzlrs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rzlrs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-rzlrs,UID:28f40742-fb37-11e8-a35e-42010a800004,ResourceVersion:21914,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc420c926c0 0xc420c926c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c92730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c92750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.784: INFO: Pod "nginx-deployment-7f9675fb8b-sshgq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sshgq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-sshgq,UID:2188613e-fb37-11e8-a35e-42010a800004,ResourceVersion:21810,Generation:0,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc420c92a80 0xc420c92a81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c92af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c92b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:03 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.84,StartTime:2018-12-08 22:18:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 22:18:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://84eb115c6d5c0c5d6ab8b5d20287a73eb6dea17ce9cdec79b7d56dd8fe60c032}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.784: INFO: Pod "nginx-deployment-7f9675fb8b-t8rd5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-t8rd5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-t8rd5,UID:2192d85d-fb37-11e8-a35e-42010a800004,ResourceVersion:21792,Generation:0,CreationTimestamp:2018-12-08 22:18:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc420c92d80 0xc420c92d81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c92df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c92e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:04 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.86,StartTime:2018-12-08 22:18:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 22:18:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://c0b4f2ce7923b3102cfea8d6e3074f0262d6bf8e9a311d43c0c32d491a0cff3b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.784: INFO: Pod "nginx-deployment-7f9675fb8b-vkmjx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vkmjx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-vkmjx,UID:28c3e765-fb37-11e8-a35e-42010a800004,ResourceVersion:21874,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc420c92f40 0xc420c92f41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c92fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c92fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.785: INFO: Pod "nginx-deployment-7f9675fb8b-w4q9h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-w4q9h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-w4q9h,UID:28e131c0-fb37-11e8-a35e-42010a800004,ResourceVersion:21903,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc420c93080 0xc420c93081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c930f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c93110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 22:18:16.786: INFO: Pod "nginx-deployment-7f9675fb8b-x4trm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-x4trm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-l7hlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l7hlx/pods/nginx-deployment-7f9675fb8b-x4trm,UID:28e12617-fb37-11e8-a35e-42010a800004,ResourceVersion:21907,Generation:0,CreationTimestamp:2018-12-08 22:18:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 217ccee1-fb37-11e8-a35e-42010a800004 0xc420c93180 0xc420c93181}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fllxh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fllxh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fllxh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c93230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c93250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:18:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:18:16.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-l7hlx" for this suite.
Dec  8 22:18:30.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:18:31.340: INFO: namespace: e2e-tests-deployment-l7hlx, resource: bindings, ignored listing per whitelist
Dec  8 22:18:31.427: INFO: namespace e2e-tests-deployment-l7hlx deletion completed in 14.545483656s

• [SLOW TEST:27.674 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:18:31.427: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:18:40.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-qdrm8" for this suite.
Dec  8 22:18:46.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:18:46.575: INFO: namespace: e2e-tests-namespaces-qdrm8, resource: bindings, ignored listing per whitelist
Dec  8 22:18:46.646: INFO: namespace e2e-tests-namespaces-qdrm8 deletion completed in 6.15976909s
STEP: Destroying namespace "e2e-tests-nsdeletetest-k8jwk" for this suite.
Dec  8 22:18:46.649: INFO: Namespace e2e-tests-nsdeletetest-k8jwk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-gvbbv" for this suite.
Dec  8 22:18:52.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:18:52.733: INFO: namespace: e2e-tests-nsdeletetest-gvbbv, resource: bindings, ignored listing per whitelist
Dec  8 22:18:52.842: INFO: namespace e2e-tests-nsdeletetest-gvbbv deletion completed in 6.193347685s

• [SLOW TEST:21.415 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:18:52.843: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-3ebe7efd-fb37-11e8-8c59-ae6969886d1b
STEP: Creating secret with name s-test-opt-upd-3ebe7f45-fb37-11e8-8c59-ae6969886d1b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3ebe7efd-fb37-11e8-8c59-ae6969886d1b
STEP: Updating secret s-test-opt-upd-3ebe7f45-fb37-11e8-8c59-ae6969886d1b
STEP: Creating secret with name s-test-opt-create-3ebe7f5a-fb37-11e8-8c59-ae6969886d1b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:18:57.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4s99x" for this suite.
Dec  8 22:19:21.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:19:21.103: INFO: namespace: e2e-tests-projected-4s99x, resource: bindings, ignored listing per whitelist
Dec  8 22:19:21.179: INFO: namespace e2e-tests-projected-4s99x deletion completed in 24.140277791s

• [SLOW TEST:28.336 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:19:21.179: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  8 22:19:21.300: INFO: Waiting up to 5m0s for pod "client-containers-4fa690e1-fb37-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-containers-zgk78" to be "success or failure"
Dec  8 22:19:21.321: INFO: Pod "client-containers-4fa690e1-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 21.002238ms
Dec  8 22:19:23.325: INFO: Pod "client-containers-4fa690e1-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024872747s
Dec  8 22:19:25.329: INFO: Pod "client-containers-4fa690e1-fb37-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028623642s
STEP: Saw pod success
Dec  8 22:19:25.329: INFO: Pod "client-containers-4fa690e1-fb37-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:19:25.340: INFO: Trying to get logs from node compliancetest pod client-containers-4fa690e1-fb37-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:19:25.483: INFO: Waiting for pod client-containers-4fa690e1-fb37-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:19:25.493: INFO: Pod client-containers-4fa690e1-fb37-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:19:25.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zgk78" for this suite.
Dec  8 22:19:31.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:19:31.719: INFO: namespace: e2e-tests-containers-zgk78, resource: bindings, ignored listing per whitelist
Dec  8 22:19:31.729: INFO: namespace e2e-tests-containers-zgk78 deletion completed in 6.230338757s

• [SLOW TEST:10.551 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:19:31.730: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  8 22:19:39.875: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:39.879: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:41.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:41.887: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:43.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:43.884: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:45.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:45.883: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:47.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:47.883: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:49.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:49.885: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:51.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:51.885: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:53.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:53.884: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:55.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:55.883: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 22:19:57.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 22:19:57.883: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:19:57.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gtsnj" for this suite.
Dec  8 22:20:19.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:20:19.960: INFO: namespace: e2e-tests-container-lifecycle-hook-gtsnj, resource: bindings, ignored listing per whitelist
Dec  8 22:20:20.032: INFO: namespace e2e-tests-container-lifecycle-hook-gtsnj deletion completed in 22.136093271s

• [SLOW TEST:48.302 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:20:20.033: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  8 22:20:20.131: INFO: Waiting up to 5m0s for pod "pod-72b76b79-fb37-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-bcbq7" to be "success or failure"
Dec  8 22:20:20.137: INFO: Pod "pod-72b76b79-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.342115ms
Dec  8 22:20:22.141: INFO: Pod "pod-72b76b79-fb37-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010036291s
STEP: Saw pod success
Dec  8 22:20:22.141: INFO: Pod "pod-72b76b79-fb37-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:20:22.144: INFO: Trying to get logs from node compliancetest pod pod-72b76b79-fb37-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:20:22.176: INFO: Waiting for pod pod-72b76b79-fb37-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:20:22.180: INFO: Pod pod-72b76b79-fb37-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:20:22.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bcbq7" for this suite.
Dec  8 22:20:28.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:20:28.336: INFO: namespace: e2e-tests-emptydir-bcbq7, resource: bindings, ignored listing per whitelist
Dec  8 22:20:28.354: INFO: namespace e2e-tests-emptydir-bcbq7 deletion completed in 6.170418023s

• [SLOW TEST:8.321 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:20:28.354: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-k48nr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 22:20:28.419: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 22:20:46.505: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.0.119 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-k48nr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 22:20:46.505: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 22:20:47.604: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:20:47.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-k48nr" for this suite.
Dec  8 22:21:11.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:21:11.647: INFO: namespace: e2e-tests-pod-network-test-k48nr, resource: bindings, ignored listing per whitelist
Dec  8 22:21:11.760: INFO: namespace e2e-tests-pod-network-test-k48nr deletion completed in 24.15154585s

• [SLOW TEST:43.406 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:21:11.760: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9189aee5-fb37-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:21:11.866: INFO: Waiting up to 5m0s for pod "pod-secrets-918a55f8-fb37-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-8xxn2" to be "success or failure"
Dec  8 22:21:11.875: INFO: Pod "pod-secrets-918a55f8-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.10453ms
Dec  8 22:21:13.879: INFO: Pod "pod-secrets-918a55f8-fb37-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.012827058s
Dec  8 22:21:15.884: INFO: Pod "pod-secrets-918a55f8-fb37-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017785767s
STEP: Saw pod success
Dec  8 22:21:15.884: INFO: Pod "pod-secrets-918a55f8-fb37-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:21:15.888: INFO: Trying to get logs from node compliancetest pod pod-secrets-918a55f8-fb37-11e8-8c59-ae6969886d1b container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:21:15.917: INFO: Waiting for pod pod-secrets-918a55f8-fb37-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:21:15.923: INFO: Pod pod-secrets-918a55f8-fb37-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:21:15.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8xxn2" for this suite.
Dec  8 22:21:21.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:21:22.042: INFO: namespace: e2e-tests-secrets-8xxn2, resource: bindings, ignored listing per whitelist
Dec  8 22:21:22.051: INFO: namespace e2e-tests-secrets-8xxn2 deletion completed in 6.124927862s

• [SLOW TEST:10.291 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:21:22.052: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  8 22:21:22.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 api-versions'
Dec  8 22:21:22.260: INFO: stderr: ""
Dec  8 22:21:22.260: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:21:22.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w7k24" for this suite.
Dec  8 22:21:28.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:21:28.373: INFO: namespace: e2e-tests-kubectl-w7k24, resource: bindings, ignored listing per whitelist
Dec  8 22:21:28.431: INFO: namespace e2e-tests-kubectl-w7k24 deletion completed in 6.166569139s

• [SLOW TEST:6.379 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:21:28.431: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9b78b4b0-fb37-11e8-8c59-ae6969886d1b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9b78b4b0-fb37-11e8-8c59-ae6969886d1b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:21:32.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2gjbt" for this suite.
Dec  8 22:21:54.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:21:54.655: INFO: namespace: e2e-tests-projected-2gjbt, resource: bindings, ignored listing per whitelist
Dec  8 22:21:54.693: INFO: namespace e2e-tests-projected-2gjbt deletion completed in 22.125855198s

• [SLOW TEST:26.262 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:21:54.694: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 22:21:57.373: INFO: Successfully updated pod "annotationupdateab268a40-fb37-11e8-8c59-ae6969886d1b"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:22:01.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jx8hf" for this suite.
Dec  8 22:22:23.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:22:23.530: INFO: namespace: e2e-tests-projected-jx8hf, resource: bindings, ignored listing per whitelist
Dec  8 22:22:23.544: INFO: namespace e2e-tests-projected-jx8hf deletion completed in 22.133229405s

• [SLOW TEST:28.851 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:22:23.545: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  8 22:22:23.611: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 22:22:23.617: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 22:22:23.621: INFO: 
Logging pods the kubelet thinks is on node compliancetest before test
Dec  8 22:22:23.628: INFO: nirmata-kube-controller-7f4cfbcc47-tbw9p from nirmata started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:22:23.628: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Dec  8 22:22:23.628: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 22:02:12 +0000 UTC (1 container statuses recorded)
Dec  8 22:22:23.628: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  8 22:22:23.628: INFO: metrics-server-7cc7d8ccb8-gxvfp from kube-system started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:22:23.628: INFO: 	Container metrics-server ready: true, restart count 0
Dec  8 22:22:23.628: INFO: ingress-default-backend-59f45f4b79-2vjfz from ingress-haproxy started at 2018-12-08 21:52:20 +0000 UTC (1 container statuses recorded)
Dec  8 22:22:23.628: INFO: 	Container ingress-default-backend ready: true, restart count 0
Dec  8 22:22:23.628: INFO: sonobuoy-systemd-logs-daemon-set-eca918e579904fef-p49sk from heptio-sonobuoy started at 2018-12-08 22:02:16 +0000 UTC (2 container statuses recorded)
Dec  8 22:22:23.628: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  8 22:22:23.628: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 22:22:23.628: INFO: kube-dns-5d95dcfb8d-28f4w from kube-system started at 2018-12-08 21:52:08 +0000 UTC (3 container statuses recorded)
Dec  8 22:22:23.628: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  8 22:22:23.628: INFO: 	Container kubedns ready: true, restart count 0
Dec  8 22:22:23.628: INFO: 	Container sidecar ready: true, restart count 0
Dec  8 22:22:23.628: INFO: nirmata-cni-installer-dgkr7 from nirmata started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:22:23.629: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 22:22:23.629: INFO: haproxy-ingress-54bf6fdf5d-qrznd from ingress-haproxy started at 2018-12-08 21:52:22 +0000 UTC (1 container statuses recorded)
Dec  8 22:22:23.629: INFO: 	Container haproxy-ingress ready: true, restart count 0
Dec  8 22:22:23.629: INFO: sonobuoy-e2e-job-02e788f5b1a14e8d from heptio-sonobuoy started at 2018-12-08 22:02:16 +0000 UTC (2 container statuses recorded)
Dec  8 22:22:23.629: INFO: 	Container e2e ready: true, restart count 0
Dec  8 22:22:23.629: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 22:22:23.629: INFO: kube-flannel-ds-sh87s from kube-system started at 2018-12-08 21:51:56 +0000 UTC (1 container statuses recorded)
Dec  8 22:22:23.629: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156e7bb5f3e738b8], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:22:24.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-tbgcc" for this suite.
Dec  8 22:22:30.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:22:30.786: INFO: namespace: e2e-tests-sched-pred-tbgcc, resource: bindings, ignored listing per whitelist
Dec  8 22:22:30.801: INFO: namespace e2e-tests-sched-pred-tbgcc deletion completed in 6.143918091s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.256 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:22:30.801: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 22:22:33.424: INFO: Successfully updated pod "labelsupdatec0a7c86a-fb37-11e8-8c59-ae6969886d1b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:22:35.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ktx8q" for this suite.
Dec  8 22:22:57.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:22:57.573: INFO: namespace: e2e-tests-downward-api-ktx8q, resource: bindings, ignored listing per whitelist
Dec  8 22:22:57.583: INFO: namespace e2e-tests-downward-api-ktx8q deletion completed in 22.136423072s

• [SLOW TEST:26.782 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:22:57.583: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  8 22:22:57.664: INFO: Waiting up to 5m0s for pod "pod-d09d8318-fb37-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-xj475" to be "success or failure"
Dec  8 22:22:57.695: INFO: Pod "pod-d09d8318-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 31.132381ms
Dec  8 22:22:59.699: INFO: Pod "pod-d09d8318-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035128305s
Dec  8 22:23:01.703: INFO: Pod "pod-d09d8318-fb37-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039516601s
STEP: Saw pod success
Dec  8 22:23:01.703: INFO: Pod "pod-d09d8318-fb37-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:23:01.707: INFO: Trying to get logs from node compliancetest pod pod-d09d8318-fb37-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:23:01.743: INFO: Waiting for pod pod-d09d8318-fb37-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:23:01.751: INFO: Pod pod-d09d8318-fb37-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:23:01.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xj475" for this suite.
Dec  8 22:23:07.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:23:07.819: INFO: namespace: e2e-tests-emptydir-xj475, resource: bindings, ignored listing per whitelist
Dec  8 22:23:07.881: INFO: namespace e2e-tests-emptydir-xj475 deletion completed in 6.126040529s

• [SLOW TEST:10.298 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:23:07.882: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:23:07.960: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6c06e9d-fb37-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-9jg86" to be "success or failure"
Dec  8 22:23:07.965: INFO: Pod "downwardapi-volume-d6c06e9d-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.16065ms
Dec  8 22:23:09.970: INFO: Pod "downwardapi-volume-d6c06e9d-fb37-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009780575s
STEP: Saw pod success
Dec  8 22:23:09.970: INFO: Pod "downwardapi-volume-d6c06e9d-fb37-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:23:09.973: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-d6c06e9d-fb37-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:23:10.011: INFO: Waiting for pod downwardapi-volume-d6c06e9d-fb37-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:23:10.015: INFO: Pod downwardapi-volume-d6c06e9d-fb37-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:23:10.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9jg86" for this suite.
Dec  8 22:23:16.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:23:16.115: INFO: namespace: e2e-tests-downward-api-9jg86, resource: bindings, ignored listing per whitelist
Dec  8 22:23:16.174: INFO: namespace e2e-tests-downward-api-9jg86 deletion completed in 6.15521119s

• [SLOW TEST:8.292 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:23:16.174: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:23:16.255: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dbb1f567-fb37-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-hgpb4" to be "success or failure"
Dec  8 22:23:16.259: INFO: Pod "downwardapi-volume-dbb1f567-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.658159ms
Dec  8 22:23:18.263: INFO: Pod "downwardapi-volume-dbb1f567-fb37-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008229674s
STEP: Saw pod success
Dec  8 22:23:18.263: INFO: Pod "downwardapi-volume-dbb1f567-fb37-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:23:18.266: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-dbb1f567-fb37-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:23:18.292: INFO: Waiting for pod downwardapi-volume-dbb1f567-fb37-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:23:18.302: INFO: Pod downwardapi-volume-dbb1f567-fb37-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:23:18.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hgpb4" for this suite.
Dec  8 22:23:24.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:23:24.397: INFO: namespace: e2e-tests-projected-hgpb4, resource: bindings, ignored listing per whitelist
Dec  8 22:23:24.433: INFO: namespace e2e-tests-projected-hgpb4 deletion completed in 6.126439974s

• [SLOW TEST:8.258 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:23:24.433: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e09f6af6-fb37-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:23:24.530: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e0a0a7f4-fb37-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-78cgz" to be "success or failure"
Dec  8 22:23:24.535: INFO: Pod "pod-projected-configmaps-e0a0a7f4-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.942764ms
Dec  8 22:23:26.546: INFO: Pod "pod-projected-configmaps-e0a0a7f4-fb37-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015759325s
Dec  8 22:23:28.550: INFO: Pod "pod-projected-configmaps-e0a0a7f4-fb37-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020184262s
STEP: Saw pod success
Dec  8 22:23:28.550: INFO: Pod "pod-projected-configmaps-e0a0a7f4-fb37-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:23:28.553: INFO: Trying to get logs from node compliancetest pod pod-projected-configmaps-e0a0a7f4-fb37-11e8-8c59-ae6969886d1b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:23:28.586: INFO: Waiting for pod pod-projected-configmaps-e0a0a7f4-fb37-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:23:28.594: INFO: Pod pod-projected-configmaps-e0a0a7f4-fb37-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:23:28.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-78cgz" for this suite.
Dec  8 22:23:34.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:23:34.714: INFO: namespace: e2e-tests-projected-78cgz, resource: bindings, ignored listing per whitelist
Dec  8 22:23:34.773: INFO: namespace e2e-tests-projected-78cgz deletion completed in 6.174601261s

• [SLOW TEST:10.340 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:23:34.773: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  8 22:23:35.370: INFO: Waiting up to 5m0s for pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-ffqxr" in namespace "e2e-tests-svcaccounts-86cjw" to be "success or failure"
Dec  8 22:23:35.374: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-ffqxr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.355523ms
Dec  8 22:23:37.378: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-ffqxr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007439348s
Dec  8 22:23:39.382: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-ffqxr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011846914s
STEP: Saw pod success
Dec  8 22:23:39.382: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-ffqxr" satisfied condition "success or failure"
Dec  8 22:23:39.388: INFO: Trying to get logs from node compliancetest pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-ffqxr container token-test: <nil>
STEP: delete the pod
Dec  8 22:23:39.426: INFO: Waiting for pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-ffqxr to disappear
Dec  8 22:23:39.434: INFO: Pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-ffqxr no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  8 22:23:39.441: INFO: Waiting up to 5m0s for pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-fwf26" in namespace "e2e-tests-svcaccounts-86cjw" to be "success or failure"
Dec  8 22:23:39.447: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-fwf26": Phase="Pending", Reason="", readiness=false. Elapsed: 5.344306ms
Dec  8 22:23:41.450: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-fwf26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009017002s
STEP: Saw pod success
Dec  8 22:23:41.451: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-fwf26" satisfied condition "success or failure"
Dec  8 22:23:41.455: INFO: Trying to get logs from node compliancetest pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-fwf26 container root-ca-test: <nil>
STEP: delete the pod
Dec  8 22:23:41.493: INFO: Waiting for pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-fwf26 to disappear
Dec  8 22:23:41.499: INFO: Pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-fwf26 no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  8 22:23:41.511: INFO: Waiting up to 5m0s for pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-dkxch" in namespace "e2e-tests-svcaccounts-86cjw" to be "success or failure"
Dec  8 22:23:41.524: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-dkxch": Phase="Pending", Reason="", readiness=false. Elapsed: 12.60876ms
Dec  8 22:23:43.528: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-dkxch": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016569622s
Dec  8 22:23:45.540: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-dkxch": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028982192s
STEP: Saw pod success
Dec  8 22:23:45.540: INFO: Pod "pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-dkxch" satisfied condition "success or failure"
Dec  8 22:23:45.582: INFO: Trying to get logs from node compliancetest pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-dkxch container namespace-test: <nil>
STEP: delete the pod
Dec  8 22:23:45.716: INFO: Waiting for pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-dkxch to disappear
Dec  8 22:23:45.735: INFO: Pod pod-service-account-e716f321-fb37-11e8-8c59-ae6969886d1b-dkxch no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:23:45.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-86cjw" for this suite.
Dec  8 22:23:51.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:23:51.833: INFO: namespace: e2e-tests-svcaccounts-86cjw, resource: bindings, ignored listing per whitelist
Dec  8 22:23:51.946: INFO: namespace e2e-tests-svcaccounts-86cjw deletion completed in 6.198913773s

• [SLOW TEST:17.173 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:23:51.946: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Dec  8 22:23:52.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-6qqnc'
Dec  8 22:23:52.877: INFO: stderr: ""
Dec  8 22:23:52.877: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  8 22:23:53.885: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:23:53.885: INFO: Found 0 / 1
Dec  8 22:23:54.882: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:23:54.882: INFO: Found 1 / 1
Dec  8 22:23:54.882: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 22:23:54.887: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:23:54.887: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  8 22:23:54.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 logs redis-master-lh4wl redis-master --namespace=e2e-tests-kubectl-6qqnc'
Dec  8 22:23:55.041: INFO: stderr: ""
Dec  8 22:23:55.041: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 22:23:53.933 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 22:23:53.961 # Server started, Redis version 3.2.12\n1:M 08 Dec 22:23:53.961 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 22:23:53.961 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  8 22:23:55.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 log redis-master-lh4wl redis-master --namespace=e2e-tests-kubectl-6qqnc --tail=1'
Dec  8 22:23:55.187: INFO: stderr: ""
Dec  8 22:23:55.188: INFO: stdout: "1:M 08 Dec 22:23:53.961 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  8 22:23:55.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 log redis-master-lh4wl redis-master --namespace=e2e-tests-kubectl-6qqnc --limit-bytes=1'
Dec  8 22:23:55.326: INFO: stderr: ""
Dec  8 22:23:55.326: INFO: stdout: " "
STEP: exposing timestamps
Dec  8 22:23:55.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 log redis-master-lh4wl redis-master --namespace=e2e-tests-kubectl-6qqnc --tail=1 --timestamps'
Dec  8 22:23:55.484: INFO: stderr: ""
Dec  8 22:23:55.484: INFO: stdout: "2018-12-08T22:23:53.961764704Z 1:M 08 Dec 22:23:53.961 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  8 22:23:57.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 log redis-master-lh4wl redis-master --namespace=e2e-tests-kubectl-6qqnc --since=1s'
Dec  8 22:23:58.119: INFO: stderr: ""
Dec  8 22:23:58.119: INFO: stdout: ""
Dec  8 22:23:58.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 log redis-master-lh4wl redis-master --namespace=e2e-tests-kubectl-6qqnc --since=24h'
Dec  8 22:23:58.315: INFO: stderr: ""
Dec  8 22:23:58.315: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 22:23:53.933 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 22:23:53.961 # Server started, Redis version 3.2.12\n1:M 08 Dec 22:23:53.961 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 22:23:53.961 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Dec  8 22:23:58.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6qqnc'
Dec  8 22:23:58.441: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 22:23:58.441: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  8 22:23:58.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-6qqnc'
Dec  8 22:23:58.840: INFO: stderr: "No resources found.\n"
Dec  8 22:23:58.840: INFO: stdout: ""
Dec  8 22:23:58.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -l name=nginx --namespace=e2e-tests-kubectl-6qqnc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 22:23:58.968: INFO: stderr: ""
Dec  8 22:23:58.968: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:23:58.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6qqnc" for this suite.
Dec  8 22:24:20.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:24:21.025: INFO: namespace: e2e-tests-kubectl-6qqnc, resource: bindings, ignored listing per whitelist
Dec  8 22:24:21.104: INFO: namespace e2e-tests-kubectl-6qqnc deletion completed in 22.131079406s

• [SLOW TEST:29.158 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:24:21.104: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-02689beb-fb38-11e8-8c59-ae6969886d1b
STEP: Creating secret with name secret-projected-all-test-volume-02689bd6-fb38-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  8 22:24:21.221: INFO: Waiting up to 5m0s for pod "projected-volume-02689ba5-fb38-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-d4zqp" to be "success or failure"
Dec  8 22:24:21.226: INFO: Pod "projected-volume-02689ba5-fb38-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.668606ms
Dec  8 22:24:23.231: INFO: Pod "projected-volume-02689ba5-fb38-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009505033s
STEP: Saw pod success
Dec  8 22:24:23.231: INFO: Pod "projected-volume-02689ba5-fb38-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:24:23.234: INFO: Trying to get logs from node compliancetest pod projected-volume-02689ba5-fb38-11e8-8c59-ae6969886d1b container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  8 22:24:23.260: INFO: Waiting for pod projected-volume-02689ba5-fb38-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:24:23.267: INFO: Pod projected-volume-02689ba5-fb38-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:24:23.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d4zqp" for this suite.
Dec  8 22:24:29.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:24:29.346: INFO: namespace: e2e-tests-projected-d4zqp, resource: bindings, ignored listing per whitelist
Dec  8 22:24:29.399: INFO: namespace e2e-tests-projected-d4zqp deletion completed in 6.12746166s

• [SLOW TEST:8.295 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:24:29.399: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  8 22:24:29.503: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-phfsw" to be "success or failure"
Dec  8 22:24:29.523: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 19.965885ms
Dec  8 22:24:31.527: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023659596s
Dec  8 22:24:33.532: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02896766s
STEP: Saw pod success
Dec  8 22:24:33.532: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  8 22:24:33.536: INFO: Trying to get logs from node compliancetest pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  8 22:24:33.566: INFO: Waiting for pod pod-host-path-test to disappear
Dec  8 22:24:33.571: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:24:33.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-phfsw" for this suite.
Dec  8 22:24:39.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:24:39.677: INFO: namespace: e2e-tests-hostpath-phfsw, resource: bindings, ignored listing per whitelist
Dec  8 22:24:39.731: INFO: namespace e2e-tests-hostpath-phfsw deletion completed in 6.156088826s

• [SLOW TEST:10.332 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:24:39.731: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  8 22:24:39.832: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-a,UID:0d83cbb8-fb38-11e8-a35e-42010a800004,ResourceVersion:22927,Generation:0,CreationTimestamp:2018-12-08 22:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 22:24:39.832: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-a,UID:0d83cbb8-fb38-11e8-a35e-42010a800004,ResourceVersion:22927,Generation:0,CreationTimestamp:2018-12-08 22:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  8 22:24:49.841: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-a,UID:0d83cbb8-fb38-11e8-a35e-42010a800004,ResourceVersion:22931,Generation:0,CreationTimestamp:2018-12-08 22:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  8 22:24:49.842: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-a,UID:0d83cbb8-fb38-11e8-a35e-42010a800004,ResourceVersion:22931,Generation:0,CreationTimestamp:2018-12-08 22:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  8 22:24:59.851: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-a,UID:0d83cbb8-fb38-11e8-a35e-42010a800004,ResourceVersion:22935,Generation:0,CreationTimestamp:2018-12-08 22:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 22:24:59.851: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-a,UID:0d83cbb8-fb38-11e8-a35e-42010a800004,ResourceVersion:22935,Generation:0,CreationTimestamp:2018-12-08 22:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  8 22:25:09.859: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-a,UID:0d83cbb8-fb38-11e8-a35e-42010a800004,ResourceVersion:22940,Generation:0,CreationTimestamp:2018-12-08 22:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 22:25:09.859: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-a,UID:0d83cbb8-fb38-11e8-a35e-42010a800004,ResourceVersion:22940,Generation:0,CreationTimestamp:2018-12-08 22:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  8 22:25:19.891: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-b,UID:25606137-fb38-11e8-a35e-42010a800004,ResourceVersion:22944,Generation:0,CreationTimestamp:2018-12-08 22:25:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 22:25:19.891: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-b,UID:25606137-fb38-11e8-a35e-42010a800004,ResourceVersion:22944,Generation:0,CreationTimestamp:2018-12-08 22:25:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  8 22:25:29.900: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-b,UID:25606137-fb38-11e8-a35e-42010a800004,ResourceVersion:22948,Generation:0,CreationTimestamp:2018-12-08 22:25:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 22:25:29.900: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-464p4,SelfLink:/api/v1/namespaces/e2e-tests-watch-464p4/configmaps/e2e-watch-test-configmap-b,UID:25606137-fb38-11e8-a35e-42010a800004,ResourceVersion:22948,Generation:0,CreationTimestamp:2018-12-08 22:25:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:25:39.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-464p4" for this suite.
Dec  8 22:25:45.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:25:45.957: INFO: namespace: e2e-tests-watch-464p4, resource: bindings, ignored listing per whitelist
Dec  8 22:25:46.029: INFO: namespace e2e-tests-watch-464p4 deletion completed in 6.123640497s

• [SLOW TEST:66.297 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:25:46.029: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  8 22:25:46.094: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 22:25:46.101: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 22:25:46.104: INFO: 
Logging pods the kubelet thinks is on node compliancetest before test
Dec  8 22:25:46.111: INFO: nirmata-kube-controller-7f4cfbcc47-tbw9p from nirmata started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Dec  8 22:25:46.111: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 22:02:12 +0000 UTC (1 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  8 22:25:46.111: INFO: metrics-server-7cc7d8ccb8-gxvfp from kube-system started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container metrics-server ready: true, restart count 0
Dec  8 22:25:46.111: INFO: ingress-default-backend-59f45f4b79-2vjfz from ingress-haproxy started at 2018-12-08 21:52:20 +0000 UTC (1 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container ingress-default-backend ready: true, restart count 0
Dec  8 22:25:46.111: INFO: sonobuoy-systemd-logs-daemon-set-eca918e579904fef-p49sk from heptio-sonobuoy started at 2018-12-08 22:02:16 +0000 UTC (2 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  8 22:25:46.111: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 22:25:46.111: INFO: kube-dns-5d95dcfb8d-28f4w from kube-system started at 2018-12-08 21:52:08 +0000 UTC (3 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  8 22:25:46.111: INFO: 	Container kubedns ready: true, restart count 0
Dec  8 22:25:46.111: INFO: 	Container sidecar ready: true, restart count 0
Dec  8 22:25:46.111: INFO: nirmata-cni-installer-dgkr7 from nirmata started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 22:25:46.111: INFO: haproxy-ingress-54bf6fdf5d-qrznd from ingress-haproxy started at 2018-12-08 21:52:22 +0000 UTC (1 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container haproxy-ingress ready: true, restart count 0
Dec  8 22:25:46.111: INFO: sonobuoy-e2e-job-02e788f5b1a14e8d from heptio-sonobuoy started at 2018-12-08 22:02:16 +0000 UTC (2 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container e2e ready: true, restart count 0
Dec  8 22:25:46.111: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 22:25:46.111: INFO: kube-flannel-ds-sh87s from kube-system started at 2018-12-08 21:51:56 +0000 UTC (1 container statuses recorded)
Dec  8 22:25:46.111: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node compliancetest
Dec  8 22:25:46.152: INFO: Pod sonobuoy requesting resource cpu=0m on Node compliancetest
Dec  8 22:25:46.152: INFO: Pod sonobuoy-e2e-job-02e788f5b1a14e8d requesting resource cpu=0m on Node compliancetest
Dec  8 22:25:46.152: INFO: Pod sonobuoy-systemd-logs-daemon-set-eca918e579904fef-p49sk requesting resource cpu=0m on Node compliancetest
Dec  8 22:25:46.152: INFO: Pod haproxy-ingress-54bf6fdf5d-qrznd requesting resource cpu=0m on Node compliancetest
Dec  8 22:25:46.153: INFO: Pod ingress-default-backend-59f45f4b79-2vjfz requesting resource cpu=0m on Node compliancetest
Dec  8 22:25:46.153: INFO: Pod kube-dns-5d95dcfb8d-28f4w requesting resource cpu=260m on Node compliancetest
Dec  8 22:25:46.153: INFO: Pod kube-flannel-ds-sh87s requesting resource cpu=0m on Node compliancetest
Dec  8 22:25:46.153: INFO: Pod metrics-server-7cc7d8ccb8-gxvfp requesting resource cpu=0m on Node compliancetest
Dec  8 22:25:46.153: INFO: Pod nirmata-cni-installer-dgkr7 requesting resource cpu=0m on Node compliancetest
Dec  8 22:25:46.153: INFO: Pod nirmata-kube-controller-7f4cfbcc47-tbw9p requesting resource cpu=0m on Node compliancetest
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-350c2e21-fb38-11e8-8c59-ae6969886d1b.156e7be51c249eef], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-g2pbh/filler-pod-350c2e21-fb38-11e8-8c59-ae6969886d1b to compliancetest]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-350c2e21-fb38-11e8-8c59-ae6969886d1b.156e7be5450d0cd4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-350c2e21-fb38-11e8-8c59-ae6969886d1b.156e7be54a53d842], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-350c2e21-fb38-11e8-8c59-ae6969886d1b.156e7be554f70184], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156e7be593920fbe], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node compliancetest
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:25:49.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-g2pbh" for this suite.
Dec  8 22:25:55.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:25:55.919: INFO: namespace: e2e-tests-sched-pred-g2pbh, resource: bindings, ignored listing per whitelist
Dec  8 22:25:56.044: INFO: namespace e2e-tests-sched-pred-g2pbh deletion completed in 6.414876396s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:10.015 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:25:56.044: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  8 22:25:56.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:25:56.407: INFO: stderr: ""
Dec  8 22:25:56.407: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 22:25:56.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:25:56.749: INFO: stderr: ""
Dec  8 22:25:56.749: INFO: stdout: "update-demo-nautilus-bqnmg update-demo-nautilus-gcw44 "
Dec  8 22:25:56.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:25:56.936: INFO: stderr: ""
Dec  8 22:25:56.936: INFO: stdout: ""
Dec  8 22:25:56.936: INFO: update-demo-nautilus-bqnmg is created but not running
Dec  8 22:26:01.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:02.058: INFO: stderr: ""
Dec  8 22:26:02.058: INFO: stdout: "update-demo-nautilus-bqnmg update-demo-nautilus-gcw44 "
Dec  8 22:26:02.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:02.183: INFO: stderr: ""
Dec  8 22:26:02.183: INFO: stdout: "true"
Dec  8 22:26:02.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:02.328: INFO: stderr: ""
Dec  8 22:26:02.328: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 22:26:02.328: INFO: validating pod update-demo-nautilus-bqnmg
Dec  8 22:26:02.349: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 22:26:02.349: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 22:26:02.349: INFO: update-demo-nautilus-bqnmg is verified up and running
Dec  8 22:26:02.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-gcw44 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:02.486: INFO: stderr: ""
Dec  8 22:26:02.486: INFO: stdout: "true"
Dec  8 22:26:02.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-gcw44 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:02.616: INFO: stderr: ""
Dec  8 22:26:02.616: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 22:26:02.616: INFO: validating pod update-demo-nautilus-gcw44
Dec  8 22:26:02.622: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 22:26:02.623: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 22:26:02.623: INFO: update-demo-nautilus-gcw44 is verified up and running
STEP: scaling down the replication controller
Dec  8 22:26:02.625: INFO: scanned /root for discovery docs: <nil>
Dec  8 22:26:02.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:03.867: INFO: stderr: ""
Dec  8 22:26:03.867: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 22:26:03.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:03.999: INFO: stderr: ""
Dec  8 22:26:03.999: INFO: stdout: "update-demo-nautilus-bqnmg update-demo-nautilus-gcw44 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  8 22:26:08.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:09.126: INFO: stderr: ""
Dec  8 22:26:09.126: INFO: stdout: "update-demo-nautilus-bqnmg update-demo-nautilus-gcw44 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  8 22:26:14.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:14.249: INFO: stderr: ""
Dec  8 22:26:14.249: INFO: stdout: "update-demo-nautilus-bqnmg update-demo-nautilus-gcw44 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  8 22:26:19.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:19.371: INFO: stderr: ""
Dec  8 22:26:19.371: INFO: stdout: "update-demo-nautilus-bqnmg "
Dec  8 22:26:19.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:19.502: INFO: stderr: ""
Dec  8 22:26:19.502: INFO: stdout: "true"
Dec  8 22:26:19.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:19.630: INFO: stderr: ""
Dec  8 22:26:19.630: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 22:26:19.630: INFO: validating pod update-demo-nautilus-bqnmg
Dec  8 22:26:19.635: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 22:26:19.635: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 22:26:19.635: INFO: update-demo-nautilus-bqnmg is verified up and running
STEP: scaling up the replication controller
Dec  8 22:26:19.637: INFO: scanned /root for discovery docs: <nil>
Dec  8 22:26:19.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:20.808: INFO: stderr: ""
Dec  8 22:26:20.808: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 22:26:20.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:20.986: INFO: stderr: ""
Dec  8 22:26:20.986: INFO: stdout: "update-demo-nautilus-bqnmg update-demo-nautilus-s6vcf "
Dec  8 22:26:20.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:21.109: INFO: stderr: ""
Dec  8 22:26:21.109: INFO: stdout: "true"
Dec  8 22:26:21.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:21.238: INFO: stderr: ""
Dec  8 22:26:21.238: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 22:26:21.238: INFO: validating pod update-demo-nautilus-bqnmg
Dec  8 22:26:21.242: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 22:26:21.242: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 22:26:21.242: INFO: update-demo-nautilus-bqnmg is verified up and running
Dec  8 22:26:21.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-s6vcf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:21.371: INFO: stderr: ""
Dec  8 22:26:21.371: INFO: stdout: ""
Dec  8 22:26:21.371: INFO: update-demo-nautilus-s6vcf is created but not running
Dec  8 22:26:26.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:26.505: INFO: stderr: ""
Dec  8 22:26:26.505: INFO: stdout: "update-demo-nautilus-bqnmg update-demo-nautilus-s6vcf "
Dec  8 22:26:26.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:26.632: INFO: stderr: ""
Dec  8 22:26:26.632: INFO: stdout: "true"
Dec  8 22:26:26.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-bqnmg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:26.750: INFO: stderr: ""
Dec  8 22:26:26.750: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 22:26:26.750: INFO: validating pod update-demo-nautilus-bqnmg
Dec  8 22:26:26.754: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 22:26:26.754: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 22:26:26.754: INFO: update-demo-nautilus-bqnmg is verified up and running
Dec  8 22:26:26.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-s6vcf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:26.920: INFO: stderr: ""
Dec  8 22:26:26.920: INFO: stdout: "true"
Dec  8 22:26:26.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-s6vcf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:27.070: INFO: stderr: ""
Dec  8 22:26:27.070: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 22:26:27.070: INFO: validating pod update-demo-nautilus-s6vcf
Dec  8 22:26:27.101: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 22:26:27.101: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 22:26:27.101: INFO: update-demo-nautilus-s6vcf is verified up and running
STEP: using delete to clean up resources
Dec  8 22:26:27.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:27.253: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 22:26:27.253: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  8 22:26:27.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-p2z4b'
Dec  8 22:26:27.639: INFO: stderr: "No resources found.\n"
Dec  8 22:26:27.639: INFO: stdout: ""
Dec  8 22:26:27.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -l name=update-demo --namespace=e2e-tests-kubectl-p2z4b -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 22:26:27.999: INFO: stderr: ""
Dec  8 22:26:27.999: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:26:27.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p2z4b" for this suite.
Dec  8 22:26:50.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:26:50.102: INFO: namespace: e2e-tests-kubectl-p2z4b, resource: bindings, ignored listing per whitelist
Dec  8 22:26:50.174: INFO: namespace e2e-tests-kubectl-p2z4b deletion completed in 22.169169932s

• [SLOW TEST:54.130 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:26:50.175: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-5b41a622-fb38-11e8-8c59-ae6969886d1b
STEP: Creating configMap with name cm-test-opt-upd-5b41a665-fb38-11e8-8c59-ae6969886d1b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5b41a622-fb38-11e8-8c59-ae6969886d1b
STEP: Updating configmap cm-test-opt-upd-5b41a665-fb38-11e8-8c59-ae6969886d1b
STEP: Creating configMap with name cm-test-opt-create-5b41a67d-fb38-11e8-8c59-ae6969886d1b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:28:22.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-llw8c" for this suite.
Dec  8 22:28:44.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:28:44.965: INFO: namespace: e2e-tests-projected-llw8c, resource: bindings, ignored listing per whitelist
Dec  8 22:28:44.989: INFO: namespace e2e-tests-projected-llw8c deletion completed in 22.135969047s

• [SLOW TEST:114.814 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:28:44.989: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 22:28:45.105: INFO: Number of nodes with available pods: 0
Dec  8 22:28:45.105: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:46.113: INFO: Number of nodes with available pods: 0
Dec  8 22:28:46.113: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:47.112: INFO: Number of nodes with available pods: 1
Dec  8 22:28:47.112: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  8 22:28:47.137: INFO: Number of nodes with available pods: 0
Dec  8 22:28:47.137: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:48.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:48.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:49.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:49.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:50.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:50.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:51.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:51.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:52.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:52.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:53.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:53.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:54.146: INFO: Number of nodes with available pods: 0
Dec  8 22:28:54.146: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:55.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:55.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:56.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:56.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:57.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:57.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:58.146: INFO: Number of nodes with available pods: 0
Dec  8 22:28:58.147: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:28:59.145: INFO: Number of nodes with available pods: 0
Dec  8 22:28:59.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:00.146: INFO: Number of nodes with available pods: 0
Dec  8 22:29:00.146: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:01.147: INFO: Number of nodes with available pods: 0
Dec  8 22:29:01.147: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:02.145: INFO: Number of nodes with available pods: 0
Dec  8 22:29:02.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:03.145: INFO: Number of nodes with available pods: 0
Dec  8 22:29:03.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:04.147: INFO: Number of nodes with available pods: 0
Dec  8 22:29:04.147: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:05.146: INFO: Number of nodes with available pods: 0
Dec  8 22:29:05.146: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:06.144: INFO: Number of nodes with available pods: 0
Dec  8 22:29:06.144: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:07.144: INFO: Number of nodes with available pods: 0
Dec  8 22:29:07.144: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:08.145: INFO: Number of nodes with available pods: 0
Dec  8 22:29:08.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:09.144: INFO: Number of nodes with available pods: 0
Dec  8 22:29:09.144: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:10.145: INFO: Number of nodes with available pods: 0
Dec  8 22:29:10.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:11.145: INFO: Number of nodes with available pods: 0
Dec  8 22:29:11.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:12.145: INFO: Number of nodes with available pods: 0
Dec  8 22:29:12.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:13.149: INFO: Number of nodes with available pods: 0
Dec  8 22:29:13.149: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:14.144: INFO: Number of nodes with available pods: 0
Dec  8 22:29:14.144: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:15.145: INFO: Number of nodes with available pods: 0
Dec  8 22:29:15.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:16.144: INFO: Number of nodes with available pods: 0
Dec  8 22:29:16.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:17.145: INFO: Number of nodes with available pods: 0
Dec  8 22:29:17.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:18.144: INFO: Number of nodes with available pods: 0
Dec  8 22:29:18.144: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:19.144: INFO: Number of nodes with available pods: 0
Dec  8 22:29:19.145: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:20.144: INFO: Number of nodes with available pods: 0
Dec  8 22:29:20.144: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:21.148: INFO: Number of nodes with available pods: 0
Dec  8 22:29:21.148: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:29:22.144: INFO: Number of nodes with available pods: 1
Dec  8 22:29:22.144: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-tjr9v, will wait for the garbage collector to delete the pods
Dec  8 22:29:22.211: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.500439ms
Dec  8 22:29:22.311: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.220616ms
Dec  8 22:29:54.916: INFO: Number of nodes with available pods: 0
Dec  8 22:29:54.917: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 22:29:54.920: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-tjr9v/daemonsets","resourceVersion":"23252"},"items":null}

Dec  8 22:29:54.925: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-tjr9v/pods","resourceVersion":"23252"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:29:54.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-tjr9v" for this suite.
Dec  8 22:30:00.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:30:01.015: INFO: namespace: e2e-tests-daemonsets-tjr9v, resource: bindings, ignored listing per whitelist
Dec  8 22:30:01.071: INFO: namespace e2e-tests-daemonsets-tjr9v deletion completed in 6.132749884s

• [SLOW TEST:76.082 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:30:01.071: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-cd0869a7-fb38-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:30:01.156: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cd091a6d-fb38-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-4bx87" to be "success or failure"
Dec  8 22:30:01.161: INFO: Pod "pod-projected-secrets-cd091a6d-fb38-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.053453ms
Dec  8 22:30:03.188: INFO: Pod "pod-projected-secrets-cd091a6d-fb38-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031467147s
STEP: Saw pod success
Dec  8 22:30:03.188: INFO: Pod "pod-projected-secrets-cd091a6d-fb38-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:30:03.201: INFO: Trying to get logs from node compliancetest pod pod-projected-secrets-cd091a6d-fb38-11e8-8c59-ae6969886d1b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:30:03.266: INFO: Waiting for pod pod-projected-secrets-cd091a6d-fb38-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:30:03.290: INFO: Pod pod-projected-secrets-cd091a6d-fb38-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:30:03.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4bx87" for this suite.
Dec  8 22:30:09.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:30:09.433: INFO: namespace: e2e-tests-projected-4bx87, resource: bindings, ignored listing per whitelist
Dec  8 22:30:09.446: INFO: namespace e2e-tests-projected-4bx87 deletion completed in 6.146166501s

• [SLOW TEST:8.375 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:30:09.446: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-chjtb/secret-test-d2079d5c-fb38-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:30:09.540: INFO: Waiting up to 5m0s for pod "pod-configmaps-d20854ec-fb38-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-chjtb" to be "success or failure"
Dec  8 22:30:09.545: INFO: Pod "pod-configmaps-d20854ec-fb38-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.683609ms
Dec  8 22:30:11.549: INFO: Pod "pod-configmaps-d20854ec-fb38-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00880819s
STEP: Saw pod success
Dec  8 22:30:11.549: INFO: Pod "pod-configmaps-d20854ec-fb38-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:30:11.553: INFO: Trying to get logs from node compliancetest pod pod-configmaps-d20854ec-fb38-11e8-8c59-ae6969886d1b container env-test: <nil>
STEP: delete the pod
Dec  8 22:30:11.585: INFO: Waiting for pod pod-configmaps-d20854ec-fb38-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:30:11.590: INFO: Pod pod-configmaps-d20854ec-fb38-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:30:11.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-chjtb" for this suite.
Dec  8 22:30:17.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:30:17.678: INFO: namespace: e2e-tests-secrets-chjtb, resource: bindings, ignored listing per whitelist
Dec  8 22:30:17.800: INFO: namespace e2e-tests-secrets-chjtb deletion completed in 6.20605857s

• [SLOW TEST:8.354 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:30:17.801: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-q62zm
Dec  8 22:30:19.907: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-q62zm
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 22:30:19.911: INFO: Initial restart count of pod liveness-exec is 0
Dec  8 22:31:06.328: INFO: Restart count of pod e2e-tests-container-probe-q62zm/liveness-exec is now 1 (46.416899573s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:31:06.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-q62zm" for this suite.
Dec  8 22:31:12.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:31:12.441: INFO: namespace: e2e-tests-container-probe-q62zm, resource: bindings, ignored listing per whitelist
Dec  8 22:31:12.496: INFO: namespace e2e-tests-container-probe-q62zm deletion completed in 6.14343625s

• [SLOW TEST:54.695 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:31:12.496: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-cpztk
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-cpztk
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-cpztk
Dec  8 22:31:12.584: INFO: Found 0 stateful pods, waiting for 1
Dec  8 22:31:22.590: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  8 22:31:22.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-cpztk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:31:22.885: INFO: stderr: ""
Dec  8 22:31:22.885: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:31:22.885: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:31:22.889: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  8 22:31:32.894: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 22:31:32.894: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 22:31:32.917: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  8 22:31:32.917: INFO: ss-0  compliancetest  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:12 +0000 UTC  }]
Dec  8 22:31:32.918: INFO: 
Dec  8 22:31:32.918: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  8 22:31:33.966: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990955369s
Dec  8 22:31:34.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.942207083s
Dec  8 22:31:35.978: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.936229526s
Dec  8 22:31:36.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.928855712s
Dec  8 22:31:37.990: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.923199115s
Dec  8 22:31:38.995: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.918208161s
Dec  8 22:31:40.000: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.913181268s
Dec  8 22:31:41.017: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.908873454s
Dec  8 22:31:42.028: INFO: Verifying statefulset ss doesn't scale past 3 for another 885.346775ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-cpztk
Dec  8 22:31:43.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-cpztk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:31:43.235: INFO: stderr: ""
Dec  8 22:31:43.235: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:31:43.235: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:31:43.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-cpztk ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:31:43.429: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  8 22:31:43.429: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:31:43.429: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:31:43.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-cpztk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:31:43.631: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  8 22:31:43.631: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:31:43.631: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:31:43.636: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec  8 22:31:53.641: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:31:53.641: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:31:53.641: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  8 22:31:53.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-cpztk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:31:53.861: INFO: stderr: ""
Dec  8 22:31:53.861: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:31:53.861: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:31:53.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-cpztk ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:31:54.171: INFO: stderr: ""
Dec  8 22:31:54.171: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:31:54.171: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:31:54.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-cpztk ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:31:54.377: INFO: stderr: ""
Dec  8 22:31:54.377: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:31:54.377: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:31:54.377: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 22:31:54.380: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  8 22:32:04.388: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 22:32:04.388: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 22:32:04.388: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 22:32:04.402: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  8 22:32:04.402: INFO: ss-0  compliancetest  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:12 +0000 UTC  }]
Dec  8 22:32:04.402: INFO: ss-1  compliancetest  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  }]
Dec  8 22:32:04.402: INFO: ss-2  compliancetest  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  }]
Dec  8 22:32:04.402: INFO: 
Dec  8 22:32:04.402: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 22:32:05.408: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  8 22:32:05.408: INFO: ss-0  compliancetest  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:12 +0000 UTC  }]
Dec  8 22:32:05.408: INFO: ss-1  compliancetest  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  }]
Dec  8 22:32:05.408: INFO: ss-2  compliancetest  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  }]
Dec  8 22:32:05.409: INFO: 
Dec  8 22:32:05.409: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 22:32:06.415: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  8 22:32:06.415: INFO: ss-0  compliancetest  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:12 +0000 UTC  }]
Dec  8 22:32:06.415: INFO: ss-1  compliancetest  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  }]
Dec  8 22:32:06.415: INFO: ss-2  compliancetest  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:31:32 +0000 UTC  }]
Dec  8 22:32:06.415: INFO: 
Dec  8 22:32:06.415: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 22:32:07.419: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.982541814s
Dec  8 22:32:08.424: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.978259564s
Dec  8 22:32:09.428: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.97391463s
Dec  8 22:32:10.432: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.969945171s
Dec  8 22:32:11.436: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.965202579s
Dec  8 22:32:12.440: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.961056888s
Dec  8 22:32:13.445: INFO: Verifying statefulset ss doesn't scale past 0 for another 957.336258ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-cpztk
Dec  8 22:32:14.449: INFO: Scaling statefulset ss to 0
Dec  8 22:32:14.459: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 22:32:14.462: INFO: Deleting all statefulset in ns e2e-tests-statefulset-cpztk
Dec  8 22:32:14.465: INFO: Scaling statefulset ss to 0
Dec  8 22:32:14.475: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 22:32:14.477: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:32:14.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-cpztk" for this suite.
Dec  8 22:32:20.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:32:20.554: INFO: namespace: e2e-tests-statefulset-cpztk, resource: bindings, ignored listing per whitelist
Dec  8 22:32:20.645: INFO: namespace e2e-tests-statefulset-cpztk deletion completed in 6.133940137s

• [SLOW TEST:68.149 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:32:20.645: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  8 22:32:20.722: INFO: Waiting up to 5m0s for pod "var-expansion-20392bb3-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-var-expansion-klgkv" to be "success or failure"
Dec  8 22:32:20.727: INFO: Pod "var-expansion-20392bb3-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.073203ms
Dec  8 22:32:22.734: INFO: Pod "var-expansion-20392bb3-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011729773s
STEP: Saw pod success
Dec  8 22:32:22.734: INFO: Pod "var-expansion-20392bb3-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:32:22.738: INFO: Trying to get logs from node compliancetest pod var-expansion-20392bb3-fb39-11e8-8c59-ae6969886d1b container dapi-container: <nil>
STEP: delete the pod
Dec  8 22:32:22.766: INFO: Waiting for pod var-expansion-20392bb3-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:32:22.770: INFO: Pod var-expansion-20392bb3-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:32:22.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-klgkv" for this suite.
Dec  8 22:32:28.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:32:28.831: INFO: namespace: e2e-tests-var-expansion-klgkv, resource: bindings, ignored listing per whitelist
Dec  8 22:32:28.919: INFO: namespace e2e-tests-var-expansion-klgkv deletion completed in 6.14439969s

• [SLOW TEST:8.273 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:32:28.920: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 22:32:28.991: INFO: Waiting up to 5m0s for pod "downward-api-2526f622-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-l4lrl" to be "success or failure"
Dec  8 22:32:28.996: INFO: Pod "downward-api-2526f622-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.133752ms
Dec  8 22:32:31.000: INFO: Pod "downward-api-2526f622-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00893438s
STEP: Saw pod success
Dec  8 22:32:31.000: INFO: Pod "downward-api-2526f622-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:32:31.003: INFO: Trying to get logs from node compliancetest pod downward-api-2526f622-fb39-11e8-8c59-ae6969886d1b container dapi-container: <nil>
STEP: delete the pod
Dec  8 22:32:31.039: INFO: Waiting for pod downward-api-2526f622-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:32:31.043: INFO: Pod downward-api-2526f622-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:32:31.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l4lrl" for this suite.
Dec  8 22:32:37.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:32:37.117: INFO: namespace: e2e-tests-downward-api-l4lrl, resource: bindings, ignored listing per whitelist
Dec  8 22:32:37.179: INFO: namespace e2e-tests-downward-api-l4lrl deletion completed in 6.132512905s

• [SLOW TEST:8.260 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:32:37.180: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:32:37.300: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a1a90a8-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-4shp9" to be "success or failure"
Dec  8 22:32:37.306: INFO: Pod "downwardapi-volume-2a1a90a8-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.212725ms
Dec  8 22:32:39.309: INFO: Pod "downwardapi-volume-2a1a90a8-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009054494s
Dec  8 22:32:41.314: INFO: Pod "downwardapi-volume-2a1a90a8-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013539873s
STEP: Saw pod success
Dec  8 22:32:41.314: INFO: Pod "downwardapi-volume-2a1a90a8-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:32:41.317: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-2a1a90a8-fb39-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:32:41.350: INFO: Waiting for pod downwardapi-volume-2a1a90a8-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:32:41.361: INFO: Pod downwardapi-volume-2a1a90a8-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:32:41.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4shp9" for this suite.
Dec  8 22:32:47.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:32:47.463: INFO: namespace: e2e-tests-projected-4shp9, resource: bindings, ignored listing per whitelist
Dec  8 22:32:47.488: INFO: namespace e2e-tests-projected-4shp9 deletion completed in 6.121607717s

• [SLOW TEST:10.309 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:32:47.489: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  8 22:32:50.109: INFO: Successfully updated pod "pod-update-activedeadlineseconds-303b769c-fb39-11e8-8c59-ae6969886d1b"
Dec  8 22:32:50.109: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-303b769c-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-pods-zzww2" to be "terminated due to deadline exceeded"
Dec  8 22:32:50.117: INFO: Pod "pod-update-activedeadlineseconds-303b769c-fb39-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 7.345246ms
Dec  8 22:32:52.121: INFO: Pod "pod-update-activedeadlineseconds-303b769c-fb39-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.01109692s
Dec  8 22:32:54.125: INFO: Pod "pod-update-activedeadlineseconds-303b769c-fb39-11e8-8c59-ae6969886d1b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015786515s
Dec  8 22:32:54.125: INFO: Pod "pod-update-activedeadlineseconds-303b769c-fb39-11e8-8c59-ae6969886d1b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:32:54.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zzww2" for this suite.
Dec  8 22:33:00.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:33:00.241: INFO: namespace: e2e-tests-pods-zzww2, resource: bindings, ignored listing per whitelist
Dec  8 22:33:00.258: INFO: namespace e2e-tests-pods-zzww2 deletion completed in 6.12806412s

• [SLOW TEST:12.769 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:33:00.259: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:33:00.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37d621e9-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-qs7b2" to be "success or failure"
Dec  8 22:33:00.343: INFO: Pod "downwardapi-volume-37d621e9-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.564655ms
Dec  8 22:33:02.347: INFO: Pod "downwardapi-volume-37d621e9-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008987566s
Dec  8 22:33:04.351: INFO: Pod "downwardapi-volume-37d621e9-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013267647s
STEP: Saw pod success
Dec  8 22:33:04.351: INFO: Pod "downwardapi-volume-37d621e9-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:33:04.355: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-37d621e9-fb39-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:33:04.392: INFO: Waiting for pod downwardapi-volume-37d621e9-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:33:04.397: INFO: Pod downwardapi-volume-37d621e9-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:33:04.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qs7b2" for this suite.
Dec  8 22:33:10.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:33:10.538: INFO: namespace: e2e-tests-projected-qs7b2, resource: bindings, ignored listing per whitelist
Dec  8 22:33:10.561: INFO: namespace e2e-tests-projected-qs7b2 deletion completed in 6.154343223s

• [SLOW TEST:10.302 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:33:10.562: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3df95280-fb39-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:33:10.641: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3df9eea0-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-dvkql" to be "success or failure"
Dec  8 22:33:10.646: INFO: Pod "pod-projected-configmaps-3df9eea0-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.116612ms
Dec  8 22:33:12.664: INFO: Pod "pod-projected-configmaps-3df9eea0-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023429662s
STEP: Saw pod success
Dec  8 22:33:12.665: INFO: Pod "pod-projected-configmaps-3df9eea0-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:33:12.669: INFO: Trying to get logs from node compliancetest pod pod-projected-configmaps-3df9eea0-fb39-11e8-8c59-ae6969886d1b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:33:12.763: INFO: Waiting for pod pod-projected-configmaps-3df9eea0-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:33:12.770: INFO: Pod pod-projected-configmaps-3df9eea0-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:33:12.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dvkql" for this suite.
Dec  8 22:33:18.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:33:18.923: INFO: namespace: e2e-tests-projected-dvkql, resource: bindings, ignored listing per whitelist
Dec  8 22:33:18.944: INFO: namespace e2e-tests-projected-dvkql deletion completed in 6.167636335s

• [SLOW TEST:8.383 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:33:18.945: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:33:19.014: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42f7e871-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-cl5g6" to be "success or failure"
Dec  8 22:33:19.019: INFO: Pod "downwardapi-volume-42f7e871-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.777496ms
Dec  8 22:33:21.025: INFO: Pod "downwardapi-volume-42f7e871-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010651108s
STEP: Saw pod success
Dec  8 22:33:21.025: INFO: Pod "downwardapi-volume-42f7e871-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:33:21.028: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-42f7e871-fb39-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:33:21.056: INFO: Waiting for pod downwardapi-volume-42f7e871-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:33:21.061: INFO: Pod downwardapi-volume-42f7e871-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:33:21.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cl5g6" for this suite.
Dec  8 22:33:27.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:33:27.126: INFO: namespace: e2e-tests-projected-cl5g6, resource: bindings, ignored listing per whitelist
Dec  8 22:33:27.199: INFO: namespace e2e-tests-projected-cl5g6 deletion completed in 6.134407588s

• [SLOW TEST:8.254 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:33:27.199: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:33:27.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47e4ba57-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-8pgt5" to be "success or failure"
Dec  8 22:33:27.285: INFO: Pod "downwardapi-volume-47e4ba57-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.838283ms
Dec  8 22:33:29.289: INFO: Pod "downwardapi-volume-47e4ba57-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010180684s
STEP: Saw pod success
Dec  8 22:33:29.289: INFO: Pod "downwardapi-volume-47e4ba57-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:33:29.292: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-47e4ba57-fb39-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:33:29.325: INFO: Waiting for pod downwardapi-volume-47e4ba57-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:33:29.330: INFO: Pod downwardapi-volume-47e4ba57-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:33:29.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8pgt5" for this suite.
Dec  8 22:33:35.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:33:35.376: INFO: namespace: e2e-tests-projected-8pgt5, resource: bindings, ignored listing per whitelist
Dec  8 22:33:35.456: INFO: namespace e2e-tests-projected-8pgt5 deletion completed in 6.120972607s

• [SLOW TEST:8.257 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:33:35.457: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:33:35.581: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4cd2abec-fb39-11e8-a35e-42010a800004", Controller:(*bool)(0xc420af70e6), BlockOwnerDeletion:(*bool)(0xc420af70e7)}}
Dec  8 22:33:35.607: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4cd08bfd-fb39-11e8-a35e-42010a800004", Controller:(*bool)(0xc420af763e), BlockOwnerDeletion:(*bool)(0xc420af763f)}}
Dec  8 22:33:35.633: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4cd1704a-fb39-11e8-a35e-42010a800004", Controller:(*bool)(0xc420af7bbe), BlockOwnerDeletion:(*bool)(0xc420af7bbf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:33:40.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-75hv5" for this suite.
Dec  8 22:33:46.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:33:46.745: INFO: namespace: e2e-tests-gc-75hv5, resource: bindings, ignored listing per whitelist
Dec  8 22:33:46.787: INFO: namespace e2e-tests-gc-75hv5 deletion completed in 6.122978296s

• [SLOW TEST:11.331 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:33:46.787: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:33:46.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 version'
Dec  8 22:33:47.004: INFO: stderr: ""
Dec  8 22:33:47.004: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:33:47.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rz2mb" for this suite.
Dec  8 22:33:53.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:33:53.046: INFO: namespace: e2e-tests-kubectl-rz2mb, resource: bindings, ignored listing per whitelist
Dec  8 22:33:53.149: INFO: namespace e2e-tests-kubectl-rz2mb deletion completed in 6.141115416s

• [SLOW TEST:6.362 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:33:53.149: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  8 22:33:53.219: INFO: Waiting up to 5m0s for pod "var-expansion-575b07ad-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-var-expansion-r9xvc" to be "success or failure"
Dec  8 22:33:53.224: INFO: Pod "var-expansion-575b07ad-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.875638ms
Dec  8 22:33:55.230: INFO: Pod "var-expansion-575b07ad-fb39-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.011629497s
Dec  8 22:33:57.234: INFO: Pod "var-expansion-575b07ad-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015539322s
STEP: Saw pod success
Dec  8 22:33:57.234: INFO: Pod "var-expansion-575b07ad-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:33:57.238: INFO: Trying to get logs from node compliancetest pod var-expansion-575b07ad-fb39-11e8-8c59-ae6969886d1b container dapi-container: <nil>
STEP: delete the pod
Dec  8 22:33:57.273: INFO: Waiting for pod var-expansion-575b07ad-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:33:57.283: INFO: Pod var-expansion-575b07ad-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:33:57.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-r9xvc" for this suite.
Dec  8 22:34:03.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:34:03.398: INFO: namespace: e2e-tests-var-expansion-r9xvc, resource: bindings, ignored listing per whitelist
Dec  8 22:34:03.447: INFO: namespace e2e-tests-var-expansion-r9xvc deletion completed in 6.158855941s

• [SLOW TEST:10.298 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:34:03.447: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hk8cx
Dec  8 22:34:05.551: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hk8cx
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 22:34:05.554: INFO: Initial restart count of pod liveness-http is 0
Dec  8 22:34:17.589: INFO: Restart count of pod e2e-tests-container-probe-hk8cx/liveness-http is now 1 (12.034379607s elapsed)
Dec  8 22:34:37.642: INFO: Restart count of pod e2e-tests-container-probe-hk8cx/liveness-http is now 2 (32.087990271s elapsed)
Dec  8 22:34:57.690: INFO: Restart count of pod e2e-tests-container-probe-hk8cx/liveness-http is now 3 (52.135242697s elapsed)
Dec  8 22:35:17.730: INFO: Restart count of pod e2e-tests-container-probe-hk8cx/liveness-http is now 4 (1m12.175040491s elapsed)
Dec  8 22:36:19.983: INFO: Restart count of pod e2e-tests-container-probe-hk8cx/liveness-http is now 5 (2m14.428059526s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:36:20.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hk8cx" for this suite.
Dec  8 22:36:26.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:36:26.311: INFO: namespace: e2e-tests-container-probe-hk8cx, resource: bindings, ignored listing per whitelist
Dec  8 22:36:26.394: INFO: namespace e2e-tests-container-probe-hk8cx deletion completed in 6.330844405s

• [SLOW TEST:142.946 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:36:26.394: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:36:26.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 version --client'
Dec  8 22:36:26.554: INFO: stderr: ""
Dec  8 22:36:26.554: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  8 22:36:26.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-7th64'
Dec  8 22:36:27.103: INFO: stderr: ""
Dec  8 22:36:27.103: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  8 22:36:27.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-7th64'
Dec  8 22:36:27.486: INFO: stderr: ""
Dec  8 22:36:27.486: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 22:36:28.491: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:36:28.491: INFO: Found 0 / 1
Dec  8 22:36:29.491: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:36:29.491: INFO: Found 1 / 1
Dec  8 22:36:29.491: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 22:36:29.495: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 22:36:29.496: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 22:36:29.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 describe pod redis-master-nwzb4 --namespace=e2e-tests-kubectl-7th64'
Dec  8 22:36:29.684: INFO: stderr: ""
Dec  8 22:36:29.684: INFO: stdout: "Name:               redis-master-nwzb4\nNamespace:          e2e-tests-kubectl-7th64\nPriority:           0\nPriorityClassName:  <none>\nNode:               compliancetest/10.128.0.4\nStart Time:         Sat, 08 Dec 2018 22:36:27 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.0.173\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1498236f24fbaf7f0b7f3158e8358278e4b19c02e6e8db1d027abc37cf2ed223\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 08 Dec 2018 22:36:28 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-pjb5h (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-pjb5h:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-pjb5h\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  2s    default-scheduler        Successfully assigned e2e-tests-kubectl-7th64/redis-master-nwzb4 to compliancetest\n  Normal  Pulled     2s    kubelet, compliancetest  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, compliancetest  Created container\n  Normal  Started    1s    kubelet, compliancetest  Started container\n"
Dec  8 22:36:29.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 describe rc redis-master --namespace=e2e-tests-kubectl-7th64'
Dec  8 22:36:29.832: INFO: stderr: ""
Dec  8 22:36:29.832: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-7th64\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-nwzb4\n"
Dec  8 22:36:29.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 describe service redis-master --namespace=e2e-tests-kubectl-7th64'
Dec  8 22:36:29.983: INFO: stderr: ""
Dec  8 22:36:29.984: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-7th64\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.10.175.236\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.0.173:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  8 22:36:29.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 describe node compliancetest'
Dec  8 22:36:30.144: INFO: stderr: ""
Dec  8 22:36:30.144: INFO: stdout: "Name:               compliancetest\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=compliancetest\n                    nirmata.io/cluster.name=conformance1123\n                    nirmata.io/cluster.role=control-plane\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"52:17:e0:c1:f6:c6\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.128.0.4\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 07 Dec 2018 21:20:50 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Sat, 08 Dec 2018 22:36:24 +0000   Fri, 07 Dec 2018 21:20:37 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Sat, 08 Dec 2018 22:36:24 +0000   Fri, 07 Dec 2018 21:20:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 08 Dec 2018 22:36:24 +0000   Fri, 07 Dec 2018 21:20:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 08 Dec 2018 22:36:24 +0000   Fri, 07 Dec 2018 21:20:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 08 Dec 2018 22:36:24 +0000   Sat, 08 Dec 2018 21:52:08 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.128.0.4\n  Hostname:    compliancetest\nCapacity:\n cpu:                1\n ephemeral-storage:  10098468Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3781804Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  9306748094\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3679404Ki\n pods:               110\nSystem Info:\n Machine ID:                 caccad8c91b81ee3bbc49c5faa2d10ea\n System UUID:                CACCAD8C-91B8-1EE3-BBC4-9C5FAA2D10EA\n Boot ID:                    237c20ca-2c8f-468f-a0c6-ec3d10aa5f9e\n Kernel Version:             4.15.0-1025-gcp\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.6.0\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-7th64    redis-master-nwzb4                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-e2e-job-02e788f5b1a14e8d                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-eca918e579904fef-p49sk    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  ingress-haproxy            haproxy-ingress-54bf6fdf5d-qrznd                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  ingress-haproxy            ingress-default-backend-59f45f4b79-2vjfz                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-dns-5d95dcfb8d-28f4w                                  260m (26%)    0 (0%)      110Mi (3%)       170Mi (4%)\n  kube-system                kube-flannel-ds-sh87s                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                metrics-server-7cc7d8ccb8-gxvfp                            0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  nirmata                    nirmata-cni-installer-dgkr7                                0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  nirmata                    nirmata-kube-controller-7f4cfbcc47-tbw9p                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       260m (26%)  0 (0%)\n  memory    110Mi (3%)  170Mi (4%)\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  NodeReady  44m   kubelet, compliancetest  Node compliancetest status is now: NodeReady\n"
Dec  8 22:36:30.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 describe namespace e2e-tests-kubectl-7th64'
Dec  8 22:36:30.285: INFO: stderr: ""
Dec  8 22:36:30.285: INFO: stdout: "Name:         e2e-tests-kubectl-7th64\nLabels:       e2e-framework=kubectl\n              e2e-run=02d4f9d4-fb35-11e8-8c59-ae6969886d1b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:36:30.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7th64" for this suite.
Dec  8 22:36:52.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:36:52.398: INFO: namespace: e2e-tests-kubectl-7th64, resource: bindings, ignored listing per whitelist
Dec  8 22:36:52.420: INFO: namespace e2e-tests-kubectl-7th64 deletion completed in 22.130499184s

• [SLOW TEST:26.026 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:36:52.420: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  8 22:36:52.504: INFO: Waiting up to 5m0s for pod "pod-c23797a1-fb39-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-w5ghf" to be "success or failure"
Dec  8 22:36:52.545: INFO: Pod "pod-c23797a1-fb39-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.332878ms
Dec  8 22:36:54.551: INFO: Pod "pod-c23797a1-fb39-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047246905s
STEP: Saw pod success
Dec  8 22:36:54.551: INFO: Pod "pod-c23797a1-fb39-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:36:54.555: INFO: Trying to get logs from node compliancetest pod pod-c23797a1-fb39-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:36:54.581: INFO: Waiting for pod pod-c23797a1-fb39-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:36:54.586: INFO: Pod pod-c23797a1-fb39-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:36:54.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w5ghf" for this suite.
Dec  8 22:37:00.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:37:00.628: INFO: namespace: e2e-tests-emptydir-w5ghf, resource: bindings, ignored listing per whitelist
Dec  8 22:37:00.730: INFO: namespace e2e-tests-emptydir-w5ghf deletion completed in 6.140384954s

• [SLOW TEST:8.310 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:37:00.730: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-tdmk6
Dec  8 22:37:02.828: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-tdmk6
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 22:37:02.856: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:41:03.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tdmk6" for this suite.
Dec  8 22:41:09.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:41:09.859: INFO: namespace: e2e-tests-container-probe-tdmk6, resource: bindings, ignored listing per whitelist
Dec  8 22:41:09.867: INFO: namespace e2e-tests-container-probe-tdmk6 deletion completed in 6.187641932s

• [SLOW TEST:249.137 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:41:09.868: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:41:09.948: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5baabf8c-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-b9fr9" to be "success or failure"
Dec  8 22:41:09.953: INFO: Pod "downwardapi-volume-5baabf8c-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.91265ms
Dec  8 22:41:11.957: INFO: Pod "downwardapi-volume-5baabf8c-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009007436s
Dec  8 22:41:13.967: INFO: Pod "downwardapi-volume-5baabf8c-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018995678s
STEP: Saw pod success
Dec  8 22:41:13.967: INFO: Pod "downwardapi-volume-5baabf8c-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:41:13.970: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-5baabf8c-fb3a-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:41:14.000: INFO: Waiting for pod downwardapi-volume-5baabf8c-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:41:14.008: INFO: Pod downwardapi-volume-5baabf8c-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:41:14.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b9fr9" for this suite.
Dec  8 22:41:20.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:41:20.170: INFO: namespace: e2e-tests-downward-api-b9fr9, resource: bindings, ignored listing per whitelist
Dec  8 22:41:20.196: INFO: namespace e2e-tests-downward-api-b9fr9 deletion completed in 6.179313226s

• [SLOW TEST:10.328 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:41:20.197: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 22:41:20.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-hzz52'
Dec  8 22:41:20.425: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 22:41:20.425: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Dec  8 22:41:24.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-hzz52'
Dec  8 22:41:24.603: INFO: stderr: ""
Dec  8 22:41:24.603: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:41:24.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hzz52" for this suite.
Dec  8 22:41:46.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:41:46.690: INFO: namespace: e2e-tests-kubectl-hzz52, resource: bindings, ignored listing per whitelist
Dec  8 22:41:46.747: INFO: namespace e2e-tests-kubectl-hzz52 deletion completed in 22.138949866s

• [SLOW TEST:26.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:41:46.747: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  8 22:41:46.841: INFO: Waiting up to 5m0s for pod "pod-71a813f0-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-95mg7" to be "success or failure"
Dec  8 22:41:46.845: INFO: Pod "pod-71a813f0-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.805854ms
Dec  8 22:41:48.862: INFO: Pod "pod-71a813f0-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020649418s
STEP: Saw pod success
Dec  8 22:41:48.862: INFO: Pod "pod-71a813f0-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:41:48.872: INFO: Trying to get logs from node compliancetest pod pod-71a813f0-fb3a-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:41:48.950: INFO: Waiting for pod pod-71a813f0-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:41:48.960: INFO: Pod pod-71a813f0-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:41:48.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-95mg7" for this suite.
Dec  8 22:41:54.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:41:55.159: INFO: namespace: e2e-tests-emptydir-95mg7, resource: bindings, ignored listing per whitelist
Dec  8 22:41:55.168: INFO: namespace e2e-tests-emptydir-95mg7 deletion completed in 6.201697771s

• [SLOW TEST:8.420 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:41:55.168: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 22:41:55.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-6lxj6'
Dec  8 22:41:55.371: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 22:41:55.371: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  8 22:41:55.378: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec  8 22:41:55.404: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  8 22:41:55.433: INFO: scanned /root for discovery docs: <nil>
Dec  8 22:41:55.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-6lxj6'
Dec  8 22:42:11.446: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  8 22:42:11.446: INFO: stdout: "Created e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea\nScaling up e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  8 22:42:11.446: INFO: stdout: "Created e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea\nScaling up e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  8 22:42:11.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6lxj6'
Dec  8 22:42:11.600: INFO: stderr: ""
Dec  8 22:42:11.600: INFO: stdout: "e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea-4t2gc "
Dec  8 22:42:11.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea-4t2gc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6lxj6'
Dec  8 22:42:11.718: INFO: stderr: ""
Dec  8 22:42:11.718: INFO: stdout: "true"
Dec  8 22:42:11.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea-4t2gc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6lxj6'
Dec  8 22:42:11.840: INFO: stderr: ""
Dec  8 22:42:11.840: INFO: stdout: "nginx:1.14-alpine"
Dec  8 22:42:11.840: INFO: e2e-test-nginx-rc-cb350ca439b475b70838770e28e9e8ea-4t2gc is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Dec  8 22:42:11.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6lxj6'
Dec  8 22:42:11.982: INFO: stderr: ""
Dec  8 22:42:11.982: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:42:11.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6lxj6" for this suite.
Dec  8 22:42:18.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:42:18.079: INFO: namespace: e2e-tests-kubectl-6lxj6, resource: bindings, ignored listing per whitelist
Dec  8 22:42:18.124: INFO: namespace e2e-tests-kubectl-6lxj6 deletion completed in 6.133796355s

• [SLOW TEST:22.956 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:42:18.124: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  8 22:42:18.220: INFO: Waiting up to 5m0s for pod "pod-845c5f39-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-9qb2k" to be "success or failure"
Dec  8 22:42:18.225: INFO: Pod "pod-845c5f39-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.78287ms
Dec  8 22:42:20.229: INFO: Pod "pod-845c5f39-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008423094s
STEP: Saw pod success
Dec  8 22:42:20.229: INFO: Pod "pod-845c5f39-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:42:20.232: INFO: Trying to get logs from node compliancetest pod pod-845c5f39-fb3a-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:42:20.263: INFO: Waiting for pod pod-845c5f39-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:42:20.267: INFO: Pod pod-845c5f39-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:42:20.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9qb2k" for this suite.
Dec  8 22:42:26.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:42:26.356: INFO: namespace: e2e-tests-emptydir-9qb2k, resource: bindings, ignored listing per whitelist
Dec  8 22:42:26.398: INFO: namespace e2e-tests-emptydir-9qb2k deletion completed in 6.127107225s

• [SLOW TEST:8.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:42:26.398: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:42:26.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8946d7f0-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-x52nk" to be "success or failure"
Dec  8 22:42:26.473: INFO: Pod "downwardapi-volume-8946d7f0-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.245504ms
Dec  8 22:42:28.477: INFO: Pod "downwardapi-volume-8946d7f0-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009058592s
STEP: Saw pod success
Dec  8 22:42:28.477: INFO: Pod "downwardapi-volume-8946d7f0-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:42:28.480: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-8946d7f0-fb3a-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:42:28.510: INFO: Waiting for pod downwardapi-volume-8946d7f0-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:42:28.518: INFO: Pod downwardapi-volume-8946d7f0-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:42:28.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x52nk" for this suite.
Dec  8 22:42:34.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:42:34.657: INFO: namespace: e2e-tests-projected-x52nk, resource: bindings, ignored listing per whitelist
Dec  8 22:42:34.700: INFO: namespace e2e-tests-projected-x52nk deletion completed in 6.177127269s

• [SLOW TEST:8.302 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:42:34.700: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  8 22:42:34.815: INFO: Waiting up to 5m0s for pod "pod-8e40186c-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-dnthh" to be "success or failure"
Dec  8 22:42:34.820: INFO: Pod "pod-8e40186c-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.593864ms
Dec  8 22:42:36.825: INFO: Pod "pod-8e40186c-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010654478s
STEP: Saw pod success
Dec  8 22:42:36.825: INFO: Pod "pod-8e40186c-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:42:36.828: INFO: Trying to get logs from node compliancetest pod pod-8e40186c-fb3a-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:42:36.858: INFO: Waiting for pod pod-8e40186c-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:42:36.863: INFO: Pod pod-8e40186c-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:42:36.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dnthh" for this suite.
Dec  8 22:42:42.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:42:42.919: INFO: namespace: e2e-tests-emptydir-dnthh, resource: bindings, ignored listing per whitelist
Dec  8 22:42:42.999: INFO: namespace e2e-tests-emptydir-dnthh deletion completed in 6.132768712s

• [SLOW TEST:8.299 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:42:42.999: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  8 22:42:43.065: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-960662691 proxy --unix-socket=/tmp/kubectl-proxy-unix525069734/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:42:43.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gx2tn" for this suite.
Dec  8 22:42:49.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:42:49.306: INFO: namespace: e2e-tests-kubectl-gx2tn, resource: bindings, ignored listing per whitelist
Dec  8 22:42:49.339: INFO: namespace e2e-tests-kubectl-gx2tn deletion completed in 6.128067008s

• [SLOW TEST:6.339 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:42:49.339: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  8 22:42:49.451: INFO: Waiting up to 5m0s for pod "client-containers-96f9b1d7-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-containers-k59l5" to be "success or failure"
Dec  8 22:42:49.456: INFO: Pod "client-containers-96f9b1d7-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.956258ms
Dec  8 22:42:51.459: INFO: Pod "client-containers-96f9b1d7-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008614155s
STEP: Saw pod success
Dec  8 22:42:51.459: INFO: Pod "client-containers-96f9b1d7-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:42:51.463: INFO: Trying to get logs from node compliancetest pod client-containers-96f9b1d7-fb3a-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:42:51.497: INFO: Waiting for pod client-containers-96f9b1d7-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:42:51.504: INFO: Pod client-containers-96f9b1d7-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:42:51.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-k59l5" for this suite.
Dec  8 22:42:57.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:42:57.567: INFO: namespace: e2e-tests-containers-k59l5, resource: bindings, ignored listing per whitelist
Dec  8 22:42:57.638: INFO: namespace e2e-tests-containers-k59l5 deletion completed in 6.130489035s

• [SLOW TEST:8.299 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:42:57.638: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:42:57.709: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9be5af8d-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-t8b6m" to be "success or failure"
Dec  8 22:42:57.714: INFO: Pod "downwardapi-volume-9be5af8d-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.107201ms
Dec  8 22:42:59.720: INFO: Pod "downwardapi-volume-9be5af8d-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01084887s
STEP: Saw pod success
Dec  8 22:42:59.720: INFO: Pod "downwardapi-volume-9be5af8d-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:42:59.723: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-9be5af8d-fb3a-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:42:59.747: INFO: Waiting for pod downwardapi-volume-9be5af8d-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:42:59.761: INFO: Pod downwardapi-volume-9be5af8d-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:42:59.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t8b6m" for this suite.
Dec  8 22:43:05.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:43:05.855: INFO: namespace: e2e-tests-downward-api-t8b6m, resource: bindings, ignored listing per whitelist
Dec  8 22:43:05.930: INFO: namespace e2e-tests-downward-api-t8b6m deletion completed in 6.165579875s

• [SLOW TEST:8.291 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:43:05.930: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a0d8a0d6-fb3a-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:43:06.016: INFO: Waiting up to 5m0s for pod "pod-configmaps-a0d94846-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-5jrnc" to be "success or failure"
Dec  8 22:43:06.021: INFO: Pod "pod-configmaps-a0d94846-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.93894ms
Dec  8 22:43:08.025: INFO: Pod "pod-configmaps-a0d94846-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008930549s
Dec  8 22:43:10.028: INFO: Pod "pod-configmaps-a0d94846-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012776047s
STEP: Saw pod success
Dec  8 22:43:10.028: INFO: Pod "pod-configmaps-a0d94846-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:43:10.032: INFO: Trying to get logs from node compliancetest pod pod-configmaps-a0d94846-fb3a-11e8-8c59-ae6969886d1b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:43:10.063: INFO: Waiting for pod pod-configmaps-a0d94846-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:43:10.070: INFO: Pod pod-configmaps-a0d94846-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:43:10.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5jrnc" for this suite.
Dec  8 22:43:16.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:43:16.129: INFO: namespace: e2e-tests-configmap-5jrnc, resource: bindings, ignored listing per whitelist
Dec  8 22:43:16.200: INFO: namespace e2e-tests-configmap-5jrnc deletion completed in 6.121849996s

• [SLOW TEST:10.269 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:43:16.200: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:43:16.285: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a6f8390f-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-f7zkw" to be "success or failure"
Dec  8 22:43:16.290: INFO: Pod "downwardapi-volume-a6f8390f-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.970276ms
Dec  8 22:43:18.294: INFO: Pod "downwardapi-volume-a6f8390f-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009239454s
STEP: Saw pod success
Dec  8 22:43:18.294: INFO: Pod "downwardapi-volume-a6f8390f-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:43:18.299: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-a6f8390f-fb3a-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:43:18.327: INFO: Waiting for pod downwardapi-volume-a6f8390f-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:43:18.335: INFO: Pod downwardapi-volume-a6f8390f-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:43:18.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f7zkw" for this suite.
Dec  8 22:43:24.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:43:24.447: INFO: namespace: e2e-tests-downward-api-f7zkw, resource: bindings, ignored listing per whitelist
Dec  8 22:43:24.467: INFO: namespace e2e-tests-downward-api-f7zkw deletion completed in 6.125187409s

• [SLOW TEST:8.267 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:43:24.468: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:43:24.605: INFO: (0) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.002393ms)
Dec  8 22:43:24.609: INFO: (1) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.374026ms)
Dec  8 22:43:24.614: INFO: (2) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.302178ms)
Dec  8 22:43:24.618: INFO: (3) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.18004ms)
Dec  8 22:43:24.622: INFO: (4) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.964106ms)
Dec  8 22:43:24.626: INFO: (5) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.819772ms)
Dec  8 22:43:24.630: INFO: (6) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.716079ms)
Dec  8 22:43:24.634: INFO: (7) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.699733ms)
Dec  8 22:43:24.638: INFO: (8) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.10025ms)
Dec  8 22:43:24.641: INFO: (9) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.511153ms)
Dec  8 22:43:24.645: INFO: (10) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.795929ms)
Dec  8 22:43:24.649: INFO: (11) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.11902ms)
Dec  8 22:43:24.654: INFO: (12) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.295311ms)
Dec  8 22:43:24.681: INFO: (13) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 27.023512ms)
Dec  8 22:43:24.689: INFO: (14) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 8.435931ms)
Dec  8 22:43:24.696: INFO: (15) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 6.940968ms)
Dec  8 22:43:24.705: INFO: (16) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 9.108238ms)
Dec  8 22:43:24.711: INFO: (17) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.693582ms)
Dec  8 22:43:24.717: INFO: (18) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.81256ms)
Dec  8 22:43:24.722: INFO: (19) /api/v1/nodes/compliancetest/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.169867ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:43:24.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wdflq" for this suite.
Dec  8 22:43:30.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:43:30.842: INFO: namespace: e2e-tests-proxy-wdflq, resource: bindings, ignored listing per whitelist
Dec  8 22:43:30.870: INFO: namespace e2e-tests-proxy-wdflq deletion completed in 6.144065064s

• [SLOW TEST:6.403 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:43:30.871: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  8 22:43:30.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 cluster-info'
Dec  8 22:43:31.089: INFO: stderr: ""
Dec  8 22:43:31.089: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.10.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.10.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:43:31.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c6jq9" for this suite.
Dec  8 22:43:37.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:43:37.205: INFO: namespace: e2e-tests-kubectl-c6jq9, resource: bindings, ignored listing per whitelist
Dec  8 22:43:37.219: INFO: namespace e2e-tests-kubectl-c6jq9 deletion completed in 6.126498745s

• [SLOW TEST:6.348 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:43:37.219: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b37e0a81-fb3a-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:43:37.302: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b37eba3d-fb3a-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-pjtd7" to be "success or failure"
Dec  8 22:43:37.308: INFO: Pod "pod-projected-configmaps-b37eba3d-fb3a-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.418307ms
Dec  8 22:43:39.312: INFO: Pod "pod-projected-configmaps-b37eba3d-fb3a-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009229819s
STEP: Saw pod success
Dec  8 22:43:39.312: INFO: Pod "pod-projected-configmaps-b37eba3d-fb3a-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:43:39.315: INFO: Trying to get logs from node compliancetest pod pod-projected-configmaps-b37eba3d-fb3a-11e8-8c59-ae6969886d1b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:43:39.341: INFO: Waiting for pod pod-projected-configmaps-b37eba3d-fb3a-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:43:39.346: INFO: Pod pod-projected-configmaps-b37eba3d-fb3a-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:43:39.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pjtd7" for this suite.
Dec  8 22:43:45.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:43:45.402: INFO: namespace: e2e-tests-projected-pjtd7, resource: bindings, ignored listing per whitelist
Dec  8 22:43:45.501: INFO: namespace e2e-tests-projected-pjtd7 deletion completed in 6.151380949s

• [SLOW TEST:8.282 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:43:45.501: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  8 22:43:49.698: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 22:43:49.702: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 22:43:51.702: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 22:43:51.706: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 22:43:53.702: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 22:43:53.706: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 22:43:55.702: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 22:43:55.706: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:43:55.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4tqjn" for this suite.
Dec  8 22:44:17.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:44:17.876: INFO: namespace: e2e-tests-container-lifecycle-hook-4tqjn, resource: bindings, ignored listing per whitelist
Dec  8 22:44:17.887: INFO: namespace e2e-tests-container-lifecycle-hook-4tqjn deletion completed in 22.167780451s

• [SLOW TEST:32.386 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:44:17.887: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6l2mc
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  8 22:44:17.975: INFO: Found 0 stateful pods, waiting for 3
Dec  8 22:44:27.979: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:44:27.980: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:44:27.980: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  8 22:44:28.010: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  8 22:44:38.052: INFO: Updating stateful set ss2
Dec  8 22:44:38.063: INFO: Waiting for Pod e2e-tests-statefulset-6l2mc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  8 22:44:48.374: INFO: Found 1 stateful pods, waiting for 3
Dec  8 22:44:58.379: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:44:58.379: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:44:58.379: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  8 22:44:58.410: INFO: Updating stateful set ss2
Dec  8 22:44:58.418: INFO: Waiting for Pod e2e-tests-statefulset-6l2mc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 22:45:08.450: INFO: Updating stateful set ss2
Dec  8 22:45:08.460: INFO: Waiting for StatefulSet e2e-tests-statefulset-6l2mc/ss2 to complete update
Dec  8 22:45:08.460: INFO: Waiting for Pod e2e-tests-statefulset-6l2mc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 22:45:18.470: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6l2mc
Dec  8 22:45:18.474: INFO: Scaling statefulset ss2 to 0
Dec  8 22:45:48.500: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 22:45:48.514: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:45:48.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6l2mc" for this suite.
Dec  8 22:45:54.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:45:54.763: INFO: namespace: e2e-tests-statefulset-6l2mc, resource: bindings, ignored listing per whitelist
Dec  8 22:45:54.835: INFO: namespace e2e-tests-statefulset-6l2mc deletion completed in 6.250451064s

• [SLOW TEST:96.948 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:45:54.836: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 22:45:54.926: INFO: Number of nodes with available pods: 0
Dec  8 22:45:54.926: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:45:55.942: INFO: Number of nodes with available pods: 0
Dec  8 22:45:55.942: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:45:56.934: INFO: Number of nodes with available pods: 1
Dec  8 22:45:56.934: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  8 22:45:57.004: INFO: Number of nodes with available pods: 0
Dec  8 22:45:57.004: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:45:58.012: INFO: Number of nodes with available pods: 0
Dec  8 22:45:58.012: INFO: Node compliancetest is running more than one daemon pod
Dec  8 22:45:59.017: INFO: Number of nodes with available pods: 1
Dec  8 22:45:59.017: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-4psbs, will wait for the garbage collector to delete the pods
Dec  8 22:45:59.106: INFO: Deleting {extensions DaemonSet} daemon-set took: 14.577335ms
Dec  8 22:45:59.306: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.343654ms
Dec  8 22:46:34.910: INFO: Number of nodes with available pods: 0
Dec  8 22:46:34.910: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 22:46:34.913: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4psbs/daemonsets","resourceVersion":"25007"},"items":null}

Dec  8 22:46:34.916: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4psbs/pods","resourceVersion":"25007"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:46:34.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4psbs" for this suite.
Dec  8 22:46:40.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:46:41.058: INFO: namespace: e2e-tests-daemonsets-4psbs, resource: bindings, ignored listing per whitelist
Dec  8 22:46:41.093: INFO: namespace e2e-tests-daemonsets-4psbs deletion completed in 6.166327166s

• [SLOW TEST:46.257 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:46:41.093: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-ln54b
Dec  8 22:46:43.190: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-ln54b
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 22:46:43.193: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:50:43.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ln54b" for this suite.
Dec  8 22:50:53.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:50:53.845: INFO: namespace: e2e-tests-container-probe-ln54b, resource: bindings, ignored listing per whitelist
Dec  8 22:50:53.881: INFO: namespace e2e-tests-container-probe-ln54b deletion completed in 10.150058882s

• [SLOW TEST:252.787 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:50:53.881: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-ckc5j/configmap-test-b7c6058c-fb3b-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:50:53.992: INFO: Waiting up to 5m0s for pod "pod-configmaps-b7c70990-fb3b-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-ckc5j" to be "success or failure"
Dec  8 22:50:54.002: INFO: Pod "pod-configmaps-b7c70990-fb3b-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.653817ms
Dec  8 22:50:56.006: INFO: Pod "pod-configmaps-b7c70990-fb3b-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01344511s
STEP: Saw pod success
Dec  8 22:50:56.006: INFO: Pod "pod-configmaps-b7c70990-fb3b-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:50:56.009: INFO: Trying to get logs from node compliancetest pod pod-configmaps-b7c70990-fb3b-11e8-8c59-ae6969886d1b container env-test: <nil>
STEP: delete the pod
Dec  8 22:50:56.046: INFO: Waiting for pod pod-configmaps-b7c70990-fb3b-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:50:56.050: INFO: Pod pod-configmaps-b7c70990-fb3b-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:50:56.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ckc5j" for this suite.
Dec  8 22:51:02.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:51:02.118: INFO: namespace: e2e-tests-configmap-ckc5j, resource: bindings, ignored listing per whitelist
Dec  8 22:51:02.185: INFO: namespace e2e-tests-configmap-ckc5j deletion completed in 6.130965351s

• [SLOW TEST:8.304 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:51:02.185: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 22:51:02.246: INFO: PodSpec: initContainers in spec.initContainers
Dec  8 22:51:46.729: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-bcb5bd29-fb3b-11e8-8c59-ae6969886d1b", GenerateName:"", Namespace:"e2e-tests-init-container-b6554", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-b6554/pods/pod-init-bcb5bd29-fb3b-11e8-8c59-ae6969886d1b", UID:"bcb644f6-fb3b-11e8-a35e-42010a800004", ResourceVersion:"25211", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679906262, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"246949561"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-2ldf6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420a1d800), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2ldf6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2ldf6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2ldf6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420fb8878), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"compliancetest", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421b6f920), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420fb8900)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420fb8920)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc420fb8928), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906262, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906262, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906262, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906262, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.0.4", PodIP:"10.244.0.211", StartTime:(*v1.Time)(0xc420e9b9a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421f27420)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421f27490)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://f1c9543c246f6f4b3d175bf5d506764d6eee7aa32e1733171b57f5de010a7a16"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420e9ba60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420e9ba20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:51:46.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-b6554" for this suite.
Dec  8 22:52:08.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:52:08.815: INFO: namespace: e2e-tests-init-container-b6554, resource: bindings, ignored listing per whitelist
Dec  8 22:52:08.888: INFO: namespace e2e-tests-init-container-b6554 deletion completed in 22.146830973s

• [SLOW TEST:66.702 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:52:08.888: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 22:52:08.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dt72h'
Dec  8 22:52:09.434: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 22:52:09.435: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  8 22:52:09.454: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-pxprf]
Dec  8 22:52:09.454: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-pxprf" in namespace "e2e-tests-kubectl-dt72h" to be "running and ready"
Dec  8 22:52:09.461: INFO: Pod "e2e-test-nginx-rc-pxprf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.530397ms
Dec  8 22:52:11.465: INFO: Pod "e2e-test-nginx-rc-pxprf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011392034s
Dec  8 22:52:13.470: INFO: Pod "e2e-test-nginx-rc-pxprf": Phase="Running", Reason="", readiness=true. Elapsed: 4.015762483s
Dec  8 22:52:13.470: INFO: Pod "e2e-test-nginx-rc-pxprf" satisfied condition "running and ready"
Dec  8 22:52:13.470: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-pxprf]
Dec  8 22:52:13.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dt72h'
Dec  8 22:52:13.626: INFO: stderr: ""
Dec  8 22:52:13.626: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Dec  8 22:52:13.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dt72h'
Dec  8 22:52:13.764: INFO: stderr: ""
Dec  8 22:52:13.764: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:52:13.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dt72h" for this suite.
Dec  8 22:52:35.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:52:35.846: INFO: namespace: e2e-tests-kubectl-dt72h, resource: bindings, ignored listing per whitelist
Dec  8 22:52:35.900: INFO: namespace e2e-tests-kubectl-dt72h deletion completed in 22.122241521s

• [SLOW TEST:27.012 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:52:35.900: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-m4qdf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 22:52:35.966: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 22:52:54.049: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.214:8080/dial?request=hostName&protocol=udp&host=10.244.0.213&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-m4qdf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 22:52:54.049: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 22:52:54.310: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:52:54.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-m4qdf" for this suite.
Dec  8 22:53:18.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:53:18.395: INFO: namespace: e2e-tests-pod-network-test-m4qdf, resource: bindings, ignored listing per whitelist
Dec  8 22:53:18.468: INFO: namespace e2e-tests-pod-network-test-m4qdf deletion completed in 24.154085428s

• [SLOW TEST:42.568 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:53:18.468: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6rcqz
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-6rcqz
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-6rcqz
Dec  8 22:53:18.693: INFO: Found 0 stateful pods, waiting for 1
Dec  8 22:53:28.698: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  8 22:53:28.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-6rcqz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:53:29.040: INFO: stderr: ""
Dec  8 22:53:29.040: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:53:29.040: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:53:29.045: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  8 22:53:39.049: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 22:53:39.049: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 22:53:39.075: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999499s
Dec  8 22:53:40.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989227305s
Dec  8 22:53:41.084: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984599944s
Dec  8 22:53:42.089: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.979772902s
Dec  8 22:53:43.093: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.975183621s
Dec  8 22:53:44.097: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.971257976s
Dec  8 22:53:45.106: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.967347321s
Dec  8 22:53:46.111: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.95753178s
Dec  8 22:53:47.116: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.953051498s
Dec  8 22:53:48.120: INFO: Verifying statefulset ss doesn't scale past 1 for another 948.514589ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-6rcqz
Dec  8 22:53:49.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-6rcqz ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:53:49.322: INFO: stderr: ""
Dec  8 22:53:49.322: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:53:49.322: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:53:49.326: INFO: Found 1 stateful pods, waiting for 3
Dec  8 22:53:59.330: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:53:59.330: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 22:53:59.330: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  8 22:53:59.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-6rcqz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:53:59.538: INFO: stderr: ""
Dec  8 22:53:59.538: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:53:59.538: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:53:59.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-6rcqz ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:53:59.728: INFO: stderr: ""
Dec  8 22:53:59.728: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:53:59.728: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:53:59.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-6rcqz ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 22:53:59.988: INFO: stderr: ""
Dec  8 22:53:59.988: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 22:53:59.988: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 22:53:59.988: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 22:53:59.992: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  8 22:54:09.999: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 22:54:09.999: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 22:54:09.999: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 22:54:10.012: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999547s
Dec  8 22:54:11.016: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996358591s
Dec  8 22:54:12.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991902137s
Dec  8 22:54:13.025: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987438518s
Dec  8 22:54:14.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982346431s
Dec  8 22:54:15.036: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977528857s
Dec  8 22:54:16.041: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972321004s
Dec  8 22:54:17.046: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967288104s
Dec  8 22:54:18.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961550653s
Dec  8 22:54:19.056: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.004572ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-6rcqz
Dec  8 22:54:20.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-6rcqz ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:54:20.256: INFO: stderr: ""
Dec  8 22:54:20.256: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:54:20.256: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:54:20.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-6rcqz ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:54:20.482: INFO: stderr: ""
Dec  8 22:54:20.482: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:54:20.482: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:54:20.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 exec --namespace=e2e-tests-statefulset-6rcqz ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 22:54:20.689: INFO: stderr: ""
Dec  8 22:54:20.689: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 22:54:20.689: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 22:54:20.689: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 22:54:30.704: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6rcqz
Dec  8 22:54:30.708: INFO: Scaling statefulset ss to 0
Dec  8 22:54:30.723: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 22:54:30.727: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:54:30.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6rcqz" for this suite.
Dec  8 22:54:36.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:54:36.809: INFO: namespace: e2e-tests-statefulset-6rcqz, resource: bindings, ignored listing per whitelist
Dec  8 22:54:36.897: INFO: namespace e2e-tests-statefulset-6rcqz deletion completed in 6.148075887s

• [SLOW TEST:78.429 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:54:36.898: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3cb0ab10-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:54:36.974: INFO: Waiting up to 5m0s for pod "pod-configmaps-3cb14801-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-v9gk5" to be "success or failure"
Dec  8 22:54:36.979: INFO: Pod "pod-configmaps-3cb14801-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497113ms
Dec  8 22:54:38.983: INFO: Pod "pod-configmaps-3cb14801-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008610158s
STEP: Saw pod success
Dec  8 22:54:38.983: INFO: Pod "pod-configmaps-3cb14801-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:54:38.986: INFO: Trying to get logs from node compliancetest pod pod-configmaps-3cb14801-fb3c-11e8-8c59-ae6969886d1b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:54:39.018: INFO: Waiting for pod pod-configmaps-3cb14801-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:54:39.025: INFO: Pod pod-configmaps-3cb14801-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:54:39.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v9gk5" for this suite.
Dec  8 22:54:45.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:54:45.116: INFO: namespace: e2e-tests-configmap-v9gk5, resource: bindings, ignored listing per whitelist
Dec  8 22:54:45.158: INFO: namespace e2e-tests-configmap-v9gk5 deletion completed in 6.129330488s

• [SLOW TEST:8.260 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:54:45.158: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-419c6d0a-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:54:45.231: INFO: Waiting up to 5m0s for pod "pod-configmaps-419d0ac9-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-jkxwv" to be "success or failure"
Dec  8 22:54:45.235: INFO: Pod "pod-configmaps-419d0ac9-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725194ms
Dec  8 22:54:47.239: INFO: Pod "pod-configmaps-419d0ac9-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008706857s
STEP: Saw pod success
Dec  8 22:54:47.239: INFO: Pod "pod-configmaps-419d0ac9-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:54:47.242: INFO: Trying to get logs from node compliancetest pod pod-configmaps-419d0ac9-fb3c-11e8-8c59-ae6969886d1b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:54:47.277: INFO: Waiting for pod pod-configmaps-419d0ac9-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:54:47.280: INFO: Pod pod-configmaps-419d0ac9-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:54:47.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jkxwv" for this suite.
Dec  8 22:54:53.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:54:53.428: INFO: namespace: e2e-tests-configmap-jkxwv, resource: bindings, ignored listing per whitelist
Dec  8 22:54:53.439: INFO: namespace e2e-tests-configmap-jkxwv deletion completed in 6.154306064s

• [SLOW TEST:8.281 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:54:53.439: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-92lb
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 22:54:53.549: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-92lb" in namespace "e2e-tests-subpath-qnmmh" to be "success or failure"
Dec  8 22:54:53.566: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.999122ms
Dec  8 22:54:55.587: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03814266s
Dec  8 22:54:57.591: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 4.042642269s
Dec  8 22:54:59.596: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 6.047270337s
Dec  8 22:55:01.600: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 8.051248505s
Dec  8 22:55:03.604: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 10.054930744s
Dec  8 22:55:05.608: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 12.059105431s
Dec  8 22:55:07.612: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 14.063201449s
Dec  8 22:55:09.616: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 16.067141339s
Dec  8 22:55:11.620: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 18.071036439s
Dec  8 22:55:13.625: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 20.076505255s
Dec  8 22:55:15.630: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Running", Reason="", readiness=false. Elapsed: 22.081297588s
Dec  8 22:55:17.635: INFO: Pod "pod-subpath-test-secret-92lb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.086258035s
STEP: Saw pod success
Dec  8 22:55:17.635: INFO: Pod "pod-subpath-test-secret-92lb" satisfied condition "success or failure"
Dec  8 22:55:17.640: INFO: Trying to get logs from node compliancetest pod pod-subpath-test-secret-92lb container test-container-subpath-secret-92lb: <nil>
STEP: delete the pod
Dec  8 22:55:17.678: INFO: Waiting for pod pod-subpath-test-secret-92lb to disappear
Dec  8 22:55:17.692: INFO: Pod pod-subpath-test-secret-92lb no longer exists
STEP: Deleting pod pod-subpath-test-secret-92lb
Dec  8 22:55:17.692: INFO: Deleting pod "pod-subpath-test-secret-92lb" in namespace "e2e-tests-subpath-qnmmh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:55:17.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qnmmh" for this suite.
Dec  8 22:55:23.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:55:23.811: INFO: namespace: e2e-tests-subpath-qnmmh, resource: bindings, ignored listing per whitelist
Dec  8 22:55:23.829: INFO: namespace e2e-tests-subpath-qnmmh deletion completed in 6.127899018s

• [SLOW TEST:30.390 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:55:23.830: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  8 22:55:23.940: INFO: Waiting up to 5m0s for pod "pod-58ab0522-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-d5sww" to be "success or failure"
Dec  8 22:55:23.954: INFO: Pod "pod-58ab0522-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.54019ms
Dec  8 22:55:25.961: INFO: Pod "pod-58ab0522-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02126265s
STEP: Saw pod success
Dec  8 22:55:25.961: INFO: Pod "pod-58ab0522-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:55:25.967: INFO: Trying to get logs from node compliancetest pod pod-58ab0522-fb3c-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:55:26.030: INFO: Waiting for pod pod-58ab0522-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:55:26.040: INFO: Pod pod-58ab0522-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:55:26.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d5sww" for this suite.
Dec  8 22:55:32.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:55:32.173: INFO: namespace: e2e-tests-emptydir-d5sww, resource: bindings, ignored listing per whitelist
Dec  8 22:55:32.213: INFO: namespace e2e-tests-emptydir-d5sww deletion completed in 6.164054738s

• [SLOW TEST:8.383 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:55:32.214: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 22:55:32.290: INFO: Waiting up to 5m0s for pod "downward-api-5da97d38-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-lzb8w" to be "success or failure"
Dec  8 22:55:32.296: INFO: Pod "downward-api-5da97d38-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.324283ms
Dec  8 22:55:34.300: INFO: Pod "downward-api-5da97d38-fb3c-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010737727s
Dec  8 22:55:36.315: INFO: Pod "downward-api-5da97d38-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025490445s
STEP: Saw pod success
Dec  8 22:55:36.315: INFO: Pod "downward-api-5da97d38-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:55:36.321: INFO: Trying to get logs from node compliancetest pod downward-api-5da97d38-fb3c-11e8-8c59-ae6969886d1b container dapi-container: <nil>
STEP: delete the pod
Dec  8 22:55:36.420: INFO: Waiting for pod downward-api-5da97d38-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:55:36.432: INFO: Pod downward-api-5da97d38-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:55:36.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lzb8w" for this suite.
Dec  8 22:55:42.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:55:42.518: INFO: namespace: e2e-tests-downward-api-lzb8w, resource: bindings, ignored listing per whitelist
Dec  8 22:55:42.584: INFO: namespace e2e-tests-downward-api-lzb8w deletion completed in 6.144863799s

• [SLOW TEST:10.370 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:55:42.584: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 22:55:42.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-bm6hc'
Dec  8 22:55:42.784: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 22:55:42.784: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Dec  8 22:55:44.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-bm6hc'
Dec  8 22:55:44.954: INFO: stderr: ""
Dec  8 22:55:44.954: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:55:44.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bm6hc" for this suite.
Dec  8 22:56:10.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:56:11.088: INFO: namespace: e2e-tests-kubectl-bm6hc, resource: bindings, ignored listing per whitelist
Dec  8 22:56:11.097: INFO: namespace e2e-tests-kubectl-bm6hc deletion completed in 26.136889591s

• [SLOW TEST:28.513 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:56:11.098: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-74d73889-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:56:11.180: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-74d7e163-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-jhwg5" to be "success or failure"
Dec  8 22:56:11.184: INFO: Pod "pod-projected-secrets-74d7e163-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.713281ms
Dec  8 22:56:13.188: INFO: Pod "pod-projected-secrets-74d7e163-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008344874s
STEP: Saw pod success
Dec  8 22:56:13.188: INFO: Pod "pod-projected-secrets-74d7e163-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:56:13.191: INFO: Trying to get logs from node compliancetest pod pod-projected-secrets-74d7e163-fb3c-11e8-8c59-ae6969886d1b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:56:13.218: INFO: Waiting for pod pod-projected-secrets-74d7e163-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:56:13.221: INFO: Pod pod-projected-secrets-74d7e163-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:56:13.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jhwg5" for this suite.
Dec  8 22:56:19.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:56:19.280: INFO: namespace: e2e-tests-projected-jhwg5, resource: bindings, ignored listing per whitelist
Dec  8 22:56:19.385: INFO: namespace e2e-tests-projected-jhwg5 deletion completed in 6.160494756s

• [SLOW TEST:8.288 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:56:19.386: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-79c7a225-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:56:21.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k9n5v" for this suite.
Dec  8 22:56:43.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:56:43.617: INFO: namespace: e2e-tests-configmap-k9n5v, resource: bindings, ignored listing per whitelist
Dec  8 22:56:43.627: INFO: namespace e2e-tests-configmap-k9n5v deletion completed in 22.120405327s

• [SLOW TEST:24.241 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:56:43.627: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:56:43.696: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:56:52.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-bs78x" for this suite.
Dec  8 22:56:58.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:56:58.888: INFO: namespace: e2e-tests-custom-resource-definition-bs78x, resource: bindings, ignored listing per whitelist
Dec  8 22:56:58.951: INFO: namespace e2e-tests-custom-resource-definition-bs78x deletion completed in 6.165899561s

• [SLOW TEST:15.324 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:56:58.952: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  8 22:56:59.578: INFO: created pod pod-service-account-defaultsa
Dec  8 22:56:59.578: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  8 22:56:59.597: INFO: created pod pod-service-account-mountsa
Dec  8 22:56:59.598: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  8 22:56:59.630: INFO: created pod pod-service-account-nomountsa
Dec  8 22:56:59.630: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  8 22:56:59.670: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  8 22:56:59.670: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  8 22:56:59.707: INFO: created pod pod-service-account-mountsa-mountspec
Dec  8 22:56:59.707: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  8 22:56:59.739: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  8 22:56:59.739: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  8 22:56:59.782: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  8 22:56:59.782: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  8 22:56:59.798: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  8 22:56:59.798: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  8 22:56:59.823: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  8 22:56:59.823: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:56:59.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-v4scr" for this suite.
Dec  8 22:57:23.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:57:23.921: INFO: namespace: e2e-tests-svcaccounts-v4scr, resource: bindings, ignored listing per whitelist
Dec  8 22:57:23.986: INFO: namespace e2e-tests-svcaccounts-v4scr deletion completed in 24.139918174s

• [SLOW TEST:25.034 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:57:23.986: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a0494e36-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:57:24.071: INFO: Waiting up to 5m0s for pod "pod-configmaps-a049edf8-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-jtjxf" to be "success or failure"
Dec  8 22:57:24.076: INFO: Pod "pod-configmaps-a049edf8-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.719074ms
Dec  8 22:57:26.080: INFO: Pod "pod-configmaps-a049edf8-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009400958s
Dec  8 22:57:28.084: INFO: Pod "pod-configmaps-a049edf8-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013466627s
STEP: Saw pod success
Dec  8 22:57:28.084: INFO: Pod "pod-configmaps-a049edf8-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:57:28.088: INFO: Trying to get logs from node compliancetest pod pod-configmaps-a049edf8-fb3c-11e8-8c59-ae6969886d1b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:57:28.113: INFO: Waiting for pod pod-configmaps-a049edf8-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:57:28.117: INFO: Pod pod-configmaps-a049edf8-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:57:28.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jtjxf" for this suite.
Dec  8 22:57:34.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:57:34.181: INFO: namespace: e2e-tests-configmap-jtjxf, resource: bindings, ignored listing per whitelist
Dec  8 22:57:34.328: INFO: namespace e2e-tests-configmap-jtjxf deletion completed in 6.198938194s

• [SLOW TEST:10.342 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:57:34.330: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 22:57:34.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5vs4b'
Dec  8 22:57:34.748: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 22:57:34.748: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Dec  8 22:57:34.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-5vs4b'
Dec  8 22:57:35.048: INFO: stderr: ""
Dec  8 22:57:35.048: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:57:35.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5vs4b" for this suite.
Dec  8 22:57:41.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:57:41.163: INFO: namespace: e2e-tests-kubectl-5vs4b, resource: bindings, ignored listing per whitelist
Dec  8 22:57:41.241: INFO: namespace e2e-tests-kubectl-5vs4b deletion completed in 6.188408436s

• [SLOW TEST:6.911 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:57:41.241: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  8 22:57:41.395: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 22:57:41.403: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 22:57:41.406: INFO: 
Logging pods the kubelet thinks is on node compliancetest before test
Dec  8 22:57:41.412: INFO: nirmata-kube-controller-7f4cfbcc47-tbw9p from nirmata started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Dec  8 22:57:41.413: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 22:02:12 +0000 UTC (1 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  8 22:57:41.413: INFO: sonobuoy-systemd-logs-daemon-set-eca918e579904fef-p49sk from heptio-sonobuoy started at 2018-12-08 22:02:16 +0000 UTC (2 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  8 22:57:41.413: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 22:57:41.413: INFO: metrics-server-7cc7d8ccb8-gxvfp from kube-system started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container metrics-server ready: true, restart count 0
Dec  8 22:57:41.413: INFO: ingress-default-backend-59f45f4b79-2vjfz from ingress-haproxy started at 2018-12-08 21:52:20 +0000 UTC (1 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container ingress-default-backend ready: true, restart count 0
Dec  8 22:57:41.413: INFO: kube-dns-5d95dcfb8d-28f4w from kube-system started at 2018-12-08 21:52:08 +0000 UTC (3 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  8 22:57:41.413: INFO: 	Container kubedns ready: true, restart count 0
Dec  8 22:57:41.413: INFO: 	Container sidecar ready: true, restart count 0
Dec  8 22:57:41.413: INFO: nirmata-cni-installer-dgkr7 from nirmata started at 2018-12-08 21:52:08 +0000 UTC (1 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 22:57:41.413: INFO: haproxy-ingress-54bf6fdf5d-qrznd from ingress-haproxy started at 2018-12-08 21:52:22 +0000 UTC (1 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container haproxy-ingress ready: true, restart count 0
Dec  8 22:57:41.413: INFO: sonobuoy-e2e-job-02e788f5b1a14e8d from heptio-sonobuoy started at 2018-12-08 22:02:16 +0000 UTC (2 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container e2e ready: true, restart count 0
Dec  8 22:57:41.413: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 22:57:41.413: INFO: kube-flannel-ds-sh87s from kube-system started at 2018-12-08 21:51:56 +0000 UTC (1 container statuses recorded)
Dec  8 22:57:41.413: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-abdd9f17-fb3c-11e8-8c59-ae6969886d1b 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-abdd9f17-fb3c-11e8-8c59-ae6969886d1b off the node compliancetest
STEP: verifying the node doesn't have the label kubernetes.io/e2e-abdd9f17-fb3c-11e8-8c59-ae6969886d1b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:57:47.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-svq7k" for this suite.
Dec  8 22:57:57.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:57:57.691: INFO: namespace: e2e-tests-sched-pred-svq7k, resource: bindings, ignored listing per whitelist
Dec  8 22:57:57.760: INFO: namespace e2e-tests-sched-pred-svq7k deletion completed in 10.144485065s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:16.519 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:57:57.760: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:57:57.847: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  8 22:58:02.852: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 22:58:02.852: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  8 22:58:04.856: INFO: Creating deployment "test-rollover-deployment"
Dec  8 22:58:04.867: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  8 22:58:06.877: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  8 22:58:06.889: INFO: Ensure that both replica sets have 1 created replica
Dec  8 22:58:06.899: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  8 22:58:06.966: INFO: Updating deployment test-rollover-deployment
Dec  8 22:58:06.967: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  8 22:58:09.020: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  8 22:58:09.026: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  8 22:58:09.033: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 22:58:09.034: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906688, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 22:58:11.041: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 22:58:11.041: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906688, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 22:58:13.042: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 22:58:13.042: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906688, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 22:58:15.042: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 22:58:15.042: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906688, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 22:58:17.042: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 22:58:17.042: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906688, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906684, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 22:58:19.046: INFO: 
Dec  8 22:58:19.046: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 22:58:19.064: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-n9rnh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n9rnh/deployments/test-rollover-deployment,UID:b89b0329-fb3c-11e8-a35e-42010a800004,ResourceVersion:26169,Generation:2,CreationTimestamp:2018-12-08 22:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-08 22:58:04 +0000 UTC 2018-12-08 22:58:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-08 22:58:18 +0000 UTC 2018-12-08 22:58:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  8 22:58:19.071: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-n9rnh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n9rnh/replicasets/test-rollover-deployment-5b76ff8c4,UID:b9d62b0d-fb3c-11e8-a35e-42010a800004,ResourceVersion:26160,Generation:2,CreationTimestamp:2018-12-08 22:58:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b89b0329-fb3c-11e8-a35e-42010a800004 0xc421c63af7 0xc421c63af8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  8 22:58:19.071: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  8 22:58:19.071: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-n9rnh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n9rnh/replicasets/test-rollover-controller,UID:b46c1176-fb3c-11e8-a35e-42010a800004,ResourceVersion:26168,Generation:2,CreationTimestamp:2018-12-08 22:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b89b0329-fb3c-11e8-a35e-42010a800004 0xc421c63a1e 0xc421c63a1f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 22:58:19.071: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-n9rnh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n9rnh/replicasets/test-rollover-deployment-6975f4fb87,UID:b8a0110b-fb3c-11e8-a35e-42010a800004,ResourceVersion:26143,Generation:2,CreationTimestamp:2018-12-08 22:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b89b0329-fb3c-11e8-a35e-42010a800004 0xc421c63c27 0xc421c63c28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 22:58:19.083: INFO: Pod "test-rollover-deployment-5b76ff8c4-xn4nw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-xn4nw,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-n9rnh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-n9rnh/pods/test-rollover-deployment-5b76ff8c4-xn4nw,UID:b9eacb94-fb3c-11e8-a35e-42010a800004,ResourceVersion:26154,Generation:0,CreationTimestamp:2018-12-08 22:58:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 b9d62b0d-fb3c-11e8-a35e-42010a800004 0xc422a5c170 0xc422a5c171}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rgh5f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rgh5f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rgh5f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a5c1e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a5c200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:58:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:58:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:58:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:58:07 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.252,StartTime:2018-12-08 22:58:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-08 22:58:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a7d8895d7f366d17f67c518f332145302163c7ffdf98be1b9b7b99296dec3753}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:58:19.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-n9rnh" for this suite.
Dec  8 22:58:25.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:58:25.193: INFO: namespace: e2e-tests-deployment-n9rnh, resource: bindings, ignored listing per whitelist
Dec  8 22:58:25.352: INFO: namespace e2e-tests-deployment-n9rnh deletion completed in 6.261594319s

• [SLOW TEST:27.592 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:58:25.353: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c4e1eaee-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:58:25.529: INFO: Waiting up to 5m0s for pod "pod-secrets-c4eabbc9-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-64gnj" to be "success or failure"
Dec  8 22:58:25.538: INFO: Pod "pod-secrets-c4eabbc9-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.830556ms
Dec  8 22:58:27.543: INFO: Pod "pod-secrets-c4eabbc9-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014679866s
STEP: Saw pod success
Dec  8 22:58:27.543: INFO: Pod "pod-secrets-c4eabbc9-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:58:27.546: INFO: Trying to get logs from node compliancetest pod pod-secrets-c4eabbc9-fb3c-11e8-8c59-ae6969886d1b container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:58:27.579: INFO: Waiting for pod pod-secrets-c4eabbc9-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:58:27.584: INFO: Pod pod-secrets-c4eabbc9-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:58:27.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-64gnj" for this suite.
Dec  8 22:58:33.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:58:33.692: INFO: namespace: e2e-tests-secrets-64gnj, resource: bindings, ignored listing per whitelist
Dec  8 22:58:33.713: INFO: namespace e2e-tests-secrets-64gnj deletion completed in 6.123664026s
STEP: Destroying namespace "e2e-tests-secret-namespace-cwxf2" for this suite.
Dec  8 22:58:39.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:58:39.798: INFO: namespace: e2e-tests-secret-namespace-cwxf2, resource: bindings, ignored listing per whitelist
Dec  8 22:58:39.839: INFO: namespace e2e-tests-secret-namespace-cwxf2 deletion completed in 6.126528886s

• [SLOW TEST:14.487 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:58:39.840: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  8 22:58:39.927: INFO: Waiting up to 5m0s for pod "pod-cd80b157-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-km8hm" to be "success or failure"
Dec  8 22:58:39.932: INFO: Pod "pod-cd80b157-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.839617ms
Dec  8 22:58:41.936: INFO: Pod "pod-cd80b157-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008873944s
STEP: Saw pod success
Dec  8 22:58:41.936: INFO: Pod "pod-cd80b157-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:58:41.940: INFO: Trying to get logs from node compliancetest pod pod-cd80b157-fb3c-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 22:58:41.974: INFO: Waiting for pod pod-cd80b157-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:58:41.988: INFO: Pod pod-cd80b157-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:58:41.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-km8hm" for this suite.
Dec  8 22:58:48.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:58:48.132: INFO: namespace: e2e-tests-emptydir-km8hm, resource: bindings, ignored listing per whitelist
Dec  8 22:58:48.135: INFO: namespace e2e-tests-emptydir-km8hm deletion completed in 6.143849932s

• [SLOW TEST:8.296 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:58:48.136: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d270f5b8-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:58:48.217: INFO: Waiting up to 5m0s for pod "pod-configmaps-d2719e53-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-xv4kz" to be "success or failure"
Dec  8 22:58:48.232: INFO: Pod "pod-configmaps-d2719e53-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.855523ms
Dec  8 22:58:50.237: INFO: Pod "pod-configmaps-d2719e53-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019930926s
STEP: Saw pod success
Dec  8 22:58:50.238: INFO: Pod "pod-configmaps-d2719e53-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:58:50.251: INFO: Trying to get logs from node compliancetest pod pod-configmaps-d2719e53-fb3c-11e8-8c59-ae6969886d1b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:58:50.343: INFO: Waiting for pod pod-configmaps-d2719e53-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:58:50.347: INFO: Pod pod-configmaps-d2719e53-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:58:50.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xv4kz" for this suite.
Dec  8 22:58:56.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:58:56.452: INFO: namespace: e2e-tests-configmap-xv4kz, resource: bindings, ignored listing per whitelist
Dec  8 22:58:56.481: INFO: namespace e2e-tests-configmap-xv4kz deletion completed in 6.128701631s

• [SLOW TEST:8.345 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:58:56.481: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 22:58:56.546: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  8 22:58:56.556: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  8 22:59:01.560: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 22:59:01.560: INFO: Creating deployment "test-rolling-update-deployment"
Dec  8 22:59:01.567: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  8 22:59:01.575: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  8 22:59:03.583: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  8 22:59:03.586: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 22:59:03.596: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-mc5d5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mc5d5/deployments/test-rolling-update-deployment,UID:da6772f6-fb3c-11e8-a35e-42010a800004,ResourceVersion:26356,Generation:1,CreationTimestamp:2018-12-08 22:59:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-08 22:59:01 +0000 UTC 2018-12-08 22:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-08 22:59:02 +0000 UTC 2018-12-08 22:59:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  8 22:59:03.600: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-mc5d5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mc5d5/replicasets/test-rolling-update-deployment-65b7695dcf,UID:da6b81fe-fb3c-11e8-a35e-42010a800004,ResourceVersion:26347,Generation:1,CreationTimestamp:2018-12-08 22:59:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment da6772f6-fb3c-11e8-a35e-42010a800004 0xc42269a3a7 0xc42269a3a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  8 22:59:03.600: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  8 22:59:03.600: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-mc5d5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mc5d5/replicasets/test-rolling-update-controller,UID:d76a3798-fb3c-11e8-a35e-42010a800004,ResourceVersion:26355,Generation:2,CreationTimestamp:2018-12-08 22:58:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment da6772f6-fb3c-11e8-a35e-42010a800004 0xc42269a20e 0xc42269a20f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 22:59:03.604: INFO: Pod "test-rolling-update-deployment-65b7695dcf-mk7dn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-mk7dn,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-mc5d5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mc5d5/pods/test-rolling-update-deployment-65b7695dcf-mk7dn,UID:da6c666d-fb3c-11e8-a35e-42010a800004,ResourceVersion:26346,Generation:0,CreationTimestamp:2018-12-08 22:59:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf da6b81fe-fb3c-11e8-a35e-42010a800004 0xc42269ae57 0xc42269ae58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sh64p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sh64p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-sh64p true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42269aee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42269af00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:59:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:59:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:59:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 22:59:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.12,StartTime:2018-12-08 22:59:01 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-08 22:59:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e6ee7a5a2b1ed95a417e2f995423152740c9cc8694918b6e03d86a45a432c867}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:59:03.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-mc5d5" for this suite.
Dec  8 22:59:09.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:59:09.658: INFO: namespace: e2e-tests-deployment-mc5d5, resource: bindings, ignored listing per whitelist
Dec  8 22:59:09.722: INFO: namespace e2e-tests-deployment-mc5d5 deletion completed in 6.113613639s

• [SLOW TEST:13.241 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:59:09.722: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-df54fdc0-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 22:59:09.845: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-df55c550-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-jdt6t" to be "success or failure"
Dec  8 22:59:09.850: INFO: Pod "pod-projected-secrets-df55c550-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.054712ms
Dec  8 22:59:11.854: INFO: Pod "pod-projected-secrets-df55c550-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008665698s
STEP: Saw pod success
Dec  8 22:59:11.854: INFO: Pod "pod-projected-secrets-df55c550-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:59:11.857: INFO: Trying to get logs from node compliancetest pod pod-projected-secrets-df55c550-fb3c-11e8-8c59-ae6969886d1b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 22:59:11.894: INFO: Waiting for pod pod-projected-secrets-df55c550-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:59:11.897: INFO: Pod pod-projected-secrets-df55c550-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:59:11.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jdt6t" for this suite.
Dec  8 22:59:17.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:59:18.093: INFO: namespace: e2e-tests-projected-jdt6t, resource: bindings, ignored listing per whitelist
Dec  8 22:59:18.095: INFO: namespace e2e-tests-projected-jdt6t deletion completed in 6.193833848s

• [SLOW TEST:8.373 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:59:18.096: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 22:59:18.189: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e44b47ca-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-dkz4b" to be "success or failure"
Dec  8 22:59:18.201: INFO: Pod "downwardapi-volume-e44b47ca-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.865175ms
Dec  8 22:59:20.206: INFO: Pod "downwardapi-volume-e44b47ca-fb3c-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.017231461s
Dec  8 22:59:22.213: INFO: Pod "downwardapi-volume-e44b47ca-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024142736s
STEP: Saw pod success
Dec  8 22:59:22.213: INFO: Pod "downwardapi-volume-e44b47ca-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:59:22.221: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-e44b47ca-fb3c-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 22:59:22.269: INFO: Waiting for pod downwardapi-volume-e44b47ca-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:59:22.274: INFO: Pod downwardapi-volume-e44b47ca-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:59:22.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dkz4b" for this suite.
Dec  8 22:59:28.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:59:28.378: INFO: namespace: e2e-tests-projected-dkz4b, resource: bindings, ignored listing per whitelist
Dec  8 22:59:28.450: INFO: namespace e2e-tests-projected-dkz4b deletion completed in 6.172618598s

• [SLOW TEST:10.355 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:59:28.451: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 22:59:33.081: INFO: Successfully updated pod "annotationupdateea7a4820-fb3c-11e8-8c59-ae6969886d1b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:59:35.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tszxh" for this suite.
Dec  8 22:59:57.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 22:59:57.233: INFO: namespace: e2e-tests-downward-api-tszxh, resource: bindings, ignored listing per whitelist
Dec  8 22:59:57.283: INFO: namespace e2e-tests-downward-api-tszxh deletion completed in 22.179079117s

• [SLOW TEST:28.832 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 22:59:57.283: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fba80e33-fb3c-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 22:59:57.364: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fba8a335-fb3c-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-wfpkr" to be "success or failure"
Dec  8 22:59:57.369: INFO: Pod "pod-projected-configmaps-fba8a335-fb3c-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.28476ms
Dec  8 22:59:59.373: INFO: Pod "pod-projected-configmaps-fba8a335-fb3c-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009206118s
STEP: Saw pod success
Dec  8 22:59:59.373: INFO: Pod "pod-projected-configmaps-fba8a335-fb3c-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 22:59:59.377: INFO: Trying to get logs from node compliancetest pod pod-projected-configmaps-fba8a335-fb3c-11e8-8c59-ae6969886d1b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 22:59:59.403: INFO: Waiting for pod pod-projected-configmaps-fba8a335-fb3c-11e8-8c59-ae6969886d1b to disappear
Dec  8 22:59:59.408: INFO: Pod pod-projected-configmaps-fba8a335-fb3c-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 22:59:59.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wfpkr" for this suite.
Dec  8 23:00:05.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:00:05.597: INFO: namespace: e2e-tests-projected-wfpkr, resource: bindings, ignored listing per whitelist
Dec  8 23:00:05.655: INFO: namespace e2e-tests-projected-wfpkr deletion completed in 6.243348216s

• [SLOW TEST:8.372 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:00:05.655: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-gw26
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 23:00:05.821: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-gw26" in namespace "e2e-tests-subpath-2k277" to be "success or failure"
Dec  8 23:00:05.835: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Pending", Reason="", readiness=false. Elapsed: 14.063376ms
Dec  8 23:00:07.840: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019161721s
Dec  8 23:00:09.845: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 4.023491935s
Dec  8 23:00:11.849: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 6.027652977s
Dec  8 23:00:13.853: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 8.031678002s
Dec  8 23:00:15.857: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 10.035757698s
Dec  8 23:00:17.861: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 12.039859962s
Dec  8 23:00:19.866: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 14.044557943s
Dec  8 23:00:21.871: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 16.050051137s
Dec  8 23:00:23.877: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 18.056078581s
Dec  8 23:00:25.882: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 20.06050515s
Dec  8 23:00:27.886: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Running", Reason="", readiness=false. Elapsed: 22.06489691s
Dec  8 23:00:29.890: INFO: Pod "pod-subpath-test-downwardapi-gw26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.068913606s
STEP: Saw pod success
Dec  8 23:00:29.890: INFO: Pod "pod-subpath-test-downwardapi-gw26" satisfied condition "success or failure"
Dec  8 23:00:29.894: INFO: Trying to get logs from node compliancetest pod pod-subpath-test-downwardapi-gw26 container test-container-subpath-downwardapi-gw26: <nil>
STEP: delete the pod
Dec  8 23:00:29.929: INFO: Waiting for pod pod-subpath-test-downwardapi-gw26 to disappear
Dec  8 23:00:29.935: INFO: Pod pod-subpath-test-downwardapi-gw26 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-gw26
Dec  8 23:00:29.935: INFO: Deleting pod "pod-subpath-test-downwardapi-gw26" in namespace "e2e-tests-subpath-2k277"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:00:29.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2k277" for this suite.
Dec  8 23:00:35.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:00:36.025: INFO: namespace: e2e-tests-subpath-2k277, resource: bindings, ignored listing per whitelist
Dec  8 23:00:36.081: INFO: namespace e2e-tests-subpath-2k277 deletion completed in 6.135973893s

• [SLOW TEST:30.426 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:00:36.081: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 23:01:00.174: INFO: Container started at 2018-12-08 23:00:37 +0000 UTC, pod became ready at 2018-12-08 23:00:58 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:01:00.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fb8bw" for this suite.
Dec  8 23:01:22.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:01:22.233: INFO: namespace: e2e-tests-container-probe-fb8bw, resource: bindings, ignored listing per whitelist
Dec  8 23:01:22.309: INFO: namespace e2e-tests-container-probe-fb8bw deletion completed in 22.131201205s

• [SLOW TEST:46.228 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:01:22.309: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2e55c3b1-fb3d-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 23:01:22.388: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e56624e-fb3d-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-nfpls" to be "success or failure"
Dec  8 23:01:22.393: INFO: Pod "pod-configmaps-2e56624e-fb3d-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.765612ms
Dec  8 23:01:24.397: INFO: Pod "pod-configmaps-2e56624e-fb3d-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009223867s
STEP: Saw pod success
Dec  8 23:01:24.398: INFO: Pod "pod-configmaps-2e56624e-fb3d-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:01:24.401: INFO: Trying to get logs from node compliancetest pod pod-configmaps-2e56624e-fb3d-11e8-8c59-ae6969886d1b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 23:01:24.428: INFO: Waiting for pod pod-configmaps-2e56624e-fb3d-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:01:24.436: INFO: Pod pod-configmaps-2e56624e-fb3d-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:01:24.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nfpls" for this suite.
Dec  8 23:01:30.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:01:30.542: INFO: namespace: e2e-tests-configmap-nfpls, resource: bindings, ignored listing per whitelist
Dec  8 23:01:30.602: INFO: namespace e2e-tests-configmap-nfpls deletion completed in 6.162124908s

• [SLOW TEST:8.293 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:01:30.603: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  8 23:01:30.691: INFO: Waiting up to 5m0s for pod "pod-334937d1-fb3d-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-4km4q" to be "success or failure"
Dec  8 23:01:30.696: INFO: Pod "pod-334937d1-fb3d-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.91007ms
Dec  8 23:01:32.701: INFO: Pod "pod-334937d1-fb3d-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009479711s
STEP: Saw pod success
Dec  8 23:01:32.701: INFO: Pod "pod-334937d1-fb3d-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:01:32.705: INFO: Trying to get logs from node compliancetest pod pod-334937d1-fb3d-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 23:01:32.739: INFO: Waiting for pod pod-334937d1-fb3d-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:01:32.744: INFO: Pod pod-334937d1-fb3d-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:01:32.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4km4q" for this suite.
Dec  8 23:01:38.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:01:38.787: INFO: namespace: e2e-tests-emptydir-4km4q, resource: bindings, ignored listing per whitelist
Dec  8 23:01:38.900: INFO: namespace e2e-tests-emptydir-4km4q deletion completed in 6.153051332s

• [SLOW TEST:8.298 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:01:38.901: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  8 23:01:38.974: INFO: Waiting up to 5m0s for pod "pod-383948b3-fb3d-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-lgs8r" to be "success or failure"
Dec  8 23:01:38.979: INFO: Pod "pod-383948b3-fb3d-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.761042ms
Dec  8 23:01:40.985: INFO: Pod "pod-383948b3-fb3d-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010612798s
STEP: Saw pod success
Dec  8 23:01:40.985: INFO: Pod "pod-383948b3-fb3d-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:01:40.991: INFO: Trying to get logs from node compliancetest pod pod-383948b3-fb3d-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 23:01:41.022: INFO: Waiting for pod pod-383948b3-fb3d-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:01:41.030: INFO: Pod pod-383948b3-fb3d-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:01:41.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lgs8r" for this suite.
Dec  8 23:01:47.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:01:47.150: INFO: namespace: e2e-tests-emptydir-lgs8r, resource: bindings, ignored listing per whitelist
Dec  8 23:01:47.227: INFO: namespace e2e-tests-emptydir-lgs8r deletion completed in 6.191573842s

• [SLOW TEST:8.326 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:01:47.227: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  8 23:01:53.343: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.343: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:53.421: INFO: Exec stderr: ""
Dec  8 23:01:53.421: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.421: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:53.502: INFO: Exec stderr: ""
Dec  8 23:01:53.502: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.502: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:53.584: INFO: Exec stderr: ""
Dec  8 23:01:53.585: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.585: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:53.667: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  8 23:01:53.667: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.667: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:53.738: INFO: Exec stderr: ""
Dec  8 23:01:53.739: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.739: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:53.808: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  8 23:01:53.808: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.808: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:53.885: INFO: Exec stderr: ""
Dec  8 23:01:53.886: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.886: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:53.971: INFO: Exec stderr: ""
Dec  8 23:01:53.971: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:53.971: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:54.072: INFO: Exec stderr: ""
Dec  8 23:01:54.072: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6sf5 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:01:54.073: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:01:54.146: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:01:54.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-v6sf5" for this suite.
Dec  8 23:02:36.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:02:36.294: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-v6sf5, resource: bindings, ignored listing per whitelist
Dec  8 23:02:36.327: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-v6sf5 deletion completed in 42.151493969s

• [SLOW TEST:49.100 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:02:36.327: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5a74420d-fb3d-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 23:02:36.407: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5a74e462-fb3d-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-bfp42" to be "success or failure"
Dec  8 23:02:36.412: INFO: Pod "pod-projected-configmaps-5a74e462-fb3d-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.936838ms
Dec  8 23:02:38.417: INFO: Pod "pod-projected-configmaps-5a74e462-fb3d-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009259138s
STEP: Saw pod success
Dec  8 23:02:38.417: INFO: Pod "pod-projected-configmaps-5a74e462-fb3d-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:02:38.421: INFO: Trying to get logs from node compliancetest pod pod-projected-configmaps-5a74e462-fb3d-11e8-8c59-ae6969886d1b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 23:02:38.457: INFO: Waiting for pod pod-projected-configmaps-5a74e462-fb3d-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:02:38.466: INFO: Pod pod-projected-configmaps-5a74e462-fb3d-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:02:38.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bfp42" for this suite.
Dec  8 23:02:44.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:02:44.575: INFO: namespace: e2e-tests-projected-bfp42, resource: bindings, ignored listing per whitelist
Dec  8 23:02:44.605: INFO: namespace e2e-tests-projected-bfp42 deletion completed in 6.133605862s

• [SLOW TEST:8.278 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:02:44.606: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5f6ac20a-fb3d-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 23:02:44.734: INFO: Waiting up to 5m0s for pod "pod-secrets-5f6b709c-fb3d-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-secrets-ttktm" to be "success or failure"
Dec  8 23:02:44.740: INFO: Pod "pod-secrets-5f6b709c-fb3d-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.199563ms
Dec  8 23:02:46.743: INFO: Pod "pod-secrets-5f6b709c-fb3d-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008782893s
STEP: Saw pod success
Dec  8 23:02:46.743: INFO: Pod "pod-secrets-5f6b709c-fb3d-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:02:46.748: INFO: Trying to get logs from node compliancetest pod pod-secrets-5f6b709c-fb3d-11e8-8c59-ae6969886d1b container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 23:02:46.809: INFO: Waiting for pod pod-secrets-5f6b709c-fb3d-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:02:46.814: INFO: Pod pod-secrets-5f6b709c-fb3d-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:02:46.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ttktm" for this suite.
Dec  8 23:02:52.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:02:52.928: INFO: namespace: e2e-tests-secrets-ttktm, resource: bindings, ignored listing per whitelist
Dec  8 23:02:52.966: INFO: namespace e2e-tests-secrets-ttktm deletion completed in 6.142216921s

• [SLOW TEST:8.359 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:02:52.966: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  8 23:02:55.087: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-64626d0d-fb3d-11e8-8c59-ae6969886d1b", GenerateName:"", Namespace:"e2e-tests-pods-67v4b", SelfLink:"/api/v1/namespaces/e2e-tests-pods-67v4b/pods/pod-submit-remove-64626d0d-fb3d-11e8-8c59-ae6969886d1b", UID:"6463997c-fb3d-11e8-a35e-42010a800004", ResourceVersion:"26837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679906973, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"54906035"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vp565", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421a92f00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vp565", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4211c85f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"compliancetest", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421e20600), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4211c8690)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4211c8730)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4211c8738), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906973, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906974, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906974, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679906973, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.0.4", PodIP:"10.244.0.29", StartTime:(*v1.Time)(0xc42254c560), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc42254c5a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6", ContainerID:"docker://e051b4280c1eb6248b8cec3b33c8e95d0441db043356486f55060f0471854a07"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:03:04.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-67v4b" for this suite.
Dec  8 23:03:10.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:03:10.948: INFO: namespace: e2e-tests-pods-67v4b, resource: bindings, ignored listing per whitelist
Dec  8 23:03:10.997: INFO: namespace e2e-tests-pods-67v4b deletion completed in 6.152321201s

• [SLOW TEST:18.030 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:03:10.997: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-znr5d
Dec  8 23:03:13.091: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-znr5d
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 23:03:13.095: INFO: Initial restart count of pod liveness-http is 0
Dec  8 23:03:35.150: INFO: Restart count of pod e2e-tests-container-probe-znr5d/liveness-http is now 1 (22.0555181s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:03:35.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-znr5d" for this suite.
Dec  8 23:03:41.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:03:41.349: INFO: namespace: e2e-tests-container-probe-znr5d, resource: bindings, ignored listing per whitelist
Dec  8 23:03:41.355: INFO: namespace e2e-tests-container-probe-znr5d deletion completed in 6.152688232s

• [SLOW TEST:30.358 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:03:41.355: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 23:03:41.437: INFO: Waiting up to 5m0s for pod "downward-api-813783aa-fb3d-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-lv485" to be "success or failure"
Dec  8 23:03:41.442: INFO: Pod "downward-api-813783aa-fb3d-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.253724ms
Dec  8 23:03:43.493: INFO: Pod "downward-api-813783aa-fb3d-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056261048s
Dec  8 23:03:45.504: INFO: Pod "downward-api-813783aa-fb3d-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067232056s
STEP: Saw pod success
Dec  8 23:03:45.504: INFO: Pod "downward-api-813783aa-fb3d-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:03:45.517: INFO: Trying to get logs from node compliancetest pod downward-api-813783aa-fb3d-11e8-8c59-ae6969886d1b container dapi-container: <nil>
STEP: delete the pod
Dec  8 23:03:45.558: INFO: Waiting for pod downward-api-813783aa-fb3d-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:03:45.566: INFO: Pod downward-api-813783aa-fb3d-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:03:45.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lv485" for this suite.
Dec  8 23:03:51.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:03:51.664: INFO: namespace: e2e-tests-downward-api-lv485, resource: bindings, ignored listing per whitelist
Dec  8 23:03:51.724: INFO: namespace e2e-tests-downward-api-lv485 deletion completed in 6.152906315s

• [SLOW TEST:10.369 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:03:51.724: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  8 23:03:51.794: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  8 23:03:51.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:03:52.517: INFO: stderr: ""
Dec  8 23:03:52.517: INFO: stdout: "service/redis-slave created\n"
Dec  8 23:03:52.517: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  8 23:03:52.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:03:52.861: INFO: stderr: ""
Dec  8 23:03:52.861: INFO: stdout: "service/redis-master created\n"
Dec  8 23:03:52.862: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  8 23:03:52.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:03:53.202: INFO: stderr: ""
Dec  8 23:03:53.202: INFO: stdout: "service/frontend created\n"
Dec  8 23:03:53.202: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  8 23:03:53.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:03:53.521: INFO: stderr: ""
Dec  8 23:03:53.521: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  8 23:03:53.521: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  8 23:03:53.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:03:54.199: INFO: stderr: ""
Dec  8 23:03:54.200: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  8 23:03:54.201: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  8 23:03:54.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:03:55.159: INFO: stderr: ""
Dec  8 23:03:55.159: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  8 23:03:55.159: INFO: Waiting for all frontend pods to be Running.
Dec  8 23:04:25.210: INFO: Waiting for frontend to serve content.
Dec  8 23:04:30.286: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec  8 23:04:35.301: INFO: Trying to add a new entry to the guestbook.
Dec  8 23:04:35.315: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  8 23:04:35.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:04:35.655: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 23:04:35.655: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 23:04:35.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:04:35.860: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 23:04:35.860: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 23:04:35.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:04:36.131: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 23:04:36.131: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 23:04:36.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:04:36.283: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 23:04:36.283: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 23:04:36.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:04:36.658: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 23:04:36.658: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 23:04:36.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-drlbh'
Dec  8 23:04:37.021: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 23:04:37.021: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:04:37.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-drlbh" for this suite.
Dec  8 23:05:17.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:05:17.328: INFO: namespace: e2e-tests-kubectl-drlbh, resource: bindings, ignored listing per whitelist
Dec  8 23:05:17.345: INFO: namespace e2e-tests-kubectl-drlbh deletion completed in 40.30027923s

• [SLOW TEST:85.621 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:05:17.346: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 23:05:17.439: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:05:20.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-p87mc" for this suite.
Dec  8 23:05:26.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:05:26.528: INFO: namespace: e2e-tests-init-container-p87mc, resource: bindings, ignored listing per whitelist
Dec  8 23:05:26.719: INFO: namespace e2e-tests-init-container-p87mc deletion completed in 6.259363917s

• [SLOW TEST:9.373 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:05:26.720: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1208 23:05:37.175481      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 23:05:37.175: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:05:37.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-dwznr" for this suite.
Dec  8 23:05:45.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:05:45.270: INFO: namespace: e2e-tests-gc-dwznr, resource: bindings, ignored listing per whitelist
Dec  8 23:05:45.326: INFO: namespace e2e-tests-gc-dwznr deletion completed in 8.147310828s

• [SLOW TEST:18.606 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:05:45.327: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-r9rq4 in namespace e2e-tests-proxy-jwt7p
I1208 23:05:45.461268      14 runners.go:180] Created replication controller with name: proxy-service-r9rq4, namespace: e2e-tests-proxy-jwt7p, replica count: 1
I1208 23:05:46.511966      14 runners.go:180] proxy-service-r9rq4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 23:05:47.512187      14 runners.go:180] proxy-service-r9rq4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 23:05:48.512438      14 runners.go:180] proxy-service-r9rq4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 23:05:49.512639      14 runners.go:180] proxy-service-r9rq4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 23:05:50.512857      14 runners.go:180] proxy-service-r9rq4 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  8 23:05:50.592: INFO: setup took 5.176740333s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  8 23:05:50.725: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 131.262464ms)
Dec  8 23:05:50.726: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 132.174215ms)
Dec  8 23:05:50.757: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 162.839519ms)
Dec  8 23:05:50.758: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 164.447232ms)
Dec  8 23:05:50.758: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 165.054612ms)
Dec  8 23:05:50.761: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 167.773127ms)
Dec  8 23:05:50.761: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 168.915886ms)
Dec  8 23:05:50.762: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 168.070532ms)
Dec  8 23:05:50.763: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 168.898797ms)
Dec  8 23:05:50.763: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 169.387708ms)
Dec  8 23:05:50.763: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 170.031801ms)
Dec  8 23:05:50.764: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 170.974714ms)
Dec  8 23:05:50.779: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 185.906614ms)
Dec  8 23:05:50.808: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 214.647304ms)
Dec  8 23:05:50.808: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 215.302826ms)
Dec  8 23:05:50.808: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 214.766689ms)
Dec  8 23:05:50.935: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 125.947304ms)
Dec  8 23:05:50.936: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 126.814288ms)
Dec  8 23:05:50.936: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 127.350142ms)
Dec  8 23:05:50.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 128.362623ms)
Dec  8 23:05:50.938: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 129.255802ms)
Dec  8 23:05:50.939: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 129.653768ms)
Dec  8 23:05:50.941: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 131.737963ms)
Dec  8 23:05:50.941: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 132.538124ms)
Dec  8 23:05:50.941: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 133.085182ms)
Dec  8 23:05:50.942: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 132.519624ms)
Dec  8 23:05:50.942: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 133.086638ms)
Dec  8 23:05:50.943: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 133.495812ms)
Dec  8 23:05:50.976: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 167.001434ms)
Dec  8 23:05:50.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 168.067947ms)
Dec  8 23:05:50.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 168.043622ms)
Dec  8 23:05:50.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 169.008285ms)
Dec  8 23:05:51.092: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 113.831106ms)
Dec  8 23:05:51.093: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 114.45721ms)
Dec  8 23:05:51.093: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 114.992189ms)
Dec  8 23:05:51.094: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 116.073512ms)
Dec  8 23:05:51.094: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 116.373111ms)
Dec  8 23:05:51.095: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 117.190272ms)
Dec  8 23:05:51.098: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 119.31876ms)
Dec  8 23:05:51.098: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 119.532011ms)
Dec  8 23:05:51.098: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 120.257784ms)
Dec  8 23:05:51.099: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 121.707302ms)
Dec  8 23:05:51.100: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 121.344861ms)
Dec  8 23:05:51.100: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 122.180555ms)
Dec  8 23:05:51.134: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 155.85427ms)
Dec  8 23:05:51.134: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 155.772709ms)
Dec  8 23:05:51.134: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 156.309088ms)
Dec  8 23:05:51.135: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 156.729349ms)
Dec  8 23:05:51.253: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 117.229989ms)
Dec  8 23:05:51.254: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 117.870333ms)
Dec  8 23:05:51.254: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 118.885157ms)
Dec  8 23:05:51.255: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 119.891088ms)
Dec  8 23:05:51.256: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 121.350935ms)
Dec  8 23:05:51.256: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 121.751567ms)
Dec  8 23:05:51.259: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 123.830381ms)
Dec  8 23:05:51.259: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 124.258343ms)
Dec  8 23:05:51.260: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 124.563511ms)
Dec  8 23:05:51.260: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 123.849144ms)
Dec  8 23:05:51.260: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 125.237729ms)
Dec  8 23:05:51.295: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 159.676036ms)
Dec  8 23:05:51.296: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 160.851504ms)
Dec  8 23:05:51.296: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 160.360903ms)
Dec  8 23:05:51.296: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 160.711021ms)
Dec  8 23:05:51.296: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 160.805084ms)
Dec  8 23:05:51.439: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 142.460859ms)
Dec  8 23:05:51.440: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 143.078777ms)
Dec  8 23:05:51.441: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 144.069272ms)
Dec  8 23:05:51.441: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 144.597126ms)
Dec  8 23:05:51.441: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 144.147568ms)
Dec  8 23:05:51.442: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 144.96554ms)
Dec  8 23:05:51.488: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 190.382019ms)
Dec  8 23:05:51.488: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 191.040353ms)
Dec  8 23:05:51.488: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 190.917259ms)
Dec  8 23:05:51.489: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 191.217373ms)
Dec  8 23:05:51.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 192.631987ms)
Dec  8 23:05:51.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 192.318525ms)
Dec  8 23:05:51.547: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 249.635093ms)
Dec  8 23:05:51.548: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 250.165788ms)
Dec  8 23:05:51.548: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 251.550307ms)
Dec  8 23:05:51.565: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 267.194824ms)
Dec  8 23:05:51.755: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 189.670368ms)
Dec  8 23:05:51.755: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 188.851585ms)
Dec  8 23:05:51.756: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 189.700304ms)
Dec  8 23:05:51.756: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 190.436008ms)
Dec  8 23:05:51.771: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 205.265532ms)
Dec  8 23:05:51.773: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 208.164091ms)
Dec  8 23:05:51.777: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 211.202304ms)
Dec  8 23:05:51.778: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 212.50528ms)
Dec  8 23:05:51.778: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 212.978559ms)
Dec  8 23:05:51.779: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 213.358205ms)
Dec  8 23:05:51.794: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 227.56331ms)
Dec  8 23:05:51.794: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 227.804128ms)
Dec  8 23:05:51.832: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 266.079507ms)
Dec  8 23:05:51.833: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 266.811456ms)
Dec  8 23:05:51.834: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 268.118987ms)
Dec  8 23:05:51.834: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 268.430366ms)
Dec  8 23:05:51.990: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 155.46687ms)
Dec  8 23:05:51.993: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 158.638607ms)
Dec  8 23:05:51.993: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 158.060013ms)
Dec  8 23:05:52.008: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 172.7587ms)
Dec  8 23:05:52.009: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 173.592042ms)
Dec  8 23:05:52.010: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 175.421329ms)
Dec  8 23:05:52.012: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 177.431123ms)
Dec  8 23:05:52.012: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 177.952602ms)
Dec  8 23:05:52.013: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 178.038296ms)
Dec  8 23:05:52.013: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 177.671595ms)
Dec  8 23:05:52.013: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 178.065539ms)
Dec  8 23:05:52.014: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 178.982115ms)
Dec  8 23:05:52.029: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 194.535347ms)
Dec  8 23:05:52.071: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 236.433682ms)
Dec  8 23:05:52.072: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 237.270988ms)
Dec  8 23:05:52.072: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 237.809776ms)
Dec  8 23:05:52.206: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 133.338777ms)
Dec  8 23:05:52.206: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 133.909112ms)
Dec  8 23:05:52.207: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 134.143255ms)
Dec  8 23:05:52.207: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 133.363157ms)
Dec  8 23:05:52.207: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 133.788678ms)
Dec  8 23:05:52.210: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 137.460975ms)
Dec  8 23:05:52.210: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 137.590657ms)
Dec  8 23:05:52.211: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 137.881487ms)
Dec  8 23:05:52.211: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 139.051064ms)
Dec  8 23:05:52.212: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 138.552972ms)
Dec  8 23:05:52.212: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 139.375925ms)
Dec  8 23:05:52.231: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 157.295479ms)
Dec  8 23:05:52.232: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 159.359844ms)
Dec  8 23:05:52.232: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 160.003989ms)
Dec  8 23:05:52.232: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 159.477329ms)
Dec  8 23:05:52.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 159.610425ms)
Dec  8 23:05:52.341: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 107.512315ms)
Dec  8 23:05:52.342: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 108.302137ms)
Dec  8 23:05:52.342: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 108.789881ms)
Dec  8 23:05:52.344: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 110.492932ms)
Dec  8 23:05:52.344: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 110.887725ms)
Dec  8 23:05:52.344: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 110.419484ms)
Dec  8 23:05:52.346: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 112.378073ms)
Dec  8 23:05:52.346: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 113.052478ms)
Dec  8 23:05:52.347: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 113.408802ms)
Dec  8 23:05:52.347: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 113.652542ms)
Dec  8 23:05:52.347: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 113.446726ms)
Dec  8 23:05:52.365: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 131.114719ms)
Dec  8 23:05:52.365: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 131.989199ms)
Dec  8 23:05:52.385: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 150.710771ms)
Dec  8 23:05:52.385: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 151.370155ms)
Dec  8 23:05:52.385: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 151.811572ms)
Dec  8 23:05:52.488: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 101.44393ms)
Dec  8 23:05:52.488: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 101.904291ms)
Dec  8 23:05:52.488: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 101.948684ms)
Dec  8 23:05:52.489: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 103.676855ms)
Dec  8 23:05:52.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 103.986869ms)
Dec  8 23:05:52.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 104.478784ms)
Dec  8 23:05:52.493: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 107.183458ms)
Dec  8 23:05:52.493: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 107.58326ms)
Dec  8 23:05:52.494: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 107.844328ms)
Dec  8 23:05:52.494: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 107.723681ms)
Dec  8 23:05:52.495: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 109.295247ms)
Dec  8 23:05:52.517: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 131.115068ms)
Dec  8 23:05:52.517: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 131.259469ms)
Dec  8 23:05:52.519: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 133.097227ms)
Dec  8 23:05:52.519: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 132.815661ms)
Dec  8 23:05:52.519: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 133.155389ms)
Dec  8 23:05:52.647: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 127.253716ms)
Dec  8 23:05:52.648: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 128.033333ms)
Dec  8 23:05:52.649: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 128.85891ms)
Dec  8 23:05:52.649: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 129.237538ms)
Dec  8 23:05:52.649: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 129.721715ms)
Dec  8 23:05:52.652: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 132.022337ms)
Dec  8 23:05:52.653: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 132.757168ms)
Dec  8 23:05:52.653: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 133.43847ms)
Dec  8 23:05:52.653: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 133.695718ms)
Dec  8 23:05:52.653: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 133.925954ms)
Dec  8 23:05:52.668: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 147.330037ms)
Dec  8 23:05:52.687: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 167.885084ms)
Dec  8 23:05:52.689: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 169.580492ms)
Dec  8 23:05:52.689: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 169.984619ms)
Dec  8 23:05:52.690: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 170.595361ms)
Dec  8 23:05:52.690: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 169.680053ms)
Dec  8 23:05:52.802: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 111.539089ms)
Dec  8 23:05:52.803: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 112.677655ms)
Dec  8 23:05:52.804: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 113.650808ms)
Dec  8 23:05:52.808: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 118.013891ms)
Dec  8 23:05:52.811: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 121.176093ms)
Dec  8 23:05:52.812: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 121.555426ms)
Dec  8 23:05:52.812: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 121.955687ms)
Dec  8 23:05:52.812: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 121.237838ms)
Dec  8 23:05:52.835: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 144.811312ms)
Dec  8 23:05:52.836: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 144.833141ms)
Dec  8 23:05:52.854: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 162.478947ms)
Dec  8 23:05:52.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 164.33105ms)
Dec  8 23:05:52.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 164.767295ms)
Dec  8 23:05:52.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 164.692728ms)
Dec  8 23:05:52.856: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 165.203519ms)
Dec  8 23:05:52.856: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 164.855604ms)
Dec  8 23:05:52.975: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 118.703813ms)
Dec  8 23:05:52.975: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 119.127528ms)
Dec  8 23:05:52.976: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 119.665224ms)
Dec  8 23:05:52.976: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 119.586021ms)
Dec  8 23:05:52.976: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 119.836524ms)
Dec  8 23:05:52.977: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 120.226494ms)
Dec  8 23:05:52.977: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 120.336021ms)
Dec  8 23:05:53.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 169.419655ms)
Dec  8 23:05:53.048: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 190.550742ms)
Dec  8 23:05:53.049: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 191.827326ms)
Dec  8 23:05:53.049: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 192.48917ms)
Dec  8 23:05:53.049: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 193.357811ms)
Dec  8 23:05:53.050: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 192.249615ms)
Dec  8 23:05:53.050: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 193.074582ms)
Dec  8 23:05:53.050: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 193.018944ms)
Dec  8 23:05:53.086: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 229.352699ms)
Dec  8 23:05:53.191: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 103.112169ms)
Dec  8 23:05:53.191: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 103.646215ms)
Dec  8 23:05:53.192: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 103.864464ms)
Dec  8 23:05:53.192: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 104.305023ms)
Dec  8 23:05:53.192: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 105.140338ms)
Dec  8 23:05:53.195: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 108.599457ms)
Dec  8 23:05:53.196: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 109.159743ms)
Dec  8 23:05:53.197: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 109.477522ms)
Dec  8 23:05:53.197: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 109.744446ms)
Dec  8 23:05:53.197: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 109.215628ms)
Dec  8 23:05:53.219: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 132.654792ms)
Dec  8 23:05:53.220: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 132.758877ms)
Dec  8 23:05:53.221: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 133.654669ms)
Dec  8 23:05:53.221: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 133.979893ms)
Dec  8 23:05:53.222: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 135.07241ms)
Dec  8 23:05:53.222: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 133.991665ms)
Dec  8 23:05:53.332: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 108.960853ms)
Dec  8 23:05:53.333: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 109.812544ms)
Dec  8 23:05:53.334: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 110.748558ms)
Dec  8 23:05:53.334: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 111.446074ms)
Dec  8 23:05:53.334: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 111.921209ms)
Dec  8 23:05:53.335: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 112.191259ms)
Dec  8 23:05:53.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 114.661643ms)
Dec  8 23:05:53.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 115.483067ms)
Dec  8 23:05:53.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 116.709369ms)
Dec  8 23:05:53.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 115.35044ms)
Dec  8 23:05:53.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 116.662997ms)
Dec  8 23:05:53.373: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 150.292881ms)
Dec  8 23:05:53.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 150.911649ms)
Dec  8 23:05:53.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 152.491279ms)
Dec  8 23:05:53.375: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 151.843396ms)
Dec  8 23:05:53.375: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 153.006428ms)
Dec  8 23:05:53.476: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 100.230725ms)
Dec  8 23:05:53.477: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 101.072749ms)
Dec  8 23:05:53.497: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 121.679242ms)
Dec  8 23:05:53.498: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 122.225132ms)
Dec  8 23:05:53.498: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 123.090741ms)
Dec  8 23:05:53.499: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 123.448087ms)
Dec  8 23:05:53.499: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 122.86014ms)
Dec  8 23:05:53.501: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 126.089646ms)
Dec  8 23:05:53.502: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 126.319184ms)
Dec  8 23:05:53.502: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 126.181189ms)
Dec  8 23:05:53.503: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 127.170023ms)
Dec  8 23:05:53.512: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 136.377275ms)
Dec  8 23:05:53.515: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 139.83763ms)
Dec  8 23:05:53.516: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 140.663017ms)
Dec  8 23:05:53.516: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 140.54847ms)
Dec  8 23:05:53.516: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 139.995319ms)
Dec  8 23:05:53.539: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 22.629646ms)
Dec  8 23:05:53.540: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 23.825568ms)
Dec  8 23:05:53.544: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 27.228463ms)
Dec  8 23:05:53.545: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 28.014586ms)
Dec  8 23:05:53.548: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 30.693245ms)
Dec  8 23:05:53.548: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 31.546791ms)
Dec  8 23:05:53.549: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 32.627784ms)
Dec  8 23:05:53.550: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 33.286344ms)
Dec  8 23:05:53.550: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 33.200993ms)
Dec  8 23:05:53.551: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 33.874355ms)
Dec  8 23:05:53.551: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 33.625377ms)
Dec  8 23:05:53.551: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 34.46698ms)
Dec  8 23:05:53.551: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 34.750885ms)
Dec  8 23:05:53.552: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 34.853475ms)
Dec  8 23:05:53.553: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 36.381972ms)
Dec  8 23:05:53.553: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 36.96886ms)
Dec  8 23:05:53.577: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 23.073674ms)
Dec  8 23:05:53.577: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 23.325771ms)
Dec  8 23:05:53.579: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 25.544843ms)
Dec  8 23:05:53.579: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 26.081628ms)
Dec  8 23:05:53.584: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 31.067734ms)
Dec  8 23:05:53.585: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 30.817544ms)
Dec  8 23:05:53.586: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 32.273673ms)
Dec  8 23:05:53.588: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 34.098193ms)
Dec  8 23:05:53.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 35.165557ms)
Dec  8 23:05:53.590: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 35.963296ms)
Dec  8 23:05:53.590: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 35.965577ms)
Dec  8 23:05:53.591: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 36.571203ms)
Dec  8 23:05:53.591: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 37.297383ms)
Dec  8 23:05:53.592: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 38.401231ms)
Dec  8 23:05:53.592: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 37.928561ms)
Dec  8 23:05:53.593: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 39.105311ms)
Dec  8 23:05:53.616: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 22.17686ms)
Dec  8 23:05:53.621: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 27.579545ms)
Dec  8 23:05:53.621: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 27.952156ms)
Dec  8 23:05:53.621: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 27.541722ms)
Dec  8 23:05:53.623: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 29.470637ms)
Dec  8 23:05:53.623: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 29.816318ms)
Dec  8 23:05:53.623: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 30.255736ms)
Dec  8 23:05:53.624: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 30.180824ms)
Dec  8 23:05:53.626: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 31.549472ms)
Dec  8 23:05:53.627: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 33.577204ms)
Dec  8 23:05:53.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 34.932915ms)
Dec  8 23:05:53.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 35.627893ms)
Dec  8 23:05:53.630: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 36.098847ms)
Dec  8 23:05:53.631: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 36.898941ms)
Dec  8 23:05:53.631: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 37.752083ms)
Dec  8 23:05:53.631: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 37.794737ms)
Dec  8 23:05:53.651: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:1080/proxy/... (200; 19.462269ms)
Dec  8 23:05:53.654: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:462/proxy/: tls qux (200; 22.216487ms)
Dec  8 23:05:53.656: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:460/proxy/: tls baz (200; 24.550033ms)
Dec  8 23:05:53.662: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:1080/proxy/rewri... (200; 29.917966ms)
Dec  8 23:05:53.662: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 30.694661ms)
Dec  8 23:05:53.665: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname1/proxy/: tls baz (200; 33.104528ms)
Dec  8 23:05:53.665: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk/proxy/rewriteme"... (200; 33.056804ms)
Dec  8 23:05:53.666: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/https:proxy-service-r9rq4-dvrzk:443/proxy/... (200; 33.593653ms)
Dec  8 23:05:53.667: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/https:proxy-service-r9rq4:tlsportname2/proxy/: tls qux (200; 35.130885ms)
Dec  8 23:05:53.667: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname2/proxy/: bar (200; 35.47523ms)
Dec  8 23:05:53.667: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:162/proxy/: bar (200; 35.125512ms)
Dec  8 23:05:53.668: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/http:proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 35.631919ms)
Dec  8 23:05:53.668: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/pods/proxy-service-r9rq4-dvrzk:160/proxy/: foo (200; 35.360305ms)
Dec  8 23:05:53.670: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/proxy-service-r9rq4:portname1/proxy/: foo (200; 37.578773ms)
Dec  8 23:05:53.670: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname1/proxy/: foo (200; 37.67299ms)
Dec  8 23:05:53.670: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jwt7p/services/http:proxy-service-r9rq4:portname2/proxy/: bar (200; 38.346495ms)
STEP: deleting { ReplicationController} proxy-service-r9rq4 in namespace e2e-tests-proxy-jwt7p, will wait for the garbage collector to delete the pods
Dec  8 23:05:53.734: INFO: Deleting { ReplicationController} proxy-service-r9rq4 took: 9.526906ms
Dec  8 23:05:53.835: INFO: Terminating { ReplicationController} proxy-service-r9rq4 pods took: 100.19304ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:05:55.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jwt7p" for this suite.
Dec  8 23:06:01.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:06:01.699: INFO: namespace: e2e-tests-proxy-jwt7p, resource: bindings, ignored listing per whitelist
Dec  8 23:06:01.771: INFO: namespace e2e-tests-proxy-jwt7p deletion completed in 6.332085877s

• [SLOW TEST:16.445 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:06:01.772: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  8 23:06:01.874: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-45bzx,SelfLink:/api/v1/namespaces/e2e-tests-watch-45bzx/configmaps/e2e-watch-test-resource-version,UID:d4ea0362-fb3d-11e8-a35e-42010a800004,ResourceVersion:27465,Generation:0,CreationTimestamp:2018-12-08 23:06:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 23:06:01.875: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-45bzx,SelfLink:/api/v1/namespaces/e2e-tests-watch-45bzx/configmaps/e2e-watch-test-resource-version,UID:d4ea0362-fb3d-11e8-a35e-42010a800004,ResourceVersion:27466,Generation:0,CreationTimestamp:2018-12-08 23:06:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:06:01.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-45bzx" for this suite.
Dec  8 23:06:07.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:06:08.043: INFO: namespace: e2e-tests-watch-45bzx, resource: bindings, ignored listing per whitelist
Dec  8 23:06:08.059: INFO: namespace e2e-tests-watch-45bzx deletion completed in 6.180503931s

• [SLOW TEST:6.287 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:06:08.059: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 23:06:08.130: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Dec  8 23:06:08.138: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hlmvv/daemonsets","resourceVersion":"27476"},"items":null}

Dec  8 23:06:08.142: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hlmvv/pods","resourceVersion":"27476"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:06:08.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hlmvv" for this suite.
Dec  8 23:06:14.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:06:14.259: INFO: namespace: e2e-tests-daemonsets-hlmvv, resource: bindings, ignored listing per whitelist
Dec  8 23:06:14.280: INFO: namespace e2e-tests-daemonsets-hlmvv deletion completed in 6.126879104s

S [SKIPPING] [6.221 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  8 23:06:08.130: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:06:14.281: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  8 23:06:14.350: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-960662691 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:06:14.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z6zw8" for this suite.
Dec  8 23:06:20.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:06:20.542: INFO: namespace: e2e-tests-kubectl-z6zw8, resource: bindings, ignored listing per whitelist
Dec  8 23:06:20.612: INFO: namespace e2e-tests-kubectl-z6zw8 deletion completed in 6.150345902s

• [SLOW TEST:6.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:06:20.612: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e0233d35-fb3d-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 23:06:20.697: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e02429e8-fb3d-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-n4kh5" to be "success or failure"
Dec  8 23:06:20.705: INFO: Pod "pod-projected-secrets-e02429e8-fb3d-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.224108ms
Dec  8 23:06:22.709: INFO: Pod "pod-projected-secrets-e02429e8-fb3d-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012334747s
STEP: Saw pod success
Dec  8 23:06:22.709: INFO: Pod "pod-projected-secrets-e02429e8-fb3d-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:06:22.712: INFO: Trying to get logs from node compliancetest pod pod-projected-secrets-e02429e8-fb3d-11e8-8c59-ae6969886d1b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 23:06:22.749: INFO: Waiting for pod pod-projected-secrets-e02429e8-fb3d-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:06:22.755: INFO: Pod pod-projected-secrets-e02429e8-fb3d-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:06:22.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n4kh5" for this suite.
Dec  8 23:06:28.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:06:28.914: INFO: namespace: e2e-tests-projected-n4kh5, resource: bindings, ignored listing per whitelist
Dec  8 23:06:28.963: INFO: namespace e2e-tests-projected-n4kh5 deletion completed in 6.202081182s

• [SLOW TEST:8.351 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:06:28.963: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-526pr.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-526pr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-526pr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-526pr.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-526pr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-526pr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  8 23:06:41.194: INFO: DNS probes using e2e-tests-dns-526pr/dns-test-e51ef6fc-fb3d-11e8-8c59-ae6969886d1b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:06:41.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-526pr" for this suite.
Dec  8 23:06:47.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:06:47.387: INFO: namespace: e2e-tests-dns-526pr, resource: bindings, ignored listing per whitelist
Dec  8 23:06:47.473: INFO: namespace e2e-tests-dns-526pr deletion completed in 6.176563908s

• [SLOW TEST:18.510 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:06:47.473: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 23:06:47.553: INFO: Creating ReplicaSet my-hostname-basic-f0280317-fb3d-11e8-8c59-ae6969886d1b
Dec  8 23:06:47.565: INFO: Pod name my-hostname-basic-f0280317-fb3d-11e8-8c59-ae6969886d1b: Found 0 pods out of 1
Dec  8 23:06:52.569: INFO: Pod name my-hostname-basic-f0280317-fb3d-11e8-8c59-ae6969886d1b: Found 1 pods out of 1
Dec  8 23:06:52.569: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f0280317-fb3d-11e8-8c59-ae6969886d1b" is running
Dec  8 23:06:52.572: INFO: Pod "my-hostname-basic-f0280317-fb3d-11e8-8c59-ae6969886d1b-8xb5n" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 23:06:47 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 23:06:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 23:06:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 23:06:47 +0000 UTC Reason: Message:}])
Dec  8 23:06:52.573: INFO: Trying to dial the pod
Dec  8 23:06:57.607: INFO: Controller my-hostname-basic-f0280317-fb3d-11e8-8c59-ae6969886d1b: Got expected result from replica 1 [my-hostname-basic-f0280317-fb3d-11e8-8c59-ae6969886d1b-8xb5n]: "my-hostname-basic-f0280317-fb3d-11e8-8c59-ae6969886d1b-8xb5n", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:06:57.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-kmsj7" for this suite.
Dec  8 23:07:03.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:07:03.730: INFO: namespace: e2e-tests-replicaset-kmsj7, resource: bindings, ignored listing per whitelist
Dec  8 23:07:03.750: INFO: namespace e2e-tests-replicaset-kmsj7 deletion completed in 6.138813234s

• [SLOW TEST:16.277 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:07:03.751: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 23:07:03.833: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:07:07.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-qs87c" for this suite.
Dec  8 23:07:29.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:07:29.801: INFO: namespace: e2e-tests-init-container-qs87c, resource: bindings, ignored listing per whitelist
Dec  8 23:07:29.906: INFO: namespace e2e-tests-init-container-qs87c deletion completed in 22.182878797s

• [SLOW TEST:26.156 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:07:29.907: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-09715edf-fb3e-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 23:07:29.992: INFO: Waiting up to 5m0s for pod "pod-configmaps-0972140e-fb3e-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-configmap-vqqtn" to be "success or failure"
Dec  8 23:07:30.020: INFO: Pod "pod-configmaps-0972140e-fb3e-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.012193ms
Dec  8 23:07:32.033: INFO: Pod "pod-configmaps-0972140e-fb3e-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041070451s
STEP: Saw pod success
Dec  8 23:07:32.033: INFO: Pod "pod-configmaps-0972140e-fb3e-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:07:32.039: INFO: Trying to get logs from node compliancetest pod pod-configmaps-0972140e-fb3e-11e8-8c59-ae6969886d1b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 23:07:32.143: INFO: Waiting for pod pod-configmaps-0972140e-fb3e-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:07:32.160: INFO: Pod pod-configmaps-0972140e-fb3e-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:07:32.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vqqtn" for this suite.
Dec  8 23:07:38.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:07:38.223: INFO: namespace: e2e-tests-configmap-vqqtn, resource: bindings, ignored listing per whitelist
Dec  8 23:07:38.315: INFO: namespace e2e-tests-configmap-vqqtn deletion completed in 6.149403477s

• [SLOW TEST:8.409 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:07:38.316: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  8 23:07:38.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:07:38.658: INFO: stderr: ""
Dec  8 23:07:38.658: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 23:07:38.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:07:38.918: INFO: stderr: ""
Dec  8 23:07:38.918: INFO: stdout: "update-demo-nautilus-nv5n4 update-demo-nautilus-rr5xq "
Dec  8 23:07:38.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-nv5n4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:07:39.062: INFO: stderr: ""
Dec  8 23:07:39.062: INFO: stdout: ""
Dec  8 23:07:39.062: INFO: update-demo-nautilus-nv5n4 is created but not running
Dec  8 23:07:44.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:07:44.186: INFO: stderr: ""
Dec  8 23:07:44.186: INFO: stdout: "update-demo-nautilus-nv5n4 update-demo-nautilus-rr5xq "
Dec  8 23:07:44.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-nv5n4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:07:44.306: INFO: stderr: ""
Dec  8 23:07:44.306: INFO: stdout: "true"
Dec  8 23:07:44.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-nv5n4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:07:44.452: INFO: stderr: ""
Dec  8 23:07:44.452: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 23:07:44.452: INFO: validating pod update-demo-nautilus-nv5n4
Dec  8 23:07:44.479: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 23:07:44.479: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 23:07:44.479: INFO: update-demo-nautilus-nv5n4 is verified up and running
Dec  8 23:07:44.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-rr5xq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:07:44.597: INFO: stderr: ""
Dec  8 23:07:44.597: INFO: stdout: "true"
Dec  8 23:07:44.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-rr5xq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:07:44.716: INFO: stderr: ""
Dec  8 23:07:44.716: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 23:07:44.716: INFO: validating pod update-demo-nautilus-rr5xq
Dec  8 23:07:44.720: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 23:07:44.720: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 23:07:44.720: INFO: update-demo-nautilus-rr5xq is verified up and running
STEP: rolling-update to new replication controller
Dec  8 23:07:44.722: INFO: scanned /root for discovery docs: <nil>
Dec  8 23:07:44.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:08:07.550: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  8 23:08:07.550: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 23:08:07.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:08:07.694: INFO: stderr: ""
Dec  8 23:08:07.694: INFO: stdout: "update-demo-kitten-m5n8f update-demo-kitten-mlqkt "
Dec  8 23:08:07.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-kitten-m5n8f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:08:07.822: INFO: stderr: ""
Dec  8 23:08:07.822: INFO: stdout: "true"
Dec  8 23:08:07.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-kitten-m5n8f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:08:07.946: INFO: stderr: ""
Dec  8 23:08:07.946: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  8 23:08:07.946: INFO: validating pod update-demo-kitten-m5n8f
Dec  8 23:08:07.951: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  8 23:08:07.952: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  8 23:08:07.952: INFO: update-demo-kitten-m5n8f is verified up and running
Dec  8 23:08:07.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-kitten-mlqkt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:08:08.071: INFO: stderr: ""
Dec  8 23:08:08.071: INFO: stdout: "true"
Dec  8 23:08:08.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-kitten-mlqkt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vq8w8'
Dec  8 23:08:08.193: INFO: stderr: ""
Dec  8 23:08:08.193: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  8 23:08:08.193: INFO: validating pod update-demo-kitten-mlqkt
Dec  8 23:08:08.197: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  8 23:08:08.197: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  8 23:08:08.197: INFO: update-demo-kitten-mlqkt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:08:08.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vq8w8" for this suite.
Dec  8 23:08:32.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:08:32.353: INFO: namespace: e2e-tests-kubectl-vq8w8, resource: bindings, ignored listing per whitelist
Dec  8 23:08:32.391: INFO: namespace e2e-tests-kubectl-vq8w8 deletion completed in 24.18995707s

• [SLOW TEST:54.075 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:08:32.391: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 23:08:32.468: INFO: (0) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.436238ms)
Dec  8 23:08:32.472: INFO: (1) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.082929ms)
Dec  8 23:08:32.477: INFO: (2) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.33116ms)
Dec  8 23:08:32.481: INFO: (3) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.300103ms)
Dec  8 23:08:32.486: INFO: (4) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.327264ms)
Dec  8 23:08:32.490: INFO: (5) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.014934ms)
Dec  8 23:08:32.494: INFO: (6) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.139459ms)
Dec  8 23:08:32.498: INFO: (7) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.051073ms)
Dec  8 23:08:32.503: INFO: (8) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.812467ms)
Dec  8 23:08:32.513: INFO: (9) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 9.644897ms)
Dec  8 23:08:32.520: INFO: (10) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 7.217875ms)
Dec  8 23:08:32.525: INFO: (11) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.805217ms)
Dec  8 23:08:32.529: INFO: (12) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.091771ms)
Dec  8 23:08:32.533: INFO: (13) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.243017ms)
Dec  8 23:08:32.538: INFO: (14) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.90584ms)
Dec  8 23:08:32.543: INFO: (15) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.916448ms)
Dec  8 23:08:32.550: INFO: (16) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 7.073454ms)
Dec  8 23:08:32.555: INFO: (17) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.874268ms)
Dec  8 23:08:32.560: INFO: (18) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.79087ms)
Dec  8 23:08:32.565: INFO: (19) /api/v1/nodes/compliancetest:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.93356ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:08:32.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-k2hhk" for this suite.
Dec  8 23:08:38.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:08:38.660: INFO: namespace: e2e-tests-proxy-k2hhk, resource: bindings, ignored listing per whitelist
Dec  8 23:08:38.703: INFO: namespace e2e-tests-proxy-k2hhk deletion completed in 6.133881795s

• [SLOW TEST:6.312 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:08:38.704: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  8 23:08:38.778: INFO: Waiting up to 5m0s for pod "client-containers-327223f2-fb3e-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-containers-8vc82" to be "success or failure"
Dec  8 23:08:38.784: INFO: Pod "client-containers-327223f2-fb3e-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.349672ms
Dec  8 23:08:40.788: INFO: Pod "client-containers-327223f2-fb3e-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009618443s
STEP: Saw pod success
Dec  8 23:08:40.788: INFO: Pod "client-containers-327223f2-fb3e-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:08:40.792: INFO: Trying to get logs from node compliancetest pod client-containers-327223f2-fb3e-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 23:08:40.859: INFO: Waiting for pod client-containers-327223f2-fb3e-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:08:40.873: INFO: Pod client-containers-327223f2-fb3e-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:08:40.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8vc82" for this suite.
Dec  8 23:08:46.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:08:46.994: INFO: namespace: e2e-tests-containers-8vc82, resource: bindings, ignored listing per whitelist
Dec  8 23:08:47.055: INFO: namespace e2e-tests-containers-8vc82 deletion completed in 6.163421249s

• [SLOW TEST:8.351 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:08:47.055: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 23:08:47.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-wm2bh'
Dec  8 23:08:47.314: INFO: stderr: ""
Dec  8 23:08:47.314: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  8 23:08:52.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-wm2bh -o json'
Dec  8 23:08:52.504: INFO: stderr: ""
Dec  8 23:08:52.504: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-08T23:08:47Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-wm2bh\",\n        \"resourceVersion\": \"27881\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-wm2bh/pods/e2e-test-nginx-pod\",\n        \"uid\": \"3783fd51-fb3e-11e8-a35e-42010a800004\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-j5zhv\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"compliancetest\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-j5zhv\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-j5zhv\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T23:08:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T23:08:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T23:08:48Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T23:08:47Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://56e409d2f7a2e969267e5d06253c975581d076dd8f358b424932127dd677fe66\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-08T23:08:48Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.128.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.0.62\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-08T23:08:47Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  8 23:08:52.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 replace -f - --namespace=e2e-tests-kubectl-wm2bh'
Dec  8 23:08:52.776: INFO: stderr: ""
Dec  8 23:08:52.776: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Dec  8 23:08:52.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-wm2bh'
Dec  8 23:09:04.862: INFO: stderr: ""
Dec  8 23:09:04.862: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:09:04.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wm2bh" for this suite.
Dec  8 23:09:10.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:09:11.032: INFO: namespace: e2e-tests-kubectl-wm2bh, resource: bindings, ignored listing per whitelist
Dec  8 23:09:11.037: INFO: namespace e2e-tests-kubectl-wm2bh deletion completed in 6.157872074s

• [SLOW TEST:23.982 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:09:11.038: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-zdnh
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 23:09:11.134: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zdnh" in namespace "e2e-tests-subpath-85k4p" to be "success or failure"
Dec  8 23:09:11.178: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Pending", Reason="", readiness=false. Elapsed: 43.972307ms
Dec  8 23:09:13.182: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048131717s
Dec  8 23:09:15.187: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 4.052747694s
Dec  8 23:09:17.191: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 6.056548582s
Dec  8 23:09:19.194: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 8.060108069s
Dec  8 23:09:21.198: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 10.064253109s
Dec  8 23:09:23.203: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 12.068571123s
Dec  8 23:09:25.206: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 14.072358017s
Dec  8 23:09:27.211: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 16.077085566s
Dec  8 23:09:29.216: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 18.08167493s
Dec  8 23:09:31.234: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 20.09968936s
Dec  8 23:09:33.244: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Running", Reason="", readiness=false. Elapsed: 22.109942892s
Dec  8 23:09:35.248: INFO: Pod "pod-subpath-test-configmap-zdnh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.114160093s
STEP: Saw pod success
Dec  8 23:09:35.248: INFO: Pod "pod-subpath-test-configmap-zdnh" satisfied condition "success or failure"
Dec  8 23:09:35.252: INFO: Trying to get logs from node compliancetest pod pod-subpath-test-configmap-zdnh container test-container-subpath-configmap-zdnh: <nil>
STEP: delete the pod
Dec  8 23:09:35.282: INFO: Waiting for pod pod-subpath-test-configmap-zdnh to disappear
Dec  8 23:09:35.289: INFO: Pod pod-subpath-test-configmap-zdnh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zdnh
Dec  8 23:09:35.289: INFO: Deleting pod "pod-subpath-test-configmap-zdnh" in namespace "e2e-tests-subpath-85k4p"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:09:35.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-85k4p" for this suite.
Dec  8 23:09:41.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:09:41.417: INFO: namespace: e2e-tests-subpath-85k4p, resource: bindings, ignored listing per whitelist
Dec  8 23:09:41.427: INFO: namespace e2e-tests-subpath-85k4p deletion completed in 6.131149843s

• [SLOW TEST:30.389 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:09:41.427: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  8 23:09:44.035: INFO: Successfully updated pod "pod-update-57d5cf5f-fb3e-11e8-8c59-ae6969886d1b"
STEP: verifying the updated pod is in kubernetes
Dec  8 23:09:44.042: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:09:44.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-br5sr" for this suite.
Dec  8 23:10:06.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:10:06.100: INFO: namespace: e2e-tests-pods-br5sr, resource: bindings, ignored listing per whitelist
Dec  8 23:10:06.186: INFO: namespace e2e-tests-pods-br5sr deletion completed in 22.138515247s

• [SLOW TEST:24.758 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:10:06.186: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  8 23:10:06.282: INFO: Waiting up to 5m0s for pod "pod-6699fbbb-fb3e-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-lp7gp" to be "success or failure"
Dec  8 23:10:06.288: INFO: Pod "pod-6699fbbb-fb3e-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.425817ms
Dec  8 23:10:08.292: INFO: Pod "pod-6699fbbb-fb3e-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009895347s
STEP: Saw pod success
Dec  8 23:10:08.292: INFO: Pod "pod-6699fbbb-fb3e-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:10:08.295: INFO: Trying to get logs from node compliancetest pod pod-6699fbbb-fb3e-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 23:10:08.327: INFO: Waiting for pod pod-6699fbbb-fb3e-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:10:08.332: INFO: Pod pod-6699fbbb-fb3e-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:10:08.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lp7gp" for this suite.
Dec  8 23:10:14.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:10:14.400: INFO: namespace: e2e-tests-emptydir-lp7gp, resource: bindings, ignored listing per whitelist
Dec  8 23:10:14.515: INFO: namespace e2e-tests-emptydir-lp7gp deletion completed in 6.178845448s

• [SLOW TEST:8.329 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:10:14.515: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  8 23:10:18.672: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:18.691: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:20.691: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:20.695: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:22.691: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:22.696: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:24.691: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:24.695: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:26.691: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:26.696: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:28.692: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:28.696: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:30.691: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:30.696: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:32.692: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:32.711: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:34.691: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:34.703: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:36.692: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:36.698: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 23:10:38.691: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 23:10:38.696: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:10:38.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jq22z" for this suite.
Dec  8 23:11:00.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:11:00.824: INFO: namespace: e2e-tests-container-lifecycle-hook-jq22z, resource: bindings, ignored listing per whitelist
Dec  8 23:11:00.862: INFO: namespace e2e-tests-container-lifecycle-hook-jq22z deletion completed in 22.161508422s

• [SLOW TEST:46.347 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:11:00.863: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 23:11:00.940: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 23:11:00.956: INFO: Number of nodes with available pods: 0
Dec  8 23:11:00.956: INFO: Node compliancetest is running more than one daemon pod
Dec  8 23:11:01.966: INFO: Number of nodes with available pods: 0
Dec  8 23:11:01.966: INFO: Node compliancetest is running more than one daemon pod
Dec  8 23:11:02.965: INFO: Number of nodes with available pods: 0
Dec  8 23:11:02.965: INFO: Node compliancetest is running more than one daemon pod
Dec  8 23:11:03.965: INFO: Number of nodes with available pods: 1
Dec  8 23:11:03.965: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  8 23:11:03.999: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:05.011: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:06.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:07.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:08.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:09.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:10.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:11.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:12.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:13.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:14.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:15.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:16.008: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:17.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:18.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:19.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:20.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:21.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:22.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:23.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:24.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:25.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:26.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:27.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:28.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:29.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:30.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:31.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:32.019: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:33.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:34.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:35.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:36.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:36.009: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:37.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:37.009: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:38.008: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:38.008: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:39.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:39.010: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:40.011: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:40.011: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:41.010: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:41.010: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:42.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:42.009: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:43.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:43.009: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:44.009: INFO: Wrong image for pod: daemon-set-fvv75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 23:11:44.009: INFO: Pod daemon-set-fvv75 is not available
Dec  8 23:11:45.011: INFO: Pod daemon-set-gdlfr is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  8 23:11:45.024: INFO: Number of nodes with available pods: 0
Dec  8 23:11:45.025: INFO: Node compliancetest is running more than one daemon pod
Dec  8 23:11:46.033: INFO: Number of nodes with available pods: 0
Dec  8 23:11:46.033: INFO: Node compliancetest is running more than one daemon pod
Dec  8 23:11:47.033: INFO: Number of nodes with available pods: 1
Dec  8 23:11:47.033: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-46mnk, will wait for the garbage collector to delete the pods
Dec  8 23:11:47.115: INFO: Deleting {extensions DaemonSet} daemon-set took: 11.757568ms
Dec  8 23:11:47.216: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.400607ms
Dec  8 23:11:50.919: INFO: Number of nodes with available pods: 0
Dec  8 23:11:50.919: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 23:11:50.923: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-46mnk/daemonsets","resourceVersion":"28145"},"items":null}

Dec  8 23:11:50.926: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-46mnk/pods","resourceVersion":"28145"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:11:50.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-46mnk" for this suite.
Dec  8 23:11:56.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:11:57.024: INFO: namespace: e2e-tests-daemonsets-46mnk, resource: bindings, ignored listing per whitelist
Dec  8 23:11:57.085: INFO: namespace e2e-tests-daemonsets-46mnk deletion completed in 6.149351835s

• [SLOW TEST:56.223 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:11:57.086: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a8b21e25-fb3e-11e8-8c59-ae6969886d1b
STEP: Creating secret with name s-test-opt-upd-a8b21ef6-fb3e-11e8-8c59-ae6969886d1b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a8b21e25-fb3e-11e8-8c59-ae6969886d1b
STEP: Updating secret s-test-opt-upd-a8b21ef6-fb3e-11e8-8c59-ae6969886d1b
STEP: Creating secret with name s-test-opt-create-a8b21f13-fb3e-11e8-8c59-ae6969886d1b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:13:27.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m78mf" for this suite.
Dec  8 23:13:49.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:13:50.023: INFO: namespace: e2e-tests-secrets-m78mf, resource: bindings, ignored listing per whitelist
Dec  8 23:13:50.066: INFO: namespace e2e-tests-secrets-m78mf deletion completed in 22.179660949s

• [SLOW TEST:112.980 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:13:50.066: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 23:13:50.145: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec08fc38-fb3e-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-l7hsr" to be "success or failure"
Dec  8 23:13:50.150: INFO: Pod "downwardapi-volume-ec08fc38-fb3e-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.665465ms
Dec  8 23:13:52.154: INFO: Pod "downwardapi-volume-ec08fc38-fb3e-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009064744s
STEP: Saw pod success
Dec  8 23:13:52.154: INFO: Pod "downwardapi-volume-ec08fc38-fb3e-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:13:52.158: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-ec08fc38-fb3e-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 23:13:52.241: INFO: Waiting for pod downwardapi-volume-ec08fc38-fb3e-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:13:52.249: INFO: Pod downwardapi-volume-ec08fc38-fb3e-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:13:52.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l7hsr" for this suite.
Dec  8 23:13:58.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:13:58.390: INFO: namespace: e2e-tests-downward-api-l7hsr, resource: bindings, ignored listing per whitelist
Dec  8 23:13:58.444: INFO: namespace e2e-tests-downward-api-l7hsr deletion completed in 6.187337953s

• [SLOW TEST:8.377 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:13:58.444: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f106ea7c-fb3e-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 23:13:58.529: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f108136c-fb3e-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-7fhbl" to be "success or failure"
Dec  8 23:13:58.536: INFO: Pod "pod-projected-configmaps-f108136c-fb3e-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.46386ms
Dec  8 23:14:00.540: INFO: Pod "pod-projected-configmaps-f108136c-fb3e-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010678843s
STEP: Saw pod success
Dec  8 23:14:00.540: INFO: Pod "pod-projected-configmaps-f108136c-fb3e-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:14:00.544: INFO: Trying to get logs from node compliancetest pod pod-projected-configmaps-f108136c-fb3e-11e8-8c59-ae6969886d1b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 23:14:00.586: INFO: Waiting for pod pod-projected-configmaps-f108136c-fb3e-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:14:00.591: INFO: Pod pod-projected-configmaps-f108136c-fb3e-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:14:00.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7fhbl" for this suite.
Dec  8 23:14:06.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:14:06.663: INFO: namespace: e2e-tests-projected-7fhbl, resource: bindings, ignored listing per whitelist
Dec  8 23:14:06.746: INFO: namespace e2e-tests-projected-7fhbl deletion completed in 6.15133289s

• [SLOW TEST:8.302 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:14:06.746: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  8 23:14:06.839: INFO: Waiting up to 5m0s for pod "pod-f5fbd65b-fb3e-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-bw75s" to be "success or failure"
Dec  8 23:14:06.844: INFO: Pod "pod-f5fbd65b-fb3e-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.878743ms
Dec  8 23:14:08.848: INFO: Pod "pod-f5fbd65b-fb3e-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009054046s
STEP: Saw pod success
Dec  8 23:14:08.848: INFO: Pod "pod-f5fbd65b-fb3e-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:14:08.851: INFO: Trying to get logs from node compliancetest pod pod-f5fbd65b-fb3e-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 23:14:08.876: INFO: Waiting for pod pod-f5fbd65b-fb3e-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:14:08.881: INFO: Pod pod-f5fbd65b-fb3e-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:14:08.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bw75s" for this suite.
Dec  8 23:14:14.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:14:14.954: INFO: namespace: e2e-tests-emptydir-bw75s, resource: bindings, ignored listing per whitelist
Dec  8 23:14:15.012: INFO: namespace e2e-tests-emptydir-bw75s deletion completed in 6.127350487s

• [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:14:15.012: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-fae802db-fb3e-11e8-8c59-ae6969886d1b
STEP: Creating configMap with name cm-test-opt-upd-fae80316-fb3e-11e8-8c59-ae6969886d1b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fae802db-fb3e-11e8-8c59-ae6969886d1b
STEP: Updating configmap cm-test-opt-upd-fae80316-fb3e-11e8-8c59-ae6969886d1b
STEP: Creating configMap with name cm-test-opt-create-fae8032d-fb3e-11e8-8c59-ae6969886d1b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:15:43.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f9smd" for this suite.
Dec  8 23:16:09.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:16:09.913: INFO: namespace: e2e-tests-configmap-f9smd, resource: bindings, ignored listing per whitelist
Dec  8 23:16:09.990: INFO: namespace e2e-tests-configmap-f9smd deletion completed in 26.175975501s

• [SLOW TEST:114.977 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:16:09.990: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  8 23:16:12.083: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-3f6f8af4-fb3f-11e8-8c59-ae6969886d1b,GenerateName:,Namespace:e2e-tests-events-dsg4w,SelfLink:/api/v1/namespaces/e2e-tests-events-dsg4w/pods/send-events-3f6f8af4-fb3f-11e8-8c59-ae6969886d1b,UID:3f701abe-fb3f-11e8-a35e-42010a800004,ResourceVersion:28426,Generation:0,CreationTimestamp:2018-12-08 23:16:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 58628151,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zgdtb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zgdtb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-zgdtb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a5c7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a5c7c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 23:16:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 23:16:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 23:16:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 23:16:10 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.244.0.78,StartTime:2018-12-08 23:16:10 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-08 23:16:11 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://2b6870a6832b0b07a856483eff23d674956a14bfc0445932e764fada19fa0411}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  8 23:16:14.088: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  8 23:16:16.093: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:16:16.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-dsg4w" for this suite.
Dec  8 23:17:02.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:17:02.243: INFO: namespace: e2e-tests-events-dsg4w, resource: bindings, ignored listing per whitelist
Dec  8 23:17:02.246: INFO: namespace e2e-tests-events-dsg4w deletion completed in 46.129557267s

• [SLOW TEST:52.256 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:17:02.247: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 23:17:02.338: INFO: Waiting up to 5m0s for pod "downward-api-5e9746bb-fb3f-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-vw7k6" to be "success or failure"
Dec  8 23:17:02.355: INFO: Pod "downward-api-5e9746bb-fb3f-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.408609ms
Dec  8 23:17:04.360: INFO: Pod "downward-api-5e9746bb-fb3f-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021846718s
STEP: Saw pod success
Dec  8 23:17:04.360: INFO: Pod "downward-api-5e9746bb-fb3f-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:17:04.366: INFO: Trying to get logs from node compliancetest pod downward-api-5e9746bb-fb3f-11e8-8c59-ae6969886d1b container dapi-container: <nil>
STEP: delete the pod
Dec  8 23:17:04.443: INFO: Waiting for pod downward-api-5e9746bb-fb3f-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:17:04.451: INFO: Pod downward-api-5e9746bb-fb3f-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:17:04.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vw7k6" for this suite.
Dec  8 23:17:10.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:17:10.541: INFO: namespace: e2e-tests-downward-api-vw7k6, resource: bindings, ignored listing per whitelist
Dec  8 23:17:10.597: INFO: namespace e2e-tests-downward-api-vw7k6 deletion completed in 6.141336165s

• [SLOW TEST:8.351 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:17:10.598: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 23:17:10.660: INFO: Creating deployment "test-recreate-deployment"
Dec  8 23:17:10.666: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  8 23:17:10.674: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec  8 23:17:12.681: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  8 23:17:12.685: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  8 23:17:12.694: INFO: Updating deployment test-recreate-deployment
Dec  8 23:17:12.694: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 23:17:12.910: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-b84hw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-b84hw/deployments/test-recreate-deployment,UID:638ece3f-fb3f-11e8-a35e-42010a800004,ResourceVersion:28529,Generation:2,CreationTimestamp:2018-12-08 23:17:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-08 23:17:12 +0000 UTC 2018-12-08 23:17:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-08 23:17:12 +0000 UTC 2018-12-08 23:17:10 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  8 23:17:12.914: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-b84hw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-b84hw/replicasets/test-recreate-deployment-7cf749666b,UID:64cdcec0-fb3f-11e8-a35e-42010a800004,ResourceVersion:28525,Generation:1,CreationTimestamp:2018-12-08 23:17:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 638ece3f-fb3f-11e8-a35e-42010a800004 0xc422062b77 0xc422062b78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 23:17:12.915: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  8 23:17:12.915: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-b84hw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-b84hw/replicasets/test-recreate-deployment-79f694ff59,UID:63915d3d-fb3f-11e8-a35e-42010a800004,ResourceVersion:28517,Generation:2,CreationTimestamp:2018-12-08 23:17:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 638ece3f-fb3f-11e8-a35e-42010a800004 0xc422062ab7 0xc422062ab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 23:17:12.919: INFO: Pod "test-recreate-deployment-7cf749666b-psmct" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-psmct,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-b84hw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-b84hw/pods/test-recreate-deployment-7cf749666b-psmct,UID:64cebb92-fb3f-11e8-a35e-42010a800004,ResourceVersion:28528,Generation:0,CreationTimestamp:2018-12-08 23:17:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 64cdcec0-fb3f-11e8-a35e-42010a800004 0xc422063367 0xc422063368}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9rdlp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rdlp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rdlp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:compliancetest,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4220633e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422063400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 23:17:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 23:17:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 23:17:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 23:17:12 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-08 23:17:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:17:12.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-b84hw" for this suite.
Dec  8 23:17:18.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:17:19.018: INFO: namespace: e2e-tests-deployment-b84hw, resource: bindings, ignored listing per whitelist
Dec  8 23:17:19.108: INFO: namespace e2e-tests-deployment-b84hw deletion completed in 6.185866412s

• [SLOW TEST:8.511 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:17:19.109: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-c4qzq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 23:17:19.176: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 23:17:43.284: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.85:8080/dial?request=hostName&protocol=http&host=10.244.0.84&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-c4qzq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:17:43.284: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:17:43.394: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:17:43.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-c4qzq" for this suite.
Dec  8 23:18:07.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:18:07.467: INFO: namespace: e2e-tests-pod-network-test-c4qzq, resource: bindings, ignored listing per whitelist
Dec  8 23:18:07.541: INFO: namespace e2e-tests-pod-network-test-c4qzq deletion completed in 24.143022209s

• [SLOW TEST:48.432 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:18:07.541: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kbl9x
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-kbl9x
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-kbl9x
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-kbl9x
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-kbl9x
Dec  8 23:18:09.764: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kbl9x, name: ss-0, uid: 85b102de-fb3f-11e8-a35e-42010a800004, status phase: Pending. Waiting for statefulset controller to delete.
Dec  8 23:18:14.809: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kbl9x, name: ss-0, uid: 85b102de-fb3f-11e8-a35e-42010a800004, status phase: Failed. Waiting for statefulset controller to delete.
Dec  8 23:18:14.828: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kbl9x, name: ss-0, uid: 85b102de-fb3f-11e8-a35e-42010a800004, status phase: Failed. Waiting for statefulset controller to delete.
Dec  8 23:18:14.843: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-kbl9x
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-kbl9x
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-kbl9x and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 23:18:16.987: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kbl9x
Dec  8 23:18:16.991: INFO: Scaling statefulset ss to 0
Dec  8 23:18:27.030: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 23:18:27.035: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:18:27.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kbl9x" for this suite.
Dec  8 23:18:33.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:18:33.152: INFO: namespace: e2e-tests-statefulset-kbl9x, resource: bindings, ignored listing per whitelist
Dec  8 23:18:33.200: INFO: namespace e2e-tests-statefulset-kbl9x deletion completed in 6.136894356s

• [SLOW TEST:25.659 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:18:33.201: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 23:18:33.281: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94cbd7cf-fb3f-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-7fg54" to be "success or failure"
Dec  8 23:18:33.294: INFO: Pod "downwardapi-volume-94cbd7cf-fb3f-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.178823ms
Dec  8 23:18:35.300: INFO: Pod "downwardapi-volume-94cbd7cf-fb3f-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.018706921s
Dec  8 23:18:37.304: INFO: Pod "downwardapi-volume-94cbd7cf-fb3f-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02298546s
STEP: Saw pod success
Dec  8 23:18:37.304: INFO: Pod "downwardapi-volume-94cbd7cf-fb3f-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:18:37.381: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-94cbd7cf-fb3f-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 23:18:37.462: INFO: Waiting for pod downwardapi-volume-94cbd7cf-fb3f-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:18:37.476: INFO: Pod downwardapi-volume-94cbd7cf-fb3f-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:18:37.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7fg54" for this suite.
Dec  8 23:18:43.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:18:43.583: INFO: namespace: e2e-tests-projected-7fg54, resource: bindings, ignored listing per whitelist
Dec  8 23:18:43.659: INFO: namespace e2e-tests-projected-7fg54 deletion completed in 6.177604962s

• [SLOW TEST:10.459 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:18:43.659: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  8 23:18:43.737: INFO: Waiting up to 5m0s for pod "pod-9b07b82c-fb3f-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-emptydir-smj8n" to be "success or failure"
Dec  8 23:18:43.742: INFO: Pod "pod-9b07b82c-fb3f-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.106262ms
Dec  8 23:18:45.746: INFO: Pod "pod-9b07b82c-fb3f-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008579792s
STEP: Saw pod success
Dec  8 23:18:45.746: INFO: Pod "pod-9b07b82c-fb3f-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:18:45.750: INFO: Trying to get logs from node compliancetest pod pod-9b07b82c-fb3f-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 23:18:45.786: INFO: Waiting for pod pod-9b07b82c-fb3f-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:18:45.790: INFO: Pod pod-9b07b82c-fb3f-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:18:45.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-smj8n" for this suite.
Dec  8 23:18:51.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:18:51.907: INFO: namespace: e2e-tests-emptydir-smj8n, resource: bindings, ignored listing per whitelist
Dec  8 23:18:51.913: INFO: namespace e2e-tests-emptydir-smj8n deletion completed in 6.119568481s

• [SLOW TEST:8.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:18:51.913: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Dec  8 23:18:51.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-s6jrb'
Dec  8 23:18:52.585: INFO: stderr: ""
Dec  8 23:18:52.585: INFO: stdout: "pod/pause created\n"
Dec  8 23:18:52.585: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  8 23:18:52.585: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-s6jrb" to be "running and ready"
Dec  8 23:18:52.622: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 37.237209ms
Dec  8 23:18:54.626: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.04085056s
Dec  8 23:18:54.626: INFO: Pod "pause" satisfied condition "running and ready"
Dec  8 23:18:54.626: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  8 23:18:54.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-s6jrb'
Dec  8 23:18:54.758: INFO: stderr: ""
Dec  8 23:18:54.758: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  8 23:18:54.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pod pause -L testing-label --namespace=e2e-tests-kubectl-s6jrb'
Dec  8 23:18:54.898: INFO: stderr: ""
Dec  8 23:18:54.898: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  8 23:18:54.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 label pods pause testing-label- --namespace=e2e-tests-kubectl-s6jrb'
Dec  8 23:18:55.041: INFO: stderr: ""
Dec  8 23:18:55.041: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  8 23:18:55.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pod pause -L testing-label --namespace=e2e-tests-kubectl-s6jrb'
Dec  8 23:18:55.174: INFO: stderr: ""
Dec  8 23:18:55.174: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Dec  8 23:18:55.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s6jrb'
Dec  8 23:18:55.327: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 23:18:55.327: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  8 23:18:55.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-s6jrb'
Dec  8 23:18:55.715: INFO: stderr: "No resources found.\n"
Dec  8 23:18:55.715: INFO: stdout: ""
Dec  8 23:18:55.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -l name=pause --namespace=e2e-tests-kubectl-s6jrb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 23:18:56.000: INFO: stderr: ""
Dec  8 23:18:56.000: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:18:56.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s6jrb" for this suite.
Dec  8 23:19:02.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:19:02.102: INFO: namespace: e2e-tests-kubectl-s6jrb, resource: bindings, ignored listing per whitelist
Dec  8 23:19:02.176: INFO: namespace e2e-tests-kubectl-s6jrb deletion completed in 6.170255431s

• [SLOW TEST:10.263 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:19:02.177: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  8 23:19:06.302: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 23:19:06.306: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 23:19:08.306: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 23:19:08.320: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 23:19:10.306: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 23:19:10.310: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 23:19:12.306: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 23:19:12.312: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 23:19:14.310: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 23:19:14.314: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 23:19:16.306: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 23:19:16.310: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:19:16.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gjwxz" for this suite.
Dec  8 23:19:38.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:19:38.397: INFO: namespace: e2e-tests-container-lifecycle-hook-gjwxz, resource: bindings, ignored listing per whitelist
Dec  8 23:19:38.477: INFO: namespace e2e-tests-container-lifecycle-hook-gjwxz deletion completed in 22.163619479s

• [SLOW TEST:36.300 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:19:38.477: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  8 23:19:38.565: INFO: Waiting up to 5m0s for pod "var-expansion-bbb5b526-fb3f-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-var-expansion-qfcpn" to be "success or failure"
Dec  8 23:19:38.571: INFO: Pod "var-expansion-bbb5b526-fb3f-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758568ms
Dec  8 23:19:40.575: INFO: Pod "var-expansion-bbb5b526-fb3f-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009882568s
STEP: Saw pod success
Dec  8 23:19:40.575: INFO: Pod "var-expansion-bbb5b526-fb3f-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:19:40.579: INFO: Trying to get logs from node compliancetest pod var-expansion-bbb5b526-fb3f-11e8-8c59-ae6969886d1b container dapi-container: <nil>
STEP: delete the pod
Dec  8 23:19:40.607: INFO: Waiting for pod var-expansion-bbb5b526-fb3f-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:19:40.615: INFO: Pod var-expansion-bbb5b526-fb3f-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:19:40.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qfcpn" for this suite.
Dec  8 23:19:46.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:19:46.675: INFO: namespace: e2e-tests-var-expansion-qfcpn, resource: bindings, ignored listing per whitelist
Dec  8 23:19:46.736: INFO: namespace e2e-tests-var-expansion-qfcpn deletion completed in 6.116231161s

• [SLOW TEST:8.259 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:19:46.736: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j5v9h
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 23:19:46.810: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 23:20:12.900: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.0.97:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j5v9h PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 23:20:12.900: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
Dec  8 23:20:12.973: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:20:12.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j5v9h" for this suite.
Dec  8 23:20:37.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:20:37.118: INFO: namespace: e2e-tests-pod-network-test-j5v9h, resource: bindings, ignored listing per whitelist
Dec  8 23:20:37.126: INFO: namespace e2e-tests-pod-network-test-j5v9h deletion completed in 24.149736209s

• [SLOW TEST:50.390 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:20:37.127: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-deaa3285-fb3f-11e8-8c59-ae6969886d1b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-deaa3285-fb3f-11e8-8c59-ae6969886d1b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:20:41.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-62rsj" for this suite.
Dec  8 23:21:03.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:21:03.446: INFO: namespace: e2e-tests-configmap-62rsj, resource: bindings, ignored listing per whitelist
Dec  8 23:21:03.463: INFO: namespace e2e-tests-configmap-62rsj deletion completed in 22.140214004s

• [SLOW TEST:26.336 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:21:03.463: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ee5c1244-fb3f-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume secrets
Dec  8 23:21:03.548: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ee5cc558-fb3f-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-xnstr" to be "success or failure"
Dec  8 23:21:03.552: INFO: Pod "pod-projected-secrets-ee5cc558-fb3f-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.752985ms
Dec  8 23:21:05.557: INFO: Pod "pod-projected-secrets-ee5cc558-fb3f-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00885107s
STEP: Saw pod success
Dec  8 23:21:05.557: INFO: Pod "pod-projected-secrets-ee5cc558-fb3f-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:21:05.560: INFO: Trying to get logs from node compliancetest pod pod-projected-secrets-ee5cc558-fb3f-11e8-8c59-ae6969886d1b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 23:21:05.614: INFO: Waiting for pod pod-projected-secrets-ee5cc558-fb3f-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:21:05.619: INFO: Pod pod-projected-secrets-ee5cc558-fb3f-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:21:05.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xnstr" for this suite.
Dec  8 23:21:11.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:21:11.710: INFO: namespace: e2e-tests-projected-xnstr, resource: bindings, ignored listing per whitelist
Dec  8 23:21:11.761: INFO: namespace e2e-tests-projected-xnstr deletion completed in 6.133288248s

• [SLOW TEST:8.298 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:21:11.762: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:21:11.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-pzklc" for this suite.
Dec  8 23:21:17.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:21:17.973: INFO: namespace: e2e-tests-services-pzklc, resource: bindings, ignored listing per whitelist
Dec  8 23:21:17.993: INFO: namespace e2e-tests-services-pzklc deletion completed in 6.125489952s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.232 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:21:17.994: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  8 23:21:18.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 create -f - --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:18.371: INFO: stderr: ""
Dec  8 23:21:18.371: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 23:21:18.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:18.645: INFO: stderr: ""
Dec  8 23:21:18.646: INFO: stdout: "update-demo-nautilus-4nhqd update-demo-nautilus-pzr2v "
Dec  8 23:21:18.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-4nhqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:18.914: INFO: stderr: ""
Dec  8 23:21:18.914: INFO: stdout: ""
Dec  8 23:21:18.914: INFO: update-demo-nautilus-4nhqd is created but not running
Dec  8 23:21:23.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:24.041: INFO: stderr: ""
Dec  8 23:21:24.041: INFO: stdout: "update-demo-nautilus-4nhqd update-demo-nautilus-pzr2v "
Dec  8 23:21:24.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-4nhqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:24.163: INFO: stderr: ""
Dec  8 23:21:24.163: INFO: stdout: "true"
Dec  8 23:21:24.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-4nhqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:24.280: INFO: stderr: ""
Dec  8 23:21:24.280: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 23:21:24.280: INFO: validating pod update-demo-nautilus-4nhqd
Dec  8 23:21:24.321: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 23:21:24.321: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 23:21:24.321: INFO: update-demo-nautilus-4nhqd is verified up and running
Dec  8 23:21:24.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-pzr2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:24.445: INFO: stderr: ""
Dec  8 23:21:24.446: INFO: stdout: "true"
Dec  8 23:21:24.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods update-demo-nautilus-pzr2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:24.559: INFO: stderr: ""
Dec  8 23:21:24.559: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 23:21:24.559: INFO: validating pod update-demo-nautilus-pzr2v
Dec  8 23:21:24.565: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 23:21:24.565: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 23:21:24.565: INFO: update-demo-nautilus-pzr2v is verified up and running
STEP: using delete to clean up resources
Dec  8 23:21:24.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:24.691: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 23:21:24.691: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  8 23:21:24.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-2jsvh'
Dec  8 23:21:24.985: INFO: stderr: "No resources found.\n"
Dec  8 23:21:24.985: INFO: stdout: ""
Dec  8 23:21:24.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 get pods -l name=update-demo --namespace=e2e-tests-kubectl-2jsvh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 23:21:25.343: INFO: stderr: ""
Dec  8 23:21:25.343: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:21:25.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2jsvh" for this suite.
Dec  8 23:21:47.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:21:47.528: INFO: namespace: e2e-tests-kubectl-2jsvh, resource: bindings, ignored listing per whitelist
Dec  8 23:21:47.538: INFO: namespace e2e-tests-kubectl-2jsvh deletion completed in 22.187553054s

• [SLOW TEST:29.543 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:21:47.538: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-d49rz
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-d49rz
STEP: Deleting pre-stop pod
Dec  8 23:21:58.759: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:21:58.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-d49rz" for this suite.
Dec  8 23:22:36.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:22:37.018: INFO: namespace: e2e-tests-prestop-d49rz, resource: bindings, ignored listing per whitelist
Dec  8 23:22:37.023: INFO: namespace e2e-tests-prestop-d49rz deletion completed in 38.13314452s

• [SLOW TEST:49.485 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:22:37.023: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1208 23:22:47.124689      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 23:22:47.124: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:22:47.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nr9mw" for this suite.
Dec  8 23:22:53.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:22:53.171: INFO: namespace: e2e-tests-gc-nr9mw, resource: bindings, ignored listing per whitelist
Dec  8 23:22:53.281: INFO: namespace e2e-tests-gc-nr9mw deletion completed in 6.152344804s

• [SLOW TEST:16.257 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:22:53.281: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  8 23:22:53.362: INFO: Waiting up to 5m0s for pod "client-containers-2fd165e1-fb40-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-containers-27k79" to be "success or failure"
Dec  8 23:22:53.366: INFO: Pod "client-containers-2fd165e1-fb40-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.361981ms
Dec  8 23:22:55.370: INFO: Pod "client-containers-2fd165e1-fb40-11e8-8c59-ae6969886d1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.008156471s
Dec  8 23:22:57.374: INFO: Pod "client-containers-2fd165e1-fb40-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012440519s
STEP: Saw pod success
Dec  8 23:22:57.374: INFO: Pod "client-containers-2fd165e1-fb40-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:22:57.378: INFO: Trying to get logs from node compliancetest pod client-containers-2fd165e1-fb40-11e8-8c59-ae6969886d1b container test-container: <nil>
STEP: delete the pod
Dec  8 23:22:57.410: INFO: Waiting for pod client-containers-2fd165e1-fb40-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:22:57.417: INFO: Pod client-containers-2fd165e1-fb40-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:22:57.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-27k79" for this suite.
Dec  8 23:23:03.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:23:03.510: INFO: namespace: e2e-tests-containers-27k79, resource: bindings, ignored listing per whitelist
Dec  8 23:23:03.678: INFO: namespace e2e-tests-containers-27k79 deletion completed in 6.251496129s

• [SLOW TEST:10.397 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:23:03.678: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:24:03.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rs2wd" for this suite.
Dec  8 23:24:25.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:24:25.873: INFO: namespace: e2e-tests-container-probe-rs2wd, resource: bindings, ignored listing per whitelist
Dec  8 23:24:25.987: INFO: namespace e2e-tests-container-probe-rs2wd deletion completed in 22.168444621s

• [SLOW TEST:82.308 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:24:25.987: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 23:24:26.064: INFO: Waiting up to 5m0s for pod "downward-api-67128556-fb40-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-hnlwk" to be "success or failure"
Dec  8 23:24:26.070: INFO: Pod "downward-api-67128556-fb40-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.982173ms
Dec  8 23:24:28.074: INFO: Pod "downward-api-67128556-fb40-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009146474s
Dec  8 23:24:30.078: INFO: Pod "downward-api-67128556-fb40-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013173654s
STEP: Saw pod success
Dec  8 23:24:30.078: INFO: Pod "downward-api-67128556-fb40-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:24:30.081: INFO: Trying to get logs from node compliancetest pod downward-api-67128556-fb40-11e8-8c59-ae6969886d1b container dapi-container: <nil>
STEP: delete the pod
Dec  8 23:24:30.116: INFO: Waiting for pod downward-api-67128556-fb40-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:24:30.126: INFO: Pod downward-api-67128556-fb40-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:24:30.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hnlwk" for this suite.
Dec  8 23:24:36.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:24:36.244: INFO: namespace: e2e-tests-downward-api-hnlwk, resource: bindings, ignored listing per whitelist
Dec  8 23:24:36.275: INFO: namespace e2e-tests-downward-api-hnlwk deletion completed in 6.145186514s

• [SLOW TEST:10.288 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:24:36.276: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6d3473ff-fb40-11e8-8c59-ae6969886d1b
STEP: Creating a pod to test consume configMaps
Dec  8 23:24:36.362: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6d35251b-fb40-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-btf8z" to be "success or failure"
Dec  8 23:24:36.383: INFO: Pod "pod-projected-configmaps-6d35251b-fb40-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.538097ms
Dec  8 23:24:38.387: INFO: Pod "pod-projected-configmaps-6d35251b-fb40-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025213163s
Dec  8 23:24:40.391: INFO: Pod "pod-projected-configmaps-6d35251b-fb40-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029101631s
STEP: Saw pod success
Dec  8 23:24:40.391: INFO: Pod "pod-projected-configmaps-6d35251b-fb40-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:24:40.395: INFO: Trying to get logs from node compliancetest pod pod-projected-configmaps-6d35251b-fb40-11e8-8c59-ae6969886d1b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 23:24:40.424: INFO: Waiting for pod pod-projected-configmaps-6d35251b-fb40-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:24:40.428: INFO: Pod pod-projected-configmaps-6d35251b-fb40-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:24:40.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-btf8z" for this suite.
Dec  8 23:24:46.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:24:46.486: INFO: namespace: e2e-tests-projected-btf8z, resource: bindings, ignored listing per whitelist
Dec  8 23:24:46.579: INFO: namespace e2e-tests-projected-btf8z deletion completed in 6.146917955s

• [SLOW TEST:10.303 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:24:46.580: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 23:24:46.652: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  8 23:24:51.657: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 23:24:51.657: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 23:24:51.680: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-l4bq7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-l4bq7/deployments/test-cleanup-deployment,UID:76561ad4-fb40-11e8-a35e-42010a800004,ResourceVersion:29410,Generation:1,CreationTimestamp:2018-12-08 23:24:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  8 23:24:51.684: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:24:51.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-l4bq7" for this suite.
Dec  8 23:24:57.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:24:57.764: INFO: namespace: e2e-tests-deployment-l4bq7, resource: bindings, ignored listing per whitelist
Dec  8 23:24:57.832: INFO: namespace e2e-tests-deployment-l4bq7 deletion completed in 6.138575239s

• [SLOW TEST:11.252 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:24:57.832: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 23:25:00.456: INFO: Successfully updated pod "labelsupdate7a0e0001-fb40-11e8-8c59-ae6969886d1b"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:25:04.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pkmt7" for this suite.
Dec  8 23:25:26.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:25:26.619: INFO: namespace: e2e-tests-projected-pkmt7, resource: bindings, ignored listing per whitelist
Dec  8 23:25:26.697: INFO: namespace e2e-tests-projected-pkmt7 deletion completed in 22.175763087s

• [SLOW TEST:28.866 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:25:26.698: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 23:25:26.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b424dd9-fb40-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-downward-api-d8cbj" to be "success or failure"
Dec  8 23:25:26.779: INFO: Pod "downwardapi-volume-8b424dd9-fb40-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.279414ms
Dec  8 23:25:28.783: INFO: Pod "downwardapi-volume-8b424dd9-fb40-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008382231s
STEP: Saw pod success
Dec  8 23:25:28.783: INFO: Pod "downwardapi-volume-8b424dd9-fb40-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:25:28.786: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-8b424dd9-fb40-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 23:25:28.820: INFO: Waiting for pod downwardapi-volume-8b424dd9-fb40-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:25:28.825: INFO: Pod downwardapi-volume-8b424dd9-fb40-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:25:28.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d8cbj" for this suite.
Dec  8 23:25:34.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:25:34.943: INFO: namespace: e2e-tests-downward-api-d8cbj, resource: bindings, ignored listing per whitelist
Dec  8 23:25:34.959: INFO: namespace e2e-tests-downward-api-d8cbj deletion completed in 6.128627458s

• [SLOW TEST:8.262 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:25:34.959: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-ndrzw
I1208 23:25:35.081040      14 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-ndrzw, replica count: 1
I1208 23:25:36.131706      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 23:25:37.131956      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 23:25:38.132179      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  8 23:25:38.263: INFO: Created: latency-svc-glhkb
Dec  8 23:25:38.275: INFO: Got endpoints: latency-svc-glhkb [39.901705ms]
Dec  8 23:25:38.302: INFO: Created: latency-svc-lffvf
Dec  8 23:25:38.318: INFO: Created: latency-svc-n5wqn
Dec  8 23:25:38.329: INFO: Got endpoints: latency-svc-lffvf [53.701781ms]
Dec  8 23:25:38.345: INFO: Got endpoints: latency-svc-n5wqn [68.496548ms]
Dec  8 23:25:38.346: INFO: Created: latency-svc-2xrqn
Dec  8 23:25:38.362: INFO: Created: latency-svc-5mrzs
Dec  8 23:25:38.364: INFO: Got endpoints: latency-svc-2xrqn [88.874313ms]
Dec  8 23:25:38.377: INFO: Got endpoints: latency-svc-5mrzs [101.974136ms]
Dec  8 23:25:38.394: INFO: Created: latency-svc-zrtxn
Dec  8 23:25:38.405: INFO: Created: latency-svc-pgzm5
Dec  8 23:25:38.411: INFO: Got endpoints: latency-svc-zrtxn [135.14416ms]
Dec  8 23:25:38.431: INFO: Got endpoints: latency-svc-pgzm5 [155.752092ms]
Dec  8 23:25:38.432: INFO: Created: latency-svc-bdvhq
Dec  8 23:25:38.441: INFO: Got endpoints: latency-svc-bdvhq [165.24437ms]
Dec  8 23:25:38.453: INFO: Created: latency-svc-cgh9f
Dec  8 23:25:38.467: INFO: Created: latency-svc-gvqk8
Dec  8 23:25:38.481: INFO: Got endpoints: latency-svc-cgh9f [204.728272ms]
Dec  8 23:25:38.541: INFO: Got endpoints: latency-svc-gvqk8 [109.478048ms]
Dec  8 23:25:38.547: INFO: Created: latency-svc-qbmvd
Dec  8 23:25:38.569: INFO: Got endpoints: latency-svc-qbmvd [293.288458ms]
Dec  8 23:25:38.576: INFO: Created: latency-svc-hklv4
Dec  8 23:25:38.581: INFO: Got endpoints: latency-svc-hklv4 [304.632712ms]
Dec  8 23:25:38.594: INFO: Created: latency-svc-b9frz
Dec  8 23:25:38.606: INFO: Got endpoints: latency-svc-b9frz [330.272558ms]
Dec  8 23:25:38.617: INFO: Created: latency-svc-gpxm7
Dec  8 23:25:38.630: INFO: Created: latency-svc-zgqdm
Dec  8 23:25:38.633: INFO: Got endpoints: latency-svc-gpxm7 [356.64802ms]
Dec  8 23:25:38.648: INFO: Created: latency-svc-qrg6l
Dec  8 23:25:38.654: INFO: Got endpoints: latency-svc-zgqdm [378.093585ms]
Dec  8 23:25:38.669: INFO: Created: latency-svc-k8scm
Dec  8 23:25:38.671: INFO: Got endpoints: latency-svc-qrg6l [394.773864ms]
Dec  8 23:25:38.691: INFO: Got endpoints: latency-svc-k8scm [414.381609ms]
Dec  8 23:25:38.695: INFO: Created: latency-svc-rdgbx
Dec  8 23:25:38.709: INFO: Got endpoints: latency-svc-rdgbx [380.134831ms]
Dec  8 23:25:38.718: INFO: Created: latency-svc-j9tgz
Dec  8 23:25:38.732: INFO: Created: latency-svc-7f6km
Dec  8 23:25:38.732: INFO: Got endpoints: latency-svc-j9tgz [387.397632ms]
Dec  8 23:25:38.745: INFO: Got endpoints: latency-svc-7f6km [380.977713ms]
Dec  8 23:25:38.758: INFO: Created: latency-svc-lngqm
Dec  8 23:25:38.774: INFO: Created: latency-svc-vqpqq
Dec  8 23:25:38.777: INFO: Got endpoints: latency-svc-lngqm [400.071919ms]
Dec  8 23:25:38.796: INFO: Got endpoints: latency-svc-vqpqq [385.106286ms]
Dec  8 23:25:38.809: INFO: Created: latency-svc-m7dkn
Dec  8 23:25:38.825: INFO: Got endpoints: latency-svc-m7dkn [384.108922ms]
Dec  8 23:25:38.835: INFO: Created: latency-svc-p4gs5
Dec  8 23:25:38.847: INFO: Got endpoints: latency-svc-p4gs5 [366.211091ms]
Dec  8 23:25:38.852: INFO: Created: latency-svc-w72l6
Dec  8 23:25:38.871: INFO: Created: latency-svc-bk7n2
Dec  8 23:25:38.872: INFO: Got endpoints: latency-svc-w72l6 [331.141684ms]
Dec  8 23:25:38.888: INFO: Got endpoints: latency-svc-bk7n2 [318.694217ms]
Dec  8 23:25:38.899: INFO: Created: latency-svc-gzcxj
Dec  8 23:25:38.912: INFO: Created: latency-svc-8f5pz
Dec  8 23:25:38.913: INFO: Got endpoints: latency-svc-gzcxj [332.056573ms]
Dec  8 23:25:38.927: INFO: Got endpoints: latency-svc-8f5pz [320.03624ms]
Dec  8 23:25:38.943: INFO: Created: latency-svc-nzbwq
Dec  8 23:25:38.953: INFO: Created: latency-svc-mcsql
Dec  8 23:25:38.955: INFO: Got endpoints: latency-svc-nzbwq [321.593566ms]
Dec  8 23:25:38.965: INFO: Got endpoints: latency-svc-mcsql [310.729515ms]
Dec  8 23:25:38.980: INFO: Created: latency-svc-8z2pc
Dec  8 23:25:38.997: INFO: Got endpoints: latency-svc-8z2pc [325.344698ms]
Dec  8 23:25:38.998: INFO: Created: latency-svc-lgdxh
Dec  8 23:25:39.010: INFO: Created: latency-svc-6brkg
Dec  8 23:25:39.018: INFO: Got endpoints: latency-svc-lgdxh [327.612361ms]
Dec  8 23:25:39.028: INFO: Got endpoints: latency-svc-6brkg [318.696067ms]
Dec  8 23:25:39.042: INFO: Created: latency-svc-7ns5j
Dec  8 23:25:39.054: INFO: Created: latency-svc-zhrt4
Dec  8 23:25:39.059: INFO: Got endpoints: latency-svc-7ns5j [326.322415ms]
Dec  8 23:25:39.070: INFO: Got endpoints: latency-svc-zhrt4 [324.99984ms]
Dec  8 23:25:39.081: INFO: Created: latency-svc-w2rns
Dec  8 23:25:39.098: INFO: Created: latency-svc-kcqjb
Dec  8 23:25:39.099: INFO: Got endpoints: latency-svc-w2rns [321.229769ms]
Dec  8 23:25:39.118: INFO: Got endpoints: latency-svc-kcqjb [322.668331ms]
Dec  8 23:25:39.127: INFO: Created: latency-svc-j7d6c
Dec  8 23:25:39.143: INFO: Created: latency-svc-bwtvr
Dec  8 23:25:39.151: INFO: Got endpoints: latency-svc-j7d6c [325.308373ms]
Dec  8 23:25:39.157: INFO: Got endpoints: latency-svc-bwtvr [309.479533ms]
Dec  8 23:25:39.168: INFO: Created: latency-svc-8729w
Dec  8 23:25:39.179: INFO: Got endpoints: latency-svc-8729w [306.254873ms]
Dec  8 23:25:39.194: INFO: Created: latency-svc-f5r2p
Dec  8 23:25:39.205: INFO: Created: latency-svc-glq6q
Dec  8 23:25:39.210: INFO: Got endpoints: latency-svc-f5r2p [321.653729ms]
Dec  8 23:25:39.225: INFO: Got endpoints: latency-svc-glq6q [311.75743ms]
Dec  8 23:25:39.237: INFO: Created: latency-svc-v8hr7
Dec  8 23:25:39.249: INFO: Created: latency-svc-w69q7
Dec  8 23:25:39.252: INFO: Got endpoints: latency-svc-v8hr7 [325.821699ms]
Dec  8 23:25:39.280: INFO: Created: latency-svc-twlh7
Dec  8 23:25:39.290: INFO: Got endpoints: latency-svc-w69q7 [334.921172ms]
Dec  8 23:25:39.297: INFO: Got endpoints: latency-svc-twlh7 [331.435196ms]
Dec  8 23:25:39.307: INFO: Created: latency-svc-wxz6w
Dec  8 23:25:39.371: INFO: Created: latency-svc-szvzh
Dec  8 23:25:39.372: INFO: Got endpoints: latency-svc-wxz6w [375.389766ms]
Dec  8 23:25:39.385: INFO: Got endpoints: latency-svc-szvzh [366.645005ms]
Dec  8 23:25:39.395: INFO: Created: latency-svc-c9kv6
Dec  8 23:25:39.412: INFO: Created: latency-svc-kgdfm
Dec  8 23:25:39.413: INFO: Got endpoints: latency-svc-c9kv6 [385.296394ms]
Dec  8 23:25:39.423: INFO: Got endpoints: latency-svc-kgdfm [363.7844ms]
Dec  8 23:25:39.448: INFO: Created: latency-svc-zp6wx
Dec  8 23:25:39.459: INFO: Created: latency-svc-bz87m
Dec  8 23:25:39.466: INFO: Got endpoints: latency-svc-zp6wx [395.268378ms]
Dec  8 23:25:39.471: INFO: Got endpoints: latency-svc-bz87m [371.946919ms]
Dec  8 23:25:39.489: INFO: Created: latency-svc-xrbvl
Dec  8 23:25:39.504: INFO: Created: latency-svc-h9hcc
Dec  8 23:25:39.511: INFO: Got endpoints: latency-svc-xrbvl [392.682405ms]
Dec  8 23:25:39.537: INFO: Got endpoints: latency-svc-h9hcc [385.798773ms]
Dec  8 23:25:39.538: INFO: Created: latency-svc-8kvmp
Dec  8 23:25:39.572: INFO: Created: latency-svc-4xr4q
Dec  8 23:25:39.575: INFO: Created: latency-svc-nbjbp
Dec  8 23:25:39.582: INFO: Got endpoints: latency-svc-8kvmp [425.864114ms]
Dec  8 23:25:39.612: INFO: Got endpoints: latency-svc-nbjbp [401.788685ms]
Dec  8 23:25:39.612: INFO: Got endpoints: latency-svc-4xr4q [433.422257ms]
Dec  8 23:25:39.620: INFO: Created: latency-svc-2mkwc
Dec  8 23:25:39.651: INFO: Got endpoints: latency-svc-2mkwc [426.295215ms]
Dec  8 23:25:39.663: INFO: Created: latency-svc-qdg7p
Dec  8 23:25:39.681: INFO: Created: latency-svc-fhscp
Dec  8 23:25:39.689: INFO: Created: latency-svc-xccf2
Dec  8 23:25:39.695: INFO: Got endpoints: latency-svc-qdg7p [442.045242ms]
Dec  8 23:25:39.707: INFO: Created: latency-svc-qqzsg
Dec  8 23:25:39.720: INFO: Created: latency-svc-7fq2b
Dec  8 23:25:39.721: INFO: Got endpoints: latency-svc-fhscp [431.714052ms]
Dec  8 23:25:39.737: INFO: Created: latency-svc-982m4
Dec  8 23:25:39.745: INFO: Created: latency-svc-86lhk
Dec  8 23:25:39.757: INFO: Created: latency-svc-92m88
Dec  8 23:25:39.771: INFO: Got endpoints: latency-svc-xccf2 [474.661053ms]
Dec  8 23:25:39.787: INFO: Created: latency-svc-2m6r4
Dec  8 23:25:39.795: INFO: Created: latency-svc-p644k
Dec  8 23:25:39.805: INFO: Created: latency-svc-6w8dc
Dec  8 23:25:39.816: INFO: Created: latency-svc-vf4cj
Dec  8 23:25:39.823: INFO: Got endpoints: latency-svc-qqzsg [450.937072ms]
Dec  8 23:25:39.840: INFO: Created: latency-svc-jzjf2
Dec  8 23:25:39.847: INFO: Created: latency-svc-qddv2
Dec  8 23:25:39.857: INFO: Created: latency-svc-bl759
Dec  8 23:25:39.870: INFO: Got endpoints: latency-svc-7fq2b [484.671818ms]
Dec  8 23:25:39.876: INFO: Created: latency-svc-69vkl
Dec  8 23:25:39.893: INFO: Created: latency-svc-hj52h
Dec  8 23:25:39.903: INFO: Created: latency-svc-b22s7
Dec  8 23:25:39.914: INFO: Created: latency-svc-tf5s7
Dec  8 23:25:39.932: INFO: Got endpoints: latency-svc-982m4 [519.413821ms]
Dec  8 23:25:39.947: INFO: Created: latency-svc-2r7mj
Dec  8 23:25:39.953: INFO: Created: latency-svc-njb6w
Dec  8 23:25:39.961: INFO: Got endpoints: latency-svc-86lhk [538.0214ms]
Dec  8 23:25:39.975: INFO: Created: latency-svc-j7nts
Dec  8 23:25:40.013: INFO: Got endpoints: latency-svc-92m88 [547.507264ms]
Dec  8 23:25:40.029: INFO: Created: latency-svc-mcx2k
Dec  8 23:25:40.061: INFO: Got endpoints: latency-svc-2m6r4 [590.369569ms]
Dec  8 23:25:40.080: INFO: Created: latency-svc-v2t46
Dec  8 23:25:40.114: INFO: Got endpoints: latency-svc-p644k [531.32393ms]
Dec  8 23:25:40.130: INFO: Created: latency-svc-znh72
Dec  8 23:25:40.161: INFO: Got endpoints: latency-svc-6w8dc [549.552663ms]
Dec  8 23:25:40.252: INFO: Created: latency-svc-nvdxr
Dec  8 23:25:40.257: INFO: Got endpoints: latency-svc-vf4cj [645.02387ms]
Dec  8 23:25:40.275: INFO: Got endpoints: latency-svc-jzjf2 [763.259462ms]
Dec  8 23:25:40.290: INFO: Created: latency-svc-bssq8
Dec  8 23:25:40.302: INFO: Created: latency-svc-2rszq
Dec  8 23:25:40.312: INFO: Got endpoints: latency-svc-qddv2 [775.312405ms]
Dec  8 23:25:40.328: INFO: Created: latency-svc-qxwvf
Dec  8 23:25:40.362: INFO: Got endpoints: latency-svc-bl759 [711.260922ms]
Dec  8 23:25:40.380: INFO: Created: latency-svc-277mw
Dec  8 23:25:40.416: INFO: Got endpoints: latency-svc-69vkl [721.71103ms]
Dec  8 23:25:40.433: INFO: Created: latency-svc-lqngw
Dec  8 23:25:40.463: INFO: Got endpoints: latency-svc-hj52h [741.936389ms]
Dec  8 23:25:40.483: INFO: Created: latency-svc-vzqtn
Dec  8 23:25:40.513: INFO: Got endpoints: latency-svc-b22s7 [741.587ms]
Dec  8 23:25:40.530: INFO: Created: latency-svc-74r26
Dec  8 23:25:40.564: INFO: Got endpoints: latency-svc-tf5s7 [740.785595ms]
Dec  8 23:25:40.578: INFO: Created: latency-svc-2s9t2
Dec  8 23:25:40.613: INFO: Got endpoints: latency-svc-2r7mj [742.916553ms]
Dec  8 23:25:40.629: INFO: Created: latency-svc-nm2zc
Dec  8 23:25:40.661: INFO: Got endpoints: latency-svc-njb6w [728.641042ms]
Dec  8 23:25:40.680: INFO: Created: latency-svc-h42dc
Dec  8 23:25:40.713: INFO: Got endpoints: latency-svc-j7nts [752.466734ms]
Dec  8 23:25:40.741: INFO: Created: latency-svc-nxxv4
Dec  8 23:25:40.761: INFO: Got endpoints: latency-svc-mcx2k [747.966775ms]
Dec  8 23:25:40.779: INFO: Created: latency-svc-gwlfw
Dec  8 23:25:40.811: INFO: Got endpoints: latency-svc-v2t46 [749.787358ms]
Dec  8 23:25:40.833: INFO: Created: latency-svc-clmbm
Dec  8 23:25:40.863: INFO: Got endpoints: latency-svc-znh72 [749.120095ms]
Dec  8 23:25:40.878: INFO: Created: latency-svc-qjtgz
Dec  8 23:25:40.911: INFO: Got endpoints: latency-svc-nvdxr [749.786519ms]
Dec  8 23:25:40.928: INFO: Created: latency-svc-j8gj7
Dec  8 23:25:40.963: INFO: Got endpoints: latency-svc-bssq8 [705.967067ms]
Dec  8 23:25:40.992: INFO: Created: latency-svc-477j4
Dec  8 23:25:41.012: INFO: Got endpoints: latency-svc-2rszq [737.512174ms]
Dec  8 23:25:41.031: INFO: Created: latency-svc-9g6kc
Dec  8 23:25:41.063: INFO: Got endpoints: latency-svc-qxwvf [751.019723ms]
Dec  8 23:25:41.082: INFO: Created: latency-svc-8gvcg
Dec  8 23:25:41.113: INFO: Got endpoints: latency-svc-277mw [750.917338ms]
Dec  8 23:25:41.132: INFO: Created: latency-svc-k8ww5
Dec  8 23:25:41.164: INFO: Got endpoints: latency-svc-lqngw [747.205105ms]
Dec  8 23:25:41.178: INFO: Created: latency-svc-fb589
Dec  8 23:25:41.213: INFO: Got endpoints: latency-svc-vzqtn [749.804762ms]
Dec  8 23:25:41.229: INFO: Created: latency-svc-xtlx9
Dec  8 23:25:41.263: INFO: Got endpoints: latency-svc-74r26 [749.586296ms]
Dec  8 23:25:41.283: INFO: Created: latency-svc-wrwsv
Dec  8 23:25:41.313: INFO: Got endpoints: latency-svc-2s9t2 [749.163016ms]
Dec  8 23:25:41.328: INFO: Created: latency-svc-jjg79
Dec  8 23:25:41.362: INFO: Got endpoints: latency-svc-nm2zc [749.434123ms]
Dec  8 23:25:41.380: INFO: Created: latency-svc-v8bk7
Dec  8 23:25:41.412: INFO: Got endpoints: latency-svc-h42dc [751.081083ms]
Dec  8 23:25:41.435: INFO: Created: latency-svc-tm5x2
Dec  8 23:25:41.461: INFO: Got endpoints: latency-svc-nxxv4 [747.418938ms]
Dec  8 23:25:41.476: INFO: Created: latency-svc-qq7hw
Dec  8 23:25:41.511: INFO: Got endpoints: latency-svc-gwlfw [749.88638ms]
Dec  8 23:25:41.528: INFO: Created: latency-svc-q2dsf
Dec  8 23:25:41.561: INFO: Got endpoints: latency-svc-clmbm [750.140447ms]
Dec  8 23:25:41.578: INFO: Created: latency-svc-wk2z6
Dec  8 23:25:41.613: INFO: Got endpoints: latency-svc-qjtgz [749.845177ms]
Dec  8 23:25:41.628: INFO: Created: latency-svc-7dvc5
Dec  8 23:25:41.661: INFO: Got endpoints: latency-svc-j8gj7 [749.976306ms]
Dec  8 23:25:41.677: INFO: Created: latency-svc-9fdv7
Dec  8 23:25:41.714: INFO: Got endpoints: latency-svc-477j4 [750.380308ms]
Dec  8 23:25:41.728: INFO: Created: latency-svc-4d9kf
Dec  8 23:25:41.763: INFO: Got endpoints: latency-svc-9g6kc [750.796486ms]
Dec  8 23:25:41.777: INFO: Created: latency-svc-pznn6
Dec  8 23:25:41.820: INFO: Got endpoints: latency-svc-8gvcg [756.49773ms]
Dec  8 23:25:41.848: INFO: Created: latency-svc-fb6kz
Dec  8 23:25:41.870: INFO: Got endpoints: latency-svc-k8ww5 [756.246788ms]
Dec  8 23:25:41.949: INFO: Got endpoints: latency-svc-fb589 [785.763326ms]
Dec  8 23:25:41.960: INFO: Created: latency-svc-q27qs
Dec  8 23:25:41.982: INFO: Got endpoints: latency-svc-xtlx9 [768.783417ms]
Dec  8 23:25:41.994: INFO: Created: latency-svc-5znb4
Dec  8 23:25:42.003: INFO: Created: latency-svc-c4fcn
Dec  8 23:25:42.011: INFO: Got endpoints: latency-svc-wrwsv [747.791611ms]
Dec  8 23:25:42.025: INFO: Created: latency-svc-b8nf5
Dec  8 23:25:42.065: INFO: Got endpoints: latency-svc-jjg79 [751.696642ms]
Dec  8 23:25:42.088: INFO: Created: latency-svc-dm6q4
Dec  8 23:25:42.113: INFO: Got endpoints: latency-svc-v8bk7 [750.468356ms]
Dec  8 23:25:42.130: INFO: Created: latency-svc-5b2kw
Dec  8 23:25:42.163: INFO: Got endpoints: latency-svc-tm5x2 [750.28009ms]
Dec  8 23:25:42.185: INFO: Created: latency-svc-hgwjt
Dec  8 23:25:42.213: INFO: Got endpoints: latency-svc-qq7hw [751.642064ms]
Dec  8 23:25:42.229: INFO: Created: latency-svc-b9tfn
Dec  8 23:25:42.261: INFO: Got endpoints: latency-svc-q2dsf [749.999949ms]
Dec  8 23:25:42.284: INFO: Created: latency-svc-wtx2t
Dec  8 23:25:42.313: INFO: Got endpoints: latency-svc-wk2z6 [751.917374ms]
Dec  8 23:25:42.332: INFO: Created: latency-svc-llqcz
Dec  8 23:25:42.362: INFO: Got endpoints: latency-svc-7dvc5 [748.573863ms]
Dec  8 23:25:42.381: INFO: Created: latency-svc-gdkhq
Dec  8 23:25:42.413: INFO: Got endpoints: latency-svc-9fdv7 [751.804439ms]
Dec  8 23:25:42.433: INFO: Created: latency-svc-dm64q
Dec  8 23:25:42.464: INFO: Got endpoints: latency-svc-4d9kf [750.292916ms]
Dec  8 23:25:42.478: INFO: Created: latency-svc-xm7xg
Dec  8 23:25:42.511: INFO: Got endpoints: latency-svc-pznn6 [747.94897ms]
Dec  8 23:25:42.527: INFO: Created: latency-svc-59q7s
Dec  8 23:25:42.561: INFO: Got endpoints: latency-svc-fb6kz [741.521172ms]
Dec  8 23:25:42.579: INFO: Created: latency-svc-zrl88
Dec  8 23:25:42.611: INFO: Got endpoints: latency-svc-q27qs [741.263252ms]
Dec  8 23:25:42.626: INFO: Created: latency-svc-szxzm
Dec  8 23:25:42.662: INFO: Got endpoints: latency-svc-5znb4 [712.640214ms]
Dec  8 23:25:42.677: INFO: Created: latency-svc-8zdsc
Dec  8 23:25:42.711: INFO: Got endpoints: latency-svc-c4fcn [728.945627ms]
Dec  8 23:25:42.728: INFO: Created: latency-svc-p4d2t
Dec  8 23:25:42.763: INFO: Got endpoints: latency-svc-b8nf5 [752.525122ms]
Dec  8 23:25:42.778: INFO: Created: latency-svc-xhcrn
Dec  8 23:25:42.811: INFO: Got endpoints: latency-svc-dm6q4 [746.121981ms]
Dec  8 23:25:42.828: INFO: Created: latency-svc-vscw9
Dec  8 23:25:42.864: INFO: Got endpoints: latency-svc-5b2kw [750.455022ms]
Dec  8 23:25:42.879: INFO: Created: latency-svc-k8dqr
Dec  8 23:25:42.913: INFO: Got endpoints: latency-svc-hgwjt [750.312414ms]
Dec  8 23:25:42.928: INFO: Created: latency-svc-5xlkx
Dec  8 23:25:42.961: INFO: Got endpoints: latency-svc-b9tfn [748.806804ms]
Dec  8 23:25:42.987: INFO: Created: latency-svc-pnc5f
Dec  8 23:25:43.013: INFO: Got endpoints: latency-svc-wtx2t [751.727702ms]
Dec  8 23:25:43.032: INFO: Created: latency-svc-qnnwh
Dec  8 23:25:43.063: INFO: Got endpoints: latency-svc-llqcz [749.304867ms]
Dec  8 23:25:43.079: INFO: Created: latency-svc-74zgl
Dec  8 23:25:43.112: INFO: Got endpoints: latency-svc-gdkhq [750.585742ms]
Dec  8 23:25:43.128: INFO: Created: latency-svc-r9fl7
Dec  8 23:25:43.180: INFO: Got endpoints: latency-svc-dm64q [766.434444ms]
Dec  8 23:25:43.196: INFO: Created: latency-svc-zn7bk
Dec  8 23:25:43.212: INFO: Got endpoints: latency-svc-xm7xg [747.872772ms]
Dec  8 23:25:43.226: INFO: Created: latency-svc-9rkfx
Dec  8 23:25:43.261: INFO: Got endpoints: latency-svc-59q7s [749.99521ms]
Dec  8 23:25:43.277: INFO: Created: latency-svc-tw26m
Dec  8 23:25:43.313: INFO: Got endpoints: latency-svc-zrl88 [751.564359ms]
Dec  8 23:25:43.328: INFO: Created: latency-svc-968qx
Dec  8 23:25:43.361: INFO: Got endpoints: latency-svc-szxzm [750.123502ms]
Dec  8 23:25:43.381: INFO: Created: latency-svc-ggkxm
Dec  8 23:25:43.412: INFO: Got endpoints: latency-svc-8zdsc [750.163062ms]
Dec  8 23:25:43.433: INFO: Created: latency-svc-5dvgm
Dec  8 23:25:43.463: INFO: Got endpoints: latency-svc-p4d2t [751.727531ms]
Dec  8 23:25:43.482: INFO: Created: latency-svc-dspzz
Dec  8 23:25:43.513: INFO: Got endpoints: latency-svc-xhcrn [749.944876ms]
Dec  8 23:25:43.529: INFO: Created: latency-svc-vgdc7
Dec  8 23:25:43.564: INFO: Got endpoints: latency-svc-vscw9 [752.598431ms]
Dec  8 23:25:43.578: INFO: Created: latency-svc-c5r9t
Dec  8 23:25:43.611: INFO: Got endpoints: latency-svc-k8dqr [747.665525ms]
Dec  8 23:25:43.629: INFO: Created: latency-svc-dvc7t
Dec  8 23:25:43.663: INFO: Got endpoints: latency-svc-5xlkx [749.695336ms]
Dec  8 23:25:43.726: INFO: Got endpoints: latency-svc-pnc5f [764.854748ms]
Dec  8 23:25:43.730: INFO: Created: latency-svc-nlzcj
Dec  8 23:25:43.756: INFO: Created: latency-svc-vj85t
Dec  8 23:25:43.763: INFO: Got endpoints: latency-svc-qnnwh [749.871347ms]
Dec  8 23:25:43.779: INFO: Created: latency-svc-pgmln
Dec  8 23:25:43.814: INFO: Got endpoints: latency-svc-74zgl [751.2012ms]
Dec  8 23:25:43.828: INFO: Created: latency-svc-nhdv5
Dec  8 23:25:43.861: INFO: Got endpoints: latency-svc-r9fl7 [748.83197ms]
Dec  8 23:25:43.877: INFO: Created: latency-svc-r92ph
Dec  8 23:25:43.913: INFO: Got endpoints: latency-svc-zn7bk [732.844273ms]
Dec  8 23:25:43.930: INFO: Created: latency-svc-2dg5b
Dec  8 23:25:43.963: INFO: Got endpoints: latency-svc-9rkfx [751.103319ms]
Dec  8 23:25:43.979: INFO: Created: latency-svc-rddhk
Dec  8 23:25:44.013: INFO: Got endpoints: latency-svc-tw26m [751.308353ms]
Dec  8 23:25:44.041: INFO: Created: latency-svc-ffvpw
Dec  8 23:25:44.064: INFO: Got endpoints: latency-svc-968qx [751.036446ms]
Dec  8 23:25:44.083: INFO: Created: latency-svc-5rxbz
Dec  8 23:25:44.111: INFO: Got endpoints: latency-svc-ggkxm [749.657949ms]
Dec  8 23:25:44.127: INFO: Created: latency-svc-9hql2
Dec  8 23:25:44.161: INFO: Got endpoints: latency-svc-5dvgm [748.695131ms]
Dec  8 23:25:44.177: INFO: Created: latency-svc-lctzr
Dec  8 23:25:44.213: INFO: Got endpoints: latency-svc-dspzz [749.58445ms]
Dec  8 23:25:44.228: INFO: Created: latency-svc-6rcjt
Dec  8 23:25:44.263: INFO: Got endpoints: latency-svc-vgdc7 [749.621597ms]
Dec  8 23:25:44.279: INFO: Created: latency-svc-g5xrx
Dec  8 23:25:44.313: INFO: Got endpoints: latency-svc-c5r9t [749.559386ms]
Dec  8 23:25:44.330: INFO: Created: latency-svc-txz6q
Dec  8 23:25:44.364: INFO: Got endpoints: latency-svc-dvc7t [752.493972ms]
Dec  8 23:25:44.383: INFO: Created: latency-svc-j66pk
Dec  8 23:25:44.414: INFO: Got endpoints: latency-svc-nlzcj [750.755031ms]
Dec  8 23:25:44.431: INFO: Created: latency-svc-7gv5f
Dec  8 23:25:44.462: INFO: Got endpoints: latency-svc-vj85t [735.133486ms]
Dec  8 23:25:44.481: INFO: Created: latency-svc-kg22t
Dec  8 23:25:44.511: INFO: Got endpoints: latency-svc-pgmln [748.367344ms]
Dec  8 23:25:44.532: INFO: Created: latency-svc-gch2g
Dec  8 23:25:44.563: INFO: Got endpoints: latency-svc-nhdv5 [748.717064ms]
Dec  8 23:25:44.581: INFO: Created: latency-svc-46bnd
Dec  8 23:25:44.612: INFO: Got endpoints: latency-svc-r92ph [750.604936ms]
Dec  8 23:25:44.629: INFO: Created: latency-svc-dkqml
Dec  8 23:25:44.663: INFO: Got endpoints: latency-svc-2dg5b [750.817922ms]
Dec  8 23:25:44.681: INFO: Created: latency-svc-522sr
Dec  8 23:25:44.714: INFO: Got endpoints: latency-svc-rddhk [750.816792ms]
Dec  8 23:25:44.733: INFO: Created: latency-svc-cfwst
Dec  8 23:25:44.763: INFO: Got endpoints: latency-svc-ffvpw [749.821348ms]
Dec  8 23:25:44.779: INFO: Created: latency-svc-8h8qc
Dec  8 23:25:44.812: INFO: Got endpoints: latency-svc-5rxbz [747.409838ms]
Dec  8 23:25:44.835: INFO: Created: latency-svc-rcrcw
Dec  8 23:25:44.862: INFO: Got endpoints: latency-svc-9hql2 [750.484502ms]
Dec  8 23:25:44.880: INFO: Created: latency-svc-76w2c
Dec  8 23:25:44.914: INFO: Got endpoints: latency-svc-lctzr [752.637942ms]
Dec  8 23:25:44.930: INFO: Created: latency-svc-6kq57
Dec  8 23:25:44.965: INFO: Got endpoints: latency-svc-6rcjt [751.86801ms]
Dec  8 23:25:44.982: INFO: Created: latency-svc-b9wxw
Dec  8 23:25:45.012: INFO: Got endpoints: latency-svc-g5xrx [748.654281ms]
Dec  8 23:25:45.029: INFO: Created: latency-svc-wkj4z
Dec  8 23:25:45.064: INFO: Got endpoints: latency-svc-txz6q [750.759523ms]
Dec  8 23:25:45.082: INFO: Created: latency-svc-x7tp5
Dec  8 23:25:45.114: INFO: Got endpoints: latency-svc-j66pk [749.70713ms]
Dec  8 23:25:45.131: INFO: Created: latency-svc-cxhm7
Dec  8 23:25:45.164: INFO: Got endpoints: latency-svc-7gv5f [750.174443ms]
Dec  8 23:25:45.181: INFO: Created: latency-svc-nbcbs
Dec  8 23:25:45.213: INFO: Got endpoints: latency-svc-kg22t [751.64802ms]
Dec  8 23:25:45.232: INFO: Created: latency-svc-cn469
Dec  8 23:25:45.262: INFO: Got endpoints: latency-svc-gch2g [750.947656ms]
Dec  8 23:25:45.281: INFO: Created: latency-svc-f7jdz
Dec  8 23:25:45.312: INFO: Got endpoints: latency-svc-46bnd [749.146211ms]
Dec  8 23:25:45.336: INFO: Created: latency-svc-rxrtx
Dec  8 23:25:45.364: INFO: Got endpoints: latency-svc-dkqml [751.696431ms]
Dec  8 23:25:45.380: INFO: Created: latency-svc-dvkfm
Dec  8 23:25:45.414: INFO: Got endpoints: latency-svc-522sr [750.354165ms]
Dec  8 23:25:45.490: INFO: Got endpoints: latency-svc-cfwst [775.993004ms]
Dec  8 23:25:45.513: INFO: Created: latency-svc-bjh22
Dec  8 23:25:45.519: INFO: Got endpoints: latency-svc-8h8qc [756.558095ms]
Dec  8 23:25:45.537: INFO: Created: latency-svc-kwkj7
Dec  8 23:25:45.548: INFO: Created: latency-svc-ftb6t
Dec  8 23:25:45.574: INFO: Got endpoints: latency-svc-rcrcw [762.203287ms]
Dec  8 23:25:45.592: INFO: Created: latency-svc-zgtlr
Dec  8 23:25:45.613: INFO: Got endpoints: latency-svc-76w2c [751.37486ms]
Dec  8 23:25:45.631: INFO: Created: latency-svc-tqqpv
Dec  8 23:25:45.662: INFO: Got endpoints: latency-svc-6kq57 [747.593801ms]
Dec  8 23:25:45.679: INFO: Created: latency-svc-xxl44
Dec  8 23:25:45.714: INFO: Got endpoints: latency-svc-b9wxw [749.284754ms]
Dec  8 23:25:45.730: INFO: Created: latency-svc-fh74d
Dec  8 23:25:45.763: INFO: Got endpoints: latency-svc-wkj4z [751.490423ms]
Dec  8 23:25:45.779: INFO: Created: latency-svc-qhckb
Dec  8 23:25:45.813: INFO: Got endpoints: latency-svc-x7tp5 [748.893851ms]
Dec  8 23:25:45.830: INFO: Created: latency-svc-hbn4m
Dec  8 23:25:45.861: INFO: Got endpoints: latency-svc-cxhm7 [747.686219ms]
Dec  8 23:25:45.882: INFO: Created: latency-svc-nwq7h
Dec  8 23:25:45.914: INFO: Got endpoints: latency-svc-nbcbs [749.852098ms]
Dec  8 23:25:45.930: INFO: Created: latency-svc-8qkvm
Dec  8 23:25:45.962: INFO: Got endpoints: latency-svc-cn469 [748.398262ms]
Dec  8 23:25:45.982: INFO: Created: latency-svc-287bp
Dec  8 23:25:46.014: INFO: Got endpoints: latency-svc-f7jdz [751.504264ms]
Dec  8 23:25:46.051: INFO: Created: latency-svc-czb55
Dec  8 23:25:46.064: INFO: Got endpoints: latency-svc-rxrtx [751.605043ms]
Dec  8 23:25:46.081: INFO: Created: latency-svc-v9m6g
Dec  8 23:25:46.112: INFO: Got endpoints: latency-svc-dvkfm [748.404297ms]
Dec  8 23:25:46.162: INFO: Got endpoints: latency-svc-bjh22 [747.785722ms]
Dec  8 23:25:46.213: INFO: Got endpoints: latency-svc-kwkj7 [723.057973ms]
Dec  8 23:25:46.264: INFO: Got endpoints: latency-svc-ftb6t [744.725257ms]
Dec  8 23:25:46.314: INFO: Got endpoints: latency-svc-zgtlr [740.121062ms]
Dec  8 23:25:46.363: INFO: Got endpoints: latency-svc-tqqpv [750.191984ms]
Dec  8 23:25:46.414: INFO: Got endpoints: latency-svc-xxl44 [751.922441ms]
Dec  8 23:25:46.463: INFO: Got endpoints: latency-svc-fh74d [748.734311ms]
Dec  8 23:25:46.514: INFO: Got endpoints: latency-svc-qhckb [750.522551ms]
Dec  8 23:25:46.564: INFO: Got endpoints: latency-svc-hbn4m [750.510741ms]
Dec  8 23:25:46.614: INFO: Got endpoints: latency-svc-nwq7h [752.234385ms]
Dec  8 23:25:46.664: INFO: Got endpoints: latency-svc-8qkvm [749.996642ms]
Dec  8 23:25:46.713: INFO: Got endpoints: latency-svc-287bp [750.970882ms]
Dec  8 23:25:46.764: INFO: Got endpoints: latency-svc-czb55 [749.828059ms]
Dec  8 23:25:46.813: INFO: Got endpoints: latency-svc-v9m6g [748.84056ms]
Dec  8 23:25:46.813: INFO: Latencies: [53.701781ms 68.496548ms 88.874313ms 101.974136ms 109.478048ms 135.14416ms 155.752092ms 165.24437ms 204.728272ms 293.288458ms 304.632712ms 306.254873ms 309.479533ms 310.729515ms 311.75743ms 318.694217ms 318.696067ms 320.03624ms 321.229769ms 321.593566ms 321.653729ms 322.668331ms 324.99984ms 325.308373ms 325.344698ms 325.821699ms 326.322415ms 327.612361ms 330.272558ms 331.141684ms 331.435196ms 332.056573ms 334.921172ms 356.64802ms 363.7844ms 366.211091ms 366.645005ms 371.946919ms 375.389766ms 378.093585ms 380.134831ms 380.977713ms 384.108922ms 385.106286ms 385.296394ms 385.798773ms 387.397632ms 392.682405ms 394.773864ms 395.268378ms 400.071919ms 401.788685ms 414.381609ms 425.864114ms 426.295215ms 431.714052ms 433.422257ms 442.045242ms 450.937072ms 474.661053ms 484.671818ms 519.413821ms 531.32393ms 538.0214ms 547.507264ms 549.552663ms 590.369569ms 645.02387ms 705.967067ms 711.260922ms 712.640214ms 721.71103ms 723.057973ms 728.641042ms 728.945627ms 732.844273ms 735.133486ms 737.512174ms 740.121062ms 740.785595ms 741.263252ms 741.521172ms 741.587ms 741.936389ms 742.916553ms 744.725257ms 746.121981ms 747.205105ms 747.409838ms 747.418938ms 747.593801ms 747.665525ms 747.686219ms 747.785722ms 747.791611ms 747.872772ms 747.94897ms 747.966775ms 748.367344ms 748.398262ms 748.404297ms 748.573863ms 748.654281ms 748.695131ms 748.717064ms 748.734311ms 748.806804ms 748.83197ms 748.84056ms 748.893851ms 749.120095ms 749.146211ms 749.163016ms 749.284754ms 749.304867ms 749.434123ms 749.559386ms 749.58445ms 749.586296ms 749.621597ms 749.657949ms 749.695336ms 749.70713ms 749.786519ms 749.787358ms 749.804762ms 749.821348ms 749.828059ms 749.845177ms 749.852098ms 749.871347ms 749.88638ms 749.944876ms 749.976306ms 749.99521ms 749.996642ms 749.999949ms 750.123502ms 750.140447ms 750.163062ms 750.174443ms 750.191984ms 750.28009ms 750.292916ms 750.312414ms 750.354165ms 750.380308ms 750.455022ms 750.468356ms 750.484502ms 750.510741ms 750.522551ms 750.585742ms 750.604936ms 750.755031ms 750.759523ms 750.796486ms 750.816792ms 750.817922ms 750.917338ms 750.947656ms 750.970882ms 751.019723ms 751.036446ms 751.081083ms 751.103319ms 751.2012ms 751.308353ms 751.37486ms 751.490423ms 751.504264ms 751.564359ms 751.605043ms 751.642064ms 751.64802ms 751.696431ms 751.696642ms 751.727531ms 751.727702ms 751.804439ms 751.86801ms 751.917374ms 751.922441ms 752.234385ms 752.466734ms 752.493972ms 752.525122ms 752.598431ms 752.637942ms 756.246788ms 756.49773ms 756.558095ms 762.203287ms 763.259462ms 764.854748ms 766.434444ms 768.783417ms 775.312405ms 775.993004ms 785.763326ms]
Dec  8 23:25:46.813: INFO: 50 %ile: 748.404297ms
Dec  8 23:25:46.813: INFO: 90 %ile: 751.86801ms
Dec  8 23:25:46.813: INFO: 99 %ile: 775.993004ms
Dec  8 23:25:46.813: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:25:46.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-ndrzw" for this suite.
Dec  8 23:26:04.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:26:04.955: INFO: namespace: e2e-tests-svc-latency-ndrzw, resource: bindings, ignored listing per whitelist
Dec  8 23:26:05.016: INFO: namespace e2e-tests-svc-latency-ndrzw deletion completed in 18.192861996s

• [SLOW TEST:30.057 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:26:05.017: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 23:26:05.133: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a21e920f-fb40-11e8-8c59-ae6969886d1b" in namespace "e2e-tests-projected-69mrh" to be "success or failure"
Dec  8 23:26:05.140: INFO: Pod "downwardapi-volume-a21e920f-fb40-11e8-8c59-ae6969886d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.407551ms
Dec  8 23:26:07.152: INFO: Pod "downwardapi-volume-a21e920f-fb40-11e8-8c59-ae6969886d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019357285s
STEP: Saw pod success
Dec  8 23:26:07.152: INFO: Pod "downwardapi-volume-a21e920f-fb40-11e8-8c59-ae6969886d1b" satisfied condition "success or failure"
Dec  8 23:26:07.160: INFO: Trying to get logs from node compliancetest pod downwardapi-volume-a21e920f-fb40-11e8-8c59-ae6969886d1b container client-container: <nil>
STEP: delete the pod
Dec  8 23:26:07.205: INFO: Waiting for pod downwardapi-volume-a21e920f-fb40-11e8-8c59-ae6969886d1b to disappear
Dec  8 23:26:07.212: INFO: Pod downwardapi-volume-a21e920f-fb40-11e8-8c59-ae6969886d1b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:26:07.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-69mrh" for this suite.
Dec  8 23:26:13.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:26:13.326: INFO: namespace: e2e-tests-projected-69mrh, resource: bindings, ignored listing per whitelist
Dec  8 23:26:13.411: INFO: namespace e2e-tests-projected-69mrh deletion completed in 6.188544991s

• [SLOW TEST:8.394 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:26:13.411: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1208 23:26:44.064146      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 23:26:44.064: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:26:44.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-26fk2" for this suite.
Dec  8 23:26:50.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:26:50.115: INFO: namespace: e2e-tests-gc-26fk2, resource: bindings, ignored listing per whitelist
Dec  8 23:26:50.202: INFO: namespace e2e-tests-gc-26fk2 deletion completed in 6.134874769s

• [SLOW TEST:36.791 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 23:26:50.202: INFO: >>> kubeConfig: /tmp/kubeconfig-960662691
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 23:26:50.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5gpf6'
Dec  8 23:26:50.421: INFO: stderr: ""
Dec  8 23:26:50.421: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Dec  8 23:26:50.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-960662691 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-5gpf6'
Dec  8 23:27:04.833: INFO: stderr: ""
Dec  8 23:27:04.833: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 23:27:04.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5gpf6" for this suite.
Dec  8 23:27:10.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 23:27:10.904: INFO: namespace: e2e-tests-kubectl-5gpf6, resource: bindings, ignored listing per whitelist
Dec  8 23:27:10.970: INFO: namespace e2e-tests-kubectl-5gpf6 deletion completed in 6.129807935s

• [SLOW TEST:20.767 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSDec  8 23:27:10.970: INFO: Running AfterSuite actions on all node
Dec  8 23:27:10.970: INFO: Running AfterSuite actions on node 1
Dec  8 23:27:10.970: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5056.349 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h24m17.765911825s
Test Suite Passed
