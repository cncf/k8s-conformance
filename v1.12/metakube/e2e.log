Nov  1 15:48:33.852: INFO: Overriding default scale value of zero to 1
Nov  1 15:48:33.853: INFO: Overriding default milliseconds value of zero to 5000
I1101 15:48:34.735907      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-994938124
I1101 15:48:34.736275      15 e2e.go:304] Starting e2e run "9682bf76-dded-11e8-a64b-2ef904c43a0d" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1541087313 - Will randomize all specs
Will run 188 of 1814 specs

Nov  1 15:48:34.975: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 15:48:34.978: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  1 15:48:35.055: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  1 15:48:35.109: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  1 15:48:35.109: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
Nov  1 15:48:35.110: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  1 15:48:35.130: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Nov  1 15:48:35.134: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Nov  1 15:48:35.134: INFO: e2e test version: v1.12.1
Nov  1 15:48:35.141: INFO: kube-apiserver version: v1.12.2
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:48:35.142: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
Nov  1 15:48:35.358: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  1 15:48:35.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s6nsd'
Nov  1 15:48:36.386: INFO: stderr: ""
Nov  1 15:48:36.386: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Nov  1 15:48:46.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s6nsd -o json'
Nov  1 15:48:46.628: INFO: stderr: ""
Nov  1 15:48:46.628: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-11-01T15:48:36Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-s6nsd\",\n        \"resourceVersion\": \"1926\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-s6nsd/pods/e2e-test-nginx-pod\",\n        \"uid\": \"981569eb-dded-11e8-a94b-0a580af40661\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gwvc9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gwvc9\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gwvc9\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-01T15:48:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-01T15:48:41Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-01T15:48:41Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-01T15:48:36Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://8b5e34aa5d3f225a34e994a7fa22bafbaa3dadc7efcb34edf64f0852ed966dab\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-11-01T15:48:41Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.10\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.25.1.5\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-11-01T15:48:36Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  1 15:48:46.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 replace -f - --namespace=e2e-tests-kubectl-s6nsd'
Nov  1 15:48:47.836: INFO: stderr: ""
Nov  1 15:48:47.836: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Nov  1 15:48:47.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s6nsd'
Nov  1 15:49:03.181: INFO: stderr: ""
Nov  1 15:49:03.181: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:49:03.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s6nsd" for this suite.
Nov  1 15:49:09.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:49:10.070: INFO: namespace: e2e-tests-kubectl-s6nsd, resource: bindings, ignored listing per whitelist
Nov  1 15:49:10.431: INFO: namespace e2e-tests-kubectl-s6nsd deletion completed in 7.208201636s

• [SLOW TEST:35.289 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:49:10.432: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-ac92637a-dded-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 15:49:10.872: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac946fba-dded-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-v4cxp" to be "success or failure"
Nov  1 15:49:10.880: INFO: Pod "pod-projected-secrets-ac946fba-dded-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.94997ms
Nov  1 15:49:12.897: INFO: Pod "pod-projected-secrets-ac946fba-dded-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024281057s
Nov  1 15:49:15.006: INFO: Pod "pod-projected-secrets-ac946fba-dded-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.133025515s
STEP: Saw pod success
Nov  1 15:49:15.006: INFO: Pod "pod-projected-secrets-ac946fba-dded-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:49:15.012: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-secrets-ac946fba-dded-11e8-a64b-2ef904c43a0d container secret-volume-test: <nil>
STEP: delete the pod
Nov  1 15:49:15.247: INFO: Waiting for pod pod-projected-secrets-ac946fba-dded-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:49:15.252: INFO: Pod pod-projected-secrets-ac946fba-dded-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:49:15.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v4cxp" for this suite.
Nov  1 15:49:23.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:49:23.468: INFO: namespace: e2e-tests-projected-v4cxp, resource: bindings, ignored listing per whitelist
Nov  1 15:49:23.690: INFO: namespace e2e-tests-projected-v4cxp deletion completed in 8.432212902s

• [SLOW TEST:13.259 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:49:23.697: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  1 15:49:23.977: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  1 15:49:24.010: INFO: Waiting for terminating namespaces to be deleted...
Nov  1 15:49:24.019: INFO: 
Logging pods the kubelet thinks is on node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn before test
Nov  1 15:49:24.058: INFO: restic-jvl9h from heptio-ark started at 2018-11-01 15:45:36 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.058: INFO: 	Container ark ready: true, restart count 0
Nov  1 15:49:24.058: INFO: canal-n7cr4 from kube-system started at 2018-11-01 15:45:36 +0000 UTC (3 container statuses recorded)
Nov  1 15:49:24.058: INFO: 	Container calico-node ready: true, restart count 0
Nov  1 15:49:24.058: INFO: 	Container install-cni ready: true, restart count 0
Nov  1 15:49:24.058: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  1 15:49:24.058: INFO: kube-proxy-75xl8 from kube-system started at 2018-11-01 15:45:36 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.058: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  1 15:49:24.058: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-01 15:46:48 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.058: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  1 15:49:24.058: INFO: sonobuoy-e2e-job-885a13fbb80f41a2 from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 15:49:24.058: INFO: 	Container e2e ready: true, restart count 0
Nov  1 15:49:24.058: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  1 15:49:24.058: INFO: sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kmrb5 from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 15:49:24.058: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  1 15:49:24.058: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  1 15:49:24.058: INFO: 
Logging pods the kubelet thinks is on node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo before test
Nov  1 15:49:24.155: INFO: canal-zw4zc from kube-system started at 2018-11-01 15:44:13 +0000 UTC (3 container statuses recorded)
Nov  1 15:49:24.155: INFO: 	Container calico-node ready: true, restart count 0
Nov  1 15:49:24.155: INFO: 	Container install-cni ready: true, restart count 0
Nov  1 15:49:24.156: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  1 15:49:24.156: INFO: sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kqkwn from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 15:49:24.156: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  1 15:49:24.156: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  1 15:49:24.156: INFO: kube-dns-6d7bb85cbd-hb8ww from kube-system started at 2018-11-01 15:44:13 +0000 UTC (3 container statuses recorded)
Nov  1 15:49:24.156: INFO: 	Container dnsmasq ready: true, restart count 0
Nov  1 15:49:24.156: INFO: 	Container kubedns ready: true, restart count 0
Nov  1 15:49:24.156: INFO: 	Container sidecar ready: true, restart count 0
Nov  1 15:49:24.156: INFO: metrics-server-5db78d768c-2n22k from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.156: INFO: 	Container metrics-server ready: true, restart count 0
Nov  1 15:49:24.156: INFO: restic-jmd9j from heptio-ark started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.156: INFO: 	Container ark ready: true, restart count 0
Nov  1 15:49:24.157: INFO: kube-dns-autoscaler-68447488d7-x9lm8 from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.157: INFO: 	Container autoscaler ready: true, restart count 0
Nov  1 15:49:24.157: INFO: tiller-deploy-6dd86cd8fc-5dqf4 from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.157: INFO: 	Container tiller ready: true, restart count 0
Nov  1 15:49:24.157: INFO: ark-6d5cb4c7df-rfr5c from heptio-ark started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.157: INFO: 	Container ark ready: true, restart count 2
Nov  1 15:49:24.158: INFO: openvpn-client-765b7d6ccd-zv6hj from kube-system started at 2018-11-01 15:44:13 +0000 UTC (2 container statuses recorded)
Nov  1 15:49:24.158: INFO: 	Container dnat-controller ready: true, restart count 0
Nov  1 15:49:24.158: INFO: 	Container openvpn-client ready: true, restart count 0
Nov  1 15:49:24.158: INFO: kubernetes-dashboard-55f8478c57-wv65g from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.158: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  1 15:49:24.158: INFO: kube-proxy-v89pd from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 15:49:24.158: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  1 15:49:24.158: INFO: kube-dns-6d7bb85cbd-fmf54 from kube-system started at 2018-11-01 15:45:41 +0000 UTC (3 container statuses recorded)
Nov  1 15:49:24.158: INFO: 	Container dnsmasq ready: true, restart count 0
Nov  1 15:49:24.158: INFO: 	Container kubedns ready: true, restart count 0
Nov  1 15:49:24.158: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15630acaf5454236], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:49:25.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ftzl6" for this suite.
Nov  1 15:49:31.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:49:31.640: INFO: namespace: e2e-tests-sched-pred-ftzl6, resource: bindings, ignored listing per whitelist
Nov  1 15:49:31.710: INFO: namespace e2e-tests-sched-pred-ftzl6 deletion completed in 6.457100576s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:8.015 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:49:31.715: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1101 15:49:42.170101      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  1 15:49:42.170: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:49:42.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rsl2h" for this suite.
Nov  1 15:49:50.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:49:50.388: INFO: namespace: e2e-tests-gc-rsl2h, resource: bindings, ignored listing per whitelist
Nov  1 15:49:50.701: INFO: namespace e2e-tests-gc-rsl2h deletion completed in 8.525559686s

• [SLOW TEST:18.987 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:49:50.705: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:49:50.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rqfnl" for this suite.
Nov  1 15:49:56.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:49:57.062: INFO: namespace: e2e-tests-services-rqfnl, resource: bindings, ignored listing per whitelist
Nov  1 15:49:57.358: INFO: namespace e2e-tests-services-rqfnl deletion completed in 6.417400511s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.655 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:49:57.363: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-5shfj.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-5shfj.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5shfj.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-5shfj.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-5shfj.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5shfj.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  1 15:50:47.442: INFO: DNS probes using e2e-tests-dns-5shfj/dns-test-c87d5186-dded-11e8-a64b-2ef904c43a0d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:50:47.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-5shfj" for this suite.
Nov  1 15:50:53.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:50:53.780: INFO: namespace: e2e-tests-dns-5shfj, resource: bindings, ignored listing per whitelist
Nov  1 15:50:54.178: INFO: namespace e2e-tests-dns-5shfj deletion completed in 6.531196319s

• [SLOW TEST:56.816 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:50:54.181: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Nov  1 15:50:54.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:50:54.968: INFO: stderr: ""
Nov  1 15:50:54.968: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  1 15:50:54.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:50:55.148: INFO: stderr: ""
Nov  1 15:50:55.148: INFO: stdout: "update-demo-nautilus-2b4dh update-demo-nautilus-sfsrx "
Nov  1 15:50:55.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-2b4dh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:50:55.359: INFO: stderr: ""
Nov  1 15:50:55.359: INFO: stdout: ""
Nov  1 15:50:55.359: INFO: update-demo-nautilus-2b4dh is created but not running
Nov  1 15:51:00.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:51:00.531: INFO: stderr: ""
Nov  1 15:51:00.531: INFO: stdout: "update-demo-nautilus-2b4dh update-demo-nautilus-sfsrx "
Nov  1 15:51:00.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-2b4dh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:51:00.664: INFO: stderr: ""
Nov  1 15:51:00.664: INFO: stdout: "true"
Nov  1 15:51:00.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-2b4dh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:51:00.856: INFO: stderr: ""
Nov  1 15:51:00.856: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 15:51:00.856: INFO: validating pod update-demo-nautilus-2b4dh
Nov  1 15:51:00.898: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 15:51:00.898: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 15:51:00.898: INFO: update-demo-nautilus-2b4dh is verified up and running
Nov  1 15:51:00.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-sfsrx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:51:01.048: INFO: stderr: ""
Nov  1 15:51:01.048: INFO: stdout: "true"
Nov  1 15:51:01.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-sfsrx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:51:01.302: INFO: stderr: ""
Nov  1 15:51:01.302: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 15:51:01.302: INFO: validating pod update-demo-nautilus-sfsrx
Nov  1 15:51:01.404: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 15:51:01.404: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 15:51:01.404: INFO: update-demo-nautilus-sfsrx is verified up and running
STEP: using delete to clean up resources
Nov  1 15:51:01.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:51:01.560: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 15:51:01.560: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  1 15:51:01.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-mbtql'
Nov  1 15:51:01.793: INFO: stderr: "No resources found.\n"
Nov  1 15:51:01.793: INFO: stdout: ""
Nov  1 15:51:01.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -l name=update-demo --namespace=e2e-tests-kubectl-mbtql -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  1 15:51:02.068: INFO: stderr: ""
Nov  1 15:51:02.068: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:51:02.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mbtql" for this suite.
Nov  1 15:51:26.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:51:26.200: INFO: namespace: e2e-tests-kubectl-mbtql, resource: bindings, ignored listing per whitelist
Nov  1 15:51:26.570: INFO: namespace e2e-tests-kubectl-mbtql deletion completed in 24.489804579s

• [SLOW TEST:32.390 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:51:26.576: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fdb97680-dded-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 15:51:26.920: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fdc01b42-dded-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-hsm2t" to be "success or failure"
Nov  1 15:51:26.928: INFO: Pod "pod-projected-configmaps-fdc01b42-dded-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.58738ms
Nov  1 15:51:28.938: INFO: Pod "pod-projected-configmaps-fdc01b42-dded-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017040632s
STEP: Saw pod success
Nov  1 15:51:28.938: INFO: Pod "pod-projected-configmaps-fdc01b42-dded-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:51:28.942: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-configmaps-fdc01b42-dded-11e8-a64b-2ef904c43a0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 15:51:28.992: INFO: Waiting for pod pod-projected-configmaps-fdc01b42-dded-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:51:28.997: INFO: Pod pod-projected-configmaps-fdc01b42-dded-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:51:28.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hsm2t" for this suite.
Nov  1 15:51:35.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:51:35.624: INFO: namespace: e2e-tests-projected-hsm2t, resource: bindings, ignored listing per whitelist
Nov  1 15:51:36.398: INFO: namespace e2e-tests-projected-hsm2t deletion completed in 7.39444606s

• [SLOW TEST:9.823 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:51:36.402: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:51:36.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7qwch" for this suite.
Nov  1 15:52:00.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:52:01.082: INFO: namespace: e2e-tests-pods-7qwch, resource: bindings, ignored listing per whitelist
Nov  1 15:52:01.399: INFO: namespace e2e-tests-pods-7qwch deletion completed in 24.579910218s

• [SLOW TEST:24.997 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:52:01.399: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  1 15:52:01.668: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mj9kq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mj9kq/configmaps/e2e-watch-test-label-changed,UID:1271bf01-ddee-11e8-a94b-0a580af40661,ResourceVersion:2751,Generation:0,CreationTimestamp:2018-11-01 15:52:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  1 15:52:01.669: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mj9kq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mj9kq/configmaps/e2e-watch-test-label-changed,UID:1271bf01-ddee-11e8-a94b-0a580af40661,ResourceVersion:2752,Generation:0,CreationTimestamp:2018-11-01 15:52:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  1 15:52:01.669: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mj9kq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mj9kq/configmaps/e2e-watch-test-label-changed,UID:1271bf01-ddee-11e8-a94b-0a580af40661,ResourceVersion:2753,Generation:0,CreationTimestamp:2018-11-01 15:52:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  1 15:52:11.759: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mj9kq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mj9kq/configmaps/e2e-watch-test-label-changed,UID:1271bf01-ddee-11e8-a94b-0a580af40661,ResourceVersion:2774,Generation:0,CreationTimestamp:2018-11-01 15:52:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  1 15:52:11.760: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mj9kq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mj9kq/configmaps/e2e-watch-test-label-changed,UID:1271bf01-ddee-11e8-a94b-0a580af40661,ResourceVersion:2775,Generation:0,CreationTimestamp:2018-11-01 15:52:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  1 15:52:11.760: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mj9kq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mj9kq/configmaps/e2e-watch-test-label-changed,UID:1271bf01-ddee-11e8-a94b-0a580af40661,ResourceVersion:2776,Generation:0,CreationTimestamp:2018-11-01 15:52:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:52:11.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mj9kq" for this suite.
Nov  1 15:52:17.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:52:17.880: INFO: namespace: e2e-tests-watch-mj9kq, resource: bindings, ignored listing per whitelist
Nov  1 15:52:18.300: INFO: namespace e2e-tests-watch-mj9kq deletion completed in 6.532486734s

• [SLOW TEST:16.901 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:52:18.303: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 15:52:18.575: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c85dcb5-ddee-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-qrldv" to be "success or failure"
Nov  1 15:52:18.584: INFO: Pod "downwardapi-volume-1c85dcb5-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.483702ms
Nov  1 15:52:20.592: INFO: Pod "downwardapi-volume-1c85dcb5-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017119915s
Nov  1 15:52:22.622: INFO: Pod "downwardapi-volume-1c85dcb5-ddee-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046813614s
STEP: Saw pod success
Nov  1 15:52:22.622: INFO: Pod "downwardapi-volume-1c85dcb5-ddee-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:52:22.631: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod downwardapi-volume-1c85dcb5-ddee-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 15:52:22.733: INFO: Waiting for pod downwardapi-volume-1c85dcb5-ddee-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:52:22.737: INFO: Pod downwardapi-volume-1c85dcb5-ddee-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:52:22.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qrldv" for this suite.
Nov  1 15:52:28.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:52:29.136: INFO: namespace: e2e-tests-downward-api-qrldv, resource: bindings, ignored listing per whitelist
Nov  1 15:52:29.188: INFO: namespace e2e-tests-downward-api-qrldv deletion completed in 6.443759173s

• [SLOW TEST:10.886 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:52:29.189: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  1 15:52:29.454: INFO: Waiting up to 5m0s for pod "downward-api-2302f60a-ddee-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-wbrqx" to be "success or failure"
Nov  1 15:52:29.460: INFO: Pod "downward-api-2302f60a-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.708783ms
Nov  1 15:52:31.508: INFO: Pod "downward-api-2302f60a-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05400281s
Nov  1 15:52:33.526: INFO: Pod "downward-api-2302f60a-ddee-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071713199s
STEP: Saw pod success
Nov  1 15:52:33.526: INFO: Pod "downward-api-2302f60a-ddee-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:52:33.531: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downward-api-2302f60a-ddee-11e8-a64b-2ef904c43a0d container dapi-container: <nil>
STEP: delete the pod
Nov  1 15:52:33.610: INFO: Waiting for pod downward-api-2302f60a-ddee-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:52:33.629: INFO: Pod downward-api-2302f60a-ddee-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:52:33.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wbrqx" for this suite.
Nov  1 15:52:39.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:52:39.852: INFO: namespace: e2e-tests-downward-api-wbrqx, resource: bindings, ignored listing per whitelist
Nov  1 15:52:39.937: INFO: namespace e2e-tests-downward-api-wbrqx deletion completed in 6.300803719s

• [SLOW TEST:10.748 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:52:39.944: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-29708793-ddee-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 15:52:40.238: INFO: Waiting up to 5m0s for pod "pod-configmaps-29735ad2-ddee-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-vtg25" to be "success or failure"
Nov  1 15:52:40.310: INFO: Pod "pod-configmaps-29735ad2-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 71.91006ms
Nov  1 15:52:42.345: INFO: Pod "pod-configmaps-29735ad2-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106343666s
Nov  1 15:52:44.387: INFO: Pod "pod-configmaps-29735ad2-ddee-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.148675294s
STEP: Saw pod success
Nov  1 15:52:44.387: INFO: Pod "pod-configmaps-29735ad2-ddee-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:52:44.395: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-configmaps-29735ad2-ddee-11e8-a64b-2ef904c43a0d container configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 15:52:44.453: INFO: Waiting for pod pod-configmaps-29735ad2-ddee-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:52:44.495: INFO: Pod pod-configmaps-29735ad2-ddee-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:52:44.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vtg25" for this suite.
Nov  1 15:52:50.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:52:51.065: INFO: namespace: e2e-tests-configmap-vtg25, resource: bindings, ignored listing per whitelist
Nov  1 15:52:51.071: INFO: namespace e2e-tests-configmap-vtg25 deletion completed in 6.567024892s

• [SLOW TEST:11.128 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:52:51.078: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  1 15:52:57.429: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-301083c7-ddee-11e8-a64b-2ef904c43a0d,GenerateName:,Namespace:e2e-tests-events-d27xl,SelfLink:/api/v1/namespaces/e2e-tests-events-d27xl/pods/send-events-301083c7-ddee-11e8-a64b-2ef904c43a0d,UID:30162109-ddee-11e8-a94b-0a580af40661,ResourceVersion:2962,Generation:0,CreationTimestamp:2018-11-01 15:52:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 314381968,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ljlgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ljlgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-ljlgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4213a0b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4213a0b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 15:52:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 15:52:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 15:52:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 15:52:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.20,StartTime:2018-11-01 15:52:51 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-11-01 15:52:54 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://093c94aa5d83b525df157ac911de0ea42a5a034fc644b46ec19b2b79f8164e94}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Nov  1 15:52:59.439: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  1 15:53:01.448: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:53:01.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-d27xl" for this suite.
Nov  1 15:53:43.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:53:43.887: INFO: namespace: e2e-tests-events-d27xl, resource: bindings, ignored listing per whitelist
Nov  1 15:53:43.929: INFO: namespace e2e-tests-events-d27xl deletion completed in 42.457066345s

• [SLOW TEST:52.853 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:53:43.934: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Nov  1 15:53:44.136: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-994938124 proxy --unix-socket=/tmp/kubectl-proxy-unix329124603/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:53:44.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-grsld" for this suite.
Nov  1 15:53:50.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:53:50.675: INFO: namespace: e2e-tests-kubectl-grsld, resource: bindings, ignored listing per whitelist
Nov  1 15:53:50.778: INFO: namespace e2e-tests-kubectl-grsld deletion completed in 6.511556645s

• [SLOW TEST:6.845 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:53:50.780: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  1 15:53:51.154: INFO: Number of nodes with available pods: 0
Nov  1 15:53:51.154: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:53:52.241: INFO: Number of nodes with available pods: 0
Nov  1 15:53:52.241: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:53:53.179: INFO: Number of nodes with available pods: 1
Nov  1 15:53:53.179: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:53:54.336: INFO: Number of nodes with available pods: 1
Nov  1 15:53:54.337: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:53:55.171: INFO: Number of nodes with available pods: 2
Nov  1 15:53:55.172: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  1 15:53:55.225: INFO: Number of nodes with available pods: 1
Nov  1 15:53:55.225: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:53:56.241: INFO: Number of nodes with available pods: 1
Nov  1 15:53:56.242: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:53:57.246: INFO: Number of nodes with available pods: 1
Nov  1 15:53:57.247: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:53:58.248: INFO: Number of nodes with available pods: 1
Nov  1 15:53:58.248: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:53:59.246: INFO: Number of nodes with available pods: 1
Nov  1 15:53:59.246: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:00.243: INFO: Number of nodes with available pods: 1
Nov  1 15:54:00.243: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:01.237: INFO: Number of nodes with available pods: 1
Nov  1 15:54:01.238: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:02.261: INFO: Number of nodes with available pods: 1
Nov  1 15:54:02.261: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:03.265: INFO: Number of nodes with available pods: 1
Nov  1 15:54:03.265: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:04.257: INFO: Number of nodes with available pods: 1
Nov  1 15:54:04.258: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:05.243: INFO: Number of nodes with available pods: 1
Nov  1 15:54:05.243: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:06.238: INFO: Number of nodes with available pods: 1
Nov  1 15:54:06.238: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:07.247: INFO: Number of nodes with available pods: 1
Nov  1 15:54:07.247: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:08.247: INFO: Number of nodes with available pods: 1
Nov  1 15:54:08.248: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:09.236: INFO: Number of nodes with available pods: 1
Nov  1 15:54:09.236: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:10.257: INFO: Number of nodes with available pods: 1
Nov  1 15:54:10.257: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:11.322: INFO: Number of nodes with available pods: 1
Nov  1 15:54:11.322: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:12.242: INFO: Number of nodes with available pods: 1
Nov  1 15:54:12.242: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:13.328: INFO: Number of nodes with available pods: 1
Nov  1 15:54:13.328: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:14.258: INFO: Number of nodes with available pods: 1
Nov  1 15:54:14.258: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:15.254: INFO: Number of nodes with available pods: 1
Nov  1 15:54:15.254: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:16.251: INFO: Number of nodes with available pods: 1
Nov  1 15:54:16.251: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:17.239: INFO: Number of nodes with available pods: 1
Nov  1 15:54:17.239: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:18.244: INFO: Number of nodes with available pods: 1
Nov  1 15:54:18.244: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:19.245: INFO: Number of nodes with available pods: 1
Nov  1 15:54:19.245: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:20.247: INFO: Number of nodes with available pods: 1
Nov  1 15:54:20.248: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:21.310: INFO: Number of nodes with available pods: 1
Nov  1 15:54:21.311: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:22.251: INFO: Number of nodes with available pods: 1
Nov  1 15:54:22.251: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:23.316: INFO: Number of nodes with available pods: 1
Nov  1 15:54:23.316: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:24.325: INFO: Number of nodes with available pods: 1
Nov  1 15:54:24.325: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:25.242: INFO: Number of nodes with available pods: 1
Nov  1 15:54:25.242: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:26.248: INFO: Number of nodes with available pods: 1
Nov  1 15:54:26.249: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:27.238: INFO: Number of nodes with available pods: 1
Nov  1 15:54:27.238: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:28.242: INFO: Number of nodes with available pods: 1
Nov  1 15:54:28.242: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:29.243: INFO: Number of nodes with available pods: 1
Nov  1 15:54:29.243: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:30.315: INFO: Number of nodes with available pods: 1
Nov  1 15:54:30.315: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:31.239: INFO: Number of nodes with available pods: 1
Nov  1 15:54:31.239: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:54:32.261: INFO: Number of nodes with available pods: 2
Nov  1 15:54:32.261: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-rzm5f, will wait for the garbage collector to delete the pods
Nov  1 15:54:32.342: INFO: Deleting {extensions DaemonSet} daemon-set took: 16.954405ms
Nov  1 15:54:32.442: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.192052ms
Nov  1 15:55:13.359: INFO: Number of nodes with available pods: 0
Nov  1 15:55:13.359: INFO: Number of running nodes: 0, number of available pods: 0
Nov  1 15:55:13.371: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rzm5f/daemonsets","resourceVersion":"3302"},"items":null}

Nov  1 15:55:13.377: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rzm5f/pods","resourceVersion":"3302"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:55:13.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rzm5f" for this suite.
Nov  1 15:55:19.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:55:19.663: INFO: namespace: e2e-tests-daemonsets-rzm5f, resource: bindings, ignored listing per whitelist
Nov  1 15:55:19.885: INFO: namespace e2e-tests-daemonsets-rzm5f deletion completed in 6.484570059s

• [SLOW TEST:89.105 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:55:19.889: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  1 15:55:24.974: INFO: Successfully updated pod "annotationupdate88c9f50b-ddee-11e8-a64b-2ef904c43a0d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:55:27.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v5zn6" for this suite.
Nov  1 15:55:51.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:55:51.357: INFO: namespace: e2e-tests-downward-api-v5zn6, resource: bindings, ignored listing per whitelist
Nov  1 15:55:51.690: INFO: namespace e2e-tests-downward-api-v5zn6 deletion completed in 24.573405907s

• [SLOW TEST:31.803 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:55:51.695: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 15:55:52.027: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  1 15:55:52.344: INFO: Number of nodes with available pods: 0
Nov  1 15:55:52.344: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:55:53.439: INFO: Number of nodes with available pods: 0
Nov  1 15:55:53.439: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:55:54.357: INFO: Number of nodes with available pods: 0
Nov  1 15:55:54.357: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:55:55.358: INFO: Number of nodes with available pods: 2
Nov  1 15:55:55.359: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  1 15:55:55.411: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:55.411: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:56.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:56.432: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:57.454: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:57.454: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:58.437: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:58.438: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:59.433: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:55:59.433: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:00.434: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:00.434: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:01.455: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:01.455: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:02.434: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:02.434: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:03.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:03.432: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:04.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:04.433: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:05.458: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:05.458: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:06.436: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:06.436: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:07.440: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:07.440: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:08.518: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:08.518: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:09.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:09.432: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:10.433: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:10.433: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:11.437: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:11.437: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:12.434: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:12.435: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:13.447: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:13.447: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:14.443: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:14.444: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:15.450: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:15.450: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:16.445: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:16.445: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:17.437: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:17.437: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:18.438: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:18.438: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:19.445: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:19.445: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:20.434: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:20.435: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:21.441: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:21.441: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:22.433: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:22.433: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:23.437: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:23.437: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:24.436: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:24.436: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:25.456: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:25.456: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:26.442: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:26.443: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:27.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:27.432: INFO: Wrong image for pod: daemon-set-tchbn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:27.432: INFO: Pod daemon-set-tchbn is not available
Nov  1 15:56:28.435: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:28.435: INFO: Pod daemon-set-lp5xw is not available
Nov  1 15:56:29.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:29.432: INFO: Pod daemon-set-lp5xw is not available
Nov  1 15:56:30.450: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:30.450: INFO: Pod daemon-set-lp5xw is not available
Nov  1 15:56:31.435: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:31.435: INFO: Pod daemon-set-lp5xw is not available
Nov  1 15:56:32.437: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:32.438: INFO: Pod daemon-set-lp5xw is not available
Nov  1 15:56:33.433: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:34.435: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:35.503: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:36.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:37.431: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:38.504: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:39.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:40.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:41.509: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:42.435: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:43.432: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:44.458: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:45.507: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:46.433: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:47.433: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:48.439: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:49.507: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:50.440: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:51.532: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:52.435: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:53.439: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:54.443: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:55.431: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:56.434: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:57.435: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:58.434: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:56:59.435: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:57:00.433: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:57:01.434: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:57:02.447: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:57:03.442: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:57:04.436: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:57:05.433: INFO: Wrong image for pod: daemon-set-49c8t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  1 15:57:05.433: INFO: Pod daemon-set-49c8t is not available
Nov  1 15:57:06.436: INFO: Pod daemon-set-dqj4x is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  1 15:57:06.457: INFO: Number of nodes with available pods: 1
Nov  1 15:57:06.457: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:57:07.558: INFO: Number of nodes with available pods: 1
Nov  1 15:57:07.558: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:57:08.475: INFO: Number of nodes with available pods: 1
Nov  1 15:57:08.475: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:57:09.476: INFO: Number of nodes with available pods: 1
Nov  1 15:57:09.476: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 15:57:10.483: INFO: Number of nodes with available pods: 2
Nov  1 15:57:10.483: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-dpgwz, will wait for the garbage collector to delete the pods
Nov  1 15:57:10.605: INFO: Deleting {extensions DaemonSet} daemon-set took: 26.044339ms
Nov  1 15:57:10.705: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.213031ms
Nov  1 15:57:14.130: INFO: Number of nodes with available pods: 0
Nov  1 15:57:14.130: INFO: Number of running nodes: 0, number of available pods: 0
Nov  1 15:57:14.141: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dpgwz/daemonsets","resourceVersion":"3656"},"items":null}

Nov  1 15:57:14.145: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dpgwz/pods","resourceVersion":"3656"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:57:14.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dpgwz" for this suite.
Nov  1 15:57:22.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:57:22.268: INFO: namespace: e2e-tests-daemonsets-dpgwz, resource: bindings, ignored listing per whitelist
Nov  1 15:57:22.634: INFO: namespace e2e-tests-daemonsets-dpgwz deletion completed in 8.461921105s

• [SLOW TEST:90.940 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:57:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 15:57:22.836: INFO: Creating deployment "test-recreate-deployment"
Nov  1 15:57:22.860: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  1 15:57:22.882: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Nov  1 15:57:24.913: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  1 15:57:24.925: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676684642, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676684642, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676684643, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676684642, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 15:57:26.934: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  1 15:57:26.960: INFO: Updating deployment test-recreate-deployment
Nov  1 15:57:26.961: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  1 15:57:27.138: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-9zpmd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9zpmd/deployments/test-recreate-deployment,UID:d1e7a404-ddee-11e8-a94b-0a580af40661,ResourceVersion:3753,Generation:2,CreationTimestamp:2018-11-01 15:57:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-11-01 15:57:27 +0000 UTC 2018-11-01 15:57:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-11-01 15:57:27 +0000 UTC 2018-11-01 15:57:22 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Nov  1 15:57:27.149: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-9zpmd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9zpmd/replicasets/test-recreate-deployment-7cf749666b,UID:d46a7b3c-ddee-11e8-ad00-0a580af40ec2,ResourceVersion:3750,Generation:1,CreationTimestamp:2018-11-01 15:57:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d1e7a404-ddee-11e8-a94b-0a580af40661 0xc4217a5e27 0xc4217a5e28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  1 15:57:27.149: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  1 15:57:27.149: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-9zpmd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9zpmd/replicasets/test-recreate-deployment-79f694ff59,UID:d1ed5983-ddee-11e8-ad00-0a580af40ec2,ResourceVersion:3741,Generation:2,CreationTimestamp:2018-11-01 15:57:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d1e7a404-ddee-11e8-a94b-0a580af40661 0xc4217a5d77 0xc4217a5d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  1 15:57:27.155: INFO: Pod "test-recreate-deployment-7cf749666b-rvqm2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-rvqm2,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-9zpmd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9zpmd/pods/test-recreate-deployment-7cf749666b-rvqm2,UID:d46c96ab-ddee-11e8-ad00-0a580af40ec2,ResourceVersion:3754,Generation:0,CreationTimestamp:2018-11-01 15:57:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b d46a7b3c-ddee-11e8-ad00-0a580af40ec2 0xc42239c5f7 0xc42239c5f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-szhk6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-szhk6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-szhk6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42239c660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42239c680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 15:57:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 15:57:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 15:57:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 15:57:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 15:57:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:57:27.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9zpmd" for this suite.
Nov  1 15:57:35.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:57:35.688: INFO: namespace: e2e-tests-deployment-9zpmd, resource: bindings, ignored listing per whitelist
Nov  1 15:57:35.716: INFO: namespace e2e-tests-deployment-9zpmd deletion completed in 8.554379867s

• [SLOW TEST:13.081 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:57:35.725: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Nov  1 15:57:36.057: INFO: Waiting up to 5m0s for pod "var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-var-expansion-pl79f" to be "success or failure"
Nov  1 15:57:36.086: INFO: Pod "var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.347489ms
Nov  1 15:57:38.107: INFO: Pod "var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04943473s
Nov  1 15:57:40.116: INFO: Pod "var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058266026s
Nov  1 15:57:42.124: INFO: Pod "var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.066541844s
STEP: Saw pod success
Nov  1 15:57:42.125: INFO: Pod "var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:57:42.210: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d container dapi-container: <nil>
STEP: delete the pod
Nov  1 15:57:42.339: INFO: Waiting for pod var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:57:42.344: INFO: Pod var-expansion-d9c556e0-ddee-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:57:42.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-pl79f" for this suite.
Nov  1 15:57:48.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:57:48.492: INFO: namespace: e2e-tests-var-expansion-pl79f, resource: bindings, ignored listing per whitelist
Nov  1 15:57:48.952: INFO: namespace e2e-tests-var-expansion-pl79f deletion completed in 6.600366784s

• [SLOW TEST:13.228 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:57:48.958: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e19bff00-ddee-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 15:57:49.236: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e19f685e-ddee-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-9ccck" to be "success or failure"
Nov  1 15:57:49.244: INFO: Pod "pod-projected-configmaps-e19f685e-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.453556ms
Nov  1 15:57:51.264: INFO: Pod "pod-projected-configmaps-e19f685e-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027950869s
Nov  1 15:57:53.297: INFO: Pod "pod-projected-configmaps-e19f685e-ddee-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060836581s
STEP: Saw pod success
Nov  1 15:57:53.297: INFO: Pod "pod-projected-configmaps-e19f685e-ddee-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:57:53.303: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-projected-configmaps-e19f685e-ddee-11e8-a64b-2ef904c43a0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 15:57:53.435: INFO: Waiting for pod pod-projected-configmaps-e19f685e-ddee-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:57:53.441: INFO: Pod pod-projected-configmaps-e19f685e-ddee-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:57:53.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9ccck" for this suite.
Nov  1 15:57:59.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:57:59.796: INFO: namespace: e2e-tests-projected-9ccck, resource: bindings, ignored listing per whitelist
Nov  1 15:57:59.970: INFO: namespace e2e-tests-projected-9ccck deletion completed in 6.523196789s

• [SLOW TEST:11.014 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:57:59.975: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  1 15:58:00.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-lggx2'
Nov  1 15:58:00.359: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  1 15:58:00.359: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Nov  1 15:58:00.370: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Nov  1 15:58:00.393: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  1 15:58:00.413: INFO: scanned /root for discovery docs: <nil>
Nov  1 15:58:00.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-lggx2'
Nov  1 15:58:16.893: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  1 15:58:16.893: INFO: stdout: "Created e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d\nScaling up e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Nov  1 15:58:16.893: INFO: stdout: "Created e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d\nScaling up e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Nov  1 15:58:16.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lggx2'
Nov  1 15:58:17.049: INFO: stderr: ""
Nov  1 15:58:17.049: INFO: stdout: "e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d-8npps "
Nov  1 15:58:17.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d-8npps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lggx2'
Nov  1 15:58:17.206: INFO: stderr: ""
Nov  1 15:58:17.206: INFO: stdout: "true"
Nov  1 15:58:17.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d-8npps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lggx2'
Nov  1 15:58:17.375: INFO: stderr: ""
Nov  1 15:58:17.375: INFO: stdout: "nginx:1.14-alpine"
Nov  1 15:58:17.375: INFO: e2e-test-nginx-rc-d6beee68da4165a9cd4c3c5ed46b824d-8npps is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Nov  1 15:58:17.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lggx2'
Nov  1 15:58:17.523: INFO: stderr: ""
Nov  1 15:58:17.524: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:58:17.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lggx2" for this suite.
Nov  1 15:58:25.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:58:25.644: INFO: namespace: e2e-tests-kubectl-lggx2, resource: bindings, ignored listing per whitelist
Nov  1 15:58:26.040: INFO: namespace e2e-tests-kubectl-lggx2 deletion completed in 8.499866164s

• [SLOW TEST:26.066 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:58:26.044: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  1 15:58:26.326: INFO: Waiting up to 5m0s for pod "pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-zq2m5" to be "success or failure"
Nov  1 15:58:26.332: INFO: Pod "pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.200593ms
Nov  1 15:58:28.340: INFO: Pod "pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012900884s
Nov  1 15:58:30.387: INFO: Pod "pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.060390691s
Nov  1 15:58:32.395: INFO: Pod "pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.068117065s
STEP: Saw pod success
Nov  1 15:58:32.395: INFO: Pod "pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:58:32.400: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 15:58:32.473: INFO: Waiting for pod pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:58:32.479: INFO: Pod pod-f7bbfec3-ddee-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:58:32.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zq2m5" for this suite.
Nov  1 15:58:38.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:58:38.565: INFO: namespace: e2e-tests-emptydir-zq2m5, resource: bindings, ignored listing per whitelist
Nov  1 15:58:38.873: INFO: namespace e2e-tests-emptydir-zq2m5 deletion completed in 6.387464817s

• [SLOW TEST:12.830 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:58:38.875: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 15:58:39.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ff54eef9-ddee-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-v2mlk" to be "success or failure"
Nov  1 15:58:39.097: INFO: Pod "downwardapi-volume-ff54eef9-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.912943ms
Nov  1 15:58:41.137: INFO: Pod "downwardapi-volume-ff54eef9-ddee-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061131908s
Nov  1 15:58:43.143: INFO: Pod "downwardapi-volume-ff54eef9-ddee-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067720061s
STEP: Saw pod success
Nov  1 15:58:43.143: INFO: Pod "downwardapi-volume-ff54eef9-ddee-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 15:58:43.150: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-ff54eef9-ddee-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 15:58:43.291: INFO: Waiting for pod downwardapi-volume-ff54eef9-ddee-11e8-a64b-2ef904c43a0d to disappear
Nov  1 15:58:43.303: INFO: Pod downwardapi-volume-ff54eef9-ddee-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:58:43.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v2mlk" for this suite.
Nov  1 15:58:49.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:58:49.698: INFO: namespace: e2e-tests-projected-v2mlk, resource: bindings, ignored listing per whitelist
Nov  1 15:58:49.821: INFO: namespace e2e-tests-projected-v2mlk deletion completed in 6.512343417s

• [SLOW TEST:10.947 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:58:49.826: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-l225
STEP: Creating a pod to test atomic-volume-subpath
Nov  1 15:58:50.162: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-l225" in namespace "e2e-tests-subpath-wxqcn" to be "success or failure"
Nov  1 15:58:50.169: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Pending", Reason="", readiness=false. Elapsed: 7.085857ms
Nov  1 15:58:52.222: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060197873s
Nov  1 15:58:54.323: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 4.160885599s
Nov  1 15:58:56.331: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 6.168970738s
Nov  1 15:58:58.340: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 8.178061285s
Nov  1 15:59:00.353: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 10.190775302s
Nov  1 15:59:02.372: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 12.21019639s
Nov  1 15:59:04.380: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 14.218066891s
Nov  1 15:59:06.409: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 16.246727465s
Nov  1 15:59:08.419: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 18.257319112s
Nov  1 15:59:10.430: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 20.267715536s
Nov  1 15:59:12.464: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Running", Reason="", readiness=false. Elapsed: 22.302255829s
Nov  1 15:59:14.516: INFO: Pod "pod-subpath-test-configmap-l225": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.354031972s
STEP: Saw pod success
Nov  1 15:59:14.516: INFO: Pod "pod-subpath-test-configmap-l225" satisfied condition "success or failure"
Nov  1 15:59:14.525: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-subpath-test-configmap-l225 container test-container-subpath-configmap-l225: <nil>
STEP: delete the pod
Nov  1 15:59:14.654: INFO: Waiting for pod pod-subpath-test-configmap-l225 to disappear
Nov  1 15:59:14.665: INFO: Pod pod-subpath-test-configmap-l225 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-l225
Nov  1 15:59:14.665: INFO: Deleting pod "pod-subpath-test-configmap-l225" in namespace "e2e-tests-subpath-wxqcn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:59:14.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wxqcn" for this suite.
Nov  1 15:59:20.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:59:20.848: INFO: namespace: e2e-tests-subpath-wxqcn, resource: bindings, ignored listing per whitelist
Nov  1 15:59:21.150: INFO: namespace e2e-tests-subpath-wxqcn deletion completed in 6.473507552s

• [SLOW TEST:31.324 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:59:21.151: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1101 15:59:27.447922      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  1 15:59:27.448: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 15:59:27.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6crdn" for this suite.
Nov  1 15:59:35.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 15:59:35.561: INFO: namespace: e2e-tests-gc-6crdn, resource: bindings, ignored listing per whitelist
Nov  1 15:59:35.782: INFO: namespace e2e-tests-gc-6crdn deletion completed in 8.328644397s

• [SLOW TEST:14.631 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 15:59:35.782: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2149a100-ddef-11e8-a64b-2ef904c43a0d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-2149a100-ddef-11e8-a64b-2ef904c43a0d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:01:01.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k5glb" for this suite.
Nov  1 16:01:25.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:01:25.324: INFO: namespace: e2e-tests-configmap-k5glb, resource: bindings, ignored listing per whitelist
Nov  1 16:01:25.726: INFO: namespace e2e-tests-configmap-k5glb deletion completed in 24.495345453s

• [SLOW TEST:109.944 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:01:25.727: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-62d763f4-ddef-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:01:26.066: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-62dd0030-ddef-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-7cclp" to be "success or failure"
Nov  1 16:01:26.072: INFO: Pod "pod-projected-configmaps-62dd0030-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.092762ms
Nov  1 16:01:28.082: INFO: Pod "pod-projected-configmaps-62dd0030-ddef-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015711976s
STEP: Saw pod success
Nov  1 16:01:28.082: INFO: Pod "pod-projected-configmaps-62dd0030-ddef-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:01:28.088: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-configmaps-62dd0030-ddef-11e8-a64b-2ef904c43a0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 16:01:28.139: INFO: Waiting for pod pod-projected-configmaps-62dd0030-ddef-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:01:28.159: INFO: Pod pod-projected-configmaps-62dd0030-ddef-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:01:28.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7cclp" for this suite.
Nov  1 16:01:34.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:01:34.322: INFO: namespace: e2e-tests-projected-7cclp, resource: bindings, ignored listing per whitelist
Nov  1 16:01:35.102: INFO: namespace e2e-tests-projected-7cclp deletion completed in 6.93299279s

• [SLOW TEST:9.375 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:01:35.103: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  1 16:01:35.726: INFO: Waiting up to 5m0s for pod "pod-689f90ca-ddef-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-bhm6n" to be "success or failure"
Nov  1 16:01:35.737: INFO: Pod "pod-689f90ca-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.982743ms
Nov  1 16:01:37.749: INFO: Pod "pod-689f90ca-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023045401s
Nov  1 16:01:39.897: INFO: Pod "pod-689f90ca-ddef-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.170803919s
STEP: Saw pod success
Nov  1 16:01:39.897: INFO: Pod "pod-689f90ca-ddef-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:01:39.913: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-689f90ca-ddef-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:01:40.155: INFO: Waiting for pod pod-689f90ca-ddef-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:01:40.205: INFO: Pod pod-689f90ca-ddef-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:01:40.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bhm6n" for this suite.
Nov  1 16:01:46.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:01:46.733: INFO: namespace: e2e-tests-emptydir-bhm6n, resource: bindings, ignored listing per whitelist
Nov  1 16:01:46.746: INFO: namespace e2e-tests-emptydir-bhm6n deletion completed in 6.525590368s

• [SLOW TEST:11.644 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:01:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-frzm9
I1101 16:01:46.934477      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-frzm9, replica count: 1
I1101 16:01:47.985943      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1101 16:01:48.986478      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1101 16:01:49.987028      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  1 16:01:50.107: INFO: Created: latency-svc-pnnh9
Nov  1 16:01:50.139: INFO: Got endpoints: latency-svc-pnnh9 [51.623314ms]
Nov  1 16:01:50.166: INFO: Created: latency-svc-zpxvg
Nov  1 16:01:50.175: INFO: Got endpoints: latency-svc-zpxvg [35.196116ms]
Nov  1 16:01:50.178: INFO: Created: latency-svc-d7fxl
Nov  1 16:01:50.185: INFO: Got endpoints: latency-svc-d7fxl [44.944484ms]
Nov  1 16:01:50.189: INFO: Created: latency-svc-cm8bv
Nov  1 16:01:50.201: INFO: Got endpoints: latency-svc-cm8bv [60.057192ms]
Nov  1 16:01:50.201: INFO: Created: latency-svc-hxmfw
Nov  1 16:01:50.209: INFO: Got endpoints: latency-svc-hxmfw [68.474216ms]
Nov  1 16:01:50.224: INFO: Created: latency-svc-6dv6g
Nov  1 16:01:50.234: INFO: Got endpoints: latency-svc-6dv6g [88.65517ms]
Nov  1 16:01:50.251: INFO: Created: latency-svc-m4psw
Nov  1 16:01:50.261: INFO: Got endpoints: latency-svc-m4psw [116.378728ms]
Nov  1 16:01:50.275: INFO: Created: latency-svc-hf5qp
Nov  1 16:01:50.286: INFO: Got endpoints: latency-svc-hf5qp [141.496823ms]
Nov  1 16:01:50.300: INFO: Created: latency-svc-nk68g
Nov  1 16:01:50.308: INFO: Got endpoints: latency-svc-nk68g [163.474627ms]
Nov  1 16:01:50.313: INFO: Created: latency-svc-p44cl
Nov  1 16:01:50.322: INFO: Got endpoints: latency-svc-p44cl [177.346281ms]
Nov  1 16:01:50.334: INFO: Created: latency-svc-zzqs2
Nov  1 16:01:50.351: INFO: Got endpoints: latency-svc-zzqs2 [210.245522ms]
Nov  1 16:01:50.355: INFO: Created: latency-svc-grdc8
Nov  1 16:01:50.370: INFO: Got endpoints: latency-svc-grdc8 [225.160037ms]
Nov  1 16:01:50.387: INFO: Created: latency-svc-cshb4
Nov  1 16:01:50.399: INFO: Got endpoints: latency-svc-cshb4 [253.651339ms]
Nov  1 16:01:50.403: INFO: Created: latency-svc-9rcrp
Nov  1 16:01:50.418: INFO: Got endpoints: latency-svc-9rcrp [273.083521ms]
Nov  1 16:01:50.422: INFO: Created: latency-svc-d4krb
Nov  1 16:01:50.433: INFO: Got endpoints: latency-svc-d4krb [287.686783ms]
Nov  1 16:01:50.454: INFO: Created: latency-svc-cdtlz
Nov  1 16:01:50.463: INFO: Got endpoints: latency-svc-cdtlz [317.59705ms]
Nov  1 16:01:50.478: INFO: Created: latency-svc-rr2fr
Nov  1 16:01:50.482: INFO: Got endpoints: latency-svc-rr2fr [307.833574ms]
Nov  1 16:01:50.499: INFO: Created: latency-svc-cgndb
Nov  1 16:01:50.511: INFO: Got endpoints: latency-svc-cgndb [326.266592ms]
Nov  1 16:01:50.517: INFO: Created: latency-svc-7k264
Nov  1 16:01:50.525: INFO: Got endpoints: latency-svc-7k264 [42.507443ms]
Nov  1 16:01:50.532: INFO: Created: latency-svc-r9bcw
Nov  1 16:01:50.541: INFO: Got endpoints: latency-svc-r9bcw [339.748026ms]
Nov  1 16:01:50.550: INFO: Created: latency-svc-55m5d
Nov  1 16:01:50.561: INFO: Got endpoints: latency-svc-55m5d [352.156984ms]
Nov  1 16:01:50.571: INFO: Created: latency-svc-vnjxt
Nov  1 16:01:50.582: INFO: Got endpoints: latency-svc-vnjxt [348.719604ms]
Nov  1 16:01:50.586: INFO: Created: latency-svc-clxgt
Nov  1 16:01:50.614: INFO: Got endpoints: latency-svc-clxgt [352.55193ms]
Nov  1 16:01:50.620: INFO: Created: latency-svc-hx554
Nov  1 16:01:50.663: INFO: Got endpoints: latency-svc-hx554 [376.079045ms]
Nov  1 16:01:50.672: INFO: Created: latency-svc-xtbb2
Nov  1 16:01:50.679: INFO: Created: latency-svc-r7hzm
Nov  1 16:01:50.680: INFO: Got endpoints: latency-svc-xtbb2 [371.237264ms]
Nov  1 16:01:50.691: INFO: Created: latency-svc-4jdzv
Nov  1 16:01:50.707: INFO: Got endpoints: latency-svc-r7hzm [384.177863ms]
Nov  1 16:01:50.755: INFO: Got endpoints: latency-svc-4jdzv [403.811082ms]
Nov  1 16:01:50.771: INFO: Created: latency-svc-8bmmt
Nov  1 16:01:50.786: INFO: Got endpoints: latency-svc-8bmmt [415.24784ms]
Nov  1 16:01:50.796: INFO: Created: latency-svc-spdfr
Nov  1 16:01:50.805: INFO: Got endpoints: latency-svc-spdfr [405.939818ms]
Nov  1 16:01:50.812: INFO: Created: latency-svc-2ghfw
Nov  1 16:01:50.865: INFO: Got endpoints: latency-svc-2ghfw [446.350841ms]
Nov  1 16:01:50.880: INFO: Created: latency-svc-dkzwp
Nov  1 16:01:50.895: INFO: Created: latency-svc-bnphn
Nov  1 16:01:50.895: INFO: Got endpoints: latency-svc-dkzwp [461.96259ms]
Nov  1 16:01:50.907: INFO: Got endpoints: latency-svc-bnphn [444.380865ms]
Nov  1 16:01:50.911: INFO: Created: latency-svc-xbv9t
Nov  1 16:01:50.920: INFO: Got endpoints: latency-svc-xbv9t [408.621405ms]
Nov  1 16:01:50.932: INFO: Created: latency-svc-klf9l
Nov  1 16:01:50.938: INFO: Got endpoints: latency-svc-klf9l [412.443931ms]
Nov  1 16:01:50.958: INFO: Created: latency-svc-xwhp2
Nov  1 16:01:50.980: INFO: Created: latency-svc-7tp5l
Nov  1 16:01:50.985: INFO: Got endpoints: latency-svc-xwhp2 [443.882935ms]
Nov  1 16:01:50.989: INFO: Got endpoints: latency-svc-7tp5l [427.992182ms]
Nov  1 16:01:51.001: INFO: Created: latency-svc-km95s
Nov  1 16:01:51.012: INFO: Got endpoints: latency-svc-km95s [429.728786ms]
Nov  1 16:01:51.016: INFO: Created: latency-svc-rdmhg
Nov  1 16:01:51.031: INFO: Got endpoints: latency-svc-rdmhg [417.480921ms]
Nov  1 16:01:51.045: INFO: Created: latency-svc-w66xl
Nov  1 16:01:51.072: INFO: Got endpoints: latency-svc-w66xl [409.026177ms]
Nov  1 16:01:51.077: INFO: Created: latency-svc-g489k
Nov  1 16:01:51.122: INFO: Got endpoints: latency-svc-g489k [442.630937ms]
Nov  1 16:01:51.127: INFO: Created: latency-svc-2lvqz
Nov  1 16:01:51.139: INFO: Got endpoints: latency-svc-2lvqz [431.892522ms]
Nov  1 16:01:51.145: INFO: Created: latency-svc-lm5dj
Nov  1 16:01:51.156: INFO: Got endpoints: latency-svc-lm5dj [400.869471ms]
Nov  1 16:01:51.156: INFO: Created: latency-svc-5z8zj
Nov  1 16:01:51.173: INFO: Got endpoints: latency-svc-5z8zj [387.519846ms]
Nov  1 16:01:51.191: INFO: Created: latency-svc-ms9pp
Nov  1 16:01:51.203: INFO: Got endpoints: latency-svc-ms9pp [398.553198ms]
Nov  1 16:01:51.219: INFO: Created: latency-svc-tt2x8
Nov  1 16:01:51.219: INFO: Got endpoints: latency-svc-tt2x8 [353.847644ms]
Nov  1 16:01:51.244: INFO: Created: latency-svc-sjs82
Nov  1 16:01:51.269: INFO: Got endpoints: latency-svc-sjs82 [373.857065ms]
Nov  1 16:01:51.284: INFO: Created: latency-svc-c565b
Nov  1 16:01:51.290: INFO: Created: latency-svc-w8rxv
Nov  1 16:01:51.290: INFO: Got endpoints: latency-svc-c565b [383.02664ms]
Nov  1 16:01:51.333: INFO: Got endpoints: latency-svc-w8rxv [413.096155ms]
Nov  1 16:01:51.357: INFO: Created: latency-svc-7lh68
Nov  1 16:01:51.357: INFO: Got endpoints: latency-svc-7lh68 [419.464584ms]
Nov  1 16:01:51.364: INFO: Created: latency-svc-bz8ct
Nov  1 16:01:51.385: INFO: Created: latency-svc-vc5vd
Nov  1 16:01:51.385: INFO: Got endpoints: latency-svc-bz8ct [400.524763ms]
Nov  1 16:01:51.396: INFO: Created: latency-svc-pdzpr
Nov  1 16:01:51.396: INFO: Got endpoints: latency-svc-vc5vd [406.490509ms]
Nov  1 16:01:51.422: INFO: Got endpoints: latency-svc-pdzpr [409.72884ms]
Nov  1 16:01:51.427: INFO: Created: latency-svc-mdqt8
Nov  1 16:01:51.445: INFO: Got endpoints: latency-svc-mdqt8 [413.448862ms]
Nov  1 16:01:51.451: INFO: Created: latency-svc-5mr7l
Nov  1 16:01:51.475: INFO: Got endpoints: latency-svc-5mr7l [402.635921ms]
Nov  1 16:01:51.485: INFO: Created: latency-svc-t5zsh
Nov  1 16:01:51.509: INFO: Got endpoints: latency-svc-t5zsh [386.017837ms]
Nov  1 16:01:51.519: INFO: Created: latency-svc-vdxgx
Nov  1 16:01:51.533: INFO: Created: latency-svc-zt22t
Nov  1 16:01:51.533: INFO: Got endpoints: latency-svc-vdxgx [394.463065ms]
Nov  1 16:01:51.561: INFO: Got endpoints: latency-svc-zt22t [405.842574ms]
Nov  1 16:01:51.617: INFO: Created: latency-svc-579kk
Nov  1 16:01:51.622: INFO: Got endpoints: latency-svc-579kk [448.988258ms]
Nov  1 16:01:51.627: INFO: Created: latency-svc-f7vss
Nov  1 16:01:51.641: INFO: Got endpoints: latency-svc-f7vss [437.080255ms]
Nov  1 16:01:51.659: INFO: Created: latency-svc-7wkq8
Nov  1 16:01:51.679: INFO: Got endpoints: latency-svc-7wkq8 [459.778982ms]
Nov  1 16:01:51.679: INFO: Created: latency-svc-hf9qc
Nov  1 16:01:51.688: INFO: Got endpoints: latency-svc-hf9qc [418.891084ms]
Nov  1 16:01:51.725: INFO: Created: latency-svc-8d7vs
Nov  1 16:01:51.733: INFO: Got endpoints: latency-svc-8d7vs [442.399757ms]
Nov  1 16:01:51.733: INFO: Created: latency-svc-5vbfc
Nov  1 16:01:51.747: INFO: Created: latency-svc-r7c8x
Nov  1 16:01:51.778: INFO: Created: latency-svc-5htvc
Nov  1 16:01:51.789: INFO: Got endpoints: latency-svc-5vbfc [455.436664ms]
Nov  1 16:01:51.816: INFO: Created: latency-svc-fz995
Nov  1 16:01:51.829: INFO: Created: latency-svc-lw6wq
Nov  1 16:01:51.829: INFO: Got endpoints: latency-svc-r7c8x [472.016793ms]
Nov  1 16:01:51.856: INFO: Created: latency-svc-nsjt4
Nov  1 16:01:51.893: INFO: Got endpoints: latency-svc-5htvc [507.657441ms]
Nov  1 16:01:51.896: INFO: Created: latency-svc-8ghnc
Nov  1 16:01:51.936: INFO: Created: latency-svc-xd4pb
Nov  1 16:01:51.944: INFO: Got endpoints: latency-svc-fz995 [547.635698ms]
Nov  1 16:01:51.957: INFO: Created: latency-svc-qvnz7
Nov  1 16:01:51.989: INFO: Got endpoints: latency-svc-lw6wq [567.394591ms]
Nov  1 16:01:52.002: INFO: Created: latency-svc-5gflg
Nov  1 16:01:52.022: INFO: Created: latency-svc-ldc9s
Nov  1 16:01:52.031: INFO: Got endpoints: latency-svc-nsjt4 [586.626317ms]
Nov  1 16:01:52.070: INFO: Created: latency-svc-bhlnr
Nov  1 16:01:52.088: INFO: Got endpoints: latency-svc-8ghnc [613.517705ms]
Nov  1 16:01:52.107: INFO: Created: latency-svc-p62h6
Nov  1 16:01:52.116: INFO: Created: latency-svc-fzfpt
Nov  1 16:01:52.128: INFO: Got endpoints: latency-svc-xd4pb [619.643707ms]
Nov  1 16:01:52.134: INFO: Created: latency-svc-pn8pm
Nov  1 16:01:52.155: INFO: Created: latency-svc-v75q6
Nov  1 16:01:52.169: INFO: Created: latency-svc-n45hr
Nov  1 16:01:52.180: INFO: Created: latency-svc-dcsfj
Nov  1 16:01:52.184: INFO: Got endpoints: latency-svc-qvnz7 [651.039417ms]
Nov  1 16:01:52.199: INFO: Created: latency-svc-c4vst
Nov  1 16:01:52.219: INFO: Created: latency-svc-h8mwv
Nov  1 16:01:52.228: INFO: Got endpoints: latency-svc-5gflg [666.189656ms]
Nov  1 16:01:52.237: INFO: Created: latency-svc-48v4r
Nov  1 16:01:52.258: INFO: Created: latency-svc-hnk7d
Nov  1 16:01:52.279: INFO: Got endpoints: latency-svc-ldc9s [656.327238ms]
Nov  1 16:01:52.279: INFO: Created: latency-svc-vcbpq
Nov  1 16:01:52.302: INFO: Created: latency-svc-67fb2
Nov  1 16:01:52.327: INFO: Got endpoints: latency-svc-bhlnr [685.815746ms]
Nov  1 16:01:52.336: INFO: Created: latency-svc-p9drl
Nov  1 16:01:52.358: INFO: Created: latency-svc-vnqlc
Nov  1 16:01:52.379: INFO: Created: latency-svc-nxqzf
Nov  1 16:01:52.384: INFO: Got endpoints: latency-svc-p62h6 [705.490174ms]
Nov  1 16:01:52.410: INFO: Created: latency-svc-zzhmc
Nov  1 16:01:52.425: INFO: Got endpoints: latency-svc-fzfpt [737.549876ms]
Nov  1 16:01:52.481: INFO: Got endpoints: latency-svc-pn8pm [748.252358ms]
Nov  1 16:01:52.489: INFO: Created: latency-svc-tx7dv
Nov  1 16:01:52.516: INFO: Created: latency-svc-b2qnc
Nov  1 16:01:52.532: INFO: Got endpoints: latency-svc-v75q6 [743.2553ms]
Nov  1 16:01:52.570: INFO: Created: latency-svc-pqptg
Nov  1 16:01:52.578: INFO: Got endpoints: latency-svc-n45hr [748.461546ms]
Nov  1 16:01:52.606: INFO: Created: latency-svc-8l9nt
Nov  1 16:01:52.630: INFO: Got endpoints: latency-svc-dcsfj [737.187768ms]
Nov  1 16:01:52.648: INFO: Created: latency-svc-26k5n
Nov  1 16:01:52.678: INFO: Got endpoints: latency-svc-c4vst [734.56706ms]
Nov  1 16:01:52.722: INFO: Created: latency-svc-rljl7
Nov  1 16:01:52.759: INFO: Got endpoints: latency-svc-h8mwv [769.04067ms]
Nov  1 16:01:52.786: INFO: Got endpoints: latency-svc-48v4r [754.374762ms]
Nov  1 16:01:52.792: INFO: Created: latency-svc-pk4n9
Nov  1 16:01:52.857: INFO: Got endpoints: latency-svc-hnk7d [769.138652ms]
Nov  1 16:01:52.866: INFO: Created: latency-svc-fs2ts
Nov  1 16:01:52.883: INFO: Got endpoints: latency-svc-vcbpq [753.941101ms]
Nov  1 16:01:52.889: INFO: Created: latency-svc-2gn42
Nov  1 16:01:52.899: INFO: Created: latency-svc-2l2s6
Nov  1 16:01:52.926: INFO: Got endpoints: latency-svc-67fb2 [741.135573ms]
Nov  1 16:01:52.943: INFO: Created: latency-svc-c5qfz
Nov  1 16:01:52.986: INFO: Got endpoints: latency-svc-p9drl [758.000803ms]
Nov  1 16:01:53.025: INFO: Created: latency-svc-wp2mz
Nov  1 16:01:53.031: INFO: Got endpoints: latency-svc-vnqlc [752.394837ms]
Nov  1 16:01:53.077: INFO: Created: latency-svc-qnpv9
Nov  1 16:01:53.083: INFO: Got endpoints: latency-svc-nxqzf [756.519427ms]
Nov  1 16:01:53.102: INFO: Created: latency-svc-k72q4
Nov  1 16:01:53.125: INFO: Got endpoints: latency-svc-zzhmc [741.241486ms]
Nov  1 16:01:53.152: INFO: Created: latency-svc-6dkcx
Nov  1 16:01:53.175: INFO: Got endpoints: latency-svc-tx7dv [749.956255ms]
Nov  1 16:01:53.204: INFO: Created: latency-svc-rp6kb
Nov  1 16:01:53.226: INFO: Got endpoints: latency-svc-b2qnc [744.0975ms]
Nov  1 16:01:53.242: INFO: Created: latency-svc-w5vn8
Nov  1 16:01:53.276: INFO: Got endpoints: latency-svc-pqptg [744.125657ms]
Nov  1 16:01:53.305: INFO: Created: latency-svc-j4pqn
Nov  1 16:01:53.322: INFO: Got endpoints: latency-svc-8l9nt [744.29533ms]
Nov  1 16:01:53.352: INFO: Created: latency-svc-qzb2z
Nov  1 16:01:53.380: INFO: Got endpoints: latency-svc-26k5n [749.467156ms]
Nov  1 16:01:53.401: INFO: Created: latency-svc-kf8l9
Nov  1 16:01:53.423: INFO: Got endpoints: latency-svc-rljl7 [744.338919ms]
Nov  1 16:01:53.451: INFO: Created: latency-svc-6cchm
Nov  1 16:01:53.475: INFO: Got endpoints: latency-svc-pk4n9 [716.50681ms]
Nov  1 16:01:53.499: INFO: Created: latency-svc-7tz4l
Nov  1 16:01:53.535: INFO: Got endpoints: latency-svc-fs2ts [748.659491ms]
Nov  1 16:01:53.595: INFO: Created: latency-svc-q2h28
Nov  1 16:01:53.601: INFO: Got endpoints: latency-svc-2gn42 [743.150863ms]
Nov  1 16:01:53.630: INFO: Got endpoints: latency-svc-2l2s6 [747.520479ms]
Nov  1 16:01:53.631: INFO: Created: latency-svc-6fjbt
Nov  1 16:01:53.652: INFO: Created: latency-svc-rqwts
Nov  1 16:01:53.676: INFO: Got endpoints: latency-svc-c5qfz [750.398511ms]
Nov  1 16:01:53.698: INFO: Created: latency-svc-dm5p6
Nov  1 16:01:53.729: INFO: Got endpoints: latency-svc-wp2mz [743.102209ms]
Nov  1 16:01:53.755: INFO: Created: latency-svc-pn57k
Nov  1 16:01:53.787: INFO: Got endpoints: latency-svc-qnpv9 [755.033596ms]
Nov  1 16:01:53.805: INFO: Created: latency-svc-vmcm6
Nov  1 16:01:53.822: INFO: Got endpoints: latency-svc-k72q4 [738.882517ms]
Nov  1 16:01:53.837: INFO: Created: latency-svc-mzq85
Nov  1 16:01:53.874: INFO: Got endpoints: latency-svc-6dkcx [748.880522ms]
Nov  1 16:01:53.915: INFO: Created: latency-svc-4m95q
Nov  1 16:01:53.931: INFO: Got endpoints: latency-svc-rp6kb [754.943932ms]
Nov  1 16:01:53.962: INFO: Created: latency-svc-7fb7m
Nov  1 16:01:53.976: INFO: Got endpoints: latency-svc-w5vn8 [749.50835ms]
Nov  1 16:01:53.991: INFO: Created: latency-svc-rhfxh
Nov  1 16:01:54.034: INFO: Got endpoints: latency-svc-j4pqn [756.945145ms]
Nov  1 16:01:54.073: INFO: Created: latency-svc-x9q54
Nov  1 16:01:54.092: INFO: Got endpoints: latency-svc-qzb2z [769.822353ms]
Nov  1 16:01:54.125: INFO: Created: latency-svc-xrw9p
Nov  1 16:01:54.125: INFO: Got endpoints: latency-svc-kf8l9 [744.908632ms]
Nov  1 16:01:54.143: INFO: Created: latency-svc-2t8zd
Nov  1 16:01:54.178: INFO: Got endpoints: latency-svc-6cchm [755.496192ms]
Nov  1 16:01:54.202: INFO: Created: latency-svc-gk8hc
Nov  1 16:01:54.228: INFO: Got endpoints: latency-svc-7tz4l [752.415777ms]
Nov  1 16:01:54.246: INFO: Created: latency-svc-8z49v
Nov  1 16:01:54.278: INFO: Got endpoints: latency-svc-q2h28 [743.123071ms]
Nov  1 16:01:54.324: INFO: Created: latency-svc-v26ps
Nov  1 16:01:54.330: INFO: Got endpoints: latency-svc-6fjbt [728.800633ms]
Nov  1 16:01:54.369: INFO: Created: latency-svc-xxjqt
Nov  1 16:01:54.373: INFO: Got endpoints: latency-svc-rqwts [742.417821ms]
Nov  1 16:01:54.396: INFO: Created: latency-svc-hrlth
Nov  1 16:01:54.430: INFO: Got endpoints: latency-svc-dm5p6 [754.14391ms]
Nov  1 16:01:54.458: INFO: Created: latency-svc-58z8z
Nov  1 16:01:54.477: INFO: Got endpoints: latency-svc-pn57k [747.328354ms]
Nov  1 16:01:54.521: INFO: Created: latency-svc-b9pwb
Nov  1 16:01:54.525: INFO: Got endpoints: latency-svc-vmcm6 [738.450769ms]
Nov  1 16:01:54.553: INFO: Created: latency-svc-kj22s
Nov  1 16:01:54.582: INFO: Got endpoints: latency-svc-mzq85 [760.018307ms]
Nov  1 16:01:54.608: INFO: Created: latency-svc-zcqlx
Nov  1 16:01:54.627: INFO: Got endpoints: latency-svc-4m95q [752.066144ms]
Nov  1 16:01:54.652: INFO: Created: latency-svc-9fhkp
Nov  1 16:01:54.692: INFO: Got endpoints: latency-svc-7fb7m [761.515021ms]
Nov  1 16:01:54.722: INFO: Created: latency-svc-8dqjb
Nov  1 16:01:54.725: INFO: Got endpoints: latency-svc-rhfxh [748.848508ms]
Nov  1 16:01:54.763: INFO: Created: latency-svc-2cnt6
Nov  1 16:01:54.775: INFO: Got endpoints: latency-svc-x9q54 [740.690659ms]
Nov  1 16:01:54.803: INFO: Created: latency-svc-kvdzj
Nov  1 16:01:54.830: INFO: Got endpoints: latency-svc-xrw9p [737.578383ms]
Nov  1 16:01:54.849: INFO: Created: latency-svc-n4ws5
Nov  1 16:01:54.872: INFO: Got endpoints: latency-svc-2t8zd [746.694021ms]
Nov  1 16:01:54.894: INFO: Created: latency-svc-nkxrg
Nov  1 16:01:54.925: INFO: Got endpoints: latency-svc-gk8hc [746.742235ms]
Nov  1 16:01:54.968: INFO: Created: latency-svc-zbkws
Nov  1 16:01:54.973: INFO: Got endpoints: latency-svc-8z49v [744.724721ms]
Nov  1 16:01:54.994: INFO: Created: latency-svc-g549d
Nov  1 16:01:55.026: INFO: Got endpoints: latency-svc-v26ps [748.527735ms]
Nov  1 16:01:55.045: INFO: Created: latency-svc-qkvp6
Nov  1 16:01:55.080: INFO: Got endpoints: latency-svc-xxjqt [749.977239ms]
Nov  1 16:01:55.097: INFO: Created: latency-svc-66rqg
Nov  1 16:01:55.124: INFO: Got endpoints: latency-svc-hrlth [751.361552ms]
Nov  1 16:01:55.142: INFO: Created: latency-svc-q6cqh
Nov  1 16:01:55.177: INFO: Got endpoints: latency-svc-58z8z [745.976192ms]
Nov  1 16:01:55.204: INFO: Created: latency-svc-vcqpn
Nov  1 16:01:55.224: INFO: Got endpoints: latency-svc-b9pwb [747.097932ms]
Nov  1 16:01:55.259: INFO: Created: latency-svc-5h7h4
Nov  1 16:01:55.288: INFO: Got endpoints: latency-svc-kj22s [762.633284ms]
Nov  1 16:01:55.317: INFO: Created: latency-svc-r8bbt
Nov  1 16:01:55.347: INFO: Got endpoints: latency-svc-zcqlx [764.928399ms]
Nov  1 16:01:55.381: INFO: Got endpoints: latency-svc-9fhkp [754.155941ms]
Nov  1 16:01:55.395: INFO: Created: latency-svc-vjbqj
Nov  1 16:01:55.409: INFO: Created: latency-svc-jmv8w
Nov  1 16:01:55.435: INFO: Got endpoints: latency-svc-8dqjb [742.625187ms]
Nov  1 16:01:55.458: INFO: Created: latency-svc-76hlt
Nov  1 16:01:55.474: INFO: Got endpoints: latency-svc-2cnt6 [748.19685ms]
Nov  1 16:01:55.503: INFO: Created: latency-svc-sjqhs
Nov  1 16:01:55.533: INFO: Got endpoints: latency-svc-kvdzj [757.861817ms]
Nov  1 16:01:55.561: INFO: Created: latency-svc-2wljr
Nov  1 16:01:55.579: INFO: Got endpoints: latency-svc-n4ws5 [748.530426ms]
Nov  1 16:01:55.610: INFO: Created: latency-svc-wd6tw
Nov  1 16:01:55.623: INFO: Got endpoints: latency-svc-nkxrg [750.263296ms]
Nov  1 16:01:55.640: INFO: Created: latency-svc-8f4r9
Nov  1 16:01:55.685: INFO: Got endpoints: latency-svc-zbkws [759.717475ms]
Nov  1 16:01:55.711: INFO: Created: latency-svc-qps2t
Nov  1 16:01:55.735: INFO: Got endpoints: latency-svc-g549d [761.728759ms]
Nov  1 16:01:55.766: INFO: Created: latency-svc-h8pr2
Nov  1 16:01:55.825: INFO: Got endpoints: latency-svc-qkvp6 [797.908769ms]
Nov  1 16:01:55.828: INFO: Got endpoints: latency-svc-66rqg [748.538184ms]
Nov  1 16:01:55.843: INFO: Created: latency-svc-wjzmq
Nov  1 16:01:55.869: INFO: Created: latency-svc-d9n5m
Nov  1 16:01:55.920: INFO: Got endpoints: latency-svc-q6cqh [795.538051ms]
Nov  1 16:01:55.931: INFO: Got endpoints: latency-svc-vcqpn [754.455051ms]
Nov  1 16:01:55.947: INFO: Created: latency-svc-slr6p
Nov  1 16:01:55.967: INFO: Created: latency-svc-8hf2b
Nov  1 16:01:56.012: INFO: Got endpoints: latency-svc-5h7h4 [788.382021ms]
Nov  1 16:01:56.035: INFO: Got endpoints: latency-svc-r8bbt [746.688965ms]
Nov  1 16:01:56.049: INFO: Created: latency-svc-wq49k
Nov  1 16:01:56.061: INFO: Created: latency-svc-d9mvd
Nov  1 16:01:56.112: INFO: Got endpoints: latency-svc-vjbqj [764.560279ms]
Nov  1 16:01:56.132: INFO: Got endpoints: latency-svc-jmv8w [750.819409ms]
Nov  1 16:01:56.147: INFO: Created: latency-svc-hs6df
Nov  1 16:01:56.166: INFO: Created: latency-svc-qz7fv
Nov  1 16:01:56.181: INFO: Got endpoints: latency-svc-76hlt [746.152921ms]
Nov  1 16:01:56.197: INFO: Created: latency-svc-8c7wg
Nov  1 16:01:56.225: INFO: Got endpoints: latency-svc-sjqhs [751.603182ms]
Nov  1 16:01:56.246: INFO: Created: latency-svc-x7l5t
Nov  1 16:01:56.275: INFO: Got endpoints: latency-svc-2wljr [741.56603ms]
Nov  1 16:01:56.299: INFO: Created: latency-svc-bm84x
Nov  1 16:01:56.326: INFO: Got endpoints: latency-svc-wd6tw [747.194539ms]
Nov  1 16:01:56.343: INFO: Created: latency-svc-2c5mb
Nov  1 16:01:56.375: INFO: Got endpoints: latency-svc-8f4r9 [751.904105ms]
Nov  1 16:01:56.391: INFO: Created: latency-svc-zglfc
Nov  1 16:01:56.426: INFO: Got endpoints: latency-svc-qps2t [740.356123ms]
Nov  1 16:01:56.446: INFO: Created: latency-svc-ffk4k
Nov  1 16:01:56.477: INFO: Got endpoints: latency-svc-h8pr2 [742.746641ms]
Nov  1 16:01:56.503: INFO: Created: latency-svc-7b6dw
Nov  1 16:01:56.528: INFO: Got endpoints: latency-svc-wjzmq [703.215985ms]
Nov  1 16:01:56.555: INFO: Created: latency-svc-cbjl5
Nov  1 16:01:56.583: INFO: Got endpoints: latency-svc-d9n5m [754.943696ms]
Nov  1 16:01:56.604: INFO: Created: latency-svc-8nvwt
Nov  1 16:01:56.622: INFO: Got endpoints: latency-svc-slr6p [702.509057ms]
Nov  1 16:01:56.643: INFO: Created: latency-svc-29rjp
Nov  1 16:01:56.678: INFO: Got endpoints: latency-svc-8hf2b [747.242891ms]
Nov  1 16:01:56.702: INFO: Created: latency-svc-h9cc4
Nov  1 16:01:56.730: INFO: Got endpoints: latency-svc-wq49k [718.044706ms]
Nov  1 16:01:56.758: INFO: Created: latency-svc-vlpvx
Nov  1 16:01:56.775: INFO: Got endpoints: latency-svc-d9mvd [740.3464ms]
Nov  1 16:01:56.799: INFO: Created: latency-svc-bj4z2
Nov  1 16:01:56.826: INFO: Got endpoints: latency-svc-hs6df [713.958326ms]
Nov  1 16:01:56.862: INFO: Created: latency-svc-hdcmf
Nov  1 16:01:56.886: INFO: Got endpoints: latency-svc-qz7fv [754.070364ms]
Nov  1 16:01:56.913: INFO: Created: latency-svc-lcdr9
Nov  1 16:01:56.925: INFO: Got endpoints: latency-svc-8c7wg [743.924239ms]
Nov  1 16:01:56.945: INFO: Created: latency-svc-hn924
Nov  1 16:01:56.983: INFO: Got endpoints: latency-svc-x7l5t [757.21962ms]
Nov  1 16:01:57.007: INFO: Created: latency-svc-wx8ck
Nov  1 16:01:57.032: INFO: Got endpoints: latency-svc-bm84x [757.385126ms]
Nov  1 16:01:57.060: INFO: Created: latency-svc-khgnl
Nov  1 16:01:57.077: INFO: Got endpoints: latency-svc-2c5mb [750.809264ms]
Nov  1 16:01:57.095: INFO: Created: latency-svc-s4wkt
Nov  1 16:01:57.125: INFO: Got endpoints: latency-svc-zglfc [750.612384ms]
Nov  1 16:01:57.144: INFO: Created: latency-svc-9hmwt
Nov  1 16:01:57.175: INFO: Got endpoints: latency-svc-ffk4k [748.688853ms]
Nov  1 16:01:57.193: INFO: Created: latency-svc-8zcrc
Nov  1 16:01:57.229: INFO: Got endpoints: latency-svc-7b6dw [751.089122ms]
Nov  1 16:01:57.257: INFO: Created: latency-svc-d6qrt
Nov  1 16:01:57.276: INFO: Got endpoints: latency-svc-cbjl5 [748.251531ms]
Nov  1 16:01:57.294: INFO: Created: latency-svc-nbd2b
Nov  1 16:01:57.323: INFO: Got endpoints: latency-svc-8nvwt [738.866248ms]
Nov  1 16:01:57.342: INFO: Created: latency-svc-2bfrx
Nov  1 16:01:57.388: INFO: Got endpoints: latency-svc-29rjp [765.501056ms]
Nov  1 16:01:57.428: INFO: Got endpoints: latency-svc-h9cc4 [749.921976ms]
Nov  1 16:01:57.455: INFO: Created: latency-svc-jn9q4
Nov  1 16:01:57.474: INFO: Created: latency-svc-pr528
Nov  1 16:01:57.485: INFO: Got endpoints: latency-svc-vlpvx [754.69695ms]
Nov  1 16:01:57.526: INFO: Created: latency-svc-6xjpm
Nov  1 16:01:57.534: INFO: Got endpoints: latency-svc-bj4z2 [759.324736ms]
Nov  1 16:01:57.569: INFO: Created: latency-svc-gc8rv
Nov  1 16:01:57.580: INFO: Got endpoints: latency-svc-hdcmf [753.667702ms]
Nov  1 16:01:57.614: INFO: Created: latency-svc-d76g6
Nov  1 16:01:57.628: INFO: Got endpoints: latency-svc-lcdr9 [741.636872ms]
Nov  1 16:01:57.646: INFO: Created: latency-svc-c94nj
Nov  1 16:01:57.678: INFO: Got endpoints: latency-svc-hn924 [752.849827ms]
Nov  1 16:01:57.707: INFO: Created: latency-svc-fq2vq
Nov  1 16:01:57.730: INFO: Got endpoints: latency-svc-wx8ck [747.514468ms]
Nov  1 16:01:57.750: INFO: Created: latency-svc-mf6vt
Nov  1 16:01:57.778: INFO: Got endpoints: latency-svc-khgnl [746.20533ms]
Nov  1 16:01:57.811: INFO: Created: latency-svc-cpt5z
Nov  1 16:01:57.841: INFO: Got endpoints: latency-svc-s4wkt [762.476034ms]
Nov  1 16:01:57.879: INFO: Got endpoints: latency-svc-9hmwt [753.083643ms]
Nov  1 16:01:57.879: INFO: Created: latency-svc-65tlv
Nov  1 16:01:57.903: INFO: Created: latency-svc-gh2sp
Nov  1 16:01:57.924: INFO: Got endpoints: latency-svc-8zcrc [749.514564ms]
Nov  1 16:01:57.940: INFO: Created: latency-svc-fnhjl
Nov  1 16:01:57.989: INFO: Got endpoints: latency-svc-d6qrt [760.692281ms]
Nov  1 16:01:58.029: INFO: Got endpoints: latency-svc-nbd2b [752.23231ms]
Nov  1 16:01:58.098: INFO: Got endpoints: latency-svc-2bfrx [775.737697ms]
Nov  1 16:01:58.161: INFO: Got endpoints: latency-svc-jn9q4 [772.655667ms]
Nov  1 16:01:58.194: INFO: Got endpoints: latency-svc-pr528 [765.913012ms]
Nov  1 16:01:58.249: INFO: Got endpoints: latency-svc-6xjpm [763.163338ms]
Nov  1 16:01:58.326: INFO: Got endpoints: latency-svc-gc8rv [791.073245ms]
Nov  1 16:01:58.359: INFO: Got endpoints: latency-svc-d76g6 [778.230071ms]
Nov  1 16:01:58.432: INFO: Got endpoints: latency-svc-c94nj [804.078631ms]
Nov  1 16:01:58.457: INFO: Got endpoints: latency-svc-fq2vq [778.935508ms]
Nov  1 16:01:58.509: INFO: Got endpoints: latency-svc-mf6vt [779.038744ms]
Nov  1 16:01:58.566: INFO: Got endpoints: latency-svc-cpt5z [787.389101ms]
Nov  1 16:01:58.611: INFO: Got endpoints: latency-svc-65tlv [769.421581ms]
Nov  1 16:01:58.648: INFO: Got endpoints: latency-svc-gh2sp [769.850928ms]
Nov  1 16:01:58.719: INFO: Got endpoints: latency-svc-fnhjl [794.215201ms]
Nov  1 16:01:58.719: INFO: Latencies: [35.196116ms 42.507443ms 44.944484ms 60.057192ms 68.474216ms 88.65517ms 116.378728ms 141.496823ms 163.474627ms 177.346281ms 210.245522ms 225.160037ms 253.651339ms 273.083521ms 287.686783ms 307.833574ms 317.59705ms 326.266592ms 339.748026ms 348.719604ms 352.156984ms 352.55193ms 353.847644ms 371.237264ms 373.857065ms 376.079045ms 383.02664ms 384.177863ms 386.017837ms 387.519846ms 394.463065ms 398.553198ms 400.524763ms 400.869471ms 402.635921ms 403.811082ms 405.842574ms 405.939818ms 406.490509ms 408.621405ms 409.026177ms 409.72884ms 412.443931ms 413.096155ms 413.448862ms 415.24784ms 417.480921ms 418.891084ms 419.464584ms 427.992182ms 429.728786ms 431.892522ms 437.080255ms 442.399757ms 442.630937ms 443.882935ms 444.380865ms 446.350841ms 448.988258ms 455.436664ms 459.778982ms 461.96259ms 472.016793ms 507.657441ms 547.635698ms 567.394591ms 586.626317ms 613.517705ms 619.643707ms 651.039417ms 656.327238ms 666.189656ms 685.815746ms 702.509057ms 703.215985ms 705.490174ms 713.958326ms 716.50681ms 718.044706ms 728.800633ms 734.56706ms 737.187768ms 737.549876ms 737.578383ms 738.450769ms 738.866248ms 738.882517ms 740.3464ms 740.356123ms 740.690659ms 741.135573ms 741.241486ms 741.56603ms 741.636872ms 742.417821ms 742.625187ms 742.746641ms 743.102209ms 743.123071ms 743.150863ms 743.2553ms 743.924239ms 744.0975ms 744.125657ms 744.29533ms 744.338919ms 744.724721ms 744.908632ms 745.976192ms 746.152921ms 746.20533ms 746.688965ms 746.694021ms 746.742235ms 747.097932ms 747.194539ms 747.242891ms 747.328354ms 747.514468ms 747.520479ms 748.19685ms 748.251531ms 748.252358ms 748.461546ms 748.527735ms 748.530426ms 748.538184ms 748.659491ms 748.688853ms 748.848508ms 748.880522ms 749.467156ms 749.50835ms 749.514564ms 749.921976ms 749.956255ms 749.977239ms 750.263296ms 750.398511ms 750.612384ms 750.809264ms 750.819409ms 751.089122ms 751.361552ms 751.603182ms 751.904105ms 752.066144ms 752.23231ms 752.394837ms 752.415777ms 752.849827ms 753.083643ms 753.667702ms 753.941101ms 754.070364ms 754.14391ms 754.155941ms 754.374762ms 754.455051ms 754.69695ms 754.943696ms 754.943932ms 755.033596ms 755.496192ms 756.519427ms 756.945145ms 757.21962ms 757.385126ms 757.861817ms 758.000803ms 759.324736ms 759.717475ms 760.018307ms 760.692281ms 761.515021ms 761.728759ms 762.476034ms 762.633284ms 763.163338ms 764.560279ms 764.928399ms 765.501056ms 765.913012ms 769.04067ms 769.138652ms 769.421581ms 769.822353ms 769.850928ms 772.655667ms 775.737697ms 778.230071ms 778.935508ms 779.038744ms 787.389101ms 788.382021ms 791.073245ms 794.215201ms 795.538051ms 797.908769ms 804.078631ms]
Nov  1 16:01:58.719: INFO: 50 %ile: 743.2553ms
Nov  1 16:01:58.719: INFO: 90 %ile: 764.928399ms
Nov  1 16:01:58.719: INFO: 99 %ile: 797.908769ms
Nov  1 16:01:58.719: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:01:58.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-frzm9" for this suite.
Nov  1 16:02:16.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:02:17.091: INFO: namespace: e2e-tests-svc-latency-frzm9, resource: bindings, ignored listing per whitelist
Nov  1 16:02:17.310: INFO: namespace e2e-tests-svc-latency-frzm9 deletion completed in 18.517525547s

• [SLOW TEST:30.562 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:02:17.316: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1101 16:02:57.906896      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  1 16:02:57.907: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:02:57.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5frg4" for this suite.
Nov  1 16:03:06.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:03:06.384: INFO: namespace: e2e-tests-gc-5frg4, resource: bindings, ignored listing per whitelist
Nov  1 16:03:06.418: INFO: namespace e2e-tests-gc-5frg4 deletion completed in 8.501533893s

• [SLOW TEST:49.103 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:03:06.419: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Nov  1 16:03:06.593: INFO: Waiting up to 5m0s for pod "client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-containers-fxphl" to be "success or failure"
Nov  1 16:03:06.599: INFO: Pod "client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.421464ms
Nov  1 16:03:08.627: INFO: Pod "client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034565775s
Nov  1 16:03:10.659: INFO: Pod "client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.066042627s
Nov  1 16:03:12.671: INFO: Pod "client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.077856894s
STEP: Saw pod success
Nov  1 16:03:12.671: INFO: Pod "client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:03:12.679: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:03:12.797: INFO: Waiting for pod client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:03:12.807: INFO: Pod client-containers-9ec8421e-ddef-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:03:12.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fxphl" for this suite.
Nov  1 16:03:18.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:03:19.238: INFO: namespace: e2e-tests-containers-fxphl, resource: bindings, ignored listing per whitelist
Nov  1 16:03:19.292: INFO: namespace e2e-tests-containers-fxphl deletion completed in 6.476321379s

• [SLOW TEST:12.873 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:03:19.294: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qzdlx
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  1 16:03:19.523: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  1 16:03:43.709: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.0.40:8080/dial?request=hostName&protocol=http&host=172.25.1.40&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qzdlx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 16:03:43.709: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 16:03:44.177: INFO: Waiting for endpoints: map[]
Nov  1 16:03:44.184: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.0.40:8080/dial?request=hostName&protocol=http&host=172.25.0.39&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qzdlx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 16:03:44.184: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 16:03:44.663: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:03:44.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qzdlx" for this suite.
Nov  1 16:04:08.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:04:09.015: INFO: namespace: e2e-tests-pod-network-test-qzdlx, resource: bindings, ignored listing per whitelist
Nov  1 16:04:09.072: INFO: namespace e2e-tests-pod-network-test-qzdlx deletion completed in 24.402341376s

• [SLOW TEST:49.778 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:04:09.076: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  1 16:04:09.284: INFO: Waiting up to 5m0s for pod "downward-api-c4261644-ddef-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-8f85t" to be "success or failure"
Nov  1 16:04:09.292: INFO: Pod "downward-api-c4261644-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.285026ms
Nov  1 16:04:11.302: INFO: Pod "downward-api-c4261644-ddef-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017266494s
STEP: Saw pod success
Nov  1 16:04:11.302: INFO: Pod "downward-api-c4261644-ddef-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:04:11.313: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downward-api-c4261644-ddef-11e8-a64b-2ef904c43a0d container dapi-container: <nil>
STEP: delete the pod
Nov  1 16:04:11.411: INFO: Waiting for pod downward-api-c4261644-ddef-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:04:11.432: INFO: Pod downward-api-c4261644-ddef-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:04:11.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8f85t" for this suite.
Nov  1 16:04:17.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:04:17.574: INFO: namespace: e2e-tests-downward-api-8f85t, resource: bindings, ignored listing per whitelist
Nov  1 16:04:17.978: INFO: namespace e2e-tests-downward-api-8f85t deletion completed in 6.531768402s

• [SLOW TEST:8.902 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:04:17.984: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1101 16:04:19.323974      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  1 16:04:19.324: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:04:19.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2kjmf" for this suite.
Nov  1 16:04:25.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:04:25.648: INFO: namespace: e2e-tests-gc-2kjmf, resource: bindings, ignored listing per whitelist
Nov  1 16:04:25.838: INFO: namespace e2e-tests-gc-2kjmf deletion completed in 6.506756409s

• [SLOW TEST:7.855 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:04:25.843: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:04:26.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce39176d-ddef-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-hd4qg" to be "success or failure"
Nov  1 16:04:26.306: INFO: Pod "downwardapi-volume-ce39176d-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 92.783619ms
Nov  1 16:04:28.405: INFO: Pod "downwardapi-volume-ce39176d-ddef-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.190808712s
Nov  1 16:04:30.414: INFO: Pod "downwardapi-volume-ce39176d-ddef-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.200005342s
STEP: Saw pod success
Nov  1 16:04:30.414: INFO: Pod "downwardapi-volume-ce39176d-ddef-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:04:30.419: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-ce39176d-ddef-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:04:30.539: INFO: Waiting for pod downwardapi-volume-ce39176d-ddef-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:04:30.544: INFO: Pod downwardapi-volume-ce39176d-ddef-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:04:30.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hd4qg" for this suite.
Nov  1 16:04:36.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:04:37.512: INFO: namespace: e2e-tests-projected-hd4qg, resource: bindings, ignored listing per whitelist
Nov  1 16:04:37.549: INFO: namespace e2e-tests-projected-hd4qg deletion completed in 6.998490436s

• [SLOW TEST:11.707 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:04:37.555: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Nov  1 16:04:37.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:04:39.218: INFO: stderr: ""
Nov  1 16:04:39.218: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  1 16:04:39.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:04:39.342: INFO: stderr: ""
Nov  1 16:04:39.342: INFO: stdout: "update-demo-nautilus-b6jfs "
STEP: Replicas for name=update-demo: expected=2 actual=1
Nov  1 16:04:44.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:04:44.622: INFO: stderr: ""
Nov  1 16:04:44.622: INFO: stdout: "update-demo-nautilus-b6jfs update-demo-nautilus-lf6gd "
Nov  1 16:04:44.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-b6jfs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:04:44.765: INFO: stderr: ""
Nov  1 16:04:44.765: INFO: stdout: "true"
Nov  1 16:04:44.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-b6jfs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:04:45.043: INFO: stderr: ""
Nov  1 16:04:45.043: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 16:04:45.043: INFO: validating pod update-demo-nautilus-b6jfs
Nov  1 16:04:45.153: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 16:04:45.153: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 16:04:45.153: INFO: update-demo-nautilus-b6jfs is verified up and running
Nov  1 16:04:45.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-lf6gd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:04:45.407: INFO: stderr: ""
Nov  1 16:04:45.407: INFO: stdout: "true"
Nov  1 16:04:45.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-lf6gd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:04:45.550: INFO: stderr: ""
Nov  1 16:04:45.550: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 16:04:45.550: INFO: validating pod update-demo-nautilus-lf6gd
Nov  1 16:04:45.649: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 16:04:45.649: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 16:04:45.649: INFO: update-demo-nautilus-lf6gd is verified up and running
STEP: rolling-update to new replication controller
Nov  1 16:04:45.654: INFO: scanned /root for discovery docs: <nil>
Nov  1 16:04:45.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:05:11.765: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  1 16:05:11.766: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  1 16:05:11.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:05:11.968: INFO: stderr: ""
Nov  1 16:05:11.969: INFO: stdout: "update-demo-kitten-ftpzg update-demo-kitten-nxw8d update-demo-nautilus-b6jfs "
STEP: Replicas for name=update-demo: expected=2 actual=3
Nov  1 16:05:16.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:05:17.104: INFO: stderr: ""
Nov  1 16:05:17.104: INFO: stdout: "update-demo-kitten-ftpzg update-demo-kitten-nxw8d "
Nov  1 16:05:17.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-kitten-ftpzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:05:17.330: INFO: stderr: ""
Nov  1 16:05:17.330: INFO: stdout: "true"
Nov  1 16:05:17.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-kitten-ftpzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:05:17.497: INFO: stderr: ""
Nov  1 16:05:17.497: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  1 16:05:17.497: INFO: validating pod update-demo-kitten-ftpzg
Nov  1 16:05:17.640: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  1 16:05:17.641: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  1 16:05:17.641: INFO: update-demo-kitten-ftpzg is verified up and running
Nov  1 16:05:17.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-kitten-nxw8d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:05:17.808: INFO: stderr: ""
Nov  1 16:05:17.808: INFO: stdout: "true"
Nov  1 16:05:17.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-kitten-nxw8d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqmw9'
Nov  1 16:05:17.983: INFO: stderr: ""
Nov  1 16:05:17.983: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  1 16:05:17.983: INFO: validating pod update-demo-kitten-nxw8d
Nov  1 16:05:18.109: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  1 16:05:18.109: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  1 16:05:18.109: INFO: update-demo-kitten-nxw8d is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:05:18.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hqmw9" for this suite.
Nov  1 16:05:38.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:05:38.439: INFO: namespace: e2e-tests-kubectl-hqmw9, resource: bindings, ignored listing per whitelist
Nov  1 16:05:38.617: INFO: namespace e2e-tests-kubectl-hqmw9 deletion completed in 20.464814435s

• [SLOW TEST:61.063 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:05:38.622: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:05:38.976: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Nov  1 16:05:38.988: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r5vfn/daemonsets","resourceVersion":"7099"},"items":null}

Nov  1 16:05:38.993: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r5vfn/pods","resourceVersion":"7099"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:05:39.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r5vfn" for this suite.
Nov  1 16:05:45.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:05:45.527: INFO: namespace: e2e-tests-daemonsets-r5vfn, resource: bindings, ignored listing per whitelist
Nov  1 16:05:45.535: INFO: namespace e2e-tests-daemonsets-r5vfn deletion completed in 6.51601115s

S [SKIPPING] [6.914 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Nov  1 16:05:38.976: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:05:45.537: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:05:45.967: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fdbd2c94-ddef-11e8-a94b-0a580af40661", Controller:(*bool)(0xc422034502), BlockOwnerDeletion:(*bool)(0xc422034503)}}
Nov  1 16:05:46.017: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"fdb31959-ddef-11e8-a94b-0a580af40661", Controller:(*bool)(0xc422034a3a), BlockOwnerDeletion:(*bool)(0xc422034a3b)}}
Nov  1 16:05:46.027: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fdb7fda3-ddef-11e8-a94b-0a580af40661", Controller:(*bool)(0xc422035652), BlockOwnerDeletion:(*bool)(0xc422035653)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:05:51.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cchlx" for this suite.
Nov  1 16:05:57.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:05:57.540: INFO: namespace: e2e-tests-gc-cchlx, resource: bindings, ignored listing per whitelist
Nov  1 16:05:57.610: INFO: namespace e2e-tests-gc-cchlx deletion completed in 6.50072711s

• [SLOW TEST:12.074 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:05:57.613: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:05:57.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 version'
Nov  1 16:05:58.035: INFO: stderr: ""
Nov  1 16:05:58.035: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.2\", GitCommit:\"17c77c7898218073f14c8d573582e8d2313dc740\", GitTreeState:\"clean\", BuildDate:\"2018-10-24T06:43:59Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:05:58.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pqk5z" for this suite.
Nov  1 16:06:04.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:06:04.509: INFO: namespace: e2e-tests-kubectl-pqk5z, resource: bindings, ignored listing per whitelist
Nov  1 16:06:04.652: INFO: namespace e2e-tests-kubectl-pqk5z deletion completed in 6.609327117s

• [SLOW TEST:7.040 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:06:04.655: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Nov  1 16:06:04.951: INFO: Waiting up to 5m0s for pod "var-expansion-09142e22-ddf0-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-var-expansion-qrrnw" to be "success or failure"
Nov  1 16:06:04.996: INFO: Pod "var-expansion-09142e22-ddf0-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 44.861252ms
Nov  1 16:06:07.107: INFO: Pod "var-expansion-09142e22-ddf0-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.155975513s
STEP: Saw pod success
Nov  1 16:06:07.107: INFO: Pod "var-expansion-09142e22-ddf0-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:06:07.112: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod var-expansion-09142e22-ddf0-11e8-a64b-2ef904c43a0d container dapi-container: <nil>
STEP: delete the pod
Nov  1 16:06:07.236: INFO: Waiting for pod var-expansion-09142e22-ddf0-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:06:07.254: INFO: Pod var-expansion-09142e22-ddf0-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:06:07.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qrrnw" for this suite.
Nov  1 16:06:13.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:06:13.634: INFO: namespace: e2e-tests-var-expansion-qrrnw, resource: bindings, ignored listing per whitelist
Nov  1 16:06:13.782: INFO: namespace e2e-tests-var-expansion-qrrnw deletion completed in 6.514372285s

• [SLOW TEST:9.128 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:06:13.788: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zlzgd
Nov  1 16:06:18.110: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zlzgd
STEP: checking the pod's current state and verifying that restartCount is present
Nov  1 16:06:18.117: INFO: Initial restart count of pod liveness-http is 0
Nov  1 16:06:36.312: INFO: Restart count of pod e2e-tests-container-probe-zlzgd/liveness-http is now 1 (18.194204552s elapsed)
Nov  1 16:06:54.641: INFO: Restart count of pod e2e-tests-container-probe-zlzgd/liveness-http is now 2 (36.52360837s elapsed)
Nov  1 16:07:14.847: INFO: Restart count of pod e2e-tests-container-probe-zlzgd/liveness-http is now 3 (56.729882903s elapsed)
Nov  1 16:07:35.125: INFO: Restart count of pod e2e-tests-container-probe-zlzgd/liveness-http is now 4 (1m17.007142995s elapsed)
Nov  1 16:08:35.667: INFO: Restart count of pod e2e-tests-container-probe-zlzgd/liveness-http is now 5 (2m17.549953816s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:08:35.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zlzgd" for this suite.
Nov  1 16:08:43.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:08:43.921: INFO: namespace: e2e-tests-container-probe-zlzgd, resource: bindings, ignored listing per whitelist
Nov  1 16:08:44.311: INFO: namespace e2e-tests-container-probe-zlzgd deletion completed in 8.594577007s

• [SLOW TEST:150.524 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:08:44.314: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:08:44.864: INFO: (0) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 17.099768ms)
Nov  1 16:08:44.905: INFO: (1) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 40.190184ms)
Nov  1 16:08:44.920: INFO: (2) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 15.671363ms)
Nov  1 16:08:45.006: INFO: (3) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 85.185394ms)
Nov  1 16:08:45.022: INFO: (4) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 16.533444ms)
Nov  1 16:08:45.032: INFO: (5) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 9.824328ms)
Nov  1 16:08:45.042: INFO: (6) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 9.344806ms)
Nov  1 16:08:45.055: INFO: (7) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 13.46732ms)
Nov  1 16:08:45.087: INFO: (8) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 32.041702ms)
Nov  1 16:08:45.102: INFO: (9) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 14.723763ms)
Nov  1 16:08:45.119: INFO: (10) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 16.596805ms)
Nov  1 16:08:45.145: INFO: (11) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 26.013085ms)
Nov  1 16:08:45.157: INFO: (12) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 11.768084ms)
Nov  1 16:08:45.180: INFO: (13) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 23.313375ms)
Nov  1 16:08:45.204: INFO: (14) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 23.829243ms)
Nov  1 16:08:45.296: INFO: (15) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 91.232452ms)
Nov  1 16:08:45.307: INFO: (16) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 10.683563ms)
Nov  1 16:08:45.315: INFO: (17) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 8.130943ms)
Nov  1 16:08:45.322: INFO: (18) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 7.235192ms)
Nov  1 16:08:45.330: INFO: (19) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 8.148085ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:08:45.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-x2kbn" for this suite.
Nov  1 16:08:51.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:08:51.674: INFO: namespace: e2e-tests-proxy-x2kbn, resource: bindings, ignored listing per whitelist
Nov  1 16:08:52.036: INFO: namespace e2e-tests-proxy-x2kbn deletion completed in 6.699437787s

• [SLOW TEST:7.723 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:08:52.040: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-6cd6fad4-ddf0-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:08:52.333: INFO: Waiting up to 5m0s for pod "pod-configmaps-6cd91e9d-ddf0-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-cfp6p" to be "success or failure"
Nov  1 16:08:52.380: INFO: Pod "pod-configmaps-6cd91e9d-ddf0-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 46.12184ms
Nov  1 16:08:54.390: INFO: Pod "pod-configmaps-6cd91e9d-ddf0-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056676077s
STEP: Saw pod success
Nov  1 16:08:54.390: INFO: Pod "pod-configmaps-6cd91e9d-ddf0-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:08:54.399: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-configmaps-6cd91e9d-ddf0-11e8-a64b-2ef904c43a0d container configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 16:08:54.460: INFO: Waiting for pod pod-configmaps-6cd91e9d-ddf0-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:08:54.467: INFO: Pod pod-configmaps-6cd91e9d-ddf0-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:08:54.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cfp6p" for this suite.
Nov  1 16:09:02.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:09:02.717: INFO: namespace: e2e-tests-configmap-cfp6p, resource: bindings, ignored listing per whitelist
Nov  1 16:09:03.181: INFO: namespace e2e-tests-configmap-cfp6p deletion completed in 8.707142803s

• [SLOW TEST:11.142 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:09:03.183: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  1 16:09:03.586: INFO: Waiting up to 5m0s for pod "pod-73899f5a-ddf0-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-ffntz" to be "success or failure"
Nov  1 16:09:03.675: INFO: Pod "pod-73899f5a-ddf0-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 88.787142ms
Nov  1 16:09:05.682: INFO: Pod "pod-73899f5a-ddf0-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096193289s
Nov  1 16:09:07.707: INFO: Pod "pod-73899f5a-ddf0-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.121430824s
STEP: Saw pod success
Nov  1 16:09:07.707: INFO: Pod "pod-73899f5a-ddf0-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:09:07.720: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-73899f5a-ddf0-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:09:07.781: INFO: Waiting for pod pod-73899f5a-ddf0-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:09:07.795: INFO: Pod pod-73899f5a-ddf0-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:09:07.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ffntz" for this suite.
Nov  1 16:09:13.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:09:14.191: INFO: namespace: e2e-tests-emptydir-ffntz, resource: bindings, ignored listing per whitelist
Nov  1 16:09:14.272: INFO: namespace e2e-tests-emptydir-ffntz deletion completed in 6.457232114s

• [SLOW TEST:11.090 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:09:14.279: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:09:14.519: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  1 16:09:14.545: INFO: Number of nodes with available pods: 0
Nov  1 16:09:14.545: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  1 16:09:14.591: INFO: Number of nodes with available pods: 0
Nov  1 16:09:14.591: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:15.599: INFO: Number of nodes with available pods: 0
Nov  1 16:09:15.600: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:16.601: INFO: Number of nodes with available pods: 0
Nov  1 16:09:16.602: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:17.598: INFO: Number of nodes with available pods: 1
Nov  1 16:09:17.598: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  1 16:09:17.835: INFO: Number of nodes with available pods: 0
Nov  1 16:09:17.836: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  1 16:09:17.853: INFO: Number of nodes with available pods: 0
Nov  1 16:09:17.853: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:18.927: INFO: Number of nodes with available pods: 0
Nov  1 16:09:18.927: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:19.865: INFO: Number of nodes with available pods: 0
Nov  1 16:09:19.865: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:20.871: INFO: Number of nodes with available pods: 0
Nov  1 16:09:20.872: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:21.866: INFO: Number of nodes with available pods: 0
Nov  1 16:09:21.867: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:22.899: INFO: Number of nodes with available pods: 0
Nov  1 16:09:22.899: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:23.894: INFO: Number of nodes with available pods: 0
Nov  1 16:09:23.895: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:24.863: INFO: Number of nodes with available pods: 0
Nov  1 16:09:24.863: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:25.863: INFO: Number of nodes with available pods: 0
Nov  1 16:09:25.863: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:26.864: INFO: Number of nodes with available pods: 0
Nov  1 16:09:26.865: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:27.860: INFO: Number of nodes with available pods: 0
Nov  1 16:09:27.860: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:28.861: INFO: Number of nodes with available pods: 0
Nov  1 16:09:28.861: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:29.861: INFO: Number of nodes with available pods: 0
Nov  1 16:09:29.861: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:30.864: INFO: Number of nodes with available pods: 0
Nov  1 16:09:30.864: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:31.865: INFO: Number of nodes with available pods: 0
Nov  1 16:09:31.866: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:32.868: INFO: Number of nodes with available pods: 0
Nov  1 16:09:32.868: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:33.859: INFO: Number of nodes with available pods: 0
Nov  1 16:09:33.859: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:34.910: INFO: Number of nodes with available pods: 0
Nov  1 16:09:34.911: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:35.868: INFO: Number of nodes with available pods: 0
Nov  1 16:09:35.869: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:36.875: INFO: Number of nodes with available pods: 0
Nov  1 16:09:36.876: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:37.867: INFO: Number of nodes with available pods: 0
Nov  1 16:09:37.867: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:38.867: INFO: Number of nodes with available pods: 0
Nov  1 16:09:38.867: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:39.864: INFO: Number of nodes with available pods: 0
Nov  1 16:09:39.865: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:40.866: INFO: Number of nodes with available pods: 0
Nov  1 16:09:40.866: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:41.862: INFO: Number of nodes with available pods: 0
Nov  1 16:09:41.863: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:42.861: INFO: Number of nodes with available pods: 0
Nov  1 16:09:42.861: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:43.875: INFO: Number of nodes with available pods: 0
Nov  1 16:09:43.875: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:44.862: INFO: Number of nodes with available pods: 0
Nov  1 16:09:44.862: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:45.879: INFO: Number of nodes with available pods: 0
Nov  1 16:09:45.879: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:46.860: INFO: Number of nodes with available pods: 0
Nov  1 16:09:46.860: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:47.877: INFO: Number of nodes with available pods: 0
Nov  1 16:09:47.877: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:48.865: INFO: Number of nodes with available pods: 0
Nov  1 16:09:48.865: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:49.862: INFO: Number of nodes with available pods: 0
Nov  1 16:09:49.862: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:50.859: INFO: Number of nodes with available pods: 0
Nov  1 16:09:50.860: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:51.871: INFO: Number of nodes with available pods: 0
Nov  1 16:09:51.872: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:52.872: INFO: Number of nodes with available pods: 0
Nov  1 16:09:52.874: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:53.863: INFO: Number of nodes with available pods: 0
Nov  1 16:09:53.863: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 16:09:54.862: INFO: Number of nodes with available pods: 1
Nov  1 16:09:54.863: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-mnsdq, will wait for the garbage collector to delete the pods
Nov  1 16:09:54.961: INFO: Deleting {extensions DaemonSet} daemon-set took: 24.167979ms
Nov  1 16:09:55.061: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.22928ms
Nov  1 16:10:33.286: INFO: Number of nodes with available pods: 0
Nov  1 16:10:33.287: INFO: Number of running nodes: 0, number of available pods: 0
Nov  1 16:10:33.298: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mnsdq/daemonsets","resourceVersion":"7898"},"items":null}

Nov  1 16:10:33.305: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mnsdq/pods","resourceVersion":"7898"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:10:33.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mnsdq" for this suite.
Nov  1 16:10:39.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:10:39.802: INFO: namespace: e2e-tests-daemonsets-mnsdq, resource: bindings, ignored listing per whitelist
Nov  1 16:10:39.865: INFO: namespace e2e-tests-daemonsets-mnsdq deletion completed in 6.449141552s

• [SLOW TEST:85.587 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:10:39.870: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ad1ef2de-ddf0-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:10:40.174: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad253356-ddf0-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-5gb6f" to be "success or failure"
Nov  1 16:10:40.179: INFO: Pod "pod-configmaps-ad253356-ddf0-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.672506ms
Nov  1 16:10:42.191: INFO: Pod "pod-configmaps-ad253356-ddf0-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01709895s
STEP: Saw pod success
Nov  1 16:10:42.191: INFO: Pod "pod-configmaps-ad253356-ddf0-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:10:42.199: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-configmaps-ad253356-ddf0-11e8-a64b-2ef904c43a0d container configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 16:10:42.260: INFO: Waiting for pod pod-configmaps-ad253356-ddf0-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:10:42.266: INFO: Pod pod-configmaps-ad253356-ddf0-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:10:42.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5gb6f" for this suite.
Nov  1 16:10:48.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:10:48.413: INFO: namespace: e2e-tests-configmap-5gb6f, resource: bindings, ignored listing per whitelist
Nov  1 16:10:48.708: INFO: namespace e2e-tests-configmap-5gb6f deletion completed in 6.431066648s

• [SLOW TEST:8.840 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:10:48.716: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-w6xqm
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Nov  1 16:10:48.995: INFO: Found 0 stateful pods, waiting for 3
Nov  1 16:10:59.028: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 16:10:59.029: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 16:10:59.029: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 16:10:59.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-w6xqm ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:10:59.628: INFO: stderr: ""
Nov  1 16:10:59.628: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:10:59.628: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov  1 16:11:09.716: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  1 16:11:19.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-w6xqm ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:11:20.491: INFO: stderr: ""
Nov  1 16:11:20.492: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:11:20.492: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:11:30.578: INFO: Waiting for StatefulSet e2e-tests-statefulset-w6xqm/ss2 to complete update
Nov  1 16:11:30.579: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 16:11:30.579: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 16:11:30.579: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 16:11:40.623: INFO: Waiting for StatefulSet e2e-tests-statefulset-w6xqm/ss2 to complete update
Nov  1 16:11:40.623: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 16:11:40.624: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 16:11:50.610: INFO: Waiting for StatefulSet e2e-tests-statefulset-w6xqm/ss2 to complete update
Nov  1 16:11:50.611: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 16:11:50.611: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 16:12:00.626: INFO: Waiting for StatefulSet e2e-tests-statefulset-w6xqm/ss2 to complete update
Nov  1 16:12:00.626: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 16:12:10.617: INFO: Waiting for StatefulSet e2e-tests-statefulset-w6xqm/ss2 to complete update
Nov  1 16:12:10.618: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Nov  1 16:12:20.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-w6xqm ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:12:21.201: INFO: stderr: ""
Nov  1 16:12:21.201: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:12:21.201: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:12:31.299: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  1 16:12:41.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-w6xqm ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:12:42.002: INFO: stderr: ""
Nov  1 16:12:42.002: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:12:42.002: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:12:52.099: INFO: Waiting for StatefulSet e2e-tests-statefulset-w6xqm/ss2 to complete update
Nov  1 16:12:52.099: INFO: Waiting for Pod e2e-tests-statefulset-w6xqm/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  1 16:13:02.142: INFO: Deleting all statefulset in ns e2e-tests-statefulset-w6xqm
Nov  1 16:13:02.205: INFO: Scaling statefulset ss2 to 0
Nov  1 16:13:32.268: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 16:13:32.288: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:13:32.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-w6xqm" for this suite.
Nov  1 16:13:40.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:13:40.525: INFO: namespace: e2e-tests-statefulset-w6xqm, resource: bindings, ignored listing per whitelist
Nov  1 16:13:40.740: INFO: namespace e2e-tests-statefulset-w6xqm deletion completed in 8.390735874s

• [SLOW TEST:172.025 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:13:40.741: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  1 16:13:40.901: INFO: PodSpec: initContainers in spec.initContainers
Nov  1 16:14:24.933: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-18e04c8c-ddf1-11e8-a64b-2ef904c43a0d", GenerateName:"", Namespace:"e2e-tests-init-container-rz7w9", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-rz7w9/pods/pod-init-18e04c8c-ddf1-11e8-a64b-2ef904c43a0d", UID:"18e17aa9-ddf1-11e8-a94b-0a580af40661", ResourceVersion:"8755", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63676685620, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"901001014"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-g2h89", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421720340), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-g2h89", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-g2h89", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-g2h89", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421b37a48), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421dabce0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421b37ac0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421b37ae0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421b37ae8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685621, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685621, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685621, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685621, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.8", PodIP:"172.25.0.52", StartTime:(*v1.Time)(0xc4209da6c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4224af3b0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4224af420)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://3011ffb05003f00055ed603df45b67f131f9b4921c9b5577e0e61d7c8aa3a039"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4209da8c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4209da880), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:14:24.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rz7w9" for this suite.
Nov  1 16:14:48.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:14:49.181: INFO: namespace: e2e-tests-init-container-rz7w9, resource: bindings, ignored listing per whitelist
Nov  1 16:14:49.534: INFO: namespace e2e-tests-init-container-rz7w9 deletion completed in 24.566076117s

• [SLOW TEST:68.794 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:14:49.536: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:14:49.843: INFO: Creating deployment "nginx-deployment"
Nov  1 16:14:49.884: INFO: Waiting for observed generation 1
Nov  1 16:14:51.934: INFO: Waiting for all required pods to come up
Nov  1 16:14:51.945: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  1 16:14:55.989: INFO: Waiting for deployment "nginx-deployment" to complete
Nov  1 16:14:56.001: INFO: Updating deployment "nginx-deployment" with a non-existent image
Nov  1 16:14:56.033: INFO: Updating deployment nginx-deployment
Nov  1 16:14:56.033: INFO: Waiting for observed generation 2
Nov  1 16:14:58.332: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  1 16:14:58.447: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  1 16:14:58.497: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov  1 16:14:58.536: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  1 16:14:58.536: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  1 16:14:58.543: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov  1 16:14:58.571: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Nov  1 16:14:58.571: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Nov  1 16:14:58.622: INFO: Updating deployment nginx-deployment
Nov  1 16:14:58.622: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Nov  1 16:14:58.660: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  1 16:14:58.666: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  1 16:15:00.800: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bpq9k/deployments/nginx-deployment,UID:41f8b09f-ddf1-11e8-a94b-0a580af40661,ResourceVersion:9100,Generation:3,CreationTimestamp:2018-11-01 16:14:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-11-01 16:14:58 +0000 UTC 2018-11-01 16:14:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-11-01 16:14:59 +0000 UTC 2018-11-01 16:14:50 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Nov  1 16:15:00.872: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bpq9k/replicasets/nginx-deployment-7dc8f79789,UID:45a9fa4b-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9091,Generation:3,CreationTimestamp:2018-11-01 16:14:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 41f8b09f-ddf1-11e8-a94b-0a580af40661 0xc4219333c7 0xc4219333c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  1 16:15:00.872: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Nov  1 16:15:00.872: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bpq9k/replicasets/nginx-deployment-7f9675fb8b,UID:42021a24-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9083,Generation:3,CreationTimestamp:2018-11-01 16:14:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 41f8b09f-ddf1-11e8-a94b-0a580af40661 0xc4219334b7 0xc4219334b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Nov  1 16:15:00.893: INFO: Pod "nginx-deployment-7dc8f79789-2g7cf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2g7cf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-2g7cf,UID:45b7c345-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9024,Generation:0,CreationTimestamp:2018-11-01 16:14:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc4204a8a60 0xc4204a8a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204a8ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204a8af0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.58,StartTime:2018-11-01 16:14:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.895: INFO: Pod "nginx-deployment-7dc8f79789-5cdrj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5cdrj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-5cdrj,UID:4760390e-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9137,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc4204a8ed0 0xc4204a8ed1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204a8f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204a8f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.896: INFO: Pod "nginx-deployment-7dc8f79789-7cw2l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7cw2l,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-7cw2l,UID:476a5854-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9088,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc4204a9030 0xc4204a9031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204a9380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204a93a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.896: INFO: Pod "nginx-deployment-7dc8f79789-9cfxd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9cfxd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-9cfxd,UID:4760f254-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9134,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc4204a9410 0xc4204a9411}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204a9740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204a9760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.899: INFO: Pod "nginx-deployment-7dc8f79789-9hhsh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9hhsh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-9hhsh,UID:47564436-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9122,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc4204a9820 0xc4204a9821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204a9a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204a9a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.899: INFO: Pod "nginx-deployment-7dc8f79789-b648l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-b648l,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-b648l,UID:45d47273-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9026,Generation:0,CreationTimestamp:2018-11-01 16:14:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc4204a9b40 0xc4204a9b41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204a9c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204a9c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.57,StartTime:2018-11-01 16:14:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.900: INFO: Pod "nginx-deployment-7dc8f79789-bkcwc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bkcwc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-bkcwc,UID:45b7cf55-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9029,Generation:0,CreationTimestamp:2018-11-01 16:14:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc4204a9d10 0xc4204a9d11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204a9dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204a9de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.59,StartTime:2018-11-01 16:14:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.902: INFO: Pod "nginx-deployment-7dc8f79789-gf5fp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gf5fp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-gf5fp,UID:4760c002-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9146,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc4204a9eb0 0xc4204a9eb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204a9f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204a9f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.902: INFO: Pod "nginx-deployment-7dc8f79789-hknn6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hknn6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-hknn6,UID:4760bb85-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9125,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc42142a050 0xc42142a051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142a180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142a1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.902: INFO: Pod "nginx-deployment-7dc8f79789-l86kb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-l86kb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-l86kb,UID:45cce0b0-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9025,Generation:0,CreationTimestamp:2018-11-01 16:14:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc42142a2a0 0xc42142a2a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142a460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142a480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.59,StartTime:2018-11-01 16:14:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.904: INFO: Pod "nginx-deployment-7dc8f79789-mtwl5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mtwl5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-mtwl5,UID:4746ff42-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9102,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc42142a560 0xc42142a561}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142a6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142a6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.904: INFO: Pod "nginx-deployment-7dc8f79789-w9hh4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-w9hh4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-w9hh4,UID:47558276-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9096,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc42142a820 0xc42142a821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142a8f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142a910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.904: INFO: Pod "nginx-deployment-7dc8f79789-wqtjp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wqtjp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7dc8f79789-wqtjp,UID:45b4dcc2-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9032,Generation:0,CreationTimestamp:2018-11-01 16:14:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 45a9fa4b-ddf1-11e8-ad00-0a580af40ec2 0xc42142aa60 0xc42142aa61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142abf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142ac10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.58,StartTime:2018-11-01 16:14:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.904: INFO: Pod "nginx-deployment-7f9675fb8b-2svq9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2svq9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-2svq9,UID:4746fca2-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9110,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc42142ad00 0xc42142ad01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142ae30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142ae50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.904: INFO: Pod "nginx-deployment-7f9675fb8b-4p2sp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4p2sp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-4p2sp,UID:4746fd0c-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9095,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc42142af80 0xc42142af81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142b050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142b070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.905: INFO: Pod "nginx-deployment-7f9675fb8b-6jq5r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6jq5r,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-6jq5r,UID:47557648-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9127,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc42142b1e0 0xc42142b1e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142b890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142b8b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.905: INFO: Pod "nginx-deployment-7f9675fb8b-8f2c2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8f2c2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-8f2c2,UID:421d8d03-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:8907,Generation:0,CreationTimestamp:2018-11-01 16:14:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc42142ba30 0xc42142ba31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142bc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142bcc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.53,StartTime:2018-11-01 16:14:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-01 16:14:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf docker://a703e0150ea9203e0e03adc5a9ab87c125cd2a963d277ed55e90559a4d636f6f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.907: INFO: Pod "nginx-deployment-7f9675fb8b-gm448" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gm448,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-gm448,UID:4754e479-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9103,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc42142bde0 0xc42142bde1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42142be40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42142be70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.908: INFO: Pod "nginx-deployment-7f9675fb8b-gsdst" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gsdst,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-gsdst,UID:47608f76-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9130,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc4214740a7 0xc4214740a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214741a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214741f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.908: INFO: Pod "nginx-deployment-7f9675fb8b-hld2j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hld2j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-hld2j,UID:421d9b57-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:8940,Generation:0,CreationTimestamp:2018-11-01 16:14:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421474307 0xc421474308}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421474480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421474550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.53,StartTime:2018-11-01 16:14:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-01 16:14:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf docker://4d856c36a0143fa59f2de64f39a9badba62f0c48c7c051f415d52f79e118fb2e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.908: INFO: Pod "nginx-deployment-7f9675fb8b-hlrhz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hlrhz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-hlrhz,UID:47555708-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9118,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421474990 0xc421474991}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214749f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421474a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.908: INFO: Pod "nginx-deployment-7f9675fb8b-jxb2b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jxb2b,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-jxb2b,UID:475560ed-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9108,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421474c80 0xc421474c81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421474ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421474d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.908: INFO: Pod "nginx-deployment-7f9675fb8b-k2nc7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k2nc7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-k2nc7,UID:476093d9-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9087,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421474ff7 0xc421474ff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214750c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214750e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.908: INFO: Pod "nginx-deployment-7f9675fb8b-kk5sp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kk5sp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-kk5sp,UID:4220fe31-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:8943,Generation:0,CreationTimestamp:2018-11-01 16:14:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc4214751f0 0xc4214751f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421475250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421475270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.57,StartTime:2018-11-01 16:14:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-01 16:14:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf docker://2dbde73d4bd0bdc3db758ac01686604ac794d0d838faa7ad1a8ce0959c719cfe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.908: INFO: Pod "nginx-deployment-7f9675fb8b-kms9m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kms9m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-kms9m,UID:473a486d-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9072,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421475350 0xc421475351}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421475460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421475480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2018-11-01 16:14:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.909: INFO: Pod "nginx-deployment-7f9675fb8b-kx2vt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kx2vt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-kx2vt,UID:421ad629-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:8957,Generation:0,CreationTimestamp:2018-11-01 16:14:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421475530 0xc421475531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421475600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421475620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.54,StartTime:2018-11-01 16:14:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-01 16:14:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf docker://748a9a13cea3c40e96ebfe4601384485d88384b0a1b5a1d23ba9c02daf40fb70}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.909: INFO: Pod "nginx-deployment-7f9675fb8b-l86q4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-l86q4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-l86q4,UID:4220ff32-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:8961,Generation:0,CreationTimestamp:2018-11-01 16:14:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc4214756e0 0xc4214756e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214757c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214757e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.56,StartTime:2018-11-01 16:14:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-01 16:14:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf docker://693a3be63d92f8c3d044d3f102922b6be5c955f2e7eb74bddf05028927e9bfa0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.909: INFO: Pod "nginx-deployment-7f9675fb8b-lpd5d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lpd5d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-lpd5d,UID:4760a3d2-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9144,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc4214758a0 0xc4214758a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421475910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214759f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.909: INFO: Pod "nginx-deployment-7f9675fb8b-nx74t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nx74t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-nx74t,UID:421da6d9-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:8945,Generation:0,CreationTimestamp:2018-11-01 16:14:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421475aa7 0xc421475aa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421475b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421475b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.54,StartTime:2018-11-01 16:14:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-01 16:14:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf docker://5f57a8afc4d57a72b6442c8a8ab10b6405d24230be05f6d787f64c92ef20f8e7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.909: INFO: Pod "nginx-deployment-7f9675fb8b-pfs5n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pfs5n,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-pfs5n,UID:4760a2a3-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9085,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421475d30 0xc421475d31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421475d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421475db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.910: INFO: Pod "nginx-deployment-7f9675fb8b-rhqj8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rhqj8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-rhqj8,UID:4218b5ec-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:8937,Generation:0,CreationTimestamp:2018-11-01 16:14:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc421475e90 0xc421475e91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421475fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421475fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.52,StartTime:2018-11-01 16:14:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-01 16:14:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf docker://d3c1f04f50da5d6935f48c1d035f48f11c36c53b49e8e2dedd2c6ee3ee4964e9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.910: INFO: Pod "nginx-deployment-7f9675fb8b-smz2f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-smz2f,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-smz2f,UID:4760c78f-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9117,Generation:0,CreationTimestamp:2018-11-01 16:14:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc4221640e0 0xc4221640e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422164140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422164160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2018-11-01 16:14:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  1 16:15:00.912: INFO: Pod "nginx-deployment-7f9675fb8b-tw6jf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tw6jf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bpq9k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bpq9k/pods/nginx-deployment-7f9675fb8b-tw6jf,UID:421d9d64-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:8954,Generation:0,CreationTimestamp:2018-11-01 16:14:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 42021a24-ddf1-11e8-ad00-0a580af40ec2 0xc422164267 0xc422164268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7rlrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7rlrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7rlrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4221642d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221642f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:14:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.55,StartTime:2018-11-01 16:14:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-01 16:14:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf docker://aaa9089fa67dec23b086556ded2f7ecf280311150583835f7ac21b595755ab1c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:15:00.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bpq9k" for this suite.
Nov  1 16:15:11.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:15:11.083: INFO: namespace: e2e-tests-deployment-bpq9k, resource: bindings, ignored listing per whitelist
Nov  1 16:15:11.670: INFO: namespace e2e-tests-deployment-bpq9k deletion completed in 10.742808015s

• [SLOW TEST:22.134 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:15:11.670: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4f2340e4-ddf1-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 16:15:11.983: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-z2527" to be "success or failure"
Nov  1 16:15:11.992: INFO: Pod "pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.324837ms
Nov  1 16:15:14.006: INFO: Pod "pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02346919s
Nov  1 16:15:16.023: INFO: Pod "pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04013135s
Nov  1 16:15:18.032: INFO: Pod "pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.049081208s
STEP: Saw pod success
Nov  1 16:15:18.032: INFO: Pod "pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:15:18.038: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  1 16:15:18.140: INFO: Waiting for pod pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:15:18.146: INFO: Pod pod-projected-secrets-4f25ecb9-ddf1-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:15:18.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z2527" for this suite.
Nov  1 16:15:24.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:15:24.337: INFO: namespace: e2e-tests-projected-z2527, resource: bindings, ignored listing per whitelist
Nov  1 16:15:24.696: INFO: namespace e2e-tests-projected-z2527 deletion completed in 6.533513887s

• [SLOW TEST:13.026 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:15:24.701: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:15:24.981: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  1 16:15:29.990: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  1 16:15:29.991: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  1 16:15:32.080: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-9wtwk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9wtwk/deployments/test-cleanup-deployment,UID:59e9a9d1-ddf1-11e8-a94b-0a580af40661,ResourceVersion:9529,Generation:1,CreationTimestamp:2018-11-01 16:15:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-01 16:15:30 +0000 UTC 2018-11-01 16:15:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-01 16:15:31 +0000 UTC 2018-11-01 16:15:30 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-755f6b95cc" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  1 16:15:32.085: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-9wtwk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9wtwk/replicasets/test-cleanup-deployment-755f6b95cc,UID:59edd99c-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9520,Generation:1,CreationTimestamp:2018-11-01 16:15:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 59e9a9d1-ddf1-11e8-a94b-0a580af40661 0xc420ef57e7 0xc420ef57e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  1 16:15:32.106: INFO: Pod "test-cleanup-deployment-755f6b95cc-bzqzn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-bzqzn,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-9wtwk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9wtwk/pods/test-cleanup-deployment-755f6b95cc-bzqzn,UID:59eedd43-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9519,Generation:0,CreationTimestamp:2018-11-01 16:15:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 59edd99c-ddf1-11e8-ad00-0a580af40ec2 0xc420ef5d47 0xc420ef5d48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cv2dg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cv2dg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-cv2dg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ef5db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ef5dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:15:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:15:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:15:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:15:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.73,StartTime:2018-11-01 16:15:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-01 16:15:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://89e930c9b09ecaf8fcc10dbb5501e5a6a205cf66cf74b41e940a210728359e1c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:15:32.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9wtwk" for this suite.
Nov  1 16:15:40.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:15:40.513: INFO: namespace: e2e-tests-deployment-9wtwk, resource: bindings, ignored listing per whitelist
Nov  1 16:15:40.619: INFO: namespace e2e-tests-deployment-9wtwk deletion completed in 8.493451455s

• [SLOW TEST:15.919 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:15:40.625: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:15:40.919: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  1 16:15:45.938: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  1 16:15:45.939: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  1 16:15:47.949: INFO: Creating deployment "test-rollover-deployment"
Nov  1 16:15:47.977: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  1 16:15:49.997: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  1 16:15:50.025: INFO: Ensure that both replica sets have 1 created replica
Nov  1 16:15:50.058: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  1 16:15:50.089: INFO: Updating deployment test-rollover-deployment
Nov  1 16:15:50.089: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  1 16:15:52.117: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  1 16:15:52.134: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  1 16:15:52.147: INFO: all replica sets need to contain the pod-template-hash label
Nov  1 16:15:52.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685750, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685747, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 16:15:54.178: INFO: all replica sets need to contain the pod-template-hash label
Nov  1 16:15:54.179: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685752, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685747, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 16:15:56.177: INFO: all replica sets need to contain the pod-template-hash label
Nov  1 16:15:56.177: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685752, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685747, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 16:15:58.169: INFO: all replica sets need to contain the pod-template-hash label
Nov  1 16:15:58.170: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685752, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685747, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 16:16:00.164: INFO: all replica sets need to contain the pod-template-hash label
Nov  1 16:16:00.164: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685752, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685747, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 16:16:02.167: INFO: all replica sets need to contain the pod-template-hash label
Nov  1 16:16:02.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685748, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685752, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676685747, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 16:16:04.158: INFO: 
Nov  1 16:16:04.158: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  1 16:16:04.175: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-lknj4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lknj4/deployments/test-rollover-deployment,UID:649bf593-ddf1-11e8-a94b-0a580af40661,ResourceVersion:9694,Generation:2,CreationTimestamp:2018-11-01 16:15:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-01 16:15:48 +0000 UTC 2018-11-01 16:15:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-01 16:16:02 +0000 UTC 2018-11-01 16:15:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  1 16:16:04.182: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-lknj4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lknj4/replicasets/test-rollover-deployment-5b76ff8c4,UID:65e00360-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9684,Generation:2,CreationTimestamp:2018-11-01 16:15:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 649bf593-ddf1-11e8-a94b-0a580af40661 0xc420db8d47 0xc420db8d48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  1 16:16:04.182: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  1 16:16:04.183: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-lknj4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lknj4/replicasets/test-rollover-controller,UID:6064721d-ddf1-11e8-a94b-0a580af40661,ResourceVersion:9693,Generation:2,CreationTimestamp:2018-11-01 16:15:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 649bf593-ddf1-11e8-a94b-0a580af40661 0xc420db8c8e 0xc420db8c8f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  1 16:16:04.184: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-lknj4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lknj4/replicasets/test-rollover-deployment-6975f4fb87,UID:64a0d666-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9646,Generation:2,CreationTimestamp:2018-11-01 16:15:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 649bf593-ddf1-11e8-a94b-0a580af40661 0xc420db8df7 0xc420db8df8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  1 16:16:04.190: INFO: Pod "test-rollover-deployment-5b76ff8c4-x8x28" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-x8x28,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-lknj4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lknj4/pods/test-rollover-deployment-5b76ff8c4-x8x28,UID:65ef1281-ddf1-11e8-ad00-0a580af40ec2,ResourceVersion:9662,Generation:0,CreationTimestamp:2018-11-01 16:15:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 65e00360-ddf1-11e8-ad00-0a580af40ec2 0xc420db98c0 0xc420db98c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-848vv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-848vv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-848vv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420db9920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420db9940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:15:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:15:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:15:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:15:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.74,StartTime:2018-11-01 16:15:50 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-01 16:15:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c8fc56528ad22d25d1f5ca653ab049df8636f47a35be10deeb8340fd2fffd6b1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:16:04.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lknj4" for this suite.
Nov  1 16:16:12.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:16:12.496: INFO: namespace: e2e-tests-deployment-lknj4, resource: bindings, ignored listing per whitelist
Nov  1 16:16:12.731: INFO: namespace e2e-tests-deployment-lknj4 deletion completed in 8.533852798s

• [SLOW TEST:32.108 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:16:12.738: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  1 16:16:12.975: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:16:17.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-d2w5n" for this suite.
Nov  1 16:16:25.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:16:25.877: INFO: namespace: e2e-tests-init-container-d2w5n, resource: bindings, ignored listing per whitelist
Nov  1 16:16:25.896: INFO: namespace e2e-tests-init-container-d2w5n deletion completed in 8.519467449s

• [SLOW TEST:13.160 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:16:25.901: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Nov  1 16:16:26.212: INFO: Waiting up to 5m0s for pod "client-containers-7b614354-ddf1-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-containers-spzxw" to be "success or failure"
Nov  1 16:16:26.240: INFO: Pod "client-containers-7b614354-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 27.342389ms
Nov  1 16:16:28.270: INFO: Pod "client-containers-7b614354-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057543217s
Nov  1 16:16:30.277: INFO: Pod "client-containers-7b614354-ddf1-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064551656s
STEP: Saw pod success
Nov  1 16:16:30.277: INFO: Pod "client-containers-7b614354-ddf1-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:16:30.306: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod client-containers-7b614354-ddf1-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:16:30.464: INFO: Waiting for pod client-containers-7b614354-ddf1-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:16:30.478: INFO: Pod client-containers-7b614354-ddf1-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:16:30.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-spzxw" for this suite.
Nov  1 16:16:36.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:16:37.010: INFO: namespace: e2e-tests-containers-spzxw, resource: bindings, ignored listing per whitelist
Nov  1 16:16:37.432: INFO: namespace e2e-tests-containers-spzxw deletion completed in 6.944461576s

• [SLOW TEST:11.532 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:16:37.441: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:16:37.755: INFO: Creating ReplicaSet my-hostname-basic-824a2f87-ddf1-11e8-a64b-2ef904c43a0d
Nov  1 16:16:37.811: INFO: Pod name my-hostname-basic-824a2f87-ddf1-11e8-a64b-2ef904c43a0d: Found 0 pods out of 1
Nov  1 16:16:42.896: INFO: Pod name my-hostname-basic-824a2f87-ddf1-11e8-a64b-2ef904c43a0d: Found 1 pods out of 1
Nov  1 16:16:42.897: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-824a2f87-ddf1-11e8-a64b-2ef904c43a0d" is running
Nov  1 16:16:42.904: INFO: Pod "my-hostname-basic-824a2f87-ddf1-11e8-a64b-2ef904c43a0d-rhkdg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-01 16:16:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-01 16:16:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-01 16:16:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-01 16:16:37 +0000 UTC Reason: Message:}])
Nov  1 16:16:42.904: INFO: Trying to dial the pod
Nov  1 16:16:48.039: INFO: Controller my-hostname-basic-824a2f87-ddf1-11e8-a64b-2ef904c43a0d: Got expected result from replica 1 [my-hostname-basic-824a2f87-ddf1-11e8-a64b-2ef904c43a0d-rhkdg]: "my-hostname-basic-824a2f87-ddf1-11e8-a64b-2ef904c43a0d-rhkdg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:16:48.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-m65qz" for this suite.
Nov  1 16:16:56.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:16:56.346: INFO: namespace: e2e-tests-replicaset-m65qz, resource: bindings, ignored listing per whitelist
Nov  1 16:16:56.597: INFO: namespace e2e-tests-replicaset-m65qz deletion completed in 8.548248992s

• [SLOW TEST:19.156 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:16:56.602: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:16:56.844: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8da6900d-ddf1-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-tqcw7" to be "success or failure"
Nov  1 16:16:56.854: INFO: Pod "downwardapi-volume-8da6900d-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.291318ms
Nov  1 16:16:58.865: INFO: Pod "downwardapi-volume-8da6900d-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020477181s
Nov  1 16:17:00.883: INFO: Pod "downwardapi-volume-8da6900d-ddf1-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038741355s
STEP: Saw pod success
Nov  1 16:17:00.883: INFO: Pod "downwardapi-volume-8da6900d-ddf1-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:17:00.895: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-8da6900d-ddf1-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:17:01.068: INFO: Waiting for pod downwardapi-volume-8da6900d-ddf1-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:17:01.075: INFO: Pod downwardapi-volume-8da6900d-ddf1-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:17:01.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tqcw7" for this suite.
Nov  1 16:17:07.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:17:07.433: INFO: namespace: e2e-tests-downward-api-tqcw7, resource: bindings, ignored listing per whitelist
Nov  1 16:17:07.594: INFO: namespace e2e-tests-downward-api-tqcw7 deletion completed in 6.508974251s

• [SLOW TEST:10.993 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:17:07.596: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:17:07.852: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94341c37-ddf1-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-2p74x" to be "success or failure"
Nov  1 16:17:07.863: INFO: Pod "downwardapi-volume-94341c37-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.714234ms
Nov  1 16:17:09.873: INFO: Pod "downwardapi-volume-94341c37-ddf1-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020236174s
STEP: Saw pod success
Nov  1 16:17:09.873: INFO: Pod "downwardapi-volume-94341c37-ddf1-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:17:09.877: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod downwardapi-volume-94341c37-ddf1-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:17:09.922: INFO: Waiting for pod downwardapi-volume-94341c37-ddf1-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:17:09.930: INFO: Pod downwardapi-volume-94341c37-ddf1-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:17:09.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2p74x" for this suite.
Nov  1 16:17:15.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:17:16.235: INFO: namespace: e2e-tests-downward-api-2p74x, resource: bindings, ignored listing per whitelist
Nov  1 16:17:16.439: INFO: namespace e2e-tests-downward-api-2p74x deletion completed in 6.500149029s

• [SLOW TEST:8.844 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:17:16.441: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  1 16:17:16.655: INFO: Waiting up to 5m0s for pod "pod-9975f881-ddf1-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-hmjsr" to be "success or failure"
Nov  1 16:17:16.659: INFO: Pod "pod-9975f881-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.328288ms
Nov  1 16:17:18.670: INFO: Pod "pod-9975f881-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015300878s
Nov  1 16:17:20.678: INFO: Pod "pod-9975f881-ddf1-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022599874s
STEP: Saw pod success
Nov  1 16:17:20.678: INFO: Pod "pod-9975f881-ddf1-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:17:20.684: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-9975f881-ddf1-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:17:20.726: INFO: Waiting for pod pod-9975f881-ddf1-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:17:20.748: INFO: Pod pod-9975f881-ddf1-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:17:20.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hmjsr" for this suite.
Nov  1 16:17:26.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:17:27.310: INFO: namespace: e2e-tests-emptydir-hmjsr, resource: bindings, ignored listing per whitelist
Nov  1 16:17:27.355: INFO: namespace e2e-tests-emptydir-hmjsr deletion completed in 6.594016572s

• [SLOW TEST:10.914 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:17:27.361: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  1 16:17:27.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-kmwpf'
Nov  1 16:17:28.577: INFO: stderr: ""
Nov  1 16:17:28.577: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Nov  1 16:17:28.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kmwpf'
Nov  1 16:17:33.303: INFO: stderr: ""
Nov  1 16:17:33.303: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:17:33.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kmwpf" for this suite.
Nov  1 16:17:39.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:17:39.634: INFO: namespace: e2e-tests-kubectl-kmwpf, resource: bindings, ignored listing per whitelist
Nov  1 16:17:39.826: INFO: namespace e2e-tests-kubectl-kmwpf deletion completed in 6.506879983s

• [SLOW TEST:12.466 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:17:39.836: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  1 16:17:42.720: INFO: Successfully updated pod "annotationupdatea765f4dd-ddf1-11e8-a64b-2ef904c43a0d"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:17:46.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pj5lg" for this suite.
Nov  1 16:18:10.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:18:11.014: INFO: namespace: e2e-tests-projected-pj5lg, resource: bindings, ignored listing per whitelist
Nov  1 16:18:11.380: INFO: namespace e2e-tests-projected-pj5lg deletion completed in 24.577362431s

• [SLOW TEST:31.544 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:18:11.389: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  1 16:18:11.712: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nwpx7,SelfLink:/api/v1/namespaces/e2e-tests-watch-nwpx7/configmaps/e2e-watch-test-watch-closed,UID:ba44caf0-ddf1-11e8-a94b-0a580af40661,ResourceVersion:10195,Generation:0,CreationTimestamp:2018-11-01 16:18:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  1 16:18:11.713: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nwpx7,SelfLink:/api/v1/namespaces/e2e-tests-watch-nwpx7/configmaps/e2e-watch-test-watch-closed,UID:ba44caf0-ddf1-11e8-a94b-0a580af40661,ResourceVersion:10196,Generation:0,CreationTimestamp:2018-11-01 16:18:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  1 16:18:11.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nwpx7,SelfLink:/api/v1/namespaces/e2e-tests-watch-nwpx7/configmaps/e2e-watch-test-watch-closed,UID:ba44caf0-ddf1-11e8-a94b-0a580af40661,ResourceVersion:10197,Generation:0,CreationTimestamp:2018-11-01 16:18:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  1 16:18:11.739: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nwpx7,SelfLink:/api/v1/namespaces/e2e-tests-watch-nwpx7/configmaps/e2e-watch-test-watch-closed,UID:ba44caf0-ddf1-11e8-a94b-0a580af40661,ResourceVersion:10198,Generation:0,CreationTimestamp:2018-11-01 16:18:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:18:11.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nwpx7" for this suite.
Nov  1 16:18:17.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:18:17.871: INFO: namespace: e2e-tests-watch-nwpx7, resource: bindings, ignored listing per whitelist
Nov  1 16:18:18.168: INFO: namespace e2e-tests-watch-nwpx7 deletion completed in 6.42309958s

• [SLOW TEST:6.781 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:18:18.175: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-be4e93cf-ddf1-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:18:18.506: INFO: Waiting up to 5m0s for pod "pod-configmaps-be5188af-ddf1-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-ln2r2" to be "success or failure"
Nov  1 16:18:18.518: INFO: Pod "pod-configmaps-be5188af-ddf1-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.59208ms
Nov  1 16:18:20.526: INFO: Pod "pod-configmaps-be5188af-ddf1-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020376094s
STEP: Saw pod success
Nov  1 16:18:20.526: INFO: Pod "pod-configmaps-be5188af-ddf1-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:18:20.532: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-configmaps-be5188af-ddf1-11e8-a64b-2ef904c43a0d container configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 16:18:20.600: INFO: Waiting for pod pod-configmaps-be5188af-ddf1-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:18:20.609: INFO: Pod pod-configmaps-be5188af-ddf1-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:18:20.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ln2r2" for this suite.
Nov  1 16:18:26.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:18:26.890: INFO: namespace: e2e-tests-configmap-ln2r2, resource: bindings, ignored listing per whitelist
Nov  1 16:18:27.210: INFO: namespace e2e-tests-configmap-ln2r2 deletion completed in 6.587364262s

• [SLOW TEST:9.036 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:18:27.218: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Nov  1 16:18:27.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 api-versions'
Nov  1 16:18:27.924: INFO: stderr: ""
Nov  1 16:18:27.924: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nark.heptio.com/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.k8s.io/v1alpha1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:18:27.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fzmjf" for this suite.
Nov  1 16:18:35.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:18:36.085: INFO: namespace: e2e-tests-kubectl-fzmjf, resource: bindings, ignored listing per whitelist
Nov  1 16:18:36.477: INFO: namespace e2e-tests-kubectl-fzmjf deletion completed in 8.544060984s

• [SLOW TEST:9.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:18:36.480: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-v24st
Nov  1 16:18:40.731: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-v24st
STEP: checking the pod's current state and verifying that restartCount is present
Nov  1 16:18:40.739: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:22:41.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-v24st" for this suite.
Nov  1 16:22:47.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:22:48.063: INFO: namespace: e2e-tests-container-probe-v24st, resource: bindings, ignored listing per whitelist
Nov  1 16:22:48.177: INFO: namespace e2e-tests-container-probe-v24st deletion completed in 6.501161125s

• [SLOW TEST:251.698 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:22:48.179: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vl2rh in namespace e2e-tests-proxy-qmqwx
I1101 16:22:48.499744      15 runners.go:180] Created replication controller with name: proxy-service-vl2rh, namespace: e2e-tests-proxy-qmqwx, replica count: 1
I1101 16:22:49.551436      15 runners.go:180] proxy-service-vl2rh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1101 16:22:50.553309      15 runners.go:180] proxy-service-vl2rh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1101 16:22:51.554179      15 runners.go:180] proxy-service-vl2rh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1101 16:22:52.833394      15 runners.go:180] proxy-service-vl2rh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1101 16:22:53.833971      15 runners.go:180] proxy-service-vl2rh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1101 16:22:54.834375      15 runners.go:180] proxy-service-vl2rh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1101 16:22:55.834751      15 runners.go:180] proxy-service-vl2rh Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  1 16:22:55.841: INFO: setup took 7.377831353s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  1 16:22:55.896: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 53.678925ms)
Nov  1 16:22:55.912: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 66.511041ms)
Nov  1 16:22:55.912: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 69.006553ms)
Nov  1 16:22:55.912: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 66.122613ms)
Nov  1 16:22:55.912: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 67.007073ms)
Nov  1 16:22:55.912: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 69.516496ms)
Nov  1 16:22:55.912: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 70.287822ms)
Nov  1 16:22:55.912: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 70.46459ms)
Nov  1 16:22:55.915: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 68.848063ms)
Nov  1 16:22:55.937: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 94.771198ms)
Nov  1 16:22:55.937: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 93.802772ms)
Nov  1 16:22:55.937: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 94.562337ms)
Nov  1 16:22:55.944: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 101.688043ms)
Nov  1 16:22:55.952: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 109.54964ms)
Nov  1 16:22:55.953: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 110.205193ms)
Nov  1 16:22:56.019: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 174.522451ms)
Nov  1 16:22:56.050: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 30.815942ms)
Nov  1 16:22:56.055: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 33.729187ms)
Nov  1 16:22:56.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 33.605986ms)
Nov  1 16:22:56.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 35.01114ms)
Nov  1 16:22:56.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 36.148473ms)
Nov  1 16:22:56.057: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 35.536739ms)
Nov  1 16:22:56.057: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 34.393377ms)
Nov  1 16:22:56.057: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 37.34943ms)
Nov  1 16:22:56.058: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 37.640156ms)
Nov  1 16:22:56.058: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 38.404415ms)
Nov  1 16:22:56.058: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 36.752524ms)
Nov  1 16:22:56.059: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 39.083825ms)
Nov  1 16:22:56.090: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 68.816424ms)
Nov  1 16:22:56.090: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 68.12022ms)
Nov  1 16:22:56.090: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 69.061436ms)
Nov  1 16:22:56.090: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 69.703042ms)
Nov  1 16:22:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 13.581032ms)
Nov  1 16:22:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 14.609554ms)
Nov  1 16:22:56.106: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 15.343667ms)
Nov  1 16:22:56.108: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 16.140297ms)
Nov  1 16:22:56.109: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 16.809373ms)
Nov  1 16:22:56.109: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 16.168721ms)
Nov  1 16:22:56.115: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 22.44769ms)
Nov  1 16:22:56.115: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 23.032205ms)
Nov  1 16:22:56.116: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 23.29283ms)
Nov  1 16:22:56.116: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 25.318859ms)
Nov  1 16:22:56.116: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 24.320973ms)
Nov  1 16:22:56.155: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 63.915954ms)
Nov  1 16:22:56.155: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 63.934698ms)
Nov  1 16:22:56.155: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 63.133542ms)
Nov  1 16:22:56.155: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 64.468426ms)
Nov  1 16:22:56.156: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 65.048059ms)
Nov  1 16:22:56.168: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 11.526088ms)
Nov  1 16:22:56.169: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 12.919641ms)
Nov  1 16:22:56.169: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 12.142943ms)
Nov  1 16:22:56.175: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 17.712294ms)
Nov  1 16:22:56.176: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 17.782356ms)
Nov  1 16:22:56.176: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 17.166971ms)
Nov  1 16:22:56.176: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 18.929555ms)
Nov  1 16:22:56.176: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 19.593505ms)
Nov  1 16:22:56.176: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 17.098ms)
Nov  1 16:22:56.177: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 17.923803ms)
Nov  1 16:22:56.178: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 18.115109ms)
Nov  1 16:22:56.184: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 25.152389ms)
Nov  1 16:22:56.214: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 56.170207ms)
Nov  1 16:22:56.215: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 56.078281ms)
Nov  1 16:22:56.215: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 57.512354ms)
Nov  1 16:22:56.215: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 57.479351ms)
Nov  1 16:22:56.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 20.964479ms)
Nov  1 16:22:56.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 20.740169ms)
Nov  1 16:22:56.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 24.523456ms)
Nov  1 16:22:56.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 24.052437ms)
Nov  1 16:22:56.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 24.299399ms)
Nov  1 16:22:56.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 21.775559ms)
Nov  1 16:22:56.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 23.544226ms)
Nov  1 16:22:56.241: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 21.6059ms)
Nov  1 16:22:56.241: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 22.575755ms)
Nov  1 16:22:56.241: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 22.996872ms)
Nov  1 16:22:56.241: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 24.357183ms)
Nov  1 16:22:56.247: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 29.988255ms)
Nov  1 16:22:56.248: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 30.496181ms)
Nov  1 16:22:56.248: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 28.957586ms)
Nov  1 16:22:56.249: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 29.01843ms)
Nov  1 16:22:56.249: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 30.919469ms)
Nov  1 16:22:56.263: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 12.681331ms)
Nov  1 16:22:56.269: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 17.393721ms)
Nov  1 16:22:56.269: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 19.576442ms)
Nov  1 16:22:56.304: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 50.021954ms)
Nov  1 16:22:56.304: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 49.546299ms)
Nov  1 16:22:56.304: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 49.418037ms)
Nov  1 16:22:56.304: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 54.477274ms)
Nov  1 16:22:56.304: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 52.717802ms)
Nov  1 16:22:56.304: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 52.462347ms)
Nov  1 16:22:56.304: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 51.167228ms)
Nov  1 16:22:56.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 56.55188ms)
Nov  1 16:22:56.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 52.276059ms)
Nov  1 16:22:56.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 53.466536ms)
Nov  1 16:22:56.309: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 58.13172ms)
Nov  1 16:22:56.309: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 57.977357ms)
Nov  1 16:22:56.342: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 87.554838ms)
Nov  1 16:22:56.361: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 17.992615ms)
Nov  1 16:22:56.361: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 17.651104ms)
Nov  1 16:22:56.362: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 17.40404ms)
Nov  1 16:22:56.362: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 17.539452ms)
Nov  1 16:22:56.362: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 19.36522ms)
Nov  1 16:22:56.363: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 19.422204ms)
Nov  1 16:22:56.363: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 17.950829ms)
Nov  1 16:22:56.363: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 19.358622ms)
Nov  1 16:22:56.365: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 19.724321ms)
Nov  1 16:22:56.365: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 18.773543ms)
Nov  1 16:22:56.367: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 21.771203ms)
Nov  1 16:22:56.367: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 20.701948ms)
Nov  1 16:22:56.405: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 59.318504ms)
Nov  1 16:22:56.405: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 58.552278ms)
Nov  1 16:22:56.405: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 61.730273ms)
Nov  1 16:22:56.406: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 63.330515ms)
Nov  1 16:22:56.416: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 10.229596ms)
Nov  1 16:22:56.417: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 10.569653ms)
Nov  1 16:22:56.417: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 10.771396ms)
Nov  1 16:22:56.417: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 10.837839ms)
Nov  1 16:22:56.418: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 11.537532ms)
Nov  1 16:22:56.418: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 11.656381ms)
Nov  1 16:22:56.419: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 12.094036ms)
Nov  1 16:22:56.419: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 12.39974ms)
Nov  1 16:22:56.419: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 12.821908ms)
Nov  1 16:22:56.421: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 15.465621ms)
Nov  1 16:22:56.422: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 15.152337ms)
Nov  1 16:22:56.453: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 46.227475ms)
Nov  1 16:22:56.454: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 47.32545ms)
Nov  1 16:22:56.454: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 46.782185ms)
Nov  1 16:22:56.454: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 47.491375ms)
Nov  1 16:22:56.454: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 47.157485ms)
Nov  1 16:22:56.465: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 10.830578ms)
Nov  1 16:22:56.466: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 11.149419ms)
Nov  1 16:22:56.466: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 11.57438ms)
Nov  1 16:22:56.466: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 11.467113ms)
Nov  1 16:22:56.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 14.40412ms)
Nov  1 16:22:56.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 15.595266ms)
Nov  1 16:22:56.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 15.26062ms)
Nov  1 16:22:56.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 37.755856ms)
Nov  1 16:22:56.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 38.142332ms)
Nov  1 16:22:56.495: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 39.397749ms)
Nov  1 16:22:56.495: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 39.587404ms)
Nov  1 16:22:56.495: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 39.681018ms)
Nov  1 16:22:56.496: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 40.572796ms)
Nov  1 16:22:56.496: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 40.099669ms)
Nov  1 16:22:56.496: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 41.866802ms)
Nov  1 16:22:56.497: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 40.939054ms)
Nov  1 16:22:56.530: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 29.367097ms)
Nov  1 16:22:56.531: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 32.258667ms)
Nov  1 16:22:56.531: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 32.194205ms)
Nov  1 16:22:56.531: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 33.154455ms)
Nov  1 16:22:56.532: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 32.97326ms)
Nov  1 16:22:56.532: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 34.300616ms)
Nov  1 16:22:56.532: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 30.967122ms)
Nov  1 16:22:56.533: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 32.70547ms)
Nov  1 16:22:56.533: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 31.272673ms)
Nov  1 16:22:56.533: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 33.956296ms)
Nov  1 16:22:56.533: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 32.160621ms)
Nov  1 16:22:56.536: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 35.214246ms)
Nov  1 16:22:56.536: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 36.918696ms)
Nov  1 16:22:56.537: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 36.470526ms)
Nov  1 16:22:56.537: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 36.559538ms)
Nov  1 16:22:56.537: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 37.339954ms)
Nov  1 16:22:56.552: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 13.777104ms)
Nov  1 16:22:56.553: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 12.785127ms)
Nov  1 16:22:56.553: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 13.68173ms)
Nov  1 16:22:56.553: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 13.914009ms)
Nov  1 16:22:56.554: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 14.053523ms)
Nov  1 16:22:56.554: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 15.286177ms)
Nov  1 16:22:56.593: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 54.978645ms)
Nov  1 16:22:56.593: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 54.719638ms)
Nov  1 16:22:56.594: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 55.066473ms)
Nov  1 16:22:56.594: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 56.522139ms)
Nov  1 16:22:56.594: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 54.45743ms)
Nov  1 16:22:56.595: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 56.819109ms)
Nov  1 16:22:56.595: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 54.057585ms)
Nov  1 16:22:56.595: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 55.80523ms)
Nov  1 16:22:56.595: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 57.27822ms)
Nov  1 16:22:56.603: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 63.067995ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 16.045579ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 17.078243ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 18.275247ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 18.17924ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 19.748568ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 18.928273ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 17.628991ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 17.500041ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 18.11051ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 19.274518ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 17.225006ms)
Nov  1 16:22:56.623: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 17.939411ms)
Nov  1 16:22:56.627: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 20.207078ms)
Nov  1 16:22:56.627: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 21.912189ms)
Nov  1 16:22:56.627: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 22.839492ms)
Nov  1 16:22:56.627: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 22.142724ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 65.349652ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 64.337617ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 66.722128ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 65.682271ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 65.022717ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 64.379924ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 66.999219ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 67.219729ms)
Nov  1 16:22:56.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 66.125704ms)
Nov  1 16:22:56.703: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 73.506852ms)
Nov  1 16:22:56.704: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 75.2986ms)
Nov  1 16:22:56.704: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 72.712203ms)
Nov  1 16:22:56.709: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 78.82382ms)
Nov  1 16:22:56.710: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 78.30321ms)
Nov  1 16:22:56.716: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 84.524983ms)
Nov  1 16:22:56.716: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 84.771475ms)
Nov  1 16:22:56.745: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 27.293546ms)
Nov  1 16:22:56.751: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 33.778767ms)
Nov  1 16:22:56.752: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 34.455115ms)
Nov  1 16:22:56.752: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 34.748089ms)
Nov  1 16:22:56.752: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 35.196333ms)
Nov  1 16:22:56.779: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 59.106896ms)
Nov  1 16:22:56.779: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 60.890897ms)
Nov  1 16:22:56.779: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 62.903244ms)
Nov  1 16:22:56.780: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 62.082093ms)
Nov  1 16:22:56.781: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 63.961765ms)
Nov  1 16:22:56.782: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 64.774111ms)
Nov  1 16:22:56.782: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 65.358435ms)
Nov  1 16:22:56.784: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 65.97373ms)
Nov  1 16:22:56.784: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 65.697338ms)
Nov  1 16:22:56.785: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 66.781677ms)
Nov  1 16:22:56.797: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 79.22959ms)
Nov  1 16:22:56.994: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 196.409671ms)
Nov  1 16:22:57.105: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 307.118289ms)
Nov  1 16:22:57.105: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 305.90825ms)
Nov  1 16:22:57.105: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 306.840348ms)
Nov  1 16:22:57.105: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 306.398542ms)
Nov  1 16:22:57.105: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 305.837486ms)
Nov  1 16:22:57.106: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 307.542175ms)
Nov  1 16:22:57.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 308.539088ms)
Nov  1 16:22:57.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 307.666236ms)
Nov  1 16:22:57.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 308.661192ms)
Nov  1 16:22:57.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 308.893141ms)
Nov  1 16:22:57.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 307.599167ms)
Nov  1 16:22:57.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 309.313163ms)
Nov  1 16:22:57.110: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 312.5906ms)
Nov  1 16:22:57.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 311.014486ms)
Nov  1 16:22:57.122: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 322.897017ms)
Nov  1 16:22:57.210: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 85.181111ms)
Nov  1 16:22:57.212: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 88.737964ms)
Nov  1 16:22:57.214: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 89.951629ms)
Nov  1 16:22:57.215: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 90.602084ms)
Nov  1 16:22:57.215: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 90.915721ms)
Nov  1 16:22:57.296: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 172.136529ms)
Nov  1 16:22:57.296: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 170.531972ms)
Nov  1 16:22:57.296: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 170.666073ms)
Nov  1 16:22:57.297: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 171.580595ms)
Nov  1 16:22:57.297: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 172.417075ms)
Nov  1 16:22:57.297: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 172.397275ms)
Nov  1 16:22:57.297: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 171.822463ms)
Nov  1 16:22:57.297: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 172.004766ms)
Nov  1 16:22:57.297: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 172.335155ms)
Nov  1 16:22:57.297: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 174.225714ms)
Nov  1 16:22:57.306: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 182.855421ms)
Nov  1 16:22:57.409: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 101.318193ms)
Nov  1 16:22:57.409: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 101.696263ms)
Nov  1 16:22:57.503: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 195.42781ms)
Nov  1 16:22:57.510: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 202.154336ms)
Nov  1 16:22:57.511: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 203.24128ms)
Nov  1 16:22:57.511: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 202.923408ms)
Nov  1 16:22:57.511: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 204.788563ms)
Nov  1 16:22:57.512: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 203.0472ms)
Nov  1 16:22:57.512: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 204.135709ms)
Nov  1 16:22:57.513: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 204.989266ms)
Nov  1 16:22:57.513: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 204.859482ms)
Nov  1 16:22:57.514: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 206.156864ms)
Nov  1 16:22:57.515: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 206.346634ms)
Nov  1 16:22:57.515: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 206.273095ms)
Nov  1 16:22:57.553: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 245.787083ms)
Nov  1 16:22:57.554: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 245.169925ms)
Nov  1 16:22:57.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 42.469033ms)
Nov  1 16:22:57.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 41.781583ms)
Nov  1 16:22:57.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 45.016103ms)
Nov  1 16:22:57.600: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 44.663844ms)
Nov  1 16:22:57.600: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 43.155138ms)
Nov  1 16:22:57.600: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 43.987217ms)
Nov  1 16:22:57.601: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 46.833985ms)
Nov  1 16:22:57.601: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 44.123048ms)
Nov  1 16:22:57.601: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 45.601736ms)
Nov  1 16:22:57.601: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 45.51885ms)
Nov  1 16:22:57.601: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 47.44326ms)
Nov  1 16:22:57.613: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 56.526571ms)
Nov  1 16:22:57.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 96.944343ms)
Nov  1 16:22:57.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 97.984583ms)
Nov  1 16:22:57.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 101.781088ms)
Nov  1 16:22:57.656: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 98.409428ms)
Nov  1 16:22:57.669: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 12.101117ms)
Nov  1 16:22:57.670: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 12.367034ms)
Nov  1 16:22:57.672: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 14.742057ms)
Nov  1 16:22:57.673: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 14.888988ms)
Nov  1 16:22:57.674: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 17.267903ms)
Nov  1 16:22:57.674: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 15.813578ms)
Nov  1 16:22:57.676: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 16.562611ms)
Nov  1 16:22:57.676: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 19.569716ms)
Nov  1 16:22:57.677: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 20.867262ms)
Nov  1 16:22:57.677: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 19.102407ms)
Nov  1 16:22:57.677: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 19.905709ms)
Nov  1 16:22:57.710: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 52.126441ms)
Nov  1 16:22:57.711: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 51.237913ms)
Nov  1 16:22:57.711: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 52.630115ms)
Nov  1 16:22:57.712: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 52.651408ms)
Nov  1 16:22:57.712: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 53.039222ms)
Nov  1 16:22:57.810: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj/proxy/rewriteme"... (200; 94.28063ms)
Nov  1 16:22:57.810: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:443/proxy/... (200; 94.916885ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname2/proxy/: bar (200; 97.904228ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 94.629923ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname2/proxy/: tls qux (200; 96.605345ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:1080/proxy/rewri... (200; 96.626618ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 96.128964ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/https:proxy-service-vl2rh:tlsportname1/proxy/: tls baz (200; 98.164614ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:462/proxy/: tls qux (200; 98.674737ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/http:proxy-service-vl2rh-2mshj:1080/proxy/... (200; 97.966667ms)
Nov  1 16:22:57.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/proxy-service-vl2rh:portname1/proxy/: foo (200; 95.652379ms)
Nov  1 16:22:57.939: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/https:proxy-service-vl2rh-2mshj:460/proxy/: tls baz (200; 223.100088ms)
Nov  1 16:22:57.940: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:160/proxy/: foo (200; 225.017759ms)
Nov  1 16:22:57.940: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname1/proxy/: foo (200; 226.219711ms)
Nov  1 16:22:57.940: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/services/http:proxy-service-vl2rh:portname2/proxy/: bar (200; 225.992379ms)
Nov  1 16:22:57.940: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qmqwx/pods/proxy-service-vl2rh-2mshj:162/proxy/: bar (200; 225.020504ms)
STEP: deleting { ReplicationController} proxy-service-vl2rh in namespace e2e-tests-proxy-qmqwx, will wait for the garbage collector to delete the pods
Nov  1 16:22:58.016: INFO: Deleting { ReplicationController} proxy-service-vl2rh took: 18.690872ms
Nov  1 16:22:58.116: INFO: Terminating { ReplicationController} proxy-service-vl2rh pods took: 100.280743ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:23:03.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-qmqwx" for this suite.
Nov  1 16:23:09.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:23:09.692: INFO: namespace: e2e-tests-proxy-qmqwx, resource: bindings, ignored listing per whitelist
Nov  1 16:23:09.726: INFO: namespace e2e-tests-proxy-qmqwx deletion completed in 6.469172326s

• [SLOW TEST:21.548 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:23:09.733: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  1 16:23:09.947: INFO: Waiting up to 5m0s for pod "downward-api-6c09a53d-ddf2-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-ftj2f" to be "success or failure"
Nov  1 16:23:09.969: INFO: Pod "downward-api-6c09a53d-ddf2-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 21.885183ms
Nov  1 16:23:11.986: INFO: Pod "downward-api-6c09a53d-ddf2-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038719657s
Nov  1 16:23:13.999: INFO: Pod "downward-api-6c09a53d-ddf2-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051869225s
STEP: Saw pod success
Nov  1 16:23:14.000: INFO: Pod "downward-api-6c09a53d-ddf2-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:23:14.008: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downward-api-6c09a53d-ddf2-11e8-a64b-2ef904c43a0d container dapi-container: <nil>
STEP: delete the pod
Nov  1 16:23:14.122: INFO: Waiting for pod downward-api-6c09a53d-ddf2-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:23:14.157: INFO: Pod downward-api-6c09a53d-ddf2-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:23:14.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ftj2f" for this suite.
Nov  1 16:23:20.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:23:20.580: INFO: namespace: e2e-tests-downward-api-ftj2f, resource: bindings, ignored listing per whitelist
Nov  1 16:23:20.637: INFO: namespace e2e-tests-downward-api-ftj2f deletion completed in 6.474350212s

• [SLOW TEST:10.905 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:23:20.643: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-kl7nb/configmap-test-7286281d-ddf2-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:23:20.859: INFO: Waiting up to 5m0s for pod "pod-configmaps-7289bfd9-ddf2-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-kl7nb" to be "success or failure"
Nov  1 16:23:20.866: INFO: Pod "pod-configmaps-7289bfd9-ddf2-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.573981ms
Nov  1 16:23:22.901: INFO: Pod "pod-configmaps-7289bfd9-ddf2-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041618222s
Nov  1 16:23:24.911: INFO: Pod "pod-configmaps-7289bfd9-ddf2-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051446099s
STEP: Saw pod success
Nov  1 16:23:24.911: INFO: Pod "pod-configmaps-7289bfd9-ddf2-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:23:24.922: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-configmaps-7289bfd9-ddf2-11e8-a64b-2ef904c43a0d container env-test: <nil>
STEP: delete the pod
Nov  1 16:23:25.041: INFO: Waiting for pod pod-configmaps-7289bfd9-ddf2-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:23:25.049: INFO: Pod pod-configmaps-7289bfd9-ddf2-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:23:25.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kl7nb" for this suite.
Nov  1 16:23:31.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:23:31.211: INFO: namespace: e2e-tests-configmap-kl7nb, resource: bindings, ignored listing per whitelist
Nov  1 16:23:31.620: INFO: namespace e2e-tests-configmap-kl7nb deletion completed in 6.560345523s

• [SLOW TEST:10.978 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:23:31.621: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:23:31.894: INFO: (0) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 60.643526ms)
Nov  1 16:23:31.941: INFO: (1) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 46.456994ms)
Nov  1 16:23:31.951: INFO: (2) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 9.380077ms)
Nov  1 16:23:31.961: INFO: (3) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 9.635953ms)
Nov  1 16:23:31.970: INFO: (4) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 9.092394ms)
Nov  1 16:23:31.989: INFO: (5) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 19.191278ms)
Nov  1 16:23:32.001: INFO: (6) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 11.554735ms)
Nov  1 16:23:32.101: INFO: (7) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 100.093405ms)
Nov  1 16:23:32.116: INFO: (8) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 15.031602ms)
Nov  1 16:23:32.200: INFO: (9) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 84.064732ms)
Nov  1 16:23:32.221: INFO: (10) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 20.9789ms)
Nov  1 16:23:32.235: INFO: (11) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 13.653861ms)
Nov  1 16:23:32.248: INFO: (12) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 13.094647ms)
Nov  1 16:23:32.260: INFO: (13) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 11.480078ms)
Nov  1 16:23:32.271: INFO: (14) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 11.481233ms)
Nov  1 16:23:32.306: INFO: (15) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 34.503099ms)
Nov  1 16:23:32.322: INFO: (16) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 16.39196ms)
Nov  1 16:23:32.336: INFO: (17) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 13.775989ms)
Nov  1 16:23:32.347: INFO: (18) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 10.57599ms)
Nov  1 16:23:32.360: INFO: (19) /api/v1/nodes/machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 13.128912ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:23:32.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-nvchz" for this suite.
Nov  1 16:23:38.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:23:38.752: INFO: namespace: e2e-tests-proxy-nvchz, resource: bindings, ignored listing per whitelist
Nov  1 16:23:38.814: INFO: namespace e2e-tests-proxy-nvchz deletion completed in 6.446114644s

• [SLOW TEST:7.194 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:23:38.815: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7d6d6dca-ddf2-11e8-a64b-2ef904c43a0d
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7d6d6dca-ddf2-11e8-a64b-2ef904c43a0d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:25:00.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w9fvg" for this suite.
Nov  1 16:25:24.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:25:24.492: INFO: namespace: e2e-tests-projected-w9fvg, resource: bindings, ignored listing per whitelist
Nov  1 16:25:24.737: INFO: namespace e2e-tests-projected-w9fvg deletion completed in 24.428022557s

• [SLOW TEST:105.923 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:25:24.741: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:25:24.927: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:25:26.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-zjktt" for this suite.
Nov  1 16:25:32.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:25:32.690: INFO: namespace: e2e-tests-custom-resource-definition-zjktt, resource: bindings, ignored listing per whitelist
Nov  1 16:25:32.961: INFO: namespace e2e-tests-custom-resource-definition-zjktt deletion completed in 6.467052906s

• [SLOW TEST:8.221 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:25:32.965: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-m6nkg
Nov  1 16:25:35.230: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-m6nkg
STEP: checking the pod's current state and verifying that restartCount is present
Nov  1 16:25:35.242: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:29:36.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-m6nkg" for this suite.
Nov  1 16:29:44.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:29:44.491: INFO: namespace: e2e-tests-container-probe-m6nkg, resource: bindings, ignored listing per whitelist
Nov  1 16:29:44.654: INFO: namespace e2e-tests-container-probe-m6nkg deletion completed in 8.480983815s

• [SLOW TEST:251.690 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:29:44.657: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Nov  1 16:29:45.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:46.405: INFO: stderr: ""
Nov  1 16:29:46.405: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  1 16:29:46.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:46.580: INFO: stderr: ""
Nov  1 16:29:46.580: INFO: stdout: "update-demo-nautilus-7ckqk update-demo-nautilus-whx4v "
Nov  1 16:29:46.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:46.752: INFO: stderr: ""
Nov  1 16:29:46.752: INFO: stdout: ""
Nov  1 16:29:46.752: INFO: update-demo-nautilus-7ckqk is created but not running
Nov  1 16:29:51.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:51.972: INFO: stderr: ""
Nov  1 16:29:51.972: INFO: stdout: "update-demo-nautilus-7ckqk update-demo-nautilus-whx4v "
Nov  1 16:29:51.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:52.108: INFO: stderr: ""
Nov  1 16:29:52.108: INFO: stdout: "true"
Nov  1 16:29:52.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:52.266: INFO: stderr: ""
Nov  1 16:29:52.266: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 16:29:52.266: INFO: validating pod update-demo-nautilus-7ckqk
Nov  1 16:29:52.373: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 16:29:52.373: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 16:29:52.373: INFO: update-demo-nautilus-7ckqk is verified up and running
Nov  1 16:29:52.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-whx4v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:52.528: INFO: stderr: ""
Nov  1 16:29:52.528: INFO: stdout: "true"
Nov  1 16:29:52.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-whx4v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:52.652: INFO: stderr: ""
Nov  1 16:29:52.652: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 16:29:52.652: INFO: validating pod update-demo-nautilus-whx4v
Nov  1 16:29:52.749: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 16:29:52.750: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 16:29:52.750: INFO: update-demo-nautilus-whx4v is verified up and running
STEP: scaling down the replication controller
Nov  1 16:29:52.754: INFO: scanned /root for discovery docs: <nil>
Nov  1 16:29:52.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:53.977: INFO: stderr: ""
Nov  1 16:29:53.977: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  1 16:29:53.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:54.124: INFO: stderr: ""
Nov  1 16:29:54.124: INFO: stdout: "update-demo-nautilus-7ckqk update-demo-nautilus-whx4v "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  1 16:29:59.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:59.336: INFO: stderr: ""
Nov  1 16:29:59.337: INFO: stdout: "update-demo-nautilus-7ckqk "
Nov  1 16:29:59.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:59.466: INFO: stderr: ""
Nov  1 16:29:59.466: INFO: stdout: "true"
Nov  1 16:29:59.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:29:59.618: INFO: stderr: ""
Nov  1 16:29:59.618: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 16:29:59.619: INFO: validating pod update-demo-nautilus-7ckqk
Nov  1 16:29:59.639: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 16:29:59.639: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 16:29:59.639: INFO: update-demo-nautilus-7ckqk is verified up and running
STEP: scaling up the replication controller
Nov  1 16:29:59.641: INFO: scanned /root for discovery docs: <nil>
Nov  1 16:29:59.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:00.850: INFO: stderr: ""
Nov  1 16:30:00.850: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  1 16:30:00.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:01.003: INFO: stderr: ""
Nov  1 16:30:01.003: INFO: stdout: "update-demo-nautilus-7ckqk update-demo-nautilus-cwh5v "
Nov  1 16:30:01.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:01.155: INFO: stderr: ""
Nov  1 16:30:01.155: INFO: stdout: "true"
Nov  1 16:30:01.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:01.301: INFO: stderr: ""
Nov  1 16:30:01.301: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 16:30:01.301: INFO: validating pod update-demo-nautilus-7ckqk
Nov  1 16:30:01.325: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 16:30:01.325: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 16:30:01.325: INFO: update-demo-nautilus-7ckqk is verified up and running
Nov  1 16:30:01.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-cwh5v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:01.456: INFO: stderr: ""
Nov  1 16:30:01.456: INFO: stdout: ""
Nov  1 16:30:01.456: INFO: update-demo-nautilus-cwh5v is created but not running
Nov  1 16:30:06.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:06.649: INFO: stderr: ""
Nov  1 16:30:06.649: INFO: stdout: "update-demo-nautilus-7ckqk update-demo-nautilus-cwh5v "
Nov  1 16:30:06.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:06.776: INFO: stderr: ""
Nov  1 16:30:06.776: INFO: stdout: "true"
Nov  1 16:30:06.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-7ckqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:06.902: INFO: stderr: ""
Nov  1 16:30:06.902: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 16:30:06.902: INFO: validating pod update-demo-nautilus-7ckqk
Nov  1 16:30:06.929: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 16:30:06.929: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 16:30:06.929: INFO: update-demo-nautilus-7ckqk is verified up and running
Nov  1 16:30:06.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-cwh5v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:07.059: INFO: stderr: ""
Nov  1 16:30:07.059: INFO: stdout: "true"
Nov  1 16:30:07.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods update-demo-nautilus-cwh5v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:07.215: INFO: stderr: ""
Nov  1 16:30:07.215: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  1 16:30:07.215: INFO: validating pod update-demo-nautilus-cwh5v
Nov  1 16:30:07.306: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  1 16:30:07.306: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  1 16:30:07.306: INFO: update-demo-nautilus-cwh5v is verified up and running
STEP: using delete to clean up resources
Nov  1 16:30:07.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:07.465: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 16:30:07.465: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  1 16:30:07.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bn76b'
Nov  1 16:30:07.669: INFO: stderr: "No resources found.\n"
Nov  1 16:30:07.669: INFO: stdout: ""
Nov  1 16:30:07.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -l name=update-demo --namespace=e2e-tests-kubectl-bn76b -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  1 16:30:07.919: INFO: stderr: ""
Nov  1 16:30:07.919: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:30:07.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bn76b" for this suite.
Nov  1 16:30:13.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:30:14.353: INFO: namespace: e2e-tests-kubectl-bn76b, resource: bindings, ignored listing per whitelist
Nov  1 16:30:14.401: INFO: namespace e2e-tests-kubectl-bn76b deletion completed in 6.475202714s

• [SLOW TEST:29.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:30:14.404: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:30:14.681: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6933fc0d-ddf3-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-swcwp" to be "success or failure"
Nov  1 16:30:14.700: INFO: Pod "downwardapi-volume-6933fc0d-ddf3-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.901692ms
Nov  1 16:30:16.815: INFO: Pod "downwardapi-volume-6933fc0d-ddf3-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.133674515s
STEP: Saw pod success
Nov  1 16:30:16.816: INFO: Pod "downwardapi-volume-6933fc0d-ddf3-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:30:16.822: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod downwardapi-volume-6933fc0d-ddf3-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:30:16.922: INFO: Waiting for pod downwardapi-volume-6933fc0d-ddf3-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:30:16.930: INFO: Pod downwardapi-volume-6933fc0d-ddf3-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:30:16.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-swcwp" for this suite.
Nov  1 16:30:22.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:30:22.999: INFO: namespace: e2e-tests-downward-api-swcwp, resource: bindings, ignored listing per whitelist
Nov  1 16:30:23.331: INFO: namespace e2e-tests-downward-api-swcwp deletion completed in 6.394306711s

• [SLOW TEST:8.929 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:30:23.338: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  1 16:30:23.607: INFO: Waiting up to 5m0s for pod "pod-6e8435b2-ddf3-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-2w72k" to be "success or failure"
Nov  1 16:30:23.619: INFO: Pod "pod-6e8435b2-ddf3-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.355611ms
Nov  1 16:30:25.625: INFO: Pod "pod-6e8435b2-ddf3-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017548205s
STEP: Saw pod success
Nov  1 16:30:25.625: INFO: Pod "pod-6e8435b2-ddf3-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:30:25.636: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-6e8435b2-ddf3-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:30:25.707: INFO: Waiting for pod pod-6e8435b2-ddf3-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:30:25.716: INFO: Pod pod-6e8435b2-ddf3-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:30:25.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2w72k" for this suite.
Nov  1 16:30:31.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:30:32.226: INFO: namespace: e2e-tests-emptydir-2w72k, resource: bindings, ignored listing per whitelist
Nov  1 16:30:32.263: INFO: namespace e2e-tests-emptydir-2w72k deletion completed in 6.541041232s

• [SLOW TEST:8.926 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:30:32.269: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:31:32.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8d7q7" for this suite.
Nov  1 16:31:56.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:31:57.010: INFO: namespace: e2e-tests-container-probe-8d7q7, resource: bindings, ignored listing per whitelist
Nov  1 16:31:57.071: INFO: namespace e2e-tests-container-probe-8d7q7 deletion completed in 24.509393446s

• [SLOW TEST:84.802 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:31:57.077: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-n8c5w
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-n8c5w
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-n8c5w
Nov  1 16:31:57.361: INFO: Found 0 stateful pods, waiting for 1
Nov  1 16:32:07.403: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  1 16:32:07.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:32:07.973: INFO: stderr: ""
Nov  1 16:32:07.973: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:32:07.973: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:32:07.982: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  1 16:32:18.012: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  1 16:32:18.012: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 16:32:18.075: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:18.076: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:18.076: INFO: ss-1                                                          Pending         []
Nov  1 16:32:18.076: INFO: 
Nov  1 16:32:18.077: INFO: StatefulSet ss has not reached scale 3, at 2
Nov  1 16:32:19.084: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.971672399s
Nov  1 16:32:20.091: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.963812291s
Nov  1 16:32:21.106: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.957160448s
Nov  1 16:32:22.115: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.941652761s
Nov  1 16:32:23.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.932710095s
Nov  1 16:32:24.137: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.920807553s
Nov  1 16:32:25.145: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.911104734s
Nov  1 16:32:26.152: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.903641897s
Nov  1 16:32:27.164: INFO: Verifying statefulset ss doesn't scale past 3 for another 896.440821ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-n8c5w
Nov  1 16:32:28.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:32:28.801: INFO: stderr: ""
Nov  1 16:32:28.801: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:32:28.801: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:32:28.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:32:29.517: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Nov  1 16:32:29.517: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:32:29.517: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:32:29.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:32:30.211: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Nov  1 16:32:30.211: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:32:30.211: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:32:30.219: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 16:32:30.219: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 16:32:30.219: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  1 16:32:30.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:32:30.821: INFO: stderr: ""
Nov  1 16:32:30.821: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:32:30.821: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:32:30.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:32:31.491: INFO: stderr: ""
Nov  1 16:32:31.491: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:32:31.491: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:32:31.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:32:32.201: INFO: stderr: ""
Nov  1 16:32:32.201: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:32:32.201: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:32:32.201: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 16:32:32.208: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov  1 16:32:42.230: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  1 16:32:42.231: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  1 16:32:42.231: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  1 16:32:42.263: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:42.263: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:42.264: INFO: ss-1  machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:42.264: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:42.264: INFO: 
Nov  1 16:32:42.264: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  1 16:32:43.281: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:43.282: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:43.282: INFO: ss-1  machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:43.282: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:43.282: INFO: 
Nov  1 16:32:43.282: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  1 16:32:44.290: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:44.290: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:44.291: INFO: ss-1  machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:44.291: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:44.291: INFO: 
Nov  1 16:32:44.291: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  1 16:32:45.301: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:45.301: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:45.301: INFO: ss-1  machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:45.301: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:45.301: INFO: 
Nov  1 16:32:45.301: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  1 16:32:46.329: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:46.329: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:46.330: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:46.330: INFO: 
Nov  1 16:32:46.330: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  1 16:32:47.348: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:47.348: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:47.348: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:47.348: INFO: 
Nov  1 16:32:47.348: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  1 16:32:48.355: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:48.355: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:48.355: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:48.355: INFO: 
Nov  1 16:32:48.355: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  1 16:32:49.367: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:49.367: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:49.367: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:49.367: INFO: 
Nov  1 16:32:49.367: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  1 16:32:50.373: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:50.373: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:50.373: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:50.373: INFO: 
Nov  1 16:32:50.373: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  1 16:32:51.409: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  1 16:32:51.409: INFO: ss-0  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:31:57 +0000 UTC  }]
Nov  1 16:32:51.409: INFO: ss-2  machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:32:18 +0000 UTC  }]
Nov  1 16:32:51.409: INFO: 
Nov  1 16:32:51.409: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-n8c5w
Nov  1 16:32:52.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:32:52.770: INFO: rc: 1
Nov  1 16:32:52.770: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc422216750 exit status 1 <nil> <nil> true [0xc4223a5eb0 0xc4223a5ec8 0xc4223a5ee0] [0xc4223a5eb0 0xc4223a5ec8 0xc4223a5ee0] [0xc4223a5ec0 0xc4223a5ed8] [0x8fd520 0x8fd520] 0xc421d96b40 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Nov  1 16:33:02.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:33:02.916: INFO: rc: 1
Nov  1 16:33:02.917: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422216b70 exit status 1 <nil> <nil> true [0xc4223a5ee8 0xc4223a5f00 0xc4223a5f18] [0xc4223a5ee8 0xc4223a5f00 0xc4223a5f18] [0xc4223a5ef8 0xc4223a5f10] [0x8fd520 0x8fd520] 0xc421d974a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:33:12.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:33:13.040: INFO: rc: 1
Nov  1 16:33:13.041: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422216f60 exit status 1 <nil> <nil> true [0xc4223a5f20 0xc4223a5f38 0xc4223a5f50] [0xc4223a5f20 0xc4223a5f38 0xc4223a5f50] [0xc4223a5f30 0xc4223a5f48] [0x8fd520 0x8fd520] 0xc421d975c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:33:23.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:33:23.278: INFO: rc: 1
Nov  1 16:33:23.279: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422217350 exit status 1 <nil> <nil> true [0xc4223a5f58 0xc4223a5f70 0xc4223a5f88] [0xc4223a5f58 0xc4223a5f70 0xc4223a5f88] [0xc4223a5f68 0xc4223a5f80] [0x8fd520 0x8fd520] 0xc421d976e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:33:33.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:33:33.479: INFO: rc: 1
Nov  1 16:33:33.479: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422217740 exit status 1 <nil> <nil> true [0xc4223a5f90 0xc4223a5fa8 0xc4223a5fc0] [0xc4223a5f90 0xc4223a5fa8 0xc4223a5fc0] [0xc4223a5fa0 0xc4223a5fb8] [0x8fd520 0x8fd520] 0xc421d97800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:33:43.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:33:43.657: INFO: rc: 1
Nov  1 16:33:43.657: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422217b30 exit status 1 <nil> <nil> true [0xc4223a5fc8 0xc4223a5fe0 0xc4223a5ff8] [0xc4223a5fc8 0xc4223a5fe0 0xc4223a5ff8] [0xc4223a5fd8 0xc4223a5ff0] [0x8fd520 0x8fd520] 0xc422954060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:33:53.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:33:53.810: INFO: rc: 1
Nov  1 16:33:53.811: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f58420 exit status 1 <nil> <nil> true [0xc4223a4008 0xc4223a4020 0xc4223a4038] [0xc4223a4008 0xc4223a4020 0xc4223a4038] [0xc4223a4018 0xc4223a4030] [0x8fd520 0x8fd520] 0xc420a01800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:34:03.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:34:03.959: INFO: rc: 1
Nov  1 16:34:03.959: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f58870 exit status 1 <nil> <nil> true [0xc4223a4040 0xc4223a4058 0xc4223a4070] [0xc4223a4040 0xc4223a4058 0xc4223a4070] [0xc4223a4050 0xc4223a4068] [0x8fd520 0x8fd520] 0xc422036de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:34:13.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:34:14.104: INFO: rc: 1
Nov  1 16:34:14.104: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f58fc0 exit status 1 <nil> <nil> true [0xc4223a4078 0xc4223a4090 0xc4223a40a8] [0xc4223a4078 0xc4223a4090 0xc4223a40a8] [0xc4223a4088 0xc4223a40a0] [0x8fd520 0x8fd520] 0xc422037a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:34:24.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:34:24.351: INFO: rc: 1
Nov  1 16:34:24.351: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f59470 exit status 1 <nil> <nil> true [0xc4223a40b0 0xc4223a40c8 0xc4223a40e0] [0xc4223a40b0 0xc4223a40c8 0xc4223a40e0] [0xc4223a40c0 0xc4223a40d8] [0x8fd520 0x8fd520] 0xc421d4c420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:34:34.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:34:34.510: INFO: rc: 1
Nov  1 16:34:34.511: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f59860 exit status 1 <nil> <nil> true [0xc4223a40e8 0xc4223a4100 0xc4223a4118] [0xc4223a40e8 0xc4223a4100 0xc4223a4118] [0xc4223a40f8 0xc4223a4110] [0x8fd520 0x8fd520] 0xc421d4c6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:34:44.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:34:44.716: INFO: rc: 1
Nov  1 16:34:44.716: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f59d70 exit status 1 <nil> <nil> true [0xc4223a4120 0xc4223a4138 0xc4223a4150] [0xc4223a4120 0xc4223a4138 0xc4223a4150] [0xc4223a4130 0xc4223a4148] [0x8fd520 0x8fd520] 0xc421d4cb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:34:54.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:34:54.834: INFO: rc: 1
Nov  1 16:34:54.834: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a0180 exit status 1 <nil> <nil> true [0xc4223a4158 0xc4223a4170 0xc4223a4188] [0xc4223a4158 0xc4223a4170 0xc4223a4188] [0xc4223a4168 0xc4223a4180] [0x8fd520 0x8fd520] 0xc421d4cfc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:35:04.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:35:04.988: INFO: rc: 1
Nov  1 16:35:04.988: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a05a0 exit status 1 <nil> <nil> true [0xc4223a4190 0xc4223a41a8 0xc4223a41c0] [0xc4223a4190 0xc4223a41a8 0xc4223a41c0] [0xc4223a41a0 0xc4223a41b8] [0x8fd520 0x8fd520] 0xc421d4d3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:35:14.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:35:15.148: INFO: rc: 1
Nov  1 16:35:15.148: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a0990 exit status 1 <nil> <nil> true [0xc4223a41c8 0xc4223a41e0 0xc4223a41f8] [0xc4223a41c8 0xc4223a41e0 0xc4223a41f8] [0xc4223a41d8 0xc4223a41f0] [0x8fd520 0x8fd520] 0xc421d4d6e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:35:25.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:35:25.442: INFO: rc: 1
Nov  1 16:35:25.442: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a0d80 exit status 1 <nil> <nil> true [0xc4223a4200 0xc4223a4218 0xc4223a4230] [0xc4223a4200 0xc4223a4218 0xc4223a4230] [0xc4223a4210 0xc4223a4228] [0x8fd520 0x8fd520] 0xc421d4daa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:35:35.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:35:35.595: INFO: rc: 1
Nov  1 16:35:35.595: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a1170 exit status 1 <nil> <nil> true [0xc4223a4238 0xc4223a4250 0xc4223a4268] [0xc4223a4238 0xc4223a4250 0xc4223a4268] [0xc4223a4248 0xc4223a4260] [0x8fd520 0x8fd520] 0xc421d4df20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:35:45.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:35:45.977: INFO: rc: 1
Nov  1 16:35:45.978: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a1560 exit status 1 <nil> <nil> true [0xc4223a4270 0xc4223a4288 0xc4223a42a0] [0xc4223a4270 0xc4223a4288 0xc4223a42a0] [0xc4223a4280 0xc4223a4298] [0x8fd520 0x8fd520] 0xc421d96060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:35:55.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:35:56.145: INFO: rc: 1
Nov  1 16:35:56.146: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f58450 exit status 1 <nil> <nil> true [0xc4223a4008 0xc4223a4020 0xc4223a4038] [0xc4223a4008 0xc4223a4020 0xc4223a4038] [0xc4223a4018 0xc4223a4030] [0x8fd520 0x8fd520] 0xc421921560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:36:06.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:36:06.339: INFO: rc: 1
Nov  1 16:36:06.339: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f588d0 exit status 1 <nil> <nil> true [0xc4223a4040 0xc4223a4058 0xc4223a4070] [0xc4223a4040 0xc4223a4058 0xc4223a4070] [0xc4223a4050 0xc4223a4068] [0x8fd520 0x8fd520] 0xc421d4c660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:36:16.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:36:16.494: INFO: rc: 1
Nov  1 16:36:16.494: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f59110 exit status 1 <nil> <nil> true [0xc4223a4078 0xc4223a4090 0xc4223a40a8] [0xc4223a4078 0xc4223a4090 0xc4223a40a8] [0xc4223a4088 0xc4223a40a0] [0x8fd520 0x8fd520] 0xc421d4c960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:36:26.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:36:26.611: INFO: rc: 1
Nov  1 16:36:26.611: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f59530 exit status 1 <nil> <nil> true [0xc4223a40b0 0xc4223a40c8 0xc4223a40e0] [0xc4223a40b0 0xc4223a40c8 0xc4223a40e0] [0xc4223a40c0 0xc4223a40d8] [0x8fd520 0x8fd520] 0xc421d4ce40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:36:36.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:36:36.801: INFO: rc: 1
Nov  1 16:36:36.801: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f599b0 exit status 1 <nil> <nil> true [0xc4223a40e8 0xc4223a4100 0xc4223a4118] [0xc4223a40e8 0xc4223a4100 0xc4223a4118] [0xc4223a40f8 0xc4223a4110] [0x8fd520 0x8fd520] 0xc421d4d260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:36:46.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:36:46.958: INFO: rc: 1
Nov  1 16:36:46.958: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f59e90 exit status 1 <nil> <nil> true [0xc4223a4120 0xc4223a4138 0xc4223a4150] [0xc4223a4120 0xc4223a4138 0xc4223a4150] [0xc4223a4130 0xc4223a4148] [0x8fd520 0x8fd520] 0xc421d4d620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:36:56.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:36:57.116: INFO: rc: 1
Nov  1 16:36:57.116: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a0300 exit status 1 <nil> <nil> true [0xc4223a4158 0xc4223a4170 0xc4223a4188] [0xc4223a4158 0xc4223a4170 0xc4223a4188] [0xc4223a4168 0xc4223a4180] [0x8fd520 0x8fd520] 0xc421d4d920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:37:07.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:37:07.297: INFO: rc: 1
Nov  1 16:37:07.297: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a0720 exit status 1 <nil> <nil> true [0xc4223a4190 0xc4223a41a8 0xc4223a41c0] [0xc4223a4190 0xc4223a41a8 0xc4223a41c0] [0xc4223a41a0 0xc4223a41b8] [0x8fd520 0x8fd520] 0xc421d4de60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:37:17.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:37:17.438: INFO: rc: 1
Nov  1 16:37:17.438: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a0b40 exit status 1 <nil> <nil> true [0xc4223a41c8 0xc4223a41e0 0xc4223a41f8] [0xc4223a41c8 0xc4223a41e0 0xc4223a41f8] [0xc4223a41d8 0xc4223a41f0] [0x8fd520 0x8fd520] 0xc4220369c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:37:27.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:37:27.639: INFO: rc: 1
Nov  1 16:37:27.639: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a0f60 exit status 1 <nil> <nil> true [0xc4223a4200 0xc4223a4218 0xc4223a4230] [0xc4223a4200 0xc4223a4218 0xc4223a4230] [0xc4223a4210 0xc4223a4228] [0x8fd520 0x8fd520] 0xc422037620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:37:37.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:37:37.816: INFO: rc: 1
Nov  1 16:37:37.816: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216a13e0 exit status 1 <nil> <nil> true [0xc4223a4238 0xc4223a4250 0xc4223a4268] [0xc4223a4238 0xc4223a4250 0xc4223a4268] [0xc4223a4248 0xc4223a4260] [0x8fd520 0x8fd520] 0xc422037f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:37:47.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:37:47.980: INFO: rc: 1
Nov  1 16:37:47.980: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421f58420 exit status 1 <nil> <nil> true [0xc4223a4008 0xc4223a4020 0xc4223a4038] [0xc4223a4008 0xc4223a4020 0xc4223a4038] [0xc4223a4018 0xc4223a4030] [0x8fd520 0x8fd520] 0xc4220369c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  1 16:37:57.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-n8c5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:37:58.270: INFO: rc: 1
Nov  1 16:37:58.270: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Nov  1 16:37:58.270: INFO: Scaling statefulset ss to 0
Nov  1 16:37:58.556: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  1 16:37:58.568: INFO: Deleting all statefulset in ns e2e-tests-statefulset-n8c5w
Nov  1 16:37:58.575: INFO: Scaling statefulset ss to 0
Nov  1 16:37:58.609: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 16:37:58.615: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:37:58.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-n8c5w" for this suite.
Nov  1 16:38:06.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:38:06.933: INFO: namespace: e2e-tests-statefulset-n8c5w, resource: bindings, ignored listing per whitelist
Nov  1 16:38:07.279: INFO: namespace e2e-tests-statefulset-n8c5w deletion completed in 8.606452685s

• [SLOW TEST:370.203 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:38:07.286: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8319c6f2-ddf4-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:38:07.639: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-831c7388-ddf4-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-zgf7b" to be "success or failure"
Nov  1 16:38:07.820: INFO: Pod "pod-projected-configmaps-831c7388-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 180.92631ms
Nov  1 16:38:09.876: INFO: Pod "pod-projected-configmaps-831c7388-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.237125548s
Nov  1 16:38:11.883: INFO: Pod "pod-projected-configmaps-831c7388-ddf4-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.243746171s
STEP: Saw pod success
Nov  1 16:38:11.883: INFO: Pod "pod-projected-configmaps-831c7388-ddf4-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:38:11.892: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-configmaps-831c7388-ddf4-11e8-a64b-2ef904c43a0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 16:38:11.958: INFO: Waiting for pod pod-projected-configmaps-831c7388-ddf4-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:38:11.962: INFO: Pod pod-projected-configmaps-831c7388-ddf4-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:38:11.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zgf7b" for this suite.
Nov  1 16:38:18.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:38:18.340: INFO: namespace: e2e-tests-projected-zgf7b, resource: bindings, ignored listing per whitelist
Nov  1 16:38:18.725: INFO: namespace e2e-tests-projected-zgf7b deletion completed in 6.645689346s

• [SLOW TEST:11.440 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:38:18.732: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:38:19.044: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-7b982" to be "success or failure"
Nov  1 16:38:19.052: INFO: Pod "downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.422641ms
Nov  1 16:38:21.074: INFO: Pod "downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029338551s
Nov  1 16:38:23.080: INFO: Pod "downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035847345s
Nov  1 16:38:25.090: INFO: Pod "downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045403346s
STEP: Saw pod success
Nov  1 16:38:25.090: INFO: Pod "downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:38:25.096: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:38:25.157: INFO: Waiting for pod downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:38:25.163: INFO: Pod downwardapi-volume-89e47ae6-ddf4-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:38:25.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7b982" for this suite.
Nov  1 16:38:33.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:38:33.660: INFO: namespace: e2e-tests-downward-api-7b982, resource: bindings, ignored listing per whitelist
Nov  1 16:38:33.808: INFO: namespace e2e-tests-downward-api-7b982 deletion completed in 8.525645607s

• [SLOW TEST:15.078 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:38:33.810: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-tnjdj/configmap-test-930b8b96-ddf4-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:38:34.466: INFO: Waiting up to 5m0s for pod "pod-configmaps-931207c4-ddf4-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-tnjdj" to be "success or failure"
Nov  1 16:38:34.472: INFO: Pod "pod-configmaps-931207c4-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.698227ms
Nov  1 16:38:36.542: INFO: Pod "pod-configmaps-931207c4-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075235925s
Nov  1 16:38:38.554: INFO: Pod "pod-configmaps-931207c4-ddf4-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.088091408s
STEP: Saw pod success
Nov  1 16:38:38.555: INFO: Pod "pod-configmaps-931207c4-ddf4-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:38:38.563: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-configmaps-931207c4-ddf4-11e8-a64b-2ef904c43a0d container env-test: <nil>
STEP: delete the pod
Nov  1 16:38:38.680: INFO: Waiting for pod pod-configmaps-931207c4-ddf4-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:38:38.687: INFO: Pod pod-configmaps-931207c4-ddf4-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:38:38.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tnjdj" for this suite.
Nov  1 16:38:46.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:38:47.235: INFO: namespace: e2e-tests-configmap-tnjdj, resource: bindings, ignored listing per whitelist
Nov  1 16:38:47.526: INFO: namespace e2e-tests-configmap-tnjdj deletion completed in 8.827556166s

• [SLOW TEST:13.717 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:38:47.529: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:39:14.016: INFO: Container started at 2018-11-01 16:38:51 +0000 UTC, pod became ready at 2018-11-01 16:39:13 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:39:14.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4fs85" for this suite.
Nov  1 16:39:38.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:39:38.336: INFO: namespace: e2e-tests-container-probe-4fs85, resource: bindings, ignored listing per whitelist
Nov  1 16:39:38.736: INFO: namespace e2e-tests-container-probe-4fs85 deletion completed in 24.710687114s

• [SLOW TEST:51.207 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:39:38.738: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-pm686
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-pm686
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-pm686
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-pm686
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-pm686
Nov  1 16:39:45.204: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-pm686, name: ss-0, uid: bcec1027-ddf4-11e8-ad00-0a580af40ec2, status phase: Pending. Waiting for statefulset controller to delete.
Nov  1 16:39:45.350: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-pm686, name: ss-0, uid: bcec1027-ddf4-11e8-ad00-0a580af40ec2, status phase: Failed. Waiting for statefulset controller to delete.
Nov  1 16:39:45.436: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-pm686, name: ss-0, uid: bcec1027-ddf4-11e8-ad00-0a580af40ec2, status phase: Failed. Waiting for statefulset controller to delete.
Nov  1 16:39:45.521: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-pm686
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-pm686
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-pm686 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  1 16:39:51.628: INFO: Deleting all statefulset in ns e2e-tests-statefulset-pm686
Nov  1 16:39:51.636: INFO: Scaling statefulset ss to 0
Nov  1 16:40:01.754: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 16:40:01.762: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:40:01.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-pm686" for this suite.
Nov  1 16:40:10.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:40:10.341: INFO: namespace: e2e-tests-statefulset-pm686, resource: bindings, ignored listing per whitelist
Nov  1 16:40:10.427: INFO: namespace e2e-tests-statefulset-pm686 deletion completed in 8.538088559s

• [SLOW TEST:31.690 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:40:10.431: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:40:10.715: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  1 16:40:10.820: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  1 16:40:15.835: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  1 16:40:15.836: INFO: Creating deployment "test-rolling-update-deployment"
Nov  1 16:40:15.882: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  1 16:40:15.918: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  1 16:40:17.941: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  1 16:40:17.955: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687216, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687216, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687216, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687216, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 16:40:19.961: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687216, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687216, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687216, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687216, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  1 16:40:21.992: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  1 16:40:22.018: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-8vmw5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8vmw5/deployments/test-rolling-update-deployment,UID:cf89464f-ddf4-11e8-a94b-0a580af40661,ResourceVersion:13600,Generation:1,CreationTimestamp:2018-11-01 16:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-01 16:40:16 +0000 UTC 2018-11-01 16:40:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-01 16:40:20 +0000 UTC 2018-11-01 16:40:16 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  1 16:40:22.027: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-8vmw5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8vmw5/replicasets/test-rolling-update-deployment-65b7695dcf,UID:cf9e8bfc-ddf4-11e8-ad00-0a580af40ec2,ResourceVersion:13591,Generation:1,CreationTimestamp:2018-11-01 16:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment cf89464f-ddf4-11e8-a94b-0a580af40661 0xc421de8937 0xc421de8938}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  1 16:40:22.027: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  1 16:40:22.027: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-8vmw5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8vmw5/replicasets/test-rolling-update-controller,UID:cc7d9b91-ddf4-11e8-a94b-0a580af40661,ResourceVersion:13599,Generation:2,CreationTimestamp:2018-11-01 16:40:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment cf89464f-ddf4-11e8-a94b-0a580af40661 0xc421de855e 0xc421de855f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  1 16:40:22.041: INFO: Pod "test-rolling-update-deployment-65b7695dcf-mppwn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-mppwn,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-8vmw5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8vmw5/pods/test-rolling-update-deployment-65b7695dcf-mppwn,UID:cfb00ada-ddf4-11e8-ad00-0a580af40ec2,ResourceVersion:13590,Generation:0,CreationTimestamp:2018-11-01 16:40:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf cf9e8bfc-ddf4-11e8-ad00-0a580af40ec2 0xc421de99e7 0xc421de99e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-btrtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-btrtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-btrtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421de9a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421de9a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:40:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:40:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:40:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-01 16:40:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.10,PodIP:172.25.1.90,StartTime:2018-11-01 16:40:16 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-01 16:40:19 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://52e29ccd5baab271ee8cfd56096de3106cfc728d6545f020b0650435309c8855}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:40:22.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8vmw5" for this suite.
Nov  1 16:40:28.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:40:28.440: INFO: namespace: e2e-tests-deployment-8vmw5, resource: bindings, ignored listing per whitelist
Nov  1 16:40:28.589: INFO: namespace e2e-tests-deployment-8vmw5 deletion completed in 6.535553489s

• [SLOW TEST:18.159 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:40:28.590: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Nov  1 16:40:33.061: INFO: Pod pod-hostip-d746535a-ddf4-11e8-a64b-2ef904c43a0d has hostIP: 192.168.1.8
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:40:33.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-brwfw" for this suite.
Nov  1 16:40:57.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:40:57.689: INFO: namespace: e2e-tests-pods-brwfw, resource: bindings, ignored listing per whitelist
Nov  1 16:40:57.896: INFO: namespace e2e-tests-pods-brwfw deletion completed in 24.828317594s

• [SLOW TEST:29.307 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:40:57.902: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:40:58.293: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8cec2e5-ddf4-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-g9mcl" to be "success or failure"
Nov  1 16:40:58.430: INFO: Pod "downwardapi-volume-e8cec2e5-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 137.340534ms
Nov  1 16:41:00.597: INFO: Pod "downwardapi-volume-e8cec2e5-ddf4-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.30401097s
Nov  1 16:41:02.623: INFO: Pod "downwardapi-volume-e8cec2e5-ddf4-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.330398907s
STEP: Saw pod success
Nov  1 16:41:02.623: INFO: Pod "downwardapi-volume-e8cec2e5-ddf4-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:41:02.628: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-e8cec2e5-ddf4-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:41:02.794: INFO: Waiting for pod downwardapi-volume-e8cec2e5-ddf4-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:41:02.820: INFO: Pod downwardapi-volume-e8cec2e5-ddf4-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:41:02.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g9mcl" for this suite.
Nov  1 16:41:08.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:41:09.136: INFO: namespace: e2e-tests-projected-g9mcl, resource: bindings, ignored listing per whitelist
Nov  1 16:41:09.361: INFO: namespace e2e-tests-projected-g9mcl deletion completed in 6.518992763s

• [SLOW TEST:11.460 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:41:09.366: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-rqdw7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rqdw7 to expose endpoints map[]
Nov  1 16:41:09.671: INFO: Get endpoints failed (6.133368ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov  1 16:41:10.697: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rqdw7 exposes endpoints map[] (1.032168151s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rqdw7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rqdw7 to expose endpoints map[pod1:[100]]
Nov  1 16:41:13.782: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rqdw7 exposes endpoints map[pod1:[100]] (3.07016608s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rqdw7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rqdw7 to expose endpoints map[pod1:[100] pod2:[101]]
Nov  1 16:41:16.988: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rqdw7 exposes endpoints map[pod1:[100] pod2:[101]] (3.175725337s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rqdw7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rqdw7 to expose endpoints map[pod2:[101]]
Nov  1 16:41:17.059: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rqdw7 exposes endpoints map[pod2:[101]] (19.201021ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rqdw7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rqdw7 to expose endpoints map[]
Nov  1 16:41:17.096: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rqdw7 exposes endpoints map[] (6.62173ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:41:17.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rqdw7" for this suite.
Nov  1 16:41:23.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:41:23.764: INFO: namespace: e2e-tests-services-rqdw7, resource: bindings, ignored listing per whitelist
Nov  1 16:41:23.785: INFO: namespace e2e-tests-services-rqdw7 deletion completed in 6.605377423s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:14.421 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:41:23.789: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1101 16:41:34.206622      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  1 16:41:34.206: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:41:34.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vh29t" for this suite.
Nov  1 16:41:40.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:41:41.004: INFO: namespace: e2e-tests-gc-vh29t, resource: bindings, ignored listing per whitelist
Nov  1 16:41:41.314: INFO: namespace e2e-tests-gc-vh29t deletion completed in 7.099051435s

• [SLOW TEST:17.526 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:41:41.317: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-02cadef7-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 16:41:41.920: INFO: Waiting up to 5m0s for pod "pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-9xjzn" to be "success or failure"
Nov  1 16:41:41.944: INFO: Pod "pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 23.656642ms
Nov  1 16:41:43.995: INFO: Pod "pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074615768s
Nov  1 16:41:46.018: INFO: Pod "pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.09803834s
Nov  1 16:41:48.025: INFO: Pod "pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.104761753s
STEP: Saw pod success
Nov  1 16:41:48.025: INFO: Pod "pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:41:48.034: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d container secret-volume-test: <nil>
STEP: delete the pod
Nov  1 16:41:48.188: INFO: Waiting for pod pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:41:48.195: INFO: Pod pod-secrets-02cc9673-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:41:48.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9xjzn" for this suite.
Nov  1 16:41:54.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:41:54.502: INFO: namespace: e2e-tests-secrets-9xjzn, resource: bindings, ignored listing per whitelist
Nov  1 16:41:54.667: INFO: namespace e2e-tests-secrets-9xjzn deletion completed in 6.464077711s

• [SLOW TEST:13.351 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:41:54.668: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Nov  1 16:41:58.954: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-0a9035a2-ddf5-11e8-a64b-2ef904c43a0d", GenerateName:"", Namespace:"e2e-tests-pods-vz6zm", SelfLink:"/api/v1/namespaces/e2e-tests-pods-vz6zm/pods/pod-submit-remove-0a9035a2-ddf5-11e8-a64b-2ef904c43a0d", UID:"0a94f005-ddf5-11e8-a94b-0a580af40661", ResourceVersion:"14012", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63676687314, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"874930817"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jd45v", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421bb3180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jd45v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421ec3528), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4214b2fc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421ec3560)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421ec3580)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421ec3588), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687314, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687317, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687317, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63676687314, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.10", PodIP:"172.25.1.94", StartTime:(*v1.Time)(0xc4211a7ba0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4211a7be0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:8976218be775f4244df2a60a169d44606b6978bac4375192074cefc0c7824ddf", ContainerID:"docker://84675e083e8fffeed1d40c42f4585dd670aac69c4d41b50cd2a8520f2af57296"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  1 16:42:04.109: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:42:04.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vz6zm" for this suite.
Nov  1 16:42:10.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:42:10.508: INFO: namespace: e2e-tests-pods-vz6zm, resource: bindings, ignored listing per whitelist
Nov  1 16:42:10.566: INFO: namespace e2e-tests-pods-vz6zm deletion completed in 6.427285382s

• [SLOW TEST:15.898 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:42:10.566: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-14061b52-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating secret with name s-test-opt-upd-14061d7e-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-14061b52-ddf5-11e8-a64b-2ef904c43a0d
STEP: Updating secret s-test-opt-upd-14061d7e-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating secret with name s-test-opt-create-14061db4-ddf5-11e8-a64b-2ef904c43a0d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:43:39.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x6jkq" for this suite.
Nov  1 16:44:03.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:44:03.527: INFO: namespace: e2e-tests-projected-x6jkq, resource: bindings, ignored listing per whitelist
Nov  1 16:44:03.572: INFO: namespace e2e-tests-projected-x6jkq deletion completed in 24.514816287s

• [SLOW TEST:113.007 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:44:03.578: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  1 16:44:03.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-dfbmk'
Nov  1 16:44:05.974: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  1 16:44:05.974: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Nov  1 16:44:07.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-dfbmk'
Nov  1 16:44:08.201: INFO: stderr: ""
Nov  1 16:44:08.201: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:44:08.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dfbmk" for this suite.
Nov  1 16:44:32.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:44:32.315: INFO: namespace: e2e-tests-kubectl-dfbmk, resource: bindings, ignored listing per whitelist
Nov  1 16:44:32.848: INFO: namespace e2e-tests-kubectl-dfbmk deletion completed in 24.637329724s

• [SLOW TEST:29.271 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:44:32.855: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-68e26989-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating secret with name secret-projected-all-test-volume-68e2697a-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  1 16:44:33.175: INFO: Waiting up to 5m0s for pod "projected-volume-68e2693e-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-s7tsg" to be "success or failure"
Nov  1 16:44:33.181: INFO: Pod "projected-volume-68e2693e-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.79961ms
Nov  1 16:44:35.199: INFO: Pod "projected-volume-68e2693e-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023249279s
Nov  1 16:44:37.205: INFO: Pod "projected-volume-68e2693e-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029185266s
STEP: Saw pod success
Nov  1 16:44:37.205: INFO: Pod "projected-volume-68e2693e-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:44:37.211: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod projected-volume-68e2693e-ddf5-11e8-a64b-2ef904c43a0d container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  1 16:44:37.338: INFO: Waiting for pod projected-volume-68e2693e-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:44:37.345: INFO: Pod projected-volume-68e2693e-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:44:37.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s7tsg" for this suite.
Nov  1 16:44:45.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:44:45.976: INFO: namespace: e2e-tests-projected-s7tsg, resource: bindings, ignored listing per whitelist
Nov  1 16:44:46.106: INFO: namespace e2e-tests-projected-s7tsg deletion completed in 8.75160984s

• [SLOW TEST:13.252 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:44:46.113: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-70d0bfaf-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 16:44:46.488: INFO: Waiting up to 5m0s for pod "pod-secrets-70d69ca1-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-bv79g" to be "success or failure"
Nov  1 16:44:46.500: INFO: Pod "pod-secrets-70d69ca1-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.368661ms
Nov  1 16:44:48.510: INFO: Pod "pod-secrets-70d69ca1-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021747635s
Nov  1 16:44:50.525: INFO: Pod "pod-secrets-70d69ca1-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037285643s
STEP: Saw pod success
Nov  1 16:44:50.526: INFO: Pod "pod-secrets-70d69ca1-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:44:50.530: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-secrets-70d69ca1-ddf5-11e8-a64b-2ef904c43a0d container secret-volume-test: <nil>
STEP: delete the pod
Nov  1 16:44:50.618: INFO: Waiting for pod pod-secrets-70d69ca1-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:44:50.623: INFO: Pod pod-secrets-70d69ca1-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:44:50.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bv79g" for this suite.
Nov  1 16:44:56.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:44:57.006: INFO: namespace: e2e-tests-secrets-bv79g, resource: bindings, ignored listing per whitelist
Nov  1 16:44:57.042: INFO: namespace e2e-tests-secrets-bv79g deletion completed in 6.395737398s

• [SLOW TEST:10.929 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:44:57.043: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  1 16:44:57.271: INFO: Waiting up to 5m0s for pod "pod-774460e7-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-lcjvd" to be "success or failure"
Nov  1 16:44:57.280: INFO: Pod "pod-774460e7-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.960719ms
Nov  1 16:44:59.290: INFO: Pod "pod-774460e7-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018755998s
STEP: Saw pod success
Nov  1 16:44:59.290: INFO: Pod "pod-774460e7-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:44:59.295: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-774460e7-ddf5-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:44:59.410: INFO: Waiting for pod pod-774460e7-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:44:59.419: INFO: Pod pod-774460e7-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:44:59.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lcjvd" for this suite.
Nov  1 16:45:05.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:45:06.162: INFO: namespace: e2e-tests-emptydir-lcjvd, resource: bindings, ignored listing per whitelist
Nov  1 16:45:06.181: INFO: namespace e2e-tests-emptydir-lcjvd deletion completed in 6.737870382s

• [SLOW TEST:9.138 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:45:06.184: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:45:06.375: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7cb0f2ce-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-4825s" to be "success or failure"
Nov  1 16:45:06.380: INFO: Pod "downwardapi-volume-7cb0f2ce-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.434899ms
Nov  1 16:45:08.397: INFO: Pod "downwardapi-volume-7cb0f2ce-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021929356s
Nov  1 16:45:10.405: INFO: Pod "downwardapi-volume-7cb0f2ce-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030267664s
STEP: Saw pod success
Nov  1 16:45:10.405: INFO: Pod "downwardapi-volume-7cb0f2ce-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:45:10.503: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-7cb0f2ce-ddf5-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:45:10.644: INFO: Waiting for pod downwardapi-volume-7cb0f2ce-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:45:10.651: INFO: Pod downwardapi-volume-7cb0f2ce-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:45:10.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4825s" for this suite.
Nov  1 16:45:18.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:45:19.235: INFO: namespace: e2e-tests-projected-4825s, resource: bindings, ignored listing per whitelist
Nov  1 16:45:19.397: INFO: namespace e2e-tests-projected-4825s deletion completed in 8.739563748s

• [SLOW TEST:13.214 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:45:19.401: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:45:19.942: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-rxt4f" to be "success or failure"
Nov  1 16:45:19.953: INFO: Pod "downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.296747ms
Nov  1 16:45:21.964: INFO: Pod "downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022265931s
Nov  1 16:45:23.978: INFO: Pod "downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036123693s
Nov  1 16:45:25.991: INFO: Pod "downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.049831983s
STEP: Saw pod success
Nov  1 16:45:25.992: INFO: Pod "downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:45:25.997: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:45:26.110: INFO: Waiting for pod downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:45:26.145: INFO: Pod downwardapi-volume-84b634cd-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:45:26.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rxt4f" for this suite.
Nov  1 16:45:32.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:45:32.256: INFO: namespace: e2e-tests-downward-api-rxt4f, resource: bindings, ignored listing per whitelist
Nov  1 16:45:32.616: INFO: namespace e2e-tests-downward-api-rxt4f deletion completed in 6.457907503s

• [SLOW TEST:13.215 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:45:32.620: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  1 16:45:32.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-6r25q'
Nov  1 16:45:32.995: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  1 16:45:32.995: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Nov  1 16:45:37.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-6r25q'
Nov  1 16:45:37.312: INFO: stderr: ""
Nov  1 16:45:37.312: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:45:37.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6r25q" for this suite.
Nov  1 16:45:43.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:45:43.715: INFO: namespace: e2e-tests-kubectl-6r25q, resource: bindings, ignored listing per whitelist
Nov  1 16:45:43.846: INFO: namespace e2e-tests-kubectl-6r25q deletion completed in 6.511609792s

• [SLOW TEST:11.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:45:43.853: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  1 16:45:44.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-vbp8x'
Nov  1 16:45:44.311: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  1 16:45:44.311: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Nov  1 16:45:44.330: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-v8kgj]
Nov  1 16:45:44.330: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-v8kgj" in namespace "e2e-tests-kubectl-vbp8x" to be "running and ready"
Nov  1 16:45:44.345: INFO: Pod "e2e-test-nginx-rc-v8kgj": Phase="Pending", Reason="", readiness=false. Elapsed: 15.636194ms
Nov  1 16:45:46.404: INFO: Pod "e2e-test-nginx-rc-v8kgj": Phase="Running", Reason="", readiness=true. Elapsed: 2.07404882s
Nov  1 16:45:46.404: INFO: Pod "e2e-test-nginx-rc-v8kgj" satisfied condition "running and ready"
Nov  1 16:45:46.404: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-v8kgj]
Nov  1 16:45:46.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vbp8x'
Nov  1 16:45:46.629: INFO: stderr: ""
Nov  1 16:45:46.629: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Nov  1 16:45:46.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vbp8x'
Nov  1 16:45:46.782: INFO: stderr: ""
Nov  1 16:45:46.782: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:45:46.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vbp8x" for this suite.
Nov  1 16:45:52.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:45:53.015: INFO: namespace: e2e-tests-kubectl-vbp8x, resource: bindings, ignored listing per whitelist
Nov  1 16:45:53.345: INFO: namespace e2e-tests-kubectl-vbp8x deletion completed in 6.549419387s

• [SLOW TEST:9.493 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:45:53.347: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-52v56/secret-test-98d629c4-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 16:45:53.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-98d83ef2-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-52v56" to be "success or failure"
Nov  1 16:45:53.639: INFO: Pod "pod-configmaps-98d83ef2-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.429786ms
Nov  1 16:45:55.650: INFO: Pod "pod-configmaps-98d83ef2-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030515518s
Nov  1 16:45:57.686: INFO: Pod "pod-configmaps-98d83ef2-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066272335s
STEP: Saw pod success
Nov  1 16:45:57.686: INFO: Pod "pod-configmaps-98d83ef2-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:45:57.692: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-configmaps-98d83ef2-ddf5-11e8-a64b-2ef904c43a0d container env-test: <nil>
STEP: delete the pod
Nov  1 16:45:57.780: INFO: Waiting for pod pod-configmaps-98d83ef2-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:45:57.785: INFO: Pod pod-configmaps-98d83ef2-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:45:57.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-52v56" for this suite.
Nov  1 16:46:03.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:46:04.092: INFO: namespace: e2e-tests-secrets-52v56, resource: bindings, ignored listing per whitelist
Nov  1 16:46:04.231: INFO: namespace e2e-tests-secrets-52v56 deletion completed in 6.438127311s

• [SLOW TEST:10.884 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:46:04.239: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Nov  1 16:46:04.462: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-tvz5f" to be "success or failure"
Nov  1 16:46:04.469: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 7.22495ms
Nov  1 16:46:06.489: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027266344s
Nov  1 16:46:08.516: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054210143s
STEP: Saw pod success
Nov  1 16:46:08.517: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  1 16:46:08.530: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  1 16:46:08.756: INFO: Waiting for pod pod-host-path-test to disappear
Nov  1 16:46:08.761: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:46:08.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-tvz5f" for this suite.
Nov  1 16:46:16.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:46:17.178: INFO: namespace: e2e-tests-hostpath-tvz5f, resource: bindings, ignored listing per whitelist
Nov  1 16:46:17.236: INFO: namespace e2e-tests-hostpath-tvz5f deletion completed in 8.467647794s

• [SLOW TEST:12.998 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:46:17.238: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:46:17.576: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a71e0c89-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-sc6qn" to be "success or failure"
Nov  1 16:46:17.585: INFO: Pod "downwardapi-volume-a71e0c89-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.934614ms
Nov  1 16:46:19.602: INFO: Pod "downwardapi-volume-a71e0c89-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025621589s
Nov  1 16:46:21.619: INFO: Pod "downwardapi-volume-a71e0c89-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042233478s
STEP: Saw pod success
Nov  1 16:46:21.619: INFO: Pod "downwardapi-volume-a71e0c89-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:46:21.630: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-a71e0c89-ddf5-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:46:21.740: INFO: Waiting for pod downwardapi-volume-a71e0c89-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:46:21.747: INFO: Pod downwardapi-volume-a71e0c89-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:46:21.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sc6qn" for this suite.
Nov  1 16:46:29.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:46:29.904: INFO: namespace: e2e-tests-projected-sc6qn, resource: bindings, ignored listing per whitelist
Nov  1 16:46:30.286: INFO: namespace e2e-tests-projected-sc6qn deletion completed in 8.525866566s

• [SLOW TEST:13.049 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:46:30.288: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  1 16:46:30.526: INFO: Waiting up to 5m0s for pod "pod-aed94a02-ddf5-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-mhr9k" to be "success or failure"
Nov  1 16:46:30.532: INFO: Pod "pod-aed94a02-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.661513ms
Nov  1 16:46:32.539: INFO: Pod "pod-aed94a02-ddf5-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012350111s
Nov  1 16:46:34.551: INFO: Pod "pod-aed94a02-ddf5-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02494026s
STEP: Saw pod success
Nov  1 16:46:34.551: INFO: Pod "pod-aed94a02-ddf5-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:46:34.605: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-aed94a02-ddf5-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:46:34.719: INFO: Waiting for pod pod-aed94a02-ddf5-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:46:34.723: INFO: Pod pod-aed94a02-ddf5-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:46:34.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mhr9k" for this suite.
Nov  1 16:46:41.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:46:41.799: INFO: namespace: e2e-tests-emptydir-mhr9k, resource: bindings, ignored listing per whitelist
Nov  1 16:46:41.859: INFO: namespace e2e-tests-emptydir-mhr9k deletion completed in 7.085698142s

• [SLOW TEST:11.571 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:46:41.863: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bch46
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bch46
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bch46
Nov  1 16:46:42.223: INFO: Found 0 stateful pods, waiting for 1
Nov  1 16:46:52.282: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  1 16:46:52.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-bch46 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:46:52.900: INFO: stderr: ""
Nov  1 16:46:52.900: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:46:52.900: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:46:52.907: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  1 16:47:02.925: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  1 16:47:02.925: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 16:47:03.006: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998995s
Nov  1 16:47:04.026: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.954334899s
Nov  1 16:47:05.040: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.935225004s
Nov  1 16:47:06.053: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.920977577s
Nov  1 16:47:07.064: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.906860418s
Nov  1 16:47:08.072: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.896422475s
Nov  1 16:47:09.078: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.889148569s
Nov  1 16:47:10.089: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.882697806s
Nov  1 16:47:11.096: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.872131925s
Nov  1 16:47:12.109: INFO: Verifying statefulset ss doesn't scale past 1 for another 864.321397ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bch46
Nov  1 16:47:13.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-bch46 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:47:13.847: INFO: stderr: ""
Nov  1 16:47:13.847: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:47:13.847: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:47:13.859: INFO: Found 1 stateful pods, waiting for 3
Nov  1 16:47:23.888: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 16:47:23.888: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 16:47:23.888: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  1 16:47:23.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-bch46 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:47:24.591: INFO: stderr: ""
Nov  1 16:47:24.591: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:47:24.591: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:47:24.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-bch46 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:47:25.202: INFO: stderr: ""
Nov  1 16:47:25.202: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:47:25.202: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:47:25.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-bch46 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  1 16:47:26.040: INFO: stderr: ""
Nov  1 16:47:26.040: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  1 16:47:26.040: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  1 16:47:26.040: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 16:47:26.053: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  1 16:47:36.086: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  1 16:47:36.086: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  1 16:47:36.086: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  1 16:47:36.119: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999939s
Nov  1 16:47:37.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990840447s
Nov  1 16:47:38.140: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978903353s
Nov  1 16:47:39.149: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.970639074s
Nov  1 16:47:40.157: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.96154113s
Nov  1 16:47:41.173: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.952960718s
Nov  1 16:47:42.186: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.937690639s
Nov  1 16:47:43.195: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.924492465s
Nov  1 16:47:44.205: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.915377824s
Nov  1 16:47:45.216: INFO: Verifying statefulset ss doesn't scale past 3 for another 905.606058ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bch46
Nov  1 16:47:46.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-bch46 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:47:46.834: INFO: stderr: ""
Nov  1 16:47:46.834: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:47:46.837: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:47:46.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-bch46 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:47:47.541: INFO: stderr: ""
Nov  1 16:47:47.541: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:47:47.541: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:47:47.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 exec --namespace=e2e-tests-statefulset-bch46 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  1 16:47:48.174: INFO: stderr: ""
Nov  1 16:47:48.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  1 16:47:48.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  1 16:47:48.174: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  1 16:48:08.212: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bch46
Nov  1 16:48:08.231: INFO: Scaling statefulset ss to 0
Nov  1 16:48:08.252: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 16:48:08.258: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:48:08.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bch46" for this suite.
Nov  1 16:48:16.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:48:16.590: INFO: namespace: e2e-tests-statefulset-bch46, resource: bindings, ignored listing per whitelist
Nov  1 16:48:16.759: INFO: namespace e2e-tests-statefulset-bch46 deletion completed in 8.463562054s

• [SLOW TEST:94.897 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:48:16.763: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-ee5b1aa3-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:48:21.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p672p" for this suite.
Nov  1 16:48:45.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:48:45.484: INFO: namespace: e2e-tests-configmap-p672p, resource: bindings, ignored listing per whitelist
Nov  1 16:48:45.790: INFO: namespace e2e-tests-configmap-p672p deletion completed in 24.527576223s

• [SLOW TEST:29.028 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:48:45.795: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ffa663a4-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating configMap with name cm-test-opt-upd-ffa665af-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ffa663a4-ddf5-11e8-a64b-2ef904c43a0d
STEP: Updating configmap cm-test-opt-upd-ffa665af-ddf5-11e8-a64b-2ef904c43a0d
STEP: Creating configMap with name cm-test-opt-create-ffa665e2-ddf5-11e8-a64b-2ef904c43a0d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:50:01.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6sp2j" for this suite.
Nov  1 16:50:25.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:50:26.223: INFO: namespace: e2e-tests-configmap-6sp2j, resource: bindings, ignored listing per whitelist
Nov  1 16:50:26.231: INFO: namespace e2e-tests-configmap-6sp2j deletion completed in 24.553948696s

• [SLOW TEST:100.437 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:50:26.232: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  1 16:50:26.468: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:50:29.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xtcfh" for this suite.
Nov  1 16:50:35.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:50:36.118: INFO: namespace: e2e-tests-init-container-xtcfh, resource: bindings, ignored listing per whitelist
Nov  1 16:50:36.226: INFO: namespace e2e-tests-init-container-xtcfh deletion completed in 6.642286434s

• [SLOW TEST:9.995 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:50:36.231: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Nov  1 16:50:36.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 --namespace=e2e-tests-kubectl-54xgl run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  1 16:50:39.736: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  1 16:50:39.736: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:50:41.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-54xgl" for this suite.
Nov  1 16:50:47.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:50:47.842: INFO: namespace: e2e-tests-kubectl-54xgl, resource: bindings, ignored listing per whitelist
Nov  1 16:50:48.231: INFO: namespace e2e-tests-kubectl-54xgl deletion completed in 6.46555938s

• [SLOW TEST:12.001 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:50:48.239: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  1 16:50:48.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-bscp7'
Nov  1 16:50:48.788: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  1 16:50:48.788: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Nov  1 16:50:48.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-bscp7'
Nov  1 16:50:49.271: INFO: stderr: ""
Nov  1 16:50:49.271: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:50:49.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bscp7" for this suite.
Nov  1 16:50:55.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:50:55.630: INFO: namespace: e2e-tests-kubectl-bscp7, resource: bindings, ignored listing per whitelist
Nov  1 16:50:55.878: INFO: namespace e2e-tests-kubectl-bscp7 deletion completed in 6.60000592s

• [SLOW TEST:7.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:50:55.886: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4d481847-ddf6-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:50:56.365: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4d4b92f2-ddf6-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-pwfsv" to be "success or failure"
Nov  1 16:50:56.572: INFO: Pod "pod-projected-configmaps-4d4b92f2-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 206.494391ms
Nov  1 16:50:58.647: INFO: Pod "pod-projected-configmaps-4d4b92f2-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.281783942s
Nov  1 16:51:00.665: INFO: Pod "pod-projected-configmaps-4d4b92f2-ddf6-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.299192832s
STEP: Saw pod success
Nov  1 16:51:00.665: INFO: Pod "pod-projected-configmaps-4d4b92f2-ddf6-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:51:00.687: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-configmaps-4d4b92f2-ddf6-11e8-a64b-2ef904c43a0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 16:51:00.778: INFO: Waiting for pod pod-projected-configmaps-4d4b92f2-ddf6-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:51:00.786: INFO: Pod pod-projected-configmaps-4d4b92f2-ddf6-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:51:00.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pwfsv" for this suite.
Nov  1 16:51:08.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:51:09.217: INFO: namespace: e2e-tests-projected-pwfsv, resource: bindings, ignored listing per whitelist
Nov  1 16:51:09.339: INFO: namespace e2e-tests-projected-pwfsv deletion completed in 8.542912116s

• [SLOW TEST:13.454 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:51:09.344: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-7nh2
STEP: Creating a pod to test atomic-volume-subpath
Nov  1 16:51:09.678: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-7nh2" in namespace "e2e-tests-subpath-ms9z8" to be "success or failure"
Nov  1 16:51:09.683: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.962654ms
Nov  1 16:51:11.707: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029311116s
Nov  1 16:51:13.728: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 4.050758873s
Nov  1 16:51:15.738: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 6.060476218s
Nov  1 16:51:17.745: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 8.066972306s
Nov  1 16:51:19.757: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 10.078851178s
Nov  1 16:51:21.765: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 12.08712532s
Nov  1 16:51:23.782: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 14.104007466s
Nov  1 16:51:25.789: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 16.111121862s
Nov  1 16:51:27.799: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 18.120848299s
Nov  1 16:51:29.807: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 20.129302855s
Nov  1 16:51:31.821: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Running", Reason="", readiness=false. Elapsed: 22.142998271s
Nov  1 16:51:33.913: INFO: Pod "pod-subpath-test-secret-7nh2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.235797208s
STEP: Saw pod success
Nov  1 16:51:33.914: INFO: Pod "pod-subpath-test-secret-7nh2" satisfied condition "success or failure"
Nov  1 16:51:33.921: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-subpath-test-secret-7nh2 container test-container-subpath-secret-7nh2: <nil>
STEP: delete the pod
Nov  1 16:51:34.045: INFO: Waiting for pod pod-subpath-test-secret-7nh2 to disappear
Nov  1 16:51:34.098: INFO: Pod pod-subpath-test-secret-7nh2 no longer exists
STEP: Deleting pod pod-subpath-test-secret-7nh2
Nov  1 16:51:34.099: INFO: Deleting pod "pod-subpath-test-secret-7nh2" in namespace "e2e-tests-subpath-ms9z8"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:51:34.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ms9z8" for this suite.
Nov  1 16:51:40.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:51:40.503: INFO: namespace: e2e-tests-subpath-ms9z8, resource: bindings, ignored listing per whitelist
Nov  1 16:51:41.610: INFO: namespace e2e-tests-subpath-ms9z8 deletion completed in 7.499911498s

• [SLOW TEST:32.268 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:51:41.620: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  1 16:51:42.023: INFO: Waiting up to 5m0s for pod "downward-api-68842033-ddf6-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-q5ccf" to be "success or failure"
Nov  1 16:51:42.031: INFO: Pod "downward-api-68842033-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.12679ms
Nov  1 16:51:44.049: INFO: Pod "downward-api-68842033-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024992828s
Nov  1 16:51:46.114: INFO: Pod "downward-api-68842033-ddf6-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.089875729s
STEP: Saw pod success
Nov  1 16:51:46.114: INFO: Pod "downward-api-68842033-ddf6-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:51:46.120: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downward-api-68842033-ddf6-11e8-a64b-2ef904c43a0d container dapi-container: <nil>
STEP: delete the pod
Nov  1 16:51:46.271: INFO: Waiting for pod downward-api-68842033-ddf6-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:51:46.276: INFO: Pod downward-api-68842033-ddf6-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:51:46.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q5ccf" for this suite.
Nov  1 16:51:52.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:51:52.478: INFO: namespace: e2e-tests-downward-api-q5ccf, resource: bindings, ignored listing per whitelist
Nov  1 16:51:52.708: INFO: namespace e2e-tests-downward-api-q5ccf deletion completed in 6.424096851s

• [SLOW TEST:11.089 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:51:52.710: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  1 16:51:52.959: INFO: Waiting up to 5m0s for pod "pod-6f073130-ddf6-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-2fdsl" to be "success or failure"
Nov  1 16:51:52.967: INFO: Pod "pod-6f073130-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.96462ms
Nov  1 16:51:54.988: INFO: Pod "pod-6f073130-ddf6-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028817868s
STEP: Saw pod success
Nov  1 16:51:54.988: INFO: Pod "pod-6f073130-ddf6-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:51:54.993: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-6f073130-ddf6-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 16:51:55.068: INFO: Waiting for pod pod-6f073130-ddf6-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:51:55.075: INFO: Pod pod-6f073130-ddf6-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:51:55.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2fdsl" for this suite.
Nov  1 16:52:01.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:52:01.413: INFO: namespace: e2e-tests-emptydir-2fdsl, resource: bindings, ignored listing per whitelist
Nov  1 16:52:01.519: INFO: namespace e2e-tests-emptydir-2fdsl deletion completed in 6.428574986s

• [SLOW TEST:8.810 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:52:01.522: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  1 16:52:07.822: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:07.827: INFO: Pod pod-with-prestop-http-hook still exists
Nov  1 16:52:09.830: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:09.840: INFO: Pod pod-with-prestop-http-hook still exists
Nov  1 16:52:11.827: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:11.835: INFO: Pod pod-with-prestop-http-hook still exists
Nov  1 16:52:13.828: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:13.837: INFO: Pod pod-with-prestop-http-hook still exists
Nov  1 16:52:15.828: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:15.844: INFO: Pod pod-with-prestop-http-hook still exists
Nov  1 16:52:17.827: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:17.844: INFO: Pod pod-with-prestop-http-hook still exists
Nov  1 16:52:19.827: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:19.837: INFO: Pod pod-with-prestop-http-hook still exists
Nov  1 16:52:21.827: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:21.842: INFO: Pod pod-with-prestop-http-hook still exists
Nov  1 16:52:23.827: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  1 16:52:23.905: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:52:23.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rppdm" for this suite.
Nov  1 16:52:48.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:52:48.226: INFO: namespace: e2e-tests-container-lifecycle-hook-rppdm, resource: bindings, ignored listing per whitelist
Nov  1 16:52:48.516: INFO: namespace e2e-tests-container-lifecycle-hook-rppdm deletion completed in 24.506832279s

• [SLOW TEST:46.995 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:52:48.518: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-gm55b
Nov  1 16:52:54.778: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-gm55b
STEP: checking the pod's current state and verifying that restartCount is present
Nov  1 16:52:54.783: INFO: Initial restart count of pod liveness-http is 0
Nov  1 16:53:19.122: INFO: Restart count of pod e2e-tests-container-probe-gm55b/liveness-http is now 1 (24.339501043s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:53:19.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gm55b" for this suite.
Nov  1 16:53:25.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:53:25.684: INFO: namespace: e2e-tests-container-probe-gm55b, resource: bindings, ignored listing per whitelist
Nov  1 16:53:25.685: INFO: namespace e2e-tests-container-probe-gm55b deletion completed in 6.470002734s

• [SLOW TEST:37.167 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:53:25.685: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:53:32.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-dchdr" for this suite.
Nov  1 16:53:38.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:53:38.343: INFO: namespace: e2e-tests-namespaces-dchdr, resource: bindings, ignored listing per whitelist
Nov  1 16:53:38.588: INFO: namespace e2e-tests-namespaces-dchdr deletion completed in 6.424421744s
STEP: Destroying namespace "e2e-tests-nsdeletetest-pz55s" for this suite.
Nov  1 16:53:38.595: INFO: Namespace e2e-tests-nsdeletetest-pz55s was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-wl6dg" for this suite.
Nov  1 16:53:44.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:53:44.887: INFO: namespace: e2e-tests-nsdeletetest-wl6dg, resource: bindings, ignored listing per whitelist
Nov  1 16:53:44.993: INFO: namespace e2e-tests-nsdeletetest-wl6dg deletion completed in 6.397719838s

• [SLOW TEST:19.308 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:53:44.999: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 16:53:47.348: INFO: Waiting up to 5m0s for pod "client-envvars-b338c6e2-ddf6-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-pods-4nqzf" to be "success or failure"
Nov  1 16:53:47.362: INFO: Pod "client-envvars-b338c6e2-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.29649ms
Nov  1 16:53:49.368: INFO: Pod "client-envvars-b338c6e2-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019410953s
Nov  1 16:53:51.420: INFO: Pod "client-envvars-b338c6e2-ddf6-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071933538s
STEP: Saw pod success
Nov  1 16:53:51.420: INFO: Pod "client-envvars-b338c6e2-ddf6-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:53:51.426: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod client-envvars-b338c6e2-ddf6-11e8-a64b-2ef904c43a0d container env3cont: <nil>
STEP: delete the pod
Nov  1 16:53:51.575: INFO: Waiting for pod client-envvars-b338c6e2-ddf6-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:53:51.583: INFO: Pod client-envvars-b338c6e2-ddf6-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:53:51.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4nqzf" for this suite.
Nov  1 16:54:33.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:54:34.017: INFO: namespace: e2e-tests-pods-4nqzf, resource: bindings, ignored listing per whitelist
Nov  1 16:54:34.163: INFO: namespace e2e-tests-pods-4nqzf deletion completed in 42.560354094s

• [SLOW TEST:49.165 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:54:34.166: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-cf410396-ddf6-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 16:54:34.405: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cf44579d-ddf6-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-46jh6" to be "success or failure"
Nov  1 16:54:34.416: INFO: Pod "pod-projected-secrets-cf44579d-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.742573ms
Nov  1 16:54:36.493: INFO: Pod "pod-projected-secrets-cf44579d-ddf6-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.088257416s
STEP: Saw pod success
Nov  1 16:54:36.494: INFO: Pod "pod-projected-secrets-cf44579d-ddf6-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:54:36.501: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-secrets-cf44579d-ddf6-11e8-a64b-2ef904c43a0d container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  1 16:54:36.568: INFO: Waiting for pod pod-projected-secrets-cf44579d-ddf6-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:54:36.586: INFO: Pod pod-projected-secrets-cf44579d-ddf6-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:54:36.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-46jh6" for this suite.
Nov  1 16:54:44.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:54:44.743: INFO: namespace: e2e-tests-projected-46jh6, resource: bindings, ignored listing per whitelist
Nov  1 16:54:45.030: INFO: namespace e2e-tests-projected-46jh6 deletion completed in 8.436387238s

• [SLOW TEST:10.864 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:54:45.035: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:54:45.457: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5c8de9c-ddf6-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-gvdk5" to be "success or failure"
Nov  1 16:54:45.468: INFO: Pod "downwardapi-volume-d5c8de9c-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.886434ms
Nov  1 16:54:47.505: INFO: Pod "downwardapi-volume-d5c8de9c-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047759037s
Nov  1 16:54:49.513: INFO: Pod "downwardapi-volume-d5c8de9c-ddf6-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05610619s
STEP: Saw pod success
Nov  1 16:54:49.513: INFO: Pod "downwardapi-volume-d5c8de9c-ddf6-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:54:49.520: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-d5c8de9c-ddf6-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:54:49.735: INFO: Waiting for pod downwardapi-volume-d5c8de9c-ddf6-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:54:49.744: INFO: Pod downwardapi-volume-d5c8de9c-ddf6-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:54:49.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gvdk5" for this suite.
Nov  1 16:54:55.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:54:56.116: INFO: namespace: e2e-tests-projected-gvdk5, resource: bindings, ignored listing per whitelist
Nov  1 16:54:56.261: INFO: namespace e2e-tests-projected-gvdk5 deletion completed in 6.495073536s

• [SLOW TEST:11.228 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:54:56.265: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  1 16:54:56.449: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  1 16:54:56.464: INFO: Waiting for terminating namespaces to be deleted...
Nov  1 16:54:56.472: INFO: 
Logging pods the kubelet thinks is on node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn before test
Nov  1 16:54:56.506: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-01 15:46:48 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.506: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  1 16:54:56.506: INFO: sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kmrb5 from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 16:54:56.506: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Nov  1 16:54:56.506: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  1 16:54:56.506: INFO: restic-jvl9h from heptio-ark started at 2018-11-01 15:45:36 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.507: INFO: 	Container ark ready: true, restart count 0
Nov  1 16:54:56.507: INFO: canal-n7cr4 from kube-system started at 2018-11-01 15:45:36 +0000 UTC (3 container statuses recorded)
Nov  1 16:54:56.507: INFO: 	Container calico-node ready: true, restart count 0
Nov  1 16:54:56.507: INFO: 	Container install-cni ready: true, restart count 0
Nov  1 16:54:56.507: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  1 16:54:56.507: INFO: kube-proxy-75xl8 from kube-system started at 2018-11-01 15:45:36 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.507: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  1 16:54:56.507: INFO: sonobuoy-e2e-job-885a13fbb80f41a2 from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 16:54:56.508: INFO: 	Container e2e ready: true, restart count 0
Nov  1 16:54:56.508: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  1 16:54:56.508: INFO: 
Logging pods the kubelet thinks is on node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo before test
Nov  1 16:54:56.557: INFO: sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kqkwn from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 16:54:56.557: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Nov  1 16:54:56.557: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  1 16:54:56.557: INFO: openvpn-client-765b7d6ccd-zv6hj from kube-system started at 2018-11-01 15:44:13 +0000 UTC (2 container statuses recorded)
Nov  1 16:54:56.557: INFO: 	Container dnat-controller ready: true, restart count 0
Nov  1 16:54:56.558: INFO: 	Container openvpn-client ready: true, restart count 0
Nov  1 16:54:56.558: INFO: restic-jmd9j from heptio-ark started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.558: INFO: 	Container ark ready: true, restart count 0
Nov  1 16:54:56.558: INFO: kube-dns-autoscaler-68447488d7-x9lm8 from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.558: INFO: 	Container autoscaler ready: true, restart count 0
Nov  1 16:54:56.558: INFO: tiller-deploy-6dd86cd8fc-5dqf4 from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.558: INFO: 	Container tiller ready: true, restart count 0
Nov  1 16:54:56.558: INFO: kube-dns-6d7bb85cbd-hb8ww from kube-system started at 2018-11-01 15:44:13 +0000 UTC (3 container statuses recorded)
Nov  1 16:54:56.558: INFO: 	Container dnsmasq ready: true, restart count 0
Nov  1 16:54:56.558: INFO: 	Container kubedns ready: true, restart count 0
Nov  1 16:54:56.558: INFO: 	Container sidecar ready: true, restart count 0
Nov  1 16:54:56.558: INFO: metrics-server-5db78d768c-2n22k from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.559: INFO: 	Container metrics-server ready: true, restart count 0
Nov  1 16:54:56.559: INFO: kube-dns-6d7bb85cbd-fmf54 from kube-system started at 2018-11-01 15:45:41 +0000 UTC (3 container statuses recorded)
Nov  1 16:54:56.559: INFO: 	Container dnsmasq ready: true, restart count 0
Nov  1 16:54:56.559: INFO: 	Container kubedns ready: true, restart count 0
Nov  1 16:54:56.559: INFO: 	Container sidecar ready: true, restart count 0
Nov  1 16:54:56.559: INFO: ark-6d5cb4c7df-rfr5c from heptio-ark started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.559: INFO: 	Container ark ready: true, restart count 2
Nov  1 16:54:56.559: INFO: canal-zw4zc from kube-system started at 2018-11-01 15:44:13 +0000 UTC (3 container statuses recorded)
Nov  1 16:54:56.560: INFO: 	Container calico-node ready: true, restart count 0
Nov  1 16:54:56.560: INFO: 	Container install-cni ready: true, restart count 0
Nov  1 16:54:56.560: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  1 16:54:56.561: INFO: kubernetes-dashboard-55f8478c57-wv65g from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.561: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  1 16:54:56.561: INFO: kube-proxy-v89pd from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:54:56.561: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ddbf4bdc-ddf6-11e8-a64b-2ef904c43a0d 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-ddbf4bdc-ddf6-11e8-a64b-2ef904c43a0d off the node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ddbf4bdc-ddf6-11e8-a64b-2ef904c43a0d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:55:00.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-frx7g" for this suite.
Nov  1 16:55:16.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:55:16.915: INFO: namespace: e2e-tests-sched-pred-frx7g, resource: bindings, ignored listing per whitelist
Nov  1 16:55:17.334: INFO: namespace e2e-tests-sched-pred-frx7g deletion completed in 16.523171249s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:21.070 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:55:17.338: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 16:55:17.544: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8fa5f51-ddf6-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-xnxpx" to be "success or failure"
Nov  1 16:55:17.564: INFO: Pod "downwardapi-volume-e8fa5f51-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.445294ms
Nov  1 16:55:19.616: INFO: Pod "downwardapi-volume-e8fa5f51-ddf6-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071961485s
Nov  1 16:55:21.629: INFO: Pod "downwardapi-volume-e8fa5f51-ddf6-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.084604902s
STEP: Saw pod success
Nov  1 16:55:21.629: INFO: Pod "downwardapi-volume-e8fa5f51-ddf6-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:55:21.641: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-e8fa5f51-ddf6-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 16:55:21.849: INFO: Waiting for pod downwardapi-volume-e8fa5f51-ddf6-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:55:21.880: INFO: Pod downwardapi-volume-e8fa5f51-ddf6-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:55:21.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xnxpx" for this suite.
Nov  1 16:55:30.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:55:30.149: INFO: namespace: e2e-tests-projected-xnxpx, resource: bindings, ignored listing per whitelist
Nov  1 16:55:30.421: INFO: namespace e2e-tests-projected-xnxpx deletion completed in 8.479498566s

• [SLOW TEST:13.084 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:55:30.422: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-gpjg
STEP: Creating a pod to test atomic-volume-subpath
Nov  1 16:55:30.741: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gpjg" in namespace "e2e-tests-subpath-thjn5" to be "success or failure"
Nov  1 16:55:30.747: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Pending", Reason="", readiness=false. Elapsed: 5.846794ms
Nov  1 16:55:32.755: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013884392s
Nov  1 16:55:34.766: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 4.024361235s
Nov  1 16:55:36.797: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 6.055834008s
Nov  1 16:55:38.814: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 8.072292448s
Nov  1 16:55:40.907: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 10.165370566s
Nov  1 16:55:42.915: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 12.173609154s
Nov  1 16:55:44.923: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 14.181592763s
Nov  1 16:55:46.934: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 16.191950122s
Nov  1 16:55:48.942: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 18.200442123s
Nov  1 16:55:51.077: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 20.335879626s
Nov  1 16:55:53.088: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Running", Reason="", readiness=false. Elapsed: 22.34642557s
Nov  1 16:55:55.104: INFO: Pod "pod-subpath-test-configmap-gpjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.362728874s
STEP: Saw pod success
Nov  1 16:55:55.106: INFO: Pod "pod-subpath-test-configmap-gpjg" satisfied condition "success or failure"
Nov  1 16:55:55.115: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-subpath-test-configmap-gpjg container test-container-subpath-configmap-gpjg: <nil>
STEP: delete the pod
Nov  1 16:55:55.196: INFO: Waiting for pod pod-subpath-test-configmap-gpjg to disappear
Nov  1 16:55:55.202: INFO: Pod pod-subpath-test-configmap-gpjg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gpjg
Nov  1 16:55:55.203: INFO: Deleting pod "pod-subpath-test-configmap-gpjg" in namespace "e2e-tests-subpath-thjn5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:55:55.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-thjn5" for this suite.
Nov  1 16:56:01.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:56:01.554: INFO: namespace: e2e-tests-subpath-thjn5, resource: bindings, ignored listing per whitelist
Nov  1 16:56:01.784: INFO: namespace e2e-tests-subpath-thjn5 deletion completed in 6.567861435s

• [SLOW TEST:31.363 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:56:01.787: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  1 16:56:08.338: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:08.353: INFO: Pod pod-with-poststart-http-hook still exists
Nov  1 16:56:10.353: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:10.364: INFO: Pod pod-with-poststart-http-hook still exists
Nov  1 16:56:12.353: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:12.377: INFO: Pod pod-with-poststart-http-hook still exists
Nov  1 16:56:14.359: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:14.366: INFO: Pod pod-with-poststart-http-hook still exists
Nov  1 16:56:16.353: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:16.363: INFO: Pod pod-with-poststart-http-hook still exists
Nov  1 16:56:18.354: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:18.376: INFO: Pod pod-with-poststart-http-hook still exists
Nov  1 16:56:20.353: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:20.407: INFO: Pod pod-with-poststart-http-hook still exists
Nov  1 16:56:22.353: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:22.418: INFO: Pod pod-with-poststart-http-hook still exists
Nov  1 16:56:24.353: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  1 16:56:24.366: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:56:24.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-znb8f" for this suite.
Nov  1 16:56:48.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:56:48.769: INFO: namespace: e2e-tests-container-lifecycle-hook-znb8f, resource: bindings, ignored listing per whitelist
Nov  1 16:56:48.887: INFO: namespace e2e-tests-container-lifecycle-hook-znb8f deletion completed in 24.511673336s

• [SLOW TEST:47.100 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:56:48.888: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1f96340c-ddf7-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 16:56:49.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-1f98025b-ddf7-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-2nk88" to be "success or failure"
Nov  1 16:56:49.191: INFO: Pod "pod-configmaps-1f98025b-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.52251ms
Nov  1 16:56:51.209: INFO: Pod "pod-configmaps-1f98025b-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038120235s
Nov  1 16:56:53.218: INFO: Pod "pod-configmaps-1f98025b-ddf7-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046548627s
STEP: Saw pod success
Nov  1 16:56:53.218: INFO: Pod "pod-configmaps-1f98025b-ddf7-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 16:56:53.227: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-configmaps-1f98025b-ddf7-11e8-a64b-2ef904c43a0d container configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 16:56:53.410: INFO: Waiting for pod pod-configmaps-1f98025b-ddf7-11e8-a64b-2ef904c43a0d to disappear
Nov  1 16:56:53.416: INFO: Pod pod-configmaps-1f98025b-ddf7-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:56:53.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2nk88" for this suite.
Nov  1 16:56:59.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:56:59.512: INFO: namespace: e2e-tests-configmap-2nk88, resource: bindings, ignored listing per whitelist
Nov  1 16:56:59.981: INFO: namespace e2e-tests-configmap-2nk88 deletion completed in 6.557940778s

• [SLOW TEST:11.094 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:56:59.988: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  1 16:57:00.221: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  1 16:57:00.232: INFO: Waiting for terminating namespaces to be deleted...
Nov  1 16:57:00.238: INFO: 
Logging pods the kubelet thinks is on node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn before test
Nov  1 16:57:00.307: INFO: restic-jvl9h from heptio-ark started at 2018-11-01 15:45:36 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.308: INFO: 	Container ark ready: true, restart count 0
Nov  1 16:57:00.308: INFO: canal-n7cr4 from kube-system started at 2018-11-01 15:45:36 +0000 UTC (3 container statuses recorded)
Nov  1 16:57:00.308: INFO: 	Container calico-node ready: true, restart count 0
Nov  1 16:57:00.308: INFO: 	Container install-cni ready: true, restart count 0
Nov  1 16:57:00.308: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  1 16:57:00.309: INFO: kube-proxy-75xl8 from kube-system started at 2018-11-01 15:45:36 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.309: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  1 16:57:00.309: INFO: sonobuoy-e2e-job-885a13fbb80f41a2 from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 16:57:00.309: INFO: 	Container e2e ready: true, restart count 0
Nov  1 16:57:00.310: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  1 16:57:00.310: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-01 15:46:48 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.310: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  1 16:57:00.310: INFO: sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kmrb5 from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 16:57:00.311: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Nov  1 16:57:00.311: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  1 16:57:00.311: INFO: 
Logging pods the kubelet thinks is on node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo before test
Nov  1 16:57:00.345: INFO: kubernetes-dashboard-55f8478c57-wv65g from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.345: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  1 16:57:00.345: INFO: kube-proxy-v89pd from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.345: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  1 16:57:00.345: INFO: sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kqkwn from heptio-sonobuoy started at 2018-11-01 15:46:54 +0000 UTC (2 container statuses recorded)
Nov  1 16:57:00.346: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Nov  1 16:57:00.346: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  1 16:57:00.346: INFO: openvpn-client-765b7d6ccd-zv6hj from kube-system started at 2018-11-01 15:44:13 +0000 UTC (2 container statuses recorded)
Nov  1 16:57:00.346: INFO: 	Container dnat-controller ready: true, restart count 0
Nov  1 16:57:00.346: INFO: 	Container openvpn-client ready: true, restart count 0
Nov  1 16:57:00.346: INFO: restic-jmd9j from heptio-ark started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.346: INFO: 	Container ark ready: true, restart count 0
Nov  1 16:57:00.346: INFO: kube-dns-6d7bb85cbd-hb8ww from kube-system started at 2018-11-01 15:44:13 +0000 UTC (3 container statuses recorded)
Nov  1 16:57:00.347: INFO: 	Container dnsmasq ready: true, restart count 0
Nov  1 16:57:00.347: INFO: 	Container kubedns ready: true, restart count 0
Nov  1 16:57:00.347: INFO: 	Container sidecar ready: true, restart count 0
Nov  1 16:57:00.347: INFO: metrics-server-5db78d768c-2n22k from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.347: INFO: 	Container metrics-server ready: true, restart count 0
Nov  1 16:57:00.347: INFO: kube-dns-6d7bb85cbd-fmf54 from kube-system started at 2018-11-01 15:45:41 +0000 UTC (3 container statuses recorded)
Nov  1 16:57:00.347: INFO: 	Container dnsmasq ready: true, restart count 0
Nov  1 16:57:00.347: INFO: 	Container kubedns ready: true, restart count 0
Nov  1 16:57:00.347: INFO: 	Container sidecar ready: true, restart count 0
Nov  1 16:57:00.347: INFO: kube-dns-autoscaler-68447488d7-x9lm8 from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.347: INFO: 	Container autoscaler ready: true, restart count 0
Nov  1 16:57:00.348: INFO: tiller-deploy-6dd86cd8fc-5dqf4 from kube-system started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.348: INFO: 	Container tiller ready: true, restart count 0
Nov  1 16:57:00.348: INFO: ark-6d5cb4c7df-rfr5c from heptio-ark started at 2018-11-01 15:44:13 +0000 UTC (1 container statuses recorded)
Nov  1 16:57:00.348: INFO: 	Container ark ready: true, restart count 2
Nov  1 16:57:00.348: INFO: canal-zw4zc from kube-system started at 2018-11-01 15:44:13 +0000 UTC (3 container statuses recorded)
Nov  1 16:57:00.348: INFO: 	Container calico-node ready: true, restart count 0
Nov  1 16:57:00.348: INFO: 	Container install-cni ready: true, restart count 0
Nov  1 16:57:00.348: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
STEP: verifying the node has the label node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.443: INFO: Pod ark-6d5cb4c7df-rfr5c requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.443: INFO: Pod restic-jmd9j requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.444: INFO: Pod restic-jvl9h requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
Nov  1 16:57:00.444: INFO: Pod sonobuoy requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
Nov  1 16:57:00.444: INFO: Pod sonobuoy-e2e-job-885a13fbb80f41a2 requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
Nov  1 16:57:00.444: INFO: Pod sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kmrb5 requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
Nov  1 16:57:00.444: INFO: Pod sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kqkwn requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.445: INFO: Pod canal-n7cr4 requesting resource cpu=250m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
Nov  1 16:57:00.445: INFO: Pod canal-zw4zc requesting resource cpu=250m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.445: INFO: Pod kube-dns-6d7bb85cbd-fmf54 requesting resource cpu=260m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.445: INFO: Pod kube-dns-6d7bb85cbd-hb8ww requesting resource cpu=260m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.446: INFO: Pod kube-dns-autoscaler-68447488d7-x9lm8 requesting resource cpu=20m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.446: INFO: Pod kube-proxy-75xl8 requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
Nov  1 16:57:00.446: INFO: Pod kube-proxy-v89pd requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.446: INFO: Pod kubernetes-dashboard-55f8478c57-wv65g requesting resource cpu=50m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.446: INFO: Pod metrics-server-5db78d768c-2n22k requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.447: INFO: Pod openvpn-client-765b7d6ccd-zv6hj requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
Nov  1 16:57:00.447: INFO: Pod tiller-deploy-6dd86cd8fc-5dqf4 requesting resource cpu=0m on Node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2653a4a9-ddf7-11e8-a64b-2ef904c43a0d.15630e7b5da35aa8], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-wt2q5/filler-pod-2653a4a9-ddf7-11e8-a64b-2ef904c43a0d to machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2653a4a9-ddf7-11e8-a64b-2ef904c43a0d.15630e7b9ff324c8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2653a4a9-ddf7-11e8-a64b-2ef904c43a0d.15630e7ba965b02b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2653a4a9-ddf7-11e8-a64b-2ef904c43a0d.15630e7bb65d668f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2657ea57-ddf7-11e8-a64b-2ef904c43a0d.15630e7b5e36f14b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-wt2q5/filler-pod-2657ea57-ddf7-11e8-a64b-2ef904c43a0d to machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2657ea57-ddf7-11e8-a64b-2ef904c43a0d.15630e7ba0c103f4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2657ea57-ddf7-11e8-a64b-2ef904c43a0d.15630e7ba6fcd58f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2657ea57-ddf7-11e8-a64b-2ef904c43a0d.15630e7bb164132f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15630e7c529dbaf0], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:57:05.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wt2q5" for this suite.
Nov  1 16:57:13.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:57:14.381: INFO: namespace: e2e-tests-sched-pred-wt2q5, resource: bindings, ignored listing per whitelist
Nov  1 16:57:14.415: INFO: namespace e2e-tests-sched-pred-wt2q5 deletion completed in 8.613956448s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:14.429 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:57:14.436: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Nov  1 16:57:14.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-svdzc'
Nov  1 16:57:16.241: INFO: stderr: ""
Nov  1 16:57:16.241: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  1 16:57:17.253: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 16:57:17.253: INFO: Found 0 / 1
Nov  1 16:57:18.256: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 16:57:18.256: INFO: Found 1 / 1
Nov  1 16:57:18.256: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  1 16:57:18.264: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 16:57:18.265: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  1 16:57:18.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 patch pod redis-master-vph4d --namespace=e2e-tests-kubectl-svdzc -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  1 16:57:18.510: INFO: stderr: ""
Nov  1 16:57:18.510: INFO: stdout: "pod/redis-master-vph4d patched\n"
STEP: checking annotations
Nov  1 16:57:18.520: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 16:57:18.520: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:57:18.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-svdzc" for this suite.
Nov  1 16:57:42.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:57:42.905: INFO: namespace: e2e-tests-kubectl-svdzc, resource: bindings, ignored listing per whitelist
Nov  1 16:57:43.006: INFO: namespace e2e-tests-kubectl-svdzc deletion completed in 24.476580429s

• [SLOW TEST:28.571 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:57:43.011: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Nov  1 16:57:43.208: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov  1 16:57:43.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:57:43.577: INFO: stderr: ""
Nov  1 16:57:43.577: INFO: stdout: "service/redis-slave created\n"
Nov  1 16:57:43.577: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov  1 16:57:43.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:57:43.935: INFO: stderr: ""
Nov  1 16:57:43.935: INFO: stdout: "service/redis-master created\n"
Nov  1 16:57:43.935: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  1 16:57:43.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:57:44.381: INFO: stderr: ""
Nov  1 16:57:44.381: INFO: stdout: "service/frontend created\n"
Nov  1 16:57:44.381: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov  1 16:57:44.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:57:44.848: INFO: stderr: ""
Nov  1 16:57:44.848: INFO: stdout: "deployment.extensions/frontend created\n"
Nov  1 16:57:44.849: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  1 16:57:44.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:57:45.234: INFO: stderr: ""
Nov  1 16:57:45.234: INFO: stdout: "deployment.extensions/redis-master created\n"
Nov  1 16:57:45.235: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov  1 16:57:45.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:57:45.753: INFO: stderr: ""
Nov  1 16:57:45.753: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Nov  1 16:57:45.753: INFO: Waiting for all frontend pods to be Running.
Nov  1 16:58:42.015: INFO: Waiting for frontend to serve content.
Nov  1 16:58:48.425: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Nov  1 16:59:02.772: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Nov  1 16:59:07.906: INFO: Trying to add a new entry to the guestbook.
Nov  1 16:59:07.961: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov  1 16:59:08.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:59:08.404: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 16:59:08.404: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  1 16:59:08.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:59:08.842: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 16:59:08.842: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  1 16:59:08.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:59:09.102: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 16:59:09.103: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  1 16:59:09.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:59:09.358: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 16:59:09.358: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  1 16:59:09.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:59:09.686: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 16:59:09.686: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  1 16:59:09.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nww9h'
Nov  1 16:59:10.016: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 16:59:10.016: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 16:59:10.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nww9h" for this suite.
Nov  1 16:59:50.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 16:59:50.339: INFO: namespace: e2e-tests-kubectl-nww9h, resource: bindings, ignored listing per whitelist
Nov  1 16:59:50.462: INFO: namespace e2e-tests-kubectl-nww9h deletion completed in 40.426569874s

• [SLOW TEST:127.452 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 16:59:50.465: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-8bda3e42-ddf7-11e8-a64b-2ef904c43a0d
STEP: Creating secret with name s-test-opt-upd-8bda3f36-ddf7-11e8-a64b-2ef904c43a0d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8bda3e42-ddf7-11e8-a64b-2ef904c43a0d
STEP: Updating secret s-test-opt-upd-8bda3f36-ddf7-11e8-a64b-2ef904c43a0d
STEP: Creating secret with name s-test-opt-create-8bda3f61-ddf7-11e8-a64b-2ef904c43a0d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:01:08.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fhksq" for this suite.
Nov  1 17:01:33.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:01:33.224: INFO: namespace: e2e-tests-secrets-fhksq, resource: bindings, ignored listing per whitelist
Nov  1 17:01:33.561: INFO: namespace e2e-tests-secrets-fhksq deletion completed in 24.599478728s

• [SLOW TEST:103.097 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:01:33.565: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c955c90b-ddf7-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:01:34.028: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c95aca31-ddf7-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-4ld9n" to be "success or failure"
Nov  1 17:01:34.073: INFO: Pod "pod-projected-secrets-c95aca31-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 44.063533ms
Nov  1 17:01:36.098: INFO: Pod "pod-projected-secrets-c95aca31-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069584541s
Nov  1 17:01:38.109: INFO: Pod "pod-projected-secrets-c95aca31-ddf7-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.08021407s
STEP: Saw pod success
Nov  1 17:01:38.109: INFO: Pod "pod-projected-secrets-c95aca31-ddf7-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:01:38.115: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-secrets-c95aca31-ddf7-11e8-a64b-2ef904c43a0d container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  1 17:01:38.247: INFO: Waiting for pod pod-projected-secrets-c95aca31-ddf7-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:01:38.297: INFO: Pod pod-projected-secrets-c95aca31-ddf7-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:01:38.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4ld9n" for this suite.
Nov  1 17:01:46.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:01:46.839: INFO: namespace: e2e-tests-projected-4ld9n, resource: bindings, ignored listing per whitelist
Nov  1 17:01:46.930: INFO: namespace e2e-tests-projected-4ld9n deletion completed in 8.621334052s

• [SLOW TEST:13.366 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:01:46.935: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d178a6bd-ddf7-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:01:47.721: INFO: Waiting up to 5m0s for pod "pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-m4spd" to be "success or failure"
Nov  1 17:01:47.797: INFO: Pod "pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 76.086968ms
Nov  1 17:01:49.897: INFO: Pod "pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.175891917s
Nov  1 17:01:51.962: INFO: Pod "pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.24122784s
Nov  1 17:01:53.977: INFO: Pod "pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.255949975s
STEP: Saw pod success
Nov  1 17:01:53.977: INFO: Pod "pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:01:53.982: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d container secret-volume-test: <nil>
STEP: delete the pod
Nov  1 17:01:54.131: INFO: Waiting for pod pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:01:54.162: INFO: Pod pod-secrets-d17f7b8e-ddf7-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:01:54.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m4spd" for this suite.
Nov  1 17:02:00.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:02:00.761: INFO: namespace: e2e-tests-secrets-m4spd, resource: bindings, ignored listing per whitelist
Nov  1 17:02:00.790: INFO: namespace e2e-tests-secrets-m4spd deletion completed in 6.617218629s

• [SLOW TEST:13.855 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:02:00.793: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Nov  1 17:02:01.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 cluster-info'
Nov  1 17:02:01.560: INFO: stderr: ""
Nov  1 17:02:01.560: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.10.10.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.10.10.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.10.10.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:02:01.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-smxvj" for this suite.
Nov  1 17:02:07.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:02:07.786: INFO: namespace: e2e-tests-kubectl-smxvj, resource: bindings, ignored listing per whitelist
Nov  1 17:02:08.099: INFO: namespace e2e-tests-kubectl-smxvj deletion completed in 6.525303783s

• [SLOW TEST:7.307 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:02:08.103: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  1 17:02:08.469: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-fh9j5,SelfLink:/api/v1/namespaces/e2e-tests-watch-fh9j5/configmaps/e2e-watch-test-resource-version,UID:ddd72b82-ddf7-11e8-a94b-0a580af40661,ResourceVersion:18076,Generation:0,CreationTimestamp:2018-11-01 17:02:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  1 17:02:08.469: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-fh9j5,SelfLink:/api/v1/namespaces/e2e-tests-watch-fh9j5/configmaps/e2e-watch-test-resource-version,UID:ddd72b82-ddf7-11e8-a94b-0a580af40661,ResourceVersion:18077,Generation:0,CreationTimestamp:2018-11-01 17:02:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:02:08.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fh9j5" for this suite.
Nov  1 17:02:14.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:02:14.836: INFO: namespace: e2e-tests-watch-fh9j5, resource: bindings, ignored listing per whitelist
Nov  1 17:02:15.053: INFO: namespace e2e-tests-watch-fh9j5 deletion completed in 6.568140415s

• [SLOW TEST:6.951 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:02:15.057: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e21299f9-ddf7-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:02:16.023: INFO: Waiting up to 5m0s for pod "pod-secrets-e26267e1-ddf7-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-z9sc7" to be "success or failure"
Nov  1 17:02:16.038: INFO: Pod "pod-secrets-e26267e1-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.412224ms
Nov  1 17:02:18.128: INFO: Pod "pod-secrets-e26267e1-ddf7-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1049946s
Nov  1 17:02:20.180: INFO: Pod "pod-secrets-e26267e1-ddf7-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.157051647s
STEP: Saw pod success
Nov  1 17:02:20.180: INFO: Pod "pod-secrets-e26267e1-ddf7-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:02:20.261: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-secrets-e26267e1-ddf7-11e8-a64b-2ef904c43a0d container secret-volume-test: <nil>
STEP: delete the pod
Nov  1 17:02:20.344: INFO: Waiting for pod pod-secrets-e26267e1-ddf7-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:02:20.351: INFO: Pod pod-secrets-e26267e1-ddf7-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:02:20.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-z9sc7" for this suite.
Nov  1 17:02:28.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:02:28.796: INFO: namespace: e2e-tests-secrets-z9sc7, resource: bindings, ignored listing per whitelist
Nov  1 17:02:28.924: INFO: namespace e2e-tests-secrets-z9sc7 deletion completed in 8.565468573s
STEP: Destroying namespace "e2e-tests-secret-namespace-jwkp5" for this suite.
Nov  1 17:02:34.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:02:35.120: INFO: namespace: e2e-tests-secret-namespace-jwkp5, resource: bindings, ignored listing per whitelist
Nov  1 17:02:35.716: INFO: namespace e2e-tests-secret-namespace-jwkp5 deletion completed in 6.787142488s

• [SLOW TEST:20.659 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:02:35.718: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ptcf8
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  1 17:02:36.094: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  1 17:03:04.639: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.25.1.125 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ptcf8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:03:04.640: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:03:06.115: INFO: Found all expected endpoints: [netserver-0]
Nov  1 17:03:06.124: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.25.0.116 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ptcf8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:03:06.124: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:03:07.595: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:03:07.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ptcf8" for this suite.
Nov  1 17:03:31.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:03:31.677: INFO: namespace: e2e-tests-pod-network-test-ptcf8, resource: bindings, ignored listing per whitelist
Nov  1 17:03:32.001: INFO: namespace e2e-tests-pod-network-test-ptcf8 deletion completed in 24.395894918s

• [SLOW TEST:56.286 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:03:32.006: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mq8z2
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  1 17:03:32.445: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  1 17:03:58.822: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.25.1.127:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mq8z2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:03:58.822: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:03:59.506: INFO: Found all expected endpoints: [netserver-0]
Nov  1 17:03:59.562: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.25.0.117:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mq8z2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:03:59.563: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:04:00.008: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:04:00.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mq8z2" for this suite.
Nov  1 17:04:24.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:04:24.268: INFO: namespace: e2e-tests-pod-network-test-mq8z2, resource: bindings, ignored listing per whitelist
Nov  1 17:04:24.521: INFO: namespace e2e-tests-pod-network-test-mq8z2 deletion completed in 24.496209873s

• [SLOW TEST:52.515 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:04:24.522: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  1 17:04:33.065: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:33.071: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:35.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:35.096: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:37.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:37.080: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:39.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:39.082: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:41.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:41.090: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:43.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:43.080: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:45.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:45.098: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:47.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:47.086: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:49.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:49.080: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:51.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:51.083: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  1 17:04:53.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  1 17:04:53.095: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:04:53.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-psj7s" for this suite.
Nov  1 17:05:17.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:05:17.488: INFO: namespace: e2e-tests-container-lifecycle-hook-psj7s, resource: bindings, ignored listing per whitelist
Nov  1 17:05:17.720: INFO: namespace e2e-tests-container-lifecycle-hook-psj7s deletion completed in 24.617232131s

• [SLOW TEST:53.198 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:05:17.721: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-r9nsl A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-r9nsl;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-r9nsl A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-r9nsl;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-r9nsl.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-r9nsl.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-r9nsl.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-r9nsl.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-r9nsl.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-r9nsl.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-r9nsl.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-r9nsl.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 188.10.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.10.188_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 188.10.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.10.188_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-r9nsl A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-r9nsl;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-r9nsl A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-r9nsl;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-r9nsl.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-r9nsl.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-r9nsl.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-r9nsl.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-r9nsl.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-r9nsl.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-r9nsl.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-r9nsl.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-r9nsl.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 188.10.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.10.188_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 188.10.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.10.188_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  1 17:05:36.622: INFO: DNS probes using e2e-tests-dns-r9nsl/dns-test-4efdff48-ddf8-11e8-a64b-2ef904c43a0d succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:05:36.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-r9nsl" for this suite.
Nov  1 17:05:43.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:05:43.117: INFO: namespace: e2e-tests-dns-r9nsl, resource: bindings, ignored listing per whitelist
Nov  1 17:05:43.445: INFO: namespace e2e-tests-dns-r9nsl deletion completed in 6.518714842s

• [SLOW TEST:25.728 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:05:43.450: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  1 17:05:52.133: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:05:52.146: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:05:54.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:05:54.158: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:05:56.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:05:56.270: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:05:58.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:05:58.198: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:06:00.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:06:00.158: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:06:02.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:06:02.207: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:06:04.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:06:04.156: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:06:06.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:06:06.155: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:06:08.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:06:08.171: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:06:10.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:06:10.162: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:06:12.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:06:12.153: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  1 17:06:14.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  1 17:06:14.152: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:06:14.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-64qkl" for this suite.
Nov  1 17:06:38.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:06:38.901: INFO: namespace: e2e-tests-container-lifecycle-hook-64qkl, resource: bindings, ignored listing per whitelist
Nov  1 17:06:39.136: INFO: namespace e2e-tests-container-lifecycle-hook-64qkl deletion completed in 24.882051326s

• [SLOW TEST:55.686 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:06:39.137: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Nov  1 17:06:39.529: INFO: Waiting up to 5m0s for pod "client-containers-7f792b16-ddf8-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-containers-nxjmj" to be "success or failure"
Nov  1 17:06:39.593: INFO: Pod "client-containers-7f792b16-ddf8-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 64.526915ms
Nov  1 17:06:41.607: INFO: Pod "client-containers-7f792b16-ddf8-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077808596s
Nov  1 17:06:43.614: INFO: Pod "client-containers-7f792b16-ddf8-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.085501617s
STEP: Saw pod success
Nov  1 17:06:43.615: INFO: Pod "client-containers-7f792b16-ddf8-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:06:43.621: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod client-containers-7f792b16-ddf8-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 17:06:43.797: INFO: Waiting for pod client-containers-7f792b16-ddf8-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:06:43.807: INFO: Pod client-containers-7f792b16-ddf8-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:06:43.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nxjmj" for this suite.
Nov  1 17:06:49.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:06:50.083: INFO: namespace: e2e-tests-containers-nxjmj, resource: bindings, ignored listing per whitelist
Nov  1 17:06:50.322: INFO: namespace e2e-tests-containers-nxjmj deletion completed in 6.494380615s

• [SLOW TEST:11.187 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:06:50.327: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-szgh
STEP: Creating a pod to test atomic-volume-subpath
Nov  1 17:06:50.725: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-szgh" in namespace "e2e-tests-subpath-vvtw2" to be "success or failure"
Nov  1 17:06:50.752: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Pending", Reason="", readiness=false. Elapsed: 26.594563ms
Nov  1 17:06:52.776: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050928563s
Nov  1 17:06:54.801: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 4.075406926s
Nov  1 17:06:56.807: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 6.081940101s
Nov  1 17:06:58.817: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 8.091256963s
Nov  1 17:07:00.824: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 10.098734486s
Nov  1 17:07:02.849: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 12.123826141s
Nov  1 17:07:04.861: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 14.136041054s
Nov  1 17:07:06.870: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 16.144893907s
Nov  1 17:07:08.879: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 18.154070918s
Nov  1 17:07:10.897: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 20.171810053s
Nov  1 17:07:12.911: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Running", Reason="", readiness=false. Elapsed: 22.18562412s
Nov  1 17:07:14.929: INFO: Pod "pod-subpath-test-downwardapi-szgh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.203496276s
STEP: Saw pod success
Nov  1 17:07:14.929: INFO: Pod "pod-subpath-test-downwardapi-szgh" satisfied condition "success or failure"
Nov  1 17:07:14.937: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-subpath-test-downwardapi-szgh container test-container-subpath-downwardapi-szgh: <nil>
STEP: delete the pod
Nov  1 17:07:15.183: INFO: Waiting for pod pod-subpath-test-downwardapi-szgh to disappear
Nov  1 17:07:15.191: INFO: Pod pod-subpath-test-downwardapi-szgh no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-szgh
Nov  1 17:07:15.191: INFO: Deleting pod "pod-subpath-test-downwardapi-szgh" in namespace "e2e-tests-subpath-vvtw2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:07:15.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vvtw2" for this suite.
Nov  1 17:07:21.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:07:21.373: INFO: namespace: e2e-tests-subpath-vvtw2, resource: bindings, ignored listing per whitelist
Nov  1 17:07:21.727: INFO: namespace e2e-tests-subpath-vvtw2 deletion completed in 6.510676022s

• [SLOW TEST:31.401 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:07:21.735: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Nov  1 17:07:31.652: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:07:49.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-ph8zh" for this suite.
Nov  1 17:07:55.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:07:55.549: INFO: namespace: e2e-tests-namespaces-ph8zh, resource: bindings, ignored listing per whitelist
Nov  1 17:07:55.728: INFO: namespace e2e-tests-namespaces-ph8zh deletion completed in 6.435217865s
STEP: Destroying namespace "e2e-tests-nsdeletetest-vhtsv" for this suite.
Nov  1 17:07:55.749: INFO: Namespace e2e-tests-nsdeletetest-vhtsv was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-hn7zb" for this suite.
Nov  1 17:08:01.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:08:02.103: INFO: namespace: e2e-tests-nsdeletetest-hn7zb, resource: bindings, ignored listing per whitelist
Nov  1 17:08:02.254: INFO: namespace e2e-tests-nsdeletetest-hn7zb deletion completed in 6.505220397s

• [SLOW TEST:40.523 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:08:02.260: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b0ec155f-ddf8-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 17:08:02.511: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b0eebf84-ddf8-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-qfvkw" to be "success or failure"
Nov  1 17:08:02.525: INFO: Pod "pod-projected-configmaps-b0eebf84-ddf8-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.344434ms
Nov  1 17:08:04.541: INFO: Pod "pod-projected-configmaps-b0eebf84-ddf8-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028979713s
STEP: Saw pod success
Nov  1 17:08:04.541: INFO: Pod "pod-projected-configmaps-b0eebf84-ddf8-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:08:04.547: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-projected-configmaps-b0eebf84-ddf8-11e8-a64b-2ef904c43a0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 17:08:04.628: INFO: Waiting for pod pod-projected-configmaps-b0eebf84-ddf8-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:08:04.634: INFO: Pod pod-projected-configmaps-b0eebf84-ddf8-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:08:04.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qfvkw" for this suite.
Nov  1 17:08:10.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:08:10.954: INFO: namespace: e2e-tests-projected-qfvkw, resource: bindings, ignored listing per whitelist
Nov  1 17:08:11.059: INFO: namespace e2e-tests-projected-qfvkw deletion completed in 6.417077806s

• [SLOW TEST:8.803 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:08:11.066: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 17:08:11.389: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b6362080-ddf8-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-6nwpb" to be "success or failure"
Nov  1 17:08:11.408: INFO: Pod "downwardapi-volume-b6362080-ddf8-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.130004ms
Nov  1 17:08:13.418: INFO: Pod "downwardapi-volume-b6362080-ddf8-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02850164s
Nov  1 17:08:15.424: INFO: Pod "downwardapi-volume-b6362080-ddf8-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034689059s
STEP: Saw pod success
Nov  1 17:08:15.424: INFO: Pod "downwardapi-volume-b6362080-ddf8-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:08:15.437: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-b6362080-ddf8-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 17:08:15.487: INFO: Waiting for pod downwardapi-volume-b6362080-ddf8-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:08:15.495: INFO: Pod downwardapi-volume-b6362080-ddf8-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:08:15.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6nwpb" for this suite.
Nov  1 17:08:21.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:08:21.766: INFO: namespace: e2e-tests-downward-api-6nwpb, resource: bindings, ignored listing per whitelist
Nov  1 17:08:22.004: INFO: namespace e2e-tests-downward-api-6nwpb deletion completed in 6.502081606s

• [SLOW TEST:10.941 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:08:22.009: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  1 17:08:32.389: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:32.390: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:32.904: INFO: Exec stderr: ""
Nov  1 17:08:32.904: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:32.904: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:33.466: INFO: Exec stderr: ""
Nov  1 17:08:33.466: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:33.466: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:33.839: INFO: Exec stderr: ""
Nov  1 17:08:33.839: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:33.839: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:34.393: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  1 17:08:34.394: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:34.394: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:34.864: INFO: Exec stderr: ""
Nov  1 17:08:34.864: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:34.864: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:35.394: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  1 17:08:35.394: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:35.394: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:35.876: INFO: Exec stderr: ""
Nov  1 17:08:35.876: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:35.876: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:36.378: INFO: Exec stderr: ""
Nov  1 17:08:36.378: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:36.378: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:36.840: INFO: Exec stderr: ""
Nov  1 17:08:36.840: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-f7cf4 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:08:36.840: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:08:37.326: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:08:37.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-f7cf4" for this suite.
Nov  1 17:09:27.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:09:27.757: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-f7cf4, resource: bindings, ignored listing per whitelist
Nov  1 17:09:27.793: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-f7cf4 deletion completed in 50.459681684s

• [SLOW TEST:65.785 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:09:27.795: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e3ef340c-ddf8-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:09:28.112: INFO: Waiting up to 5m0s for pod "pod-secrets-e3f48418-ddf8-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-hxkc9" to be "success or failure"
Nov  1 17:09:28.133: INFO: Pod "pod-secrets-e3f48418-ddf8-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.823087ms
Nov  1 17:09:30.146: INFO: Pod "pod-secrets-e3f48418-ddf8-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03451798s
STEP: Saw pod success
Nov  1 17:09:30.146: INFO: Pod "pod-secrets-e3f48418-ddf8-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:09:30.155: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-secrets-e3f48418-ddf8-11e8-a64b-2ef904c43a0d container secret-env-test: <nil>
STEP: delete the pod
Nov  1 17:09:30.231: INFO: Waiting for pod pod-secrets-e3f48418-ddf8-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:09:30.237: INFO: Pod pod-secrets-e3f48418-ddf8-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:09:30.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hxkc9" for this suite.
Nov  1 17:09:36.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:09:36.450: INFO: namespace: e2e-tests-secrets-hxkc9, resource: bindings, ignored listing per whitelist
Nov  1 17:09:36.684: INFO: namespace e2e-tests-secrets-hxkc9 deletion completed in 6.440518633s

• [SLOW TEST:8.894 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:09:36.688: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  1 17:09:41.460: INFO: Successfully updated pod "labelsupdatee92ed9c3-ddf8-11e8-a64b-2ef904c43a0d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:09:43.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9245l" for this suite.
Nov  1 17:10:07.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:10:07.913: INFO: namespace: e2e-tests-downward-api-9245l, resource: bindings, ignored listing per whitelist
Nov  1 17:10:07.986: INFO: namespace e2e-tests-downward-api-9245l deletion completed in 24.442120866s

• [SLOW TEST:31.298 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:10:07.988: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Nov  1 17:10:08.242: INFO: Waiting up to 5m0s for pod "var-expansion-fbe0750e-ddf8-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-var-expansion-rl8wc" to be "success or failure"
Nov  1 17:10:08.251: INFO: Pod "var-expansion-fbe0750e-ddf8-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.916192ms
Nov  1 17:10:10.299: INFO: Pod "var-expansion-fbe0750e-ddf8-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05669935s
STEP: Saw pod success
Nov  1 17:10:10.299: INFO: Pod "var-expansion-fbe0750e-ddf8-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:10:10.329: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod var-expansion-fbe0750e-ddf8-11e8-a64b-2ef904c43a0d container dapi-container: <nil>
STEP: delete the pod
Nov  1 17:10:10.497: INFO: Waiting for pod var-expansion-fbe0750e-ddf8-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:10:10.520: INFO: Pod var-expansion-fbe0750e-ddf8-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:10:10.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rl8wc" for this suite.
Nov  1 17:10:16.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:10:16.899: INFO: namespace: e2e-tests-var-expansion-rl8wc, resource: bindings, ignored listing per whitelist
Nov  1 17:10:17.080: INFO: namespace e2e-tests-var-expansion-rl8wc deletion completed in 6.542465669s

• [SLOW TEST:9.097 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:10:17.088: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  1 17:10:17.426: INFO: Waiting up to 5m0s for pod "downward-api-015529b6-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-xbzkj" to be "success or failure"
Nov  1 17:10:17.535: INFO: Pod "downward-api-015529b6-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 109.006375ms
Nov  1 17:10:19.542: INFO: Pod "downward-api-015529b6-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.116094574s
STEP: Saw pod success
Nov  1 17:10:19.542: INFO: Pod "downward-api-015529b6-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:10:19.551: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downward-api-015529b6-ddf9-11e8-a64b-2ef904c43a0d container dapi-container: <nil>
STEP: delete the pod
Nov  1 17:10:19.692: INFO: Waiting for pod downward-api-015529b6-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:10:19.698: INFO: Pod downward-api-015529b6-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:10:19.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xbzkj" for this suite.
Nov  1 17:10:25.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:10:25.881: INFO: namespace: e2e-tests-downward-api-xbzkj, resource: bindings, ignored listing per whitelist
Nov  1 17:10:26.115: INFO: namespace e2e-tests-downward-api-xbzkj deletion completed in 6.409901037s

• [SLOW TEST:9.031 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:10:26.124: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  1 17:10:26.292: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:10:30.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-qxf8q" for this suite.
Nov  1 17:10:54.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:10:55.171: INFO: namespace: e2e-tests-init-container-qxf8q, resource: bindings, ignored listing per whitelist
Nov  1 17:10:55.227: INFO: namespace e2e-tests-init-container-qxf8q deletion completed in 24.44423182s

• [SLOW TEST:29.105 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:10:55.232: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  1 17:10:58.207: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1806a51a-ddf9-11e8-a64b-2ef904c43a0d"
Nov  1 17:10:58.212: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1806a51a-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-pods-clkb8" to be "terminated due to deadline exceeded"
Nov  1 17:10:58.222: INFO: Pod "pod-update-activedeadlineseconds-1806a51a-ddf9-11e8-a64b-2ef904c43a0d": Phase="Running", Reason="", readiness=true. Elapsed: 10.3037ms
Nov  1 17:11:00.235: INFO: Pod "pod-update-activedeadlineseconds-1806a51a-ddf9-11e8-a64b-2ef904c43a0d": Phase="Running", Reason="", readiness=true. Elapsed: 2.023601526s
Nov  1 17:11:02.251: INFO: Pod "pod-update-activedeadlineseconds-1806a51a-ddf9-11e8-a64b-2ef904c43a0d": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.039615399s
Nov  1 17:11:02.252: INFO: Pod "pod-update-activedeadlineseconds-1806a51a-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:11:02.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-clkb8" for this suite.
Nov  1 17:11:08.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:11:08.732: INFO: namespace: e2e-tests-pods-clkb8, resource: bindings, ignored listing per whitelist
Nov  1 17:11:08.817: INFO: namespace e2e-tests-pods-clkb8 deletion completed in 6.55451558s

• [SLOW TEST:13.585 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:11:08.817: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  1 17:11:09.127: INFO: Number of nodes with available pods: 0
Nov  1 17:11:09.127: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 17:11:10.143: INFO: Number of nodes with available pods: 0
Nov  1 17:11:10.143: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 17:11:11.151: INFO: Number of nodes with available pods: 2
Nov  1 17:11:11.151: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  1 17:11:11.279: INFO: Number of nodes with available pods: 1
Nov  1 17:11:11.279: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 17:11:12.320: INFO: Number of nodes with available pods: 1
Nov  1 17:11:12.320: INFO: Node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn is running more than one daemon pod
Nov  1 17:11:13.302: INFO: Number of nodes with available pods: 2
Nov  1 17:11:13.302: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-l5xk7, will wait for the garbage collector to delete the pods
Nov  1 17:11:13.389: INFO: Deleting {extensions DaemonSet} daemon-set took: 19.095659ms
Nov  1 17:11:13.489: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.463886ms
Nov  1 17:11:53.310: INFO: Number of nodes with available pods: 0
Nov  1 17:11:53.310: INFO: Number of running nodes: 0, number of available pods: 0
Nov  1 17:11:53.329: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-l5xk7/daemonsets","resourceVersion":"19967"},"items":null}

Nov  1 17:11:53.333: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-l5xk7/pods","resourceVersion":"19967"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:11:53.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-l5xk7" for this suite.
Nov  1 17:11:59.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:11:59.818: INFO: namespace: e2e-tests-daemonsets-l5xk7, resource: bindings, ignored listing per whitelist
Nov  1 17:11:59.871: INFO: namespace e2e-tests-daemonsets-l5xk7 deletion completed in 6.496742548s

• [SLOW TEST:51.056 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:11:59.876: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  1 17:12:00.146: INFO: Waiting up to 5m0s for pod "pod-3e92eda4-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-kh2b4" to be "success or failure"
Nov  1 17:12:00.166: INFO: Pod "pod-3e92eda4-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.043861ms
Nov  1 17:12:02.181: INFO: Pod "pod-3e92eda4-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035031585s
STEP: Saw pod success
Nov  1 17:12:02.181: INFO: Pod "pod-3e92eda4-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:12:02.195: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-3e92eda4-ddf9-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 17:12:02.243: INFO: Waiting for pod pod-3e92eda4-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:12:02.265: INFO: Pod pod-3e92eda4-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:12:02.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kh2b4" for this suite.
Nov  1 17:12:08.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:12:08.620: INFO: namespace: e2e-tests-emptydir-kh2b4, resource: bindings, ignored listing per whitelist
Nov  1 17:12:08.777: INFO: namespace e2e-tests-emptydir-kh2b4 deletion completed in 6.502092508s

• [SLOW TEST:8.908 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:12:08.782: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 17:12:09.055: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43e226f4-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-7zwxp" to be "success or failure"
Nov  1 17:12:09.067: INFO: Pod "downwardapi-volume-43e226f4-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.454194ms
Nov  1 17:12:11.077: INFO: Pod "downwardapi-volume-43e226f4-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022559095s
Nov  1 17:12:13.086: INFO: Pod "downwardapi-volume-43e226f4-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030878257s
STEP: Saw pod success
Nov  1 17:12:13.086: INFO: Pod "downwardapi-volume-43e226f4-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:12:13.093: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-43e226f4-ddf9-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 17:12:13.173: INFO: Waiting for pod downwardapi-volume-43e226f4-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:12:13.181: INFO: Pod downwardapi-volume-43e226f4-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:12:13.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7zwxp" for this suite.
Nov  1 17:12:19.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:12:19.514: INFO: namespace: e2e-tests-projected-7zwxp, resource: bindings, ignored listing per whitelist
Nov  1 17:12:19.617: INFO: namespace e2e-tests-projected-7zwxp deletion completed in 6.427673699s

• [SLOW TEST:10.838 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:12:19.624: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4a5c1d9d-ddf9-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 17:12:19.932: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a5e31bd-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-c5nvz" to be "success or failure"
Nov  1 17:12:19.953: INFO: Pod "pod-configmaps-4a5e31bd-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 21.095047ms
Nov  1 17:12:21.961: INFO: Pod "pod-configmaps-4a5e31bd-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028709028s
STEP: Saw pod success
Nov  1 17:12:21.961: INFO: Pod "pod-configmaps-4a5e31bd-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:12:21.967: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-configmaps-4a5e31bd-ddf9-11e8-a64b-2ef904c43a0d container configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 17:12:22.049: INFO: Waiting for pod pod-configmaps-4a5e31bd-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:12:22.059: INFO: Pod pod-configmaps-4a5e31bd-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:12:22.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c5nvz" for this suite.
Nov  1 17:12:28.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:12:28.368: INFO: namespace: e2e-tests-configmap-c5nvz, resource: bindings, ignored listing per whitelist
Nov  1 17:12:28.600: INFO: namespace e2e-tests-configmap-c5nvz deletion completed in 6.504428474s

• [SLOW TEST:8.980 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:12:28.606: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Nov  1 17:12:28.801: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-994938124 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:12:28.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8ps2r" for this suite.
Nov  1 17:12:35.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:12:35.313: INFO: namespace: e2e-tests-kubectl-8ps2r, resource: bindings, ignored listing per whitelist
Nov  1 17:12:35.825: INFO: namespace e2e-tests-kubectl-8ps2r deletion completed in 6.851516253s

• [SLOW TEST:7.222 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:12:35.829: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-540ea8c9-ddf9-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:12:36.206: INFO: Waiting up to 5m0s for pod "pod-secrets-5410f1a0-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-cgrdc" to be "success or failure"
Nov  1 17:12:36.216: INFO: Pod "pod-secrets-5410f1a0-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.921075ms
Nov  1 17:12:38.245: INFO: Pod "pod-secrets-5410f1a0-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038927278s
Nov  1 17:12:40.258: INFO: Pod "pod-secrets-5410f1a0-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052039763s
STEP: Saw pod success
Nov  1 17:12:40.259: INFO: Pod "pod-secrets-5410f1a0-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:12:40.272: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-secrets-5410f1a0-ddf9-11e8-a64b-2ef904c43a0d container secret-volume-test: <nil>
STEP: delete the pod
Nov  1 17:12:40.425: INFO: Waiting for pod pod-secrets-5410f1a0-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:12:40.433: INFO: Pod pod-secrets-5410f1a0-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:12:40.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cgrdc" for this suite.
Nov  1 17:12:46.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:12:46.616: INFO: namespace: e2e-tests-secrets-cgrdc, resource: bindings, ignored listing per whitelist
Nov  1 17:12:46.960: INFO: namespace e2e-tests-secrets-cgrdc deletion completed in 6.507024256s

• [SLOW TEST:11.134 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:12:46.966: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  1 17:12:51.888: INFO: Successfully updated pod "pod-update-5aa164fd-ddf9-11e8-a64b-2ef904c43a0d"
STEP: verifying the updated pod is in kubernetes
Nov  1 17:12:51.914: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:12:51.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-b9hgp" for this suite.
Nov  1 17:13:15.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:13:16.225: INFO: namespace: e2e-tests-pods-b9hgp, resource: bindings, ignored listing per whitelist
Nov  1 17:13:16.358: INFO: namespace e2e-tests-pods-b9hgp deletion completed in 24.436109046s

• [SLOW TEST:29.392 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:13:16.362: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  1 17:13:16.837: INFO: Waiting up to 5m0s for pod "pod-6c4132ca-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-zchzq" to be "success or failure"
Nov  1 17:13:16.903: INFO: Pod "pod-6c4132ca-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 66.682223ms
Nov  1 17:13:18.913: INFO: Pod "pod-6c4132ca-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.075959451s
STEP: Saw pod success
Nov  1 17:13:18.913: INFO: Pod "pod-6c4132ca-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:13:18.922: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-6c4132ca-ddf9-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 17:13:19.150: INFO: Waiting for pod pod-6c4132ca-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:13:19.158: INFO: Pod pod-6c4132ca-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:13:19.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zchzq" for this suite.
Nov  1 17:13:27.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:13:27.260: INFO: namespace: e2e-tests-emptydir-zchzq, resource: bindings, ignored listing per whitelist
Nov  1 17:13:27.585: INFO: namespace e2e-tests-emptydir-zchzq deletion completed in 8.420601116s

• [SLOW TEST:11.224 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:13:27.590: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  1 17:13:27.847: INFO: Waiting up to 5m0s for pod "pod-72da6ae9-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-29czc" to be "success or failure"
Nov  1 17:13:27.855: INFO: Pod "pod-72da6ae9-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.825652ms
Nov  1 17:13:29.865: INFO: Pod "pod-72da6ae9-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01810971s
Nov  1 17:13:31.873: INFO: Pod "pod-72da6ae9-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026058493s
STEP: Saw pod success
Nov  1 17:13:31.873: INFO: Pod "pod-72da6ae9-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:13:31.878: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-72da6ae9-ddf9-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 17:13:32.055: INFO: Waiting for pod pod-72da6ae9-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:13:32.064: INFO: Pod pod-72da6ae9-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:13:32.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-29czc" for this suite.
Nov  1 17:13:38.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:13:38.193: INFO: namespace: e2e-tests-emptydir-29czc, resource: bindings, ignored listing per whitelist
Nov  1 17:13:38.584: INFO: namespace e2e-tests-emptydir-29czc deletion completed in 6.512527288s

• [SLOW TEST:10.994 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:13:38.585: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-796e77c8-ddf9-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:13:38.910: INFO: Waiting up to 5m0s for pod "pod-secrets-79724b7c-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-nhcsv" to be "success or failure"
Nov  1 17:13:38.917: INFO: Pod "pod-secrets-79724b7c-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.872675ms
Nov  1 17:13:40.925: INFO: Pod "pod-secrets-79724b7c-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015128844s
Nov  1 17:13:42.948: INFO: Pod "pod-secrets-79724b7c-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037697214s
STEP: Saw pod success
Nov  1 17:13:42.948: INFO: Pod "pod-secrets-79724b7c-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:13:42.953: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-secrets-79724b7c-ddf9-11e8-a64b-2ef904c43a0d container secret-volume-test: <nil>
STEP: delete the pod
Nov  1 17:13:43.028: INFO: Waiting for pod pod-secrets-79724b7c-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:13:43.067: INFO: Pod pod-secrets-79724b7c-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:13:43.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nhcsv" for this suite.
Nov  1 17:13:49.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:13:49.464: INFO: namespace: e2e-tests-secrets-nhcsv, resource: bindings, ignored listing per whitelist
Nov  1 17:13:49.708: INFO: namespace e2e-tests-secrets-nhcsv deletion completed in 6.634436754s

• [SLOW TEST:11.128 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:13:49.713: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  1 17:13:49.982: INFO: Waiting up to 5m0s for pod "pod-8009cd1c-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-hl75c" to be "success or failure"
Nov  1 17:13:49.992: INFO: Pod "pod-8009cd1c-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.619368ms
Nov  1 17:13:52.012: INFO: Pod "pod-8009cd1c-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030080993s
STEP: Saw pod success
Nov  1 17:13:52.012: INFO: Pod "pod-8009cd1c-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:13:52.025: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-8009cd1c-ddf9-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 17:13:52.104: INFO: Waiting for pod pod-8009cd1c-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:13:52.132: INFO: Pod pod-8009cd1c-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:13:52.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hl75c" for this suite.
Nov  1 17:13:58.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:13:58.286: INFO: namespace: e2e-tests-emptydir-hl75c, resource: bindings, ignored listing per whitelist
Nov  1 17:13:58.682: INFO: namespace e2e-tests-emptydir-hl75c deletion completed in 6.536083584s

• [SLOW TEST:8.969 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:13:58.687: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 17:13:58.933: INFO: Waiting up to 5m0s for pod "downwardapi-volume-855e0b0f-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-cldkf" to be "success or failure"
Nov  1 17:13:58.954: INFO: Pod "downwardapi-volume-855e0b0f-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.441206ms
Nov  1 17:14:00.973: INFO: Pod "downwardapi-volume-855e0b0f-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039733297s
Nov  1 17:14:02.984: INFO: Pod "downwardapi-volume-855e0b0f-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050258126s
STEP: Saw pod success
Nov  1 17:14:02.984: INFO: Pod "downwardapi-volume-855e0b0f-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:14:02.994: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-855e0b0f-ddf9-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 17:14:03.071: INFO: Waiting for pod downwardapi-volume-855e0b0f-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:14:03.086: INFO: Pod downwardapi-volume-855e0b0f-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:14:03.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cldkf" for this suite.
Nov  1 17:14:09.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:14:09.195: INFO: namespace: e2e-tests-downward-api-cldkf, resource: bindings, ignored listing per whitelist
Nov  1 17:14:09.605: INFO: namespace e2e-tests-downward-api-cldkf deletion completed in 6.508698157s

• [SLOW TEST:10.923 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:14:09.610: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-mwtlp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mwtlp to expose endpoints map[]
Nov  1 17:14:09.865: INFO: Get endpoints failed (11.770986ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov  1 17:14:10.871: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mwtlp exposes endpoints map[] (1.017797804s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-mwtlp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mwtlp to expose endpoints map[pod1:[80]]
Nov  1 17:14:13.974: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mwtlp exposes endpoints map[pod1:[80]] (3.075567438s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-mwtlp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mwtlp to expose endpoints map[pod1:[80] pod2:[80]]
Nov  1 17:14:17.129: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mwtlp exposes endpoints map[pod1:[80] pod2:[80]] (3.139903998s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-mwtlp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mwtlp to expose endpoints map[pod2:[80]]
Nov  1 17:14:17.196: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mwtlp exposes endpoints map[pod2:[80]] (46.253559ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-mwtlp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mwtlp to expose endpoints map[]
Nov  1 17:14:17.231: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mwtlp exposes endpoints map[] (25.867131ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:14:17.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-mwtlp" for this suite.
Nov  1 17:14:39.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:14:39.692: INFO: namespace: e2e-tests-services-mwtlp, resource: bindings, ignored listing per whitelist
Nov  1 17:14:39.855: INFO: namespace e2e-tests-services-mwtlp deletion completed in 22.564077581s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.248 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:14:39.859: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  1 17:14:44.816: INFO: Successfully updated pod "labelsupdate9def85d6-ddf9-11e8-a64b-2ef904c43a0d"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:14:46.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sq5sk" for this suite.
Nov  1 17:15:10.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:15:11.215: INFO: namespace: e2e-tests-projected-sq5sk, resource: bindings, ignored listing per whitelist
Nov  1 17:15:11.400: INFO: namespace e2e-tests-projected-sq5sk deletion completed in 24.489297017s

• [SLOW TEST:31.541 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:15:11.403: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  1 17:15:11.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 version --client'
Nov  1 17:15:11.815: INFO: stderr: ""
Nov  1 17:15:11.815: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Nov  1 17:15:11.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-sxfzw'
Nov  1 17:15:13.221: INFO: stderr: ""
Nov  1 17:15:13.221: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov  1 17:15:13.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-sxfzw'
Nov  1 17:15:13.620: INFO: stderr: ""
Nov  1 17:15:13.620: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  1 17:15:14.634: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:15:14.634: INFO: Found 0 / 1
Nov  1 17:15:15.626: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:15:15.626: INFO: Found 0 / 1
Nov  1 17:15:16.629: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:15:16.633: INFO: Found 1 / 1
Nov  1 17:15:16.633: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  1 17:15:16.639: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:15:16.639: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  1 17:15:16.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 describe pod redis-master-4rlhp --namespace=e2e-tests-kubectl-sxfzw'
Nov  1 17:15:16.862: INFO: stderr: ""
Nov  1 17:15:16.862: INFO: stdout: "Name:               redis-master-4rlhp\nNamespace:          e2e-tests-kubectl-sxfzw\nPriority:           0\nPriorityClassName:  <none>\nNode:               machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn/192.168.1.10\nStart Time:         Thu, 01 Nov 2018 17:15:13 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 172.25.1.149\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://681ef470c0544ff4fb7ba9115b9e797ab6c39b307e87dc13fa23041887ac8bc5\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 01 Nov 2018 17:15:14 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-lrqs6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-lrqs6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-lrqs6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                             Message\n  ----    ------     ----  ----                                                             -------\n  Normal  Scheduled  3s    default-scheduler                                                Successfully assigned e2e-tests-kubectl-sxfzw/redis-master-4rlhp to machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn\n  Normal  Pulled     2s    kubelet, machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Created container\n  Normal  Started    2s    kubelet, machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn  Started container\n"
Nov  1 17:15:16.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 describe rc redis-master --namespace=e2e-tests-kubectl-sxfzw'
Nov  1 17:15:17.040: INFO: stderr: ""
Nov  1 17:15:17.040: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-sxfzw\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-4rlhp\n"
Nov  1 17:15:17.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 describe service redis-master --namespace=e2e-tests-kubectl-sxfzw'
Nov  1 17:15:17.306: INFO: stderr: ""
Nov  1 17:15:17.307: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-sxfzw\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.10.10.156\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.25.1.149:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  1 17:15:17.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 describe node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn'
Nov  1 17:15:17.541: INFO: stderr: ""
Nov  1 17:15:17.541: INFO: stdout: "Name:               machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=72c6b6e7-de6f-4da4-a457-6dd477c99aa3\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=dbl\n                    failure-domain.beta.kubernetes.io/zone=dbl1\n                    kubernetes.io/hostname=machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn\n                    machine-controller/owned-by=700e39b2-ddec-11e8-ad00-0a580af40ec2\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"9a:b5:15:8e:8a:c1\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.1.10\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 01 Nov 2018 15:45:34 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Thu, 01 Nov 2018 17:15:10 +0000   Thu, 01 Nov 2018 15:45:34 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Thu, 01 Nov 2018 17:15:10 +0000   Thu, 01 Nov 2018 15:45:34 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 01 Nov 2018 17:15:10 +0000   Thu, 01 Nov 2018 15:45:34 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 01 Nov 2018 17:15:10 +0000   Thu, 01 Nov 2018 15:45:34 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 01 Nov 2018 17:15:10 +0000   Thu, 01 Nov 2018 15:46:38 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.1.10\n  ExternalIP:  195.192.129.224\n  Hostname:    machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn\nCapacity:\n cpu:                1\n ephemeral-storage:  51473000Ki\n hugepages-2Mi:      0\n memory:             2041240Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  47437516722\n hugepages-2Mi:      0\n memory:             1938840Ki\n pods:               110\nSystem Info:\n Machine ID:                 1e808eccff864574b25e377eda9fbdd1\n System UUID:                A5D32662-3136-47D7-B71D-C4E2A5C2DB6F\n Boot ID:                    535f7781-54b1-4ff0-9dc8-d8faa5de3d72\n Kernel Version:             4.15.0-30-generic\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.0\n Kubelet Version:            v1.12.2\n Kube-Proxy Version:         v1.12.2\nPodCIDR:                     172.25.1.0/24\nProviderID:                  openstack:///a5d32662-3136-47d7-b71d-c4e2a5c2db6f\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-sxfzw    redis-master-4rlhp                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-ark                 restic-jvl9h                                               0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-e2e-job-885a13fbb80f41a2                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-7fc65f4ad6ad4a3b-kmrb5    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                canal-n7cr4                                                250m (25%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-75xl8                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       250m (25%)  0 (0%)\n  memory    0 (0%)      0 (0%)\nEvents:     <none>\n"
Nov  1 17:15:17.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 describe namespace e2e-tests-kubectl-sxfzw'
Nov  1 17:15:17.702: INFO: stderr: ""
Nov  1 17:15:17.702: INFO: stdout: "Name:         e2e-tests-kubectl-sxfzw\nLabels:       e2e-framework=kubectl\n              e2e-run=9682bf76-dded-11e8-a64b-2ef904c43a0d\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:15:17.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sxfzw" for this suite.
Nov  1 17:15:37.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:15:38.084: INFO: namespace: e2e-tests-kubectl-sxfzw, resource: bindings, ignored listing per whitelist
Nov  1 17:15:38.301: INFO: namespace e2e-tests-kubectl-sxfzw deletion completed in 20.579361823s

• [SLOW TEST:26.899 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:15:38.305: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Nov  1 17:15:38.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-dfbf4'
Nov  1 17:15:38.886: INFO: stderr: ""
Nov  1 17:15:38.886: INFO: stdout: "pod/pause created\n"
Nov  1 17:15:38.886: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  1 17:15:38.886: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-dfbf4" to be "running and ready"
Nov  1 17:15:38.943: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 56.784824ms
Nov  1 17:15:40.949: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.062582615s
Nov  1 17:15:40.949: INFO: Pod "pause" satisfied condition "running and ready"
Nov  1 17:15:40.949: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  1 17:15:40.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-dfbf4'
Nov  1 17:15:41.143: INFO: stderr: ""
Nov  1 17:15:41.143: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  1 17:15:41.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pod pause -L testing-label --namespace=e2e-tests-kubectl-dfbf4'
Nov  1 17:15:41.329: INFO: stderr: ""
Nov  1 17:15:41.329: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  1 17:15:41.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 label pods pause testing-label- --namespace=e2e-tests-kubectl-dfbf4'
Nov  1 17:15:41.499: INFO: stderr: ""
Nov  1 17:15:41.500: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  1 17:15:41.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pod pause -L testing-label --namespace=e2e-tests-kubectl-dfbf4'
Nov  1 17:15:41.652: INFO: stderr: ""
Nov  1 17:15:41.652: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Nov  1 17:15:41.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dfbf4'
Nov  1 17:15:41.824: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 17:15:41.824: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  1 17:15:41.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-dfbf4'
Nov  1 17:15:41.979: INFO: stderr: "No resources found.\n"
Nov  1 17:15:41.979: INFO: stdout: ""
Nov  1 17:15:41.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -l name=pause --namespace=e2e-tests-kubectl-dfbf4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  1 17:15:42.107: INFO: stderr: ""
Nov  1 17:15:42.107: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:15:42.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dfbf4" for this suite.
Nov  1 17:15:50.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:15:50.468: INFO: namespace: e2e-tests-kubectl-dfbf4, resource: bindings, ignored listing per whitelist
Nov  1 17:15:50.553: INFO: namespace e2e-tests-kubectl-dfbf4 deletion completed in 8.438718425s

• [SLOW TEST:12.249 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:15:50.555: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 17:15:50.948: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c81ef525-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-downward-api-rp7wt" to be "success or failure"
Nov  1 17:15:50.975: INFO: Pod "downwardapi-volume-c81ef525-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.294825ms
Nov  1 17:15:52.999: INFO: Pod "downwardapi-volume-c81ef525-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05058625s
Nov  1 17:15:55.009: INFO: Pod "downwardapi-volume-c81ef525-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060109388s
STEP: Saw pod success
Nov  1 17:15:55.009: INFO: Pod "downwardapi-volume-c81ef525-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:15:55.014: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-c81ef525-ddf9-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 17:15:55.095: INFO: Waiting for pod downwardapi-volume-c81ef525-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:15:55.118: INFO: Pod downwardapi-volume-c81ef525-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:15:55.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rp7wt" for this suite.
Nov  1 17:16:01.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:16:01.335: INFO: namespace: e2e-tests-downward-api-rp7wt, resource: bindings, ignored listing per whitelist
Nov  1 17:16:01.897: INFO: namespace e2e-tests-downward-api-rp7wt deletion completed in 6.760650794s

• [SLOW TEST:11.346 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:16:01.902: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  1 17:16:02.424: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cef4a0b9-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-5cplw" to be "success or failure"
Nov  1 17:16:02.435: INFO: Pod "downwardapi-volume-cef4a0b9-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.4402ms
Nov  1 17:16:04.453: INFO: Pod "downwardapi-volume-cef4a0b9-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029058642s
Nov  1 17:16:06.459: INFO: Pod "downwardapi-volume-cef4a0b9-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035515196s
STEP: Saw pod success
Nov  1 17:16:06.460: INFO: Pod "downwardapi-volume-cef4a0b9-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:16:06.483: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod downwardapi-volume-cef4a0b9-ddf9-11e8-a64b-2ef904c43a0d container client-container: <nil>
STEP: delete the pod
Nov  1 17:16:06.573: INFO: Waiting for pod downwardapi-volume-cef4a0b9-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:16:06.581: INFO: Pod downwardapi-volume-cef4a0b9-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:16:06.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5cplw" for this suite.
Nov  1 17:16:12.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:16:13.042: INFO: namespace: e2e-tests-projected-5cplw, resource: bindings, ignored listing per whitelist
Nov  1 17:16:13.096: INFO: namespace e2e-tests-projected-5cplw deletion completed in 6.507793232s

• [SLOW TEST:11.195 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:16:13.100: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  1 17:16:13.344: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-a,UID:d57cc937-ddf9-11e8-a94b-0a580af40661,ResourceVersion:20964,Generation:0,CreationTimestamp:2018-11-01 17:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  1 17:16:13.344: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-a,UID:d57cc937-ddf9-11e8-a94b-0a580af40661,ResourceVersion:20964,Generation:0,CreationTimestamp:2018-11-01 17:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  1 17:16:23.370: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-a,UID:d57cc937-ddf9-11e8-a94b-0a580af40661,ResourceVersion:20984,Generation:0,CreationTimestamp:2018-11-01 17:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  1 17:16:23.371: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-a,UID:d57cc937-ddf9-11e8-a94b-0a580af40661,ResourceVersion:20984,Generation:0,CreationTimestamp:2018-11-01 17:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  1 17:16:33.421: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-a,UID:d57cc937-ddf9-11e8-a94b-0a580af40661,ResourceVersion:21004,Generation:0,CreationTimestamp:2018-11-01 17:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  1 17:16:33.422: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-a,UID:d57cc937-ddf9-11e8-a94b-0a580af40661,ResourceVersion:21004,Generation:0,CreationTimestamp:2018-11-01 17:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  1 17:16:43.515: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-a,UID:d57cc937-ddf9-11e8-a94b-0a580af40661,ResourceVersion:21024,Generation:0,CreationTimestamp:2018-11-01 17:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  1 17:16:43.515: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-a,UID:d57cc937-ddf9-11e8-a94b-0a580af40661,ResourceVersion:21024,Generation:0,CreationTimestamp:2018-11-01 17:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  1 17:16:53.559: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-b,UID:ed77e360-ddf9-11e8-a94b-0a580af40661,ResourceVersion:21044,Generation:0,CreationTimestamp:2018-11-01 17:16:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  1 17:16:53.559: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-b,UID:ed77e360-ddf9-11e8-a94b-0a580af40661,ResourceVersion:21044,Generation:0,CreationTimestamp:2018-11-01 17:16:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  1 17:17:03.628: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-b,UID:ed77e360-ddf9-11e8-a94b-0a580af40661,ResourceVersion:21063,Generation:0,CreationTimestamp:2018-11-01 17:16:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  1 17:17:03.629: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-tg26j,SelfLink:/api/v1/namespaces/e2e-tests-watch-tg26j/configmaps/e2e-watch-test-configmap-b,UID:ed77e360-ddf9-11e8-a94b-0a580af40661,ResourceVersion:21063,Generation:0,CreationTimestamp:2018-11-01 17:16:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:17:13.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-tg26j" for this suite.
Nov  1 17:17:19.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:17:19.845: INFO: namespace: e2e-tests-watch-tg26j, resource: bindings, ignored listing per whitelist
Nov  1 17:17:20.176: INFO: namespace e2e-tests-watch-tg26j deletion completed in 6.520501279s

• [SLOW TEST:67.080 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:17:20.183: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-fd7be16f-ddf9-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:17:20.462: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fd803ba3-ddf9-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-wd2dq" to be "success or failure"
Nov  1 17:17:20.467: INFO: Pod "pod-projected-secrets-fd803ba3-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.484162ms
Nov  1 17:17:22.476: INFO: Pod "pod-projected-secrets-fd803ba3-ddf9-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013598166s
Nov  1 17:17:24.491: INFO: Pod "pod-projected-secrets-fd803ba3-ddf9-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0291562s
STEP: Saw pod success
Nov  1 17:17:24.495: INFO: Pod "pod-projected-secrets-fd803ba3-ddf9-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:17:24.515: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-secrets-fd803ba3-ddf9-11e8-a64b-2ef904c43a0d container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  1 17:17:24.636: INFO: Waiting for pod pod-projected-secrets-fd803ba3-ddf9-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:17:24.641: INFO: Pod pod-projected-secrets-fd803ba3-ddf9-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:17:24.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wd2dq" for this suite.
Nov  1 17:17:30.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:17:31.066: INFO: namespace: e2e-tests-projected-wd2dq, resource: bindings, ignored listing per whitelist
Nov  1 17:17:31.143: INFO: namespace e2e-tests-projected-wd2dq deletion completed in 6.483373918s

• [SLOW TEST:10.959 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:17:31.144: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-0407c5ef-ddfa-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:17:31.437: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-040a6862-ddfa-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-4h4ws" to be "success or failure"
Nov  1 17:17:31.457: INFO: Pod "pod-projected-secrets-040a6862-ddfa-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.721404ms
Nov  1 17:17:33.475: INFO: Pod "pod-projected-secrets-040a6862-ddfa-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038203919s
STEP: Saw pod success
Nov  1 17:17:33.475: INFO: Pod "pod-projected-secrets-040a6862-ddfa-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:17:33.480: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-secrets-040a6862-ddfa-11e8-a64b-2ef904c43a0d container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  1 17:17:33.533: INFO: Waiting for pod pod-projected-secrets-040a6862-ddfa-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:17:33.538: INFO: Pod pod-projected-secrets-040a6862-ddfa-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:17:33.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4h4ws" for this suite.
Nov  1 17:17:39.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:17:39.961: INFO: namespace: e2e-tests-projected-4h4ws, resource: bindings, ignored listing per whitelist
Nov  1 17:17:39.993: INFO: namespace e2e-tests-projected-4h4ws deletion completed in 6.444622299s

• [SLOW TEST:8.850 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:17:39.994: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-l7hxr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  1 17:17:40.263: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  1 17:18:02.476: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.153:8080/dial?request=hostName&protocol=udp&host=172.25.0.134&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-l7hxr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:18:02.477: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:18:02.925: INFO: Waiting for endpoints: map[]
Nov  1 17:18:02.937: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.153:8080/dial?request=hostName&protocol=udp&host=172.25.1.152&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-l7hxr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  1 17:18:02.938: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
Nov  1 17:18:03.465: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:18:03.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-l7hxr" for this suite.
Nov  1 17:18:27.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:18:28.010: INFO: namespace: e2e-tests-pod-network-test-l7hxr, resource: bindings, ignored listing per whitelist
Nov  1 17:18:28.037: INFO: namespace e2e-tests-pod-network-test-l7hxr deletion completed in 24.561392146s

• [SLOW TEST:48.044 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:18:28.038: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-mpq4q
Nov  1 17:18:32.419: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-mpq4q
STEP: checking the pod's current state and verifying that restartCount is present
Nov  1 17:18:32.429: INFO: Initial restart count of pod liveness-exec is 0
Nov  1 17:19:18.917: INFO: Restart count of pod e2e-tests-container-probe-mpq4q/liveness-exec is now 1 (46.48799234s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:19:18.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mpq4q" for this suite.
Nov  1 17:19:25.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:19:25.144: INFO: namespace: e2e-tests-container-probe-mpq4q, resource: bindings, ignored listing per whitelist
Nov  1 17:19:25.390: INFO: namespace e2e-tests-container-probe-mpq4q deletion completed in 6.43554867s

• [SLOW TEST:57.356 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:19:25.395: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fxpfz
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Nov  1 17:19:25.667: INFO: Found 0 stateful pods, waiting for 3
Nov  1 17:19:35.713: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 17:19:35.714: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 17:19:35.714: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov  1 17:19:35.757: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  1 17:19:45.841: INFO: Updating stateful set ss2
Nov  1 17:19:45.858: INFO: Waiting for Pod e2e-tests-statefulset-fxpfz/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Nov  1 17:19:56.019: INFO: Found 2 stateful pods, waiting for 3
Nov  1 17:20:06.045: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 17:20:06.045: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  1 17:20:06.045: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  1 17:20:06.103: INFO: Updating stateful set ss2
Nov  1 17:20:06.129: INFO: Waiting for Pod e2e-tests-statefulset-fxpfz/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  1 17:20:16.194: INFO: Updating stateful set ss2
Nov  1 17:20:16.219: INFO: Waiting for StatefulSet e2e-tests-statefulset-fxpfz/ss2 to complete update
Nov  1 17:20:16.219: INFO: Waiting for Pod e2e-tests-statefulset-fxpfz/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  1 17:20:26.249: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fxpfz
Nov  1 17:20:26.258: INFO: Scaling statefulset ss2 to 0
Nov  1 17:20:36.312: INFO: Waiting for statefulset status.replicas updated to 0
Nov  1 17:20:36.318: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:20:36.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fxpfz" for this suite.
Nov  1 17:20:44.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:20:44.683: INFO: namespace: e2e-tests-statefulset-fxpfz, resource: bindings, ignored listing per whitelist
Nov  1 17:20:44.962: INFO: namespace e2e-tests-statefulset-fxpfz deletion completed in 8.581116738s

• [SLOW TEST:79.572 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:20:44.968: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-778ff7fd-ddfa-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume secrets
Nov  1 17:20:45.260: INFO: Waiting up to 5m0s for pod "pod-secrets-7792117d-ddfa-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-secrets-nbv8v" to be "success or failure"
Nov  1 17:20:45.275: INFO: Pod "pod-secrets-7792117d-ddfa-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.271589ms
Nov  1 17:20:47.325: INFO: Pod "pod-secrets-7792117d-ddfa-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.063998477s
STEP: Saw pod success
Nov  1 17:20:47.329: INFO: Pod "pod-secrets-7792117d-ddfa-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:20:47.339: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-secrets-7792117d-ddfa-11e8-a64b-2ef904c43a0d container secret-volume-test: <nil>
STEP: delete the pod
Nov  1 17:20:47.384: INFO: Waiting for pod pod-secrets-7792117d-ddfa-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:20:47.389: INFO: Pod pod-secrets-7792117d-ddfa-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:20:47.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nbv8v" for this suite.
Nov  1 17:20:53.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:20:53.776: INFO: namespace: e2e-tests-secrets-nbv8v, resource: bindings, ignored listing per whitelist
Nov  1 17:20:53.858: INFO: namespace e2e-tests-secrets-nbv8v deletion completed in 6.461430952s

• [SLOW TEST:8.894 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:20:53.866: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-wpjp
STEP: Creating a pod to test atomic-volume-subpath
Nov  1 17:20:54.134: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-wpjp" in namespace "e2e-tests-subpath-2fxdx" to be "success or failure"
Nov  1 17:20:54.140: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.244515ms
Nov  1 17:20:56.214: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079404277s
Nov  1 17:20:58.238: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 4.104114523s
Nov  1 17:21:00.246: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 6.112250032s
Nov  1 17:21:02.259: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 8.124499571s
Nov  1 17:21:04.267: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 10.132730832s
Nov  1 17:21:06.276: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 12.141523429s
Nov  1 17:21:08.300: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 14.165361831s
Nov  1 17:21:10.308: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 16.173688981s
Nov  1 17:21:12.326: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 18.191741592s
Nov  1 17:21:14.338: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 20.2039046s
Nov  1 17:21:16.353: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Running", Reason="", readiness=false. Elapsed: 22.219197662s
Nov  1 17:21:18.416: INFO: Pod "pod-subpath-test-projected-wpjp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.281609696s
STEP: Saw pod success
Nov  1 17:21:18.416: INFO: Pod "pod-subpath-test-projected-wpjp" satisfied condition "success or failure"
Nov  1 17:21:18.423: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-subpath-test-projected-wpjp container test-container-subpath-projected-wpjp: <nil>
STEP: delete the pod
Nov  1 17:21:18.547: INFO: Waiting for pod pod-subpath-test-projected-wpjp to disappear
Nov  1 17:21:18.555: INFO: Pod pod-subpath-test-projected-wpjp no longer exists
STEP: Deleting pod pod-subpath-test-projected-wpjp
Nov  1 17:21:18.555: INFO: Deleting pod "pod-subpath-test-projected-wpjp" in namespace "e2e-tests-subpath-2fxdx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:21:18.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2fxdx" for this suite.
Nov  1 17:21:24.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:21:24.926: INFO: namespace: e2e-tests-subpath-2fxdx, resource: bindings, ignored listing per whitelist
Nov  1 17:21:25.031: INFO: namespace e2e-tests-subpath-2fxdx deletion completed in 6.422672869s

• [SLOW TEST:31.168 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:21:25.032: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Nov  1 17:21:25.254: INFO: Waiting up to 5m0s for pod "client-containers-8f684643-ddfa-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-containers-2x25m" to be "success or failure"
Nov  1 17:21:25.259: INFO: Pod "client-containers-8f684643-ddfa-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.061666ms
Nov  1 17:21:27.266: INFO: Pod "client-containers-8f684643-ddfa-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012169862s
Nov  1 17:21:29.295: INFO: Pod "client-containers-8f684643-ddfa-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04078469s
STEP: Saw pod success
Nov  1 17:21:29.295: INFO: Pod "client-containers-8f684643-ddfa-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:21:29.300: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod client-containers-8f684643-ddfa-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 17:21:29.346: INFO: Waiting for pod client-containers-8f684643-ddfa-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:21:29.358: INFO: Pod client-containers-8f684643-ddfa-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:21:29.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2x25m" for this suite.
Nov  1 17:21:35.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:21:36.495: INFO: namespace: e2e-tests-containers-2x25m, resource: bindings, ignored listing per whitelist
Nov  1 17:21:36.802: INFO: namespace e2e-tests-containers-2x25m deletion completed in 7.423443457s

• [SLOW TEST:11.771 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:21:36.810: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-968b66d8-ddfa-11e8-a64b-2ef904c43a0d
STEP: Creating configMap with name cm-test-opt-upd-968b6765-ddfa-11e8-a64b-2ef904c43a0d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-968b66d8-ddfa-11e8-a64b-2ef904c43a0d
STEP: Updating configmap cm-test-opt-upd-968b6765-ddfa-11e8-a64b-2ef904c43a0d
STEP: Creating configMap with name cm-test-opt-create-968b67af-ddfa-11e8-a64b-2ef904c43a0d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:22:48.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zl7jt" for this suite.
Nov  1 17:23:12.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:23:12.610: INFO: namespace: e2e-tests-projected-zl7jt, resource: bindings, ignored listing per whitelist
Nov  1 17:23:12.886: INFO: namespace e2e-tests-projected-zl7jt deletion completed in 24.459753284s

• [SLOW TEST:96.079 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:23:12.891: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1101 17:23:43.712729      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  1 17:23:43.712: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:23:43.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9jc6g" for this suite.
Nov  1 17:23:51.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:23:51.950: INFO: namespace: e2e-tests-gc-9jc6g, resource: bindings, ignored listing per whitelist
Nov  1 17:23:52.284: INFO: namespace e2e-tests-gc-9jc6g deletion completed in 8.562352258s

• [SLOW TEST:39.397 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:23:52.289: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Nov  1 17:23:53.162: INFO: created pod pod-service-account-defaultsa
Nov  1 17:23:53.162: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  1 17:23:53.184: INFO: created pod pod-service-account-mountsa
Nov  1 17:23:53.184: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  1 17:23:53.196: INFO: created pod pod-service-account-nomountsa
Nov  1 17:23:53.196: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  1 17:23:53.215: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  1 17:23:53.216: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  1 17:23:53.250: INFO: created pod pod-service-account-mountsa-mountspec
Nov  1 17:23:53.250: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  1 17:23:53.271: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  1 17:23:53.271: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  1 17:23:53.281: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  1 17:23:53.281: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  1 17:23:53.305: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  1 17:23:53.305: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  1 17:23:53.342: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  1 17:23:53.342: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:23:53.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-qnl9b" for this suite.
Nov  1 17:24:17.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:24:17.631: INFO: namespace: e2e-tests-svcaccounts-qnl9b, resource: bindings, ignored listing per whitelist
Nov  1 17:24:17.940: INFO: namespace e2e-tests-svcaccounts-qnl9b deletion completed in 24.583323765s

• [SLOW TEST:25.656 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:24:17.948: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f680c97f-ddfa-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 17:24:18.239: INFO: Waiting up to 5m0s for pod "pod-configmaps-f683f093-ddfa-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-configmap-mmkzt" to be "success or failure"
Nov  1 17:24:18.245: INFO: Pod "pod-configmaps-f683f093-ddfa-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.233803ms
Nov  1 17:24:20.254: INFO: Pod "pod-configmaps-f683f093-ddfa-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015079279s
Nov  1 17:24:22.264: INFO: Pod "pod-configmaps-f683f093-ddfa-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025193093s
STEP: Saw pod success
Nov  1 17:24:22.264: INFO: Pod "pod-configmaps-f683f093-ddfa-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:24:22.270: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-configmaps-f683f093-ddfa-11e8-a64b-2ef904c43a0d container configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 17:24:22.340: INFO: Waiting for pod pod-configmaps-f683f093-ddfa-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:24:22.345: INFO: Pod pod-configmaps-f683f093-ddfa-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:24:22.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mmkzt" for this suite.
Nov  1 17:24:28.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:24:28.594: INFO: namespace: e2e-tests-configmap-mmkzt, resource: bindings, ignored listing per whitelist
Nov  1 17:24:28.942: INFO: namespace e2e-tests-configmap-mmkzt deletion completed in 6.58521819s

• [SLOW TEST:10.998 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:24:28.946: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Nov  1 17:24:29.786: INFO: Waiting up to 5m0s for pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-mbs4v" in namespace "e2e-tests-svcaccounts-rrtlc" to be "success or failure"
Nov  1 17:24:29.791: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-mbs4v": Phase="Pending", Reason="", readiness=false. Elapsed: 5.032162ms
Nov  1 17:24:31.801: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-mbs4v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014847791s
Nov  1 17:24:33.809: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-mbs4v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022978584s
STEP: Saw pod success
Nov  1 17:24:33.810: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-mbs4v" satisfied condition "success or failure"
Nov  1 17:24:33.815: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-mbs4v container token-test: <nil>
STEP: delete the pod
Nov  1 17:24:33.946: INFO: Waiting for pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-mbs4v to disappear
Nov  1 17:24:33.951: INFO: Pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-mbs4v no longer exists
STEP: Creating a pod to test consume service account root CA
Nov  1 17:24:33.975: INFO: Waiting up to 5m0s for pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-9tgfg" in namespace "e2e-tests-svcaccounts-rrtlc" to be "success or failure"
Nov  1 17:24:33.984: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-9tgfg": Phase="Pending", Reason="", readiness=false. Elapsed: 9.503415ms
Nov  1 17:24:35.993: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-9tgfg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018541746s
Nov  1 17:24:38.011: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-9tgfg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036153023s
STEP: Saw pod success
Nov  1 17:24:38.011: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-9tgfg" satisfied condition "success or failure"
Nov  1 17:24:38.018: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-9tgfg container root-ca-test: <nil>
STEP: delete the pod
Nov  1 17:24:38.183: INFO: Waiting for pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-9tgfg to disappear
Nov  1 17:24:38.189: INFO: Pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-9tgfg no longer exists
STEP: Creating a pod to test consume service account namespace
Nov  1 17:24:38.207: INFO: Waiting up to 5m0s for pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-95cqh" in namespace "e2e-tests-svcaccounts-rrtlc" to be "success or failure"
Nov  1 17:24:38.213: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-95cqh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.291704ms
Nov  1 17:24:40.230: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-95cqh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023447375s
Nov  1 17:24:42.244: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-95cqh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037366718s
STEP: Saw pod success
Nov  1 17:24:42.249: INFO: Pod "pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-95cqh" satisfied condition "success or failure"
Nov  1 17:24:42.255: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-95cqh container namespace-test: <nil>
STEP: delete the pod
Nov  1 17:24:42.337: INFO: Waiting for pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-95cqh to disappear
Nov  1 17:24:42.341: INFO: Pod pod-service-account-fd65a3d8-ddfa-11e8-a64b-2ef904c43a0d-95cqh no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:24:42.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-rrtlc" for this suite.
Nov  1 17:24:50.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:24:50.656: INFO: namespace: e2e-tests-svcaccounts-rrtlc, resource: bindings, ignored listing per whitelist
Nov  1 17:24:50.836: INFO: namespace e2e-tests-svcaccounts-rrtlc deletion completed in 8.488659181s

• [SLOW TEST:21.891 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:24:50.841: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-vnkvw
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-vnkvw
STEP: Deleting pre-stop pod
Nov  1 17:25:02.377: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:25:02.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-vnkvw" for this suite.
Nov  1 17:25:38.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:25:38.834: INFO: namespace: e2e-tests-prestop-vnkvw, resource: bindings, ignored listing per whitelist
Nov  1 17:25:38.864: INFO: namespace e2e-tests-prestop-vnkvw deletion completed in 36.436606955s

• [SLOW TEST:48.024 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:25:38.865: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-26c6f684-ddfb-11e8-a64b-2ef904c43a0d
Nov  1 17:25:39.235: INFO: Pod name my-hostname-basic-26c6f684-ddfb-11e8-a64b-2ef904c43a0d: Found 0 pods out of 1
Nov  1 17:25:44.243: INFO: Pod name my-hostname-basic-26c6f684-ddfb-11e8-a64b-2ef904c43a0d: Found 1 pods out of 1
Nov  1 17:25:44.243: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-26c6f684-ddfb-11e8-a64b-2ef904c43a0d" are running
Nov  1 17:25:44.254: INFO: Pod "my-hostname-basic-26c6f684-ddfb-11e8-a64b-2ef904c43a0d-7x2rw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-01 17:25:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-01 17:25:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-01 17:25:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-01 17:25:39 +0000 UTC Reason: Message:}])
Nov  1 17:25:44.255: INFO: Trying to dial the pod
Nov  1 17:25:49.438: INFO: Controller my-hostname-basic-26c6f684-ddfb-11e8-a64b-2ef904c43a0d: Got expected result from replica 1 [my-hostname-basic-26c6f684-ddfb-11e8-a64b-2ef904c43a0d-7x2rw]: "my-hostname-basic-26c6f684-ddfb-11e8-a64b-2ef904c43a0d-7x2rw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:25:49.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-c2xtk" for this suite.
Nov  1 17:25:55.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:25:55.594: INFO: namespace: e2e-tests-replication-controller-c2xtk, resource: bindings, ignored listing per whitelist
Nov  1 17:25:55.982: INFO: namespace e2e-tests-replication-controller-c2xtk deletion completed in 6.528021672s

• [SLOW TEST:17.120 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:25:55.989: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Nov  1 17:25:56.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-wmfvs'
Nov  1 17:25:57.583: INFO: stderr: ""
Nov  1 17:25:57.584: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Nov  1 17:25:58.624: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:25:58.624: INFO: Found 0 / 1
Nov  1 17:25:59.603: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:25:59.603: INFO: Found 1 / 1
Nov  1 17:25:59.603: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  1 17:25:59.610: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:25:59.610: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Nov  1 17:25:59.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 logs redis-master-bb9pg redis-master --namespace=e2e-tests-kubectl-wmfvs'
Nov  1 17:25:59.909: INFO: stderr: ""
Nov  1 17:25:59.909: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Nov 17:25:59.220 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Nov 17:25:59.220 # Server started, Redis version 3.2.12\n1:M 01 Nov 17:25:59.220 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Nov 17:25:59.220 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Nov  1 17:25:59.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 log redis-master-bb9pg redis-master --namespace=e2e-tests-kubectl-wmfvs --tail=1'
Nov  1 17:26:00.301: INFO: stderr: ""
Nov  1 17:26:00.301: INFO: stdout: "1:M 01 Nov 17:25:59.220 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Nov  1 17:26:00.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 log redis-master-bb9pg redis-master --namespace=e2e-tests-kubectl-wmfvs --limit-bytes=1'
Nov  1 17:26:00.500: INFO: stderr: ""
Nov  1 17:26:00.500: INFO: stdout: " "
STEP: exposing timestamps
Nov  1 17:26:00.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 log redis-master-bb9pg redis-master --namespace=e2e-tests-kubectl-wmfvs --tail=1 --timestamps'
Nov  1 17:26:00.772: INFO: stderr: ""
Nov  1 17:26:00.772: INFO: stdout: "2018-11-01T17:25:59.221352441Z 1:M 01 Nov 17:25:59.220 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Nov  1 17:26:03.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 log redis-master-bb9pg redis-master --namespace=e2e-tests-kubectl-wmfvs --since=1s'
Nov  1 17:26:03.472: INFO: stderr: ""
Nov  1 17:26:03.473: INFO: stdout: ""
Nov  1 17:26:03.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 log redis-master-bb9pg redis-master --namespace=e2e-tests-kubectl-wmfvs --since=24h'
Nov  1 17:26:03.801: INFO: stderr: ""
Nov  1 17:26:03.801: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Nov 17:25:59.220 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Nov 17:25:59.220 # Server started, Redis version 3.2.12\n1:M 01 Nov 17:25:59.220 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Nov 17:25:59.220 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Nov  1 17:26:03.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wmfvs'
Nov  1 17:26:04.108: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  1 17:26:04.108: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Nov  1 17:26:04.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-wmfvs'
Nov  1 17:26:04.285: INFO: stderr: "No resources found.\n"
Nov  1 17:26:04.285: INFO: stdout: ""
Nov  1 17:26:04.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 get pods -l name=nginx --namespace=e2e-tests-kubectl-wmfvs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  1 17:26:04.474: INFO: stderr: ""
Nov  1 17:26:04.474: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:26:04.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wmfvs" for this suite.
Nov  1 17:26:10.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:26:10.706: INFO: namespace: e2e-tests-kubectl-wmfvs, resource: bindings, ignored listing per whitelist
Nov  1 17:26:10.945: INFO: namespace e2e-tests-kubectl-wmfvs deletion completed in 6.455602045s

• [SLOW TEST:14.960 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:26:10.952: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Nov  1 17:26:11.222: INFO: namespace e2e-tests-kubectl-tg6s6
Nov  1 17:26:11.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 create -f - --namespace=e2e-tests-kubectl-tg6s6'
Nov  1 17:26:11.580: INFO: stderr: ""
Nov  1 17:26:11.580: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  1 17:26:12.588: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:26:12.588: INFO: Found 0 / 1
Nov  1 17:26:13.587: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:26:13.588: INFO: Found 0 / 1
Nov  1 17:26:14.589: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:26:14.590: INFO: Found 1 / 1
Nov  1 17:26:14.590: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  1 17:26:14.607: INFO: Selector matched 1 pods for map[app:redis]
Nov  1 17:26:14.608: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  1 17:26:14.608: INFO: wait on redis-master startup in e2e-tests-kubectl-tg6s6 
Nov  1 17:26:14.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 logs redis-master-62hd4 redis-master --namespace=e2e-tests-kubectl-tg6s6'
Nov  1 17:26:15.003: INFO: stderr: ""
Nov  1 17:26:15.004: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Nov 17:26:13.354 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Nov 17:26:13.355 # Server started, Redis version 3.2.12\n1:M 01 Nov 17:26:13.355 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Nov 17:26:13.355 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Nov  1 17:26:15.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-tg6s6'
Nov  1 17:26:15.276: INFO: stderr: ""
Nov  1 17:26:15.276: INFO: stdout: "service/rm2 exposed\n"
Nov  1 17:26:15.321: INFO: Service rm2 in namespace e2e-tests-kubectl-tg6s6 found.
STEP: exposing service
Nov  1 17:26:17.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994938124 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-tg6s6'
Nov  1 17:26:17.593: INFO: stderr: ""
Nov  1 17:26:17.593: INFO: stdout: "service/rm3 exposed\n"
Nov  1 17:26:17.660: INFO: Service rm3 in namespace e2e-tests-kubectl-tg6s6 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:26:19.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tg6s6" for this suite.
Nov  1 17:26:43.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:26:44.206: INFO: namespace: e2e-tests-kubectl-tg6s6, resource: bindings, ignored listing per whitelist
Nov  1 17:26:44.608: INFO: namespace e2e-tests-kubectl-tg6s6 deletion completed in 24.925260532s

• [SLOW TEST:33.659 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:26:44.612: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  1 17:26:45.315: INFO: Waiting up to 5m0s for pod "pod-4e13050e-ddfb-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-nknbs" to be "success or failure"
Nov  1 17:26:45.513: INFO: Pod "pod-4e13050e-ddfb-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 198.003714ms
Nov  1 17:26:47.522: INFO: Pod "pod-4e13050e-ddfb-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206641942s
Nov  1 17:26:49.528: INFO: Pod "pod-4e13050e-ddfb-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212497723s
STEP: Saw pod success
Nov  1 17:26:49.528: INFO: Pod "pod-4e13050e-ddfb-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:26:49.532: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-4e13050e-ddfb-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 17:26:49.631: INFO: Waiting for pod pod-4e13050e-ddfb-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:26:49.642: INFO: Pod pod-4e13050e-ddfb-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:26:49.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nknbs" for this suite.
Nov  1 17:26:55.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:26:55.964: INFO: namespace: e2e-tests-emptydir-nknbs, resource: bindings, ignored listing per whitelist
Nov  1 17:26:56.172: INFO: namespace e2e-tests-emptydir-nknbs deletion completed in 6.495892766s

• [SLOW TEST:11.564 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:26:56.178: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  1 17:26:56.423: INFO: Waiting up to 5m0s for pod "pod-54caaf54-ddfb-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-emptydir-vhp29" to be "success or failure"
Nov  1 17:26:56.432: INFO: Pod "pod-54caaf54-ddfb-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05771ms
Nov  1 17:26:58.445: INFO: Pod "pod-54caaf54-ddfb-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021988076s
Nov  1 17:27:00.459: INFO: Pod "pod-54caaf54-ddfb-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035685471s
STEP: Saw pod success
Nov  1 17:27:00.463: INFO: Pod "pod-54caaf54-ddfb-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:27:00.471: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-a2ymn pod pod-54caaf54-ddfb-11e8-a64b-2ef904c43a0d container test-container: <nil>
STEP: delete the pod
Nov  1 17:27:00.588: INFO: Waiting for pod pod-54caaf54-ddfb-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:27:00.598: INFO: Pod pod-54caaf54-ddfb-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:27:00.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vhp29" for this suite.
Nov  1 17:27:06.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:27:06.760: INFO: namespace: e2e-tests-emptydir-vhp29, resource: bindings, ignored listing per whitelist
Nov  1 17:27:07.166: INFO: namespace e2e-tests-emptydir-vhp29 deletion completed in 6.544899142s

• [SLOW TEST:10.988 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  1 17:27:07.167: INFO: >>> kubeConfig: /tmp/kubeconfig-994938124
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5b763c3f-ddfb-11e8-a64b-2ef904c43a0d
STEP: Creating a pod to test consume configMaps
Nov  1 17:27:07.620: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b78fc55-ddfb-11e8-a64b-2ef904c43a0d" in namespace "e2e-tests-projected-jdhks" to be "success or failure"
Nov  1 17:27:07.633: INFO: Pod "pod-projected-configmaps-5b78fc55-ddfb-11e8-a64b-2ef904c43a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.770929ms
Nov  1 17:27:09.641: INFO: Pod "pod-projected-configmaps-5b78fc55-ddfb-11e8-a64b-2ef904c43a0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020615359s
STEP: Saw pod success
Nov  1 17:27:09.646: INFO: Pod "pod-projected-configmaps-5b78fc55-ddfb-11e8-a64b-2ef904c43a0d" satisfied condition "success or failure"
Nov  1 17:27:09.652: INFO: Trying to get logs from node machine-kubermatic-conformancecluster-u9hs2qwgfl-gvuzo pod pod-projected-configmaps-5b78fc55-ddfb-11e8-a64b-2ef904c43a0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  1 17:27:09.725: INFO: Waiting for pod pod-projected-configmaps-5b78fc55-ddfb-11e8-a64b-2ef904c43a0d to disappear
Nov  1 17:27:09.740: INFO: Pod pod-projected-configmaps-5b78fc55-ddfb-11e8-a64b-2ef904c43a0d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  1 17:27:09.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jdhks" for this suite.
Nov  1 17:27:15.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  1 17:27:16.040: INFO: namespace: e2e-tests-projected-jdhks, resource: bindings, ignored listing per whitelist
Nov  1 17:27:16.232: INFO: namespace e2e-tests-projected-jdhks deletion completed in 6.47145237s

• [SLOW TEST:9.065 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSNov  1 17:27:16.236: INFO: Running AfterSuite actions on all node
Nov  1 17:27:16.236: INFO: Running AfterSuite actions on node 1
Nov  1 17:27:16.236: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5921.262 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h38m42.797497415s
Test Suite Passed
