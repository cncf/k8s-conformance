Nov  7 12:28:00.504: INFO: Overriding default scale value of zero to 1
Nov  7 12:28:00.504: INFO: Overriding default milliseconds value of zero to 5000
I1107 12:28:01.012929      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-030573999
I1107 12:28:01.013181      15 e2e.go:304] Starting e2e run "90991240-e288-11e8-bb28-1ed0160468e8" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1541593680 - Will randomize all specs
Will run 188 of 1814 specs

Nov  7 12:28:01.460: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 12:28:01.464: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  7 12:28:01.480: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  7 12:28:01.528: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  7 12:28:01.528: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Nov  7 12:28:01.528: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  7 12:28:01.538: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov  7 12:28:01.538: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Nov  7 12:28:01.538: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Nov  7 12:28:01.538: INFO: e2e test version: v1.12.1
Nov  7 12:28:01.540: INFO: kube-apiserver version: v1.12.2
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:28:01.541: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
Nov  7 12:28:01.672: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov  7 12:28:01.685: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dctsr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 12:28:01.811: INFO: Waiting up to 5m0s for pod "downwardapi-volume-916c4fb1-e288-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-dctsr" to be "success or failure"
Nov  7 12:28:01.816: INFO: Pod "downwardapi-volume-916c4fb1-e288-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.750566ms
Nov  7 12:28:03.840: INFO: Pod "downwardapi-volume-916c4fb1-e288-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028643315s
Nov  7 12:28:05.845: INFO: Pod "downwardapi-volume-916c4fb1-e288-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033698827s
STEP: Saw pod success
Nov  7 12:28:05.845: INFO: Pod "downwardapi-volume-916c4fb1-e288-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:28:05.940: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-916c4fb1-e288-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 12:28:06.116: INFO: Waiting for pod downwardapi-volume-916c4fb1-e288-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:28:06.119: INFO: Pod downwardapi-volume-916c4fb1-e288-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:28:06.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dctsr" for this suite.
Nov  7 12:28:12.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:28:12.192: INFO: namespace: e2e-tests-downward-api-dctsr, resource: bindings, ignored listing per whitelist
Nov  7 12:28:12.294: INFO: namespace e2e-tests-downward-api-dctsr deletion completed in 6.161279886s

• [SLOW TEST:10.754 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:28:12.295: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-fb8pr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fb8pr
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Nov  7 12:28:12.508: INFO: Found 0 stateful pods, waiting for 3
Nov  7 12:28:22.514: INFO: Found 2 stateful pods, waiting for 3
Nov  7 12:28:32.513: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:28:32.513: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:28:32.513: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov  7 12:28:32.538: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  7 12:28:42.574: INFO: Updating stateful set ss2
Nov  7 12:28:42.580: INFO: Waiting for Pod e2e-tests-statefulset-fb8pr/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Nov  7 12:28:52.620: INFO: Found 2 stateful pods, waiting for 3
Nov  7 12:29:02.624: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:29:02.624: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:29:02.624: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  7 12:29:02.648: INFO: Updating stateful set ss2
Nov  7 12:29:02.655: INFO: Waiting for Pod e2e-tests-statefulset-fb8pr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  7 12:29:12.679: INFO: Updating stateful set ss2
Nov  7 12:29:12.685: INFO: Waiting for StatefulSet e2e-tests-statefulset-fb8pr/ss2 to complete update
Nov  7 12:29:12.685: INFO: Waiting for Pod e2e-tests-statefulset-fb8pr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  7 12:29:22.693: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fb8pr
Nov  7 12:29:22.697: INFO: Scaling statefulset ss2 to 0
Nov  7 12:29:42.711: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 12:29:42.714: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:29:42.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fb8pr" for this suite.
Nov  7 12:29:48.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:29:48.872: INFO: namespace: e2e-tests-statefulset-fb8pr, resource: bindings, ignored listing per whitelist
Nov  7 12:29:48.946: INFO: namespace e2e-tests-statefulset-fb8pr deletion completed in 6.218018177s

• [SLOW TEST:96.652 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:29:48.947: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-tzwmp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-t4bk
STEP: Creating a pod to test atomic-volume-subpath
Nov  7 12:29:49.158: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-t4bk" in namespace "e2e-tests-subpath-tzwmp" to be "success or failure"
Nov  7 12:29:49.162: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.378927ms
Nov  7 12:29:51.166: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007609302s
Nov  7 12:29:53.171: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011755026s
Nov  7 12:29:55.175: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 6.01579118s
Nov  7 12:29:57.182: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 8.022878374s
Nov  7 12:29:59.186: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 10.027398421s
Nov  7 12:30:01.190: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 12.031595116s
Nov  7 12:30:03.195: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 14.036282032s
Nov  7 12:30:05.199: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 16.040492152s
Nov  7 12:30:07.203: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 18.044649501s
Nov  7 12:30:09.208: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 20.048973435s
Nov  7 12:30:11.218: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 22.05881677s
Nov  7 12:30:13.224: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Running", Reason="", readiness=false. Elapsed: 24.065156776s
Nov  7 12:30:15.233: INFO: Pod "pod-subpath-test-projected-t4bk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.07429207s
STEP: Saw pod success
Nov  7 12:30:15.233: INFO: Pod "pod-subpath-test-projected-t4bk" satisfied condition "success or failure"
Nov  7 12:30:15.236: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-subpath-test-projected-t4bk container test-container-subpath-projected-t4bk: <nil>
STEP: delete the pod
Nov  7 12:30:15.261: INFO: Waiting for pod pod-subpath-test-projected-t4bk to disappear
Nov  7 12:30:15.271: INFO: Pod pod-subpath-test-projected-t4bk no longer exists
STEP: Deleting pod pod-subpath-test-projected-t4bk
Nov  7 12:30:15.275: INFO: Deleting pod "pod-subpath-test-projected-t4bk" in namespace "e2e-tests-subpath-tzwmp"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:30:15.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-tzwmp" for this suite.
Nov  7 12:30:21.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:30:21.421: INFO: namespace: e2e-tests-subpath-tzwmp, resource: bindings, ignored listing per whitelist
Nov  7 12:30:21.485: INFO: namespace e2e-tests-subpath-tzwmp deletion completed in 6.197993731s

• [SLOW TEST:32.538 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:30:21.485: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-46vsc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Nov  7 12:30:21.715: INFO: Waiting up to 5m0s for pod "client-containers-e4d031ac-e288-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-containers-46vsc" to be "success or failure"
Nov  7 12:30:21.719: INFO: Pod "client-containers-e4d031ac-e288-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.58937ms
Nov  7 12:30:23.722: INFO: Pod "client-containers-e4d031ac-e288-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00743361s
Nov  7 12:30:25.741: INFO: Pod "client-containers-e4d031ac-e288-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026079756s
STEP: Saw pod success
Nov  7 12:30:25.741: INFO: Pod "client-containers-e4d031ac-e288-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:30:25.745: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod client-containers-e4d031ac-e288-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 12:30:25.765: INFO: Waiting for pod client-containers-e4d031ac-e288-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:30:25.784: INFO: Pod client-containers-e4d031ac-e288-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:30:25.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-46vsc" for this suite.
Nov  7 12:30:31.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:30:31.939: INFO: namespace: e2e-tests-containers-46vsc, resource: bindings, ignored listing per whitelist
Nov  7 12:30:31.971: INFO: namespace e2e-tests-containers-46vsc deletion completed in 6.181990454s

• [SLOW TEST:10.486 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:30:31.972: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qfkc2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-eb0e44e1-e288-11e8-bb28-1ed0160468e8
STEP: Creating secret with name secret-projected-all-test-volume-eb0e44c5-e288-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  7 12:30:32.194: INFO: Waiting up to 5m0s for pod "projected-volume-eb0e3e37-e288-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-qfkc2" to be "success or failure"
Nov  7 12:30:32.199: INFO: Pod "projected-volume-eb0e3e37-e288-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.6549ms
Nov  7 12:30:34.202: INFO: Pod "projected-volume-eb0e3e37-e288-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008121482s
STEP: Saw pod success
Nov  7 12:30:34.202: INFO: Pod "projected-volume-eb0e3e37-e288-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:30:34.205: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod projected-volume-eb0e3e37-e288-11e8-bb28-1ed0160468e8 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  7 12:30:34.225: INFO: Waiting for pod projected-volume-eb0e3e37-e288-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:30:34.235: INFO: Pod projected-volume-eb0e3e37-e288-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:30:34.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qfkc2" for this suite.
Nov  7 12:30:40.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:30:40.333: INFO: namespace: e2e-tests-projected-qfkc2, resource: bindings, ignored listing per whitelist
Nov  7 12:30:40.404: INFO: namespace e2e-tests-projected-qfkc2 deletion completed in 6.16460884s

• [SLOW TEST:8.432 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:30:40.404: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-q9tnm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  7 12:30:40.617: INFO: Waiting up to 5m0s for pod "pod-f014839c-e288-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-q9tnm" to be "success or failure"
Nov  7 12:30:40.620: INFO: Pod "pod-f014839c-e288-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.78063ms
Nov  7 12:30:42.625: INFO: Pod "pod-f014839c-e288-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00716402s
STEP: Saw pod success
Nov  7 12:30:42.625: INFO: Pod "pod-f014839c-e288-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:30:42.628: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-f014839c-e288-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 12:30:42.655: INFO: Waiting for pod pod-f014839c-e288-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:30:42.666: INFO: Pod pod-f014839c-e288-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:30:42.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q9tnm" for this suite.
Nov  7 12:30:48.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:30:48.934: INFO: namespace: e2e-tests-emptydir-q9tnm, resource: bindings, ignored listing per whitelist
Nov  7 12:30:48.948: INFO: namespace e2e-tests-emptydir-q9tnm deletion completed in 6.265269993s

• [SLOW TEST:8.544 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:30:48.948: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mwcqj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 12:30:49.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f52b500b-e288-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-mwcqj" to be "success or failure"
Nov  7 12:30:49.157: INFO: Pod "downwardapi-volume-f52b500b-e288-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.381433ms
Nov  7 12:30:51.161: INFO: Pod "downwardapi-volume-f52b500b-e288-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006387624s
STEP: Saw pod success
Nov  7 12:30:51.161: INFO: Pod "downwardapi-volume-f52b500b-e288-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:30:51.239: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-f52b500b-e288-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 12:30:51.258: INFO: Waiting for pod downwardapi-volume-f52b500b-e288-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:30:51.261: INFO: Pod downwardapi-volume-f52b500b-e288-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:30:51.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mwcqj" for this suite.
Nov  7 12:30:57.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:30:57.373: INFO: namespace: e2e-tests-projected-mwcqj, resource: bindings, ignored listing per whitelist
Nov  7 12:30:57.438: INFO: namespace e2e-tests-projected-mwcqj deletion completed in 6.173267993s

• [SLOW TEST:8.490 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:30:57.439: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kkqxr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 12:30:57.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa3cf2f2-e288-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-kkqxr" to be "success or failure"
Nov  7 12:30:57.664: INFO: Pod "downwardapi-volume-fa3cf2f2-e288-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.399694ms
Nov  7 12:30:59.668: INFO: Pod "downwardapi-volume-fa3cf2f2-e288-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006179759s
STEP: Saw pod success
Nov  7 12:30:59.668: INFO: Pod "downwardapi-volume-fa3cf2f2-e288-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:30:59.670: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-fa3cf2f2-e288-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 12:30:59.736: INFO: Waiting for pod downwardapi-volume-fa3cf2f2-e288-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:30:59.798: INFO: Pod downwardapi-volume-fa3cf2f2-e288-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:30:59.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kkqxr" for this suite.
Nov  7 12:31:05.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:31:05.853: INFO: namespace: e2e-tests-downward-api-kkqxr, resource: bindings, ignored listing per whitelist
Nov  7 12:31:06.006: INFO: namespace e2e-tests-downward-api-kkqxr deletion completed in 6.204761894s

• [SLOW TEST:8.568 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:31:06.007: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-x67p8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-x67p8
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Nov  7 12:31:06.272: INFO: Found 0 stateful pods, waiting for 3
Nov  7 12:31:16.277: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:31:16.277: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:31:16.277: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:31:16.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-x67p8 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 12:31:16.737: INFO: stderr: ""
Nov  7 12:31:16.737: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 12:31:16.737: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov  7 12:31:26.769: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  7 12:31:36.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-x67p8 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:31:37.290: INFO: stderr: ""
Nov  7 12:31:37.290: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  7 12:31:37.290: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  7 12:31:47.352: INFO: Waiting for StatefulSet e2e-tests-statefulset-x67p8/ss2 to complete update
Nov  7 12:31:47.352: INFO: Waiting for Pod e2e-tests-statefulset-x67p8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  7 12:31:47.352: INFO: Waiting for Pod e2e-tests-statefulset-x67p8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  7 12:31:47.352: INFO: Waiting for Pod e2e-tests-statefulset-x67p8/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  7 12:31:57.360: INFO: Waiting for StatefulSet e2e-tests-statefulset-x67p8/ss2 to complete update
Nov  7 12:31:57.360: INFO: Waiting for Pod e2e-tests-statefulset-x67p8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  7 12:32:07.359: INFO: Waiting for StatefulSet e2e-tests-statefulset-x67p8/ss2 to complete update
Nov  7 12:32:07.359: INFO: Waiting for Pod e2e-tests-statefulset-x67p8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Nov  7 12:32:17.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-x67p8 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 12:32:17.856: INFO: stderr: ""
Nov  7 12:32:17.856: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 12:32:17.856: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 12:32:27.888: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  7 12:32:37.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-x67p8 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:32:38.429: INFO: stderr: ""
Nov  7 12:32:38.429: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  7 12:32:38.429: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  7 12:32:48.547: INFO: Waiting for StatefulSet e2e-tests-statefulset-x67p8/ss2 to complete update
Nov  7 12:32:48.547: INFO: Waiting for Pod e2e-tests-statefulset-x67p8/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov  7 12:32:48.547: INFO: Waiting for Pod e2e-tests-statefulset-x67p8/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov  7 12:32:58.561: INFO: Waiting for StatefulSet e2e-tests-statefulset-x67p8/ss2 to complete update
Nov  7 12:32:58.561: INFO: Waiting for Pod e2e-tests-statefulset-x67p8/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov  7 12:33:08.639: INFO: Waiting for StatefulSet e2e-tests-statefulset-x67p8/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  7 12:33:18.560: INFO: Deleting all statefulset in ns e2e-tests-statefulset-x67p8
Nov  7 12:33:18.564: INFO: Scaling statefulset ss2 to 0
Nov  7 12:33:48.581: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 12:33:48.584: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:33:48.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-x67p8" for this suite.
Nov  7 12:33:54.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:33:54.628: INFO: namespace: e2e-tests-statefulset-x67p8, resource: bindings, ignored listing per whitelist
Nov  7 12:33:54.731: INFO: namespace e2e-tests-statefulset-x67p8 deletion completed in 6.132238292s

• [SLOW TEST:168.724 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:33:54.731: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-825wb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-63ef7160-e289-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 12:33:54.994: INFO: Waiting up to 5m0s for pod "pod-configmaps-63effec4-e289-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-825wb" to be "success or failure"
Nov  7 12:33:54.997: INFO: Pod "pod-configmaps-63effec4-e289-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.024234ms
Nov  7 12:33:57.042: INFO: Pod "pod-configmaps-63effec4-e289-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.048241479s
STEP: Saw pod success
Nov  7 12:33:57.042: INFO: Pod "pod-configmaps-63effec4-e289-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:33:57.045: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-63effec4-e289-11e8-bb28-1ed0160468e8 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 12:33:57.074: INFO: Waiting for pod pod-configmaps-63effec4-e289-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:33:57.076: INFO: Pod pod-configmaps-63effec4-e289-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:33:57.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-825wb" for this suite.
Nov  7 12:34:03.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:34:03.327: INFO: namespace: e2e-tests-configmap-825wb, resource: bindings, ignored listing per whitelist
Nov  7 12:34:03.387: INFO: namespace e2e-tests-configmap-825wb deletion completed in 6.305353007s

• [SLOW TEST:8.656 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:34:03.388: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-g2qd2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  7 12:34:03.610: INFO: Number of nodes with available pods: 0
Nov  7 12:34:03.610: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 12:34:04.618: INFO: Number of nodes with available pods: 0
Nov  7 12:34:04.618: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 12:34:05.619: INFO: Number of nodes with available pods: 0
Nov  7 12:34:05.619: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 12:34:06.618: INFO: Number of nodes with available pods: 2
Nov  7 12:34:06.618: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  7 12:34:06.637: INFO: Number of nodes with available pods: 1
Nov  7 12:34:06.637: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:07.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:07.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:08.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:08.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:09.645: INFO: Number of nodes with available pods: 1
Nov  7 12:34:09.645: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:10.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:10.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:11.647: INFO: Number of nodes with available pods: 1
Nov  7 12:34:11.647: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:12.646: INFO: Number of nodes with available pods: 1
Nov  7 12:34:12.646: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:13.645: INFO: Number of nodes with available pods: 1
Nov  7 12:34:13.645: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:14.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:14.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:15.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:15.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:16.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:16.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:17.645: INFO: Number of nodes with available pods: 1
Nov  7 12:34:17.645: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:18.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:18.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:19.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:19.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:20.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:20.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:21.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:21.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:22.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:22.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:23.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:23.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:24.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:24.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:25.643: INFO: Number of nodes with available pods: 1
Nov  7 12:34:25.643: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:26.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:26.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:27.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:27.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:28.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:28.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:29.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:29.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:30.643: INFO: Number of nodes with available pods: 1
Nov  7 12:34:30.643: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:31.643: INFO: Number of nodes with available pods: 1
Nov  7 12:34:31.643: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:32.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:32.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:33.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:33.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:34.742: INFO: Number of nodes with available pods: 1
Nov  7 12:34:34.742: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:35.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:35.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:36.739: INFO: Number of nodes with available pods: 1
Nov  7 12:34:36.739: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:37.645: INFO: Number of nodes with available pods: 1
Nov  7 12:34:37.645: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:38.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:38.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:39.644: INFO: Number of nodes with available pods: 1
Nov  7 12:34:39.644: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:40.645: INFO: Number of nodes with available pods: 1
Nov  7 12:34:40.645: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:41.645: INFO: Number of nodes with available pods: 1
Nov  7 12:34:41.645: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:42.739: INFO: Number of nodes with available pods: 1
Nov  7 12:34:42.739: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 is running more than one daemon pod
Nov  7 12:34:43.739: INFO: Number of nodes with available pods: 2
Nov  7 12:34:43.739: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-g2qd2, will wait for the garbage collector to delete the pods
Nov  7 12:34:43.803: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.595803ms
Nov  7 12:34:43.903: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.488347ms
Nov  7 12:35:24.507: INFO: Number of nodes with available pods: 0
Nov  7 12:35:24.507: INFO: Number of running nodes: 0, number of available pods: 0
Nov  7 12:35:24.512: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-g2qd2/daemonsets","resourceVersion":"6698"},"items":null}

Nov  7 12:35:24.516: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-g2qd2/pods","resourceVersion":"6698"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:35:24.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-g2qd2" for this suite.
Nov  7 12:35:30.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:35:30.707: INFO: namespace: e2e-tests-daemonsets-g2qd2, resource: bindings, ignored listing per whitelist
Nov  7 12:35:30.745: INFO: namespace e2e-tests-daemonsets-g2qd2 deletion completed in 6.217928265s

• [SLOW TEST:87.357 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:35:30.746: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-hjjw2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  7 12:35:33.539: INFO: Successfully updated pod "pod-update-activedeadlineseconds-9d227bf9-e289-11e8-bb28-1ed0160468e8"
Nov  7 12:35:33.539: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-9d227bf9-e289-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-pods-hjjw2" to be "terminated due to deadline exceeded"
Nov  7 12:35:33.542: INFO: Pod "pod-update-activedeadlineseconds-9d227bf9-e289-11e8-bb28-1ed0160468e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.714383ms
Nov  7 12:35:35.546: INFO: Pod "pod-update-activedeadlineseconds-9d227bf9-e289-11e8-bb28-1ed0160468e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.007220638s
Nov  7 12:35:37.549: INFO: Pod "pod-update-activedeadlineseconds-9d227bf9-e289-11e8-bb28-1ed0160468e8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.010505531s
Nov  7 12:35:37.550: INFO: Pod "pod-update-activedeadlineseconds-9d227bf9-e289-11e8-bb28-1ed0160468e8" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:35:37.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hjjw2" for this suite.
Nov  7 12:35:43.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:35:43.700: INFO: namespace: e2e-tests-pods-hjjw2, resource: bindings, ignored listing per whitelist
Nov  7 12:35:43.770: INFO: namespace e2e-tests-pods-hjjw2 deletion completed in 6.216520729s

• [SLOW TEST:13.024 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:35:43.770: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-hnzt4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hnzt4 A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-hnzt4;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hnzt4 A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-hnzt4;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hnzt4.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hnzt4.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hnzt4.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hnzt4.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-hnzt4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hnzt4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 152.65.66.100.in-addr.arpa. PTR)" && echo OK > /results/100.66.65.152_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 152.65.66.100.in-addr.arpa. PTR)" && echo OK > /results/100.66.65.152_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hnzt4 A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-hnzt4;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hnzt4 A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-hnzt4;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hnzt4.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hnzt4.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hnzt4.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-hnzt4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hnzt4.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-hnzt4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hnzt4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 152.65.66.100.in-addr.arpa. PTR)" && echo OK > /results/100.66.65.152_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 152.65.66.100.in-addr.arpa. PTR)" && echo OK > /results/100.66.65.152_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  7 12:36:12.083: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.188: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.232: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-hnzt4 from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.238: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-hnzt4 from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.243: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-hnzt4.svc from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.248: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-hnzt4.svc from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.253: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.258: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.691: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.697: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.746: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-hnzt4 from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.752: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-hnzt4 from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.757: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-hnzt4.svc from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.762: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-hnzt4.svc from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.767: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:12.772: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc from pod e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8: the server could not find the requested resource (get pods dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8)
Nov  7 12:36:13.122: INFO: Lookups using e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-hnzt4 wheezy_tcp@dns-test-service.e2e-tests-dns-hnzt4 wheezy_udp@dns-test-service.e2e-tests-dns-hnzt4.svc wheezy_tcp@dns-test-service.e2e-tests-dns-hnzt4.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-hnzt4 jessie_tcp@dns-test-service.e2e-tests-dns-hnzt4 jessie_udp@dns-test-service.e2e-tests-dns-hnzt4.svc jessie_tcp@dns-test-service.e2e-tests-dns-hnzt4.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hnzt4.svc]

Nov  7 12:36:23.793: INFO: DNS probes using e2e-tests-dns-hnzt4/dns-test-a4e8bbf3-e289-11e8-bb28-1ed0160468e8 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:36:23.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-hnzt4" for this suite.
Nov  7 12:36:29.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:36:30.002: INFO: namespace: e2e-tests-dns-hnzt4, resource: bindings, ignored listing per whitelist
Nov  7 12:36:30.037: INFO: namespace e2e-tests-dns-hnzt4 deletion completed in 6.196874535s

• [SLOW TEST:46.267 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:36:30.037: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-jrgrb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-fpmg
STEP: Creating a pod to test atomic-volume-subpath
Nov  7 12:36:30.298: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fpmg" in namespace "e2e-tests-subpath-jrgrb" to be "success or failure"
Nov  7 12:36:30.301: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.756097ms
Nov  7 12:36:32.305: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006767182s
Nov  7 12:36:34.309: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 4.010444319s
Nov  7 12:36:36.314: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 6.015484498s
Nov  7 12:36:38.318: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 8.019417133s
Nov  7 12:36:40.322: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 10.023518455s
Nov  7 12:36:42.326: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 12.027344335s
Nov  7 12:36:44.330: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 14.03144727s
Nov  7 12:36:46.334: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 16.03583109s
Nov  7 12:36:48.339: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 18.040471917s
Nov  7 12:36:50.344: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 20.045320521s
Nov  7 12:36:52.347: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Running", Reason="", readiness=false. Elapsed: 22.048954413s
Nov  7 12:36:54.351: INFO: Pod "pod-subpath-test-configmap-fpmg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052328727s
STEP: Saw pod success
Nov  7 12:36:54.351: INFO: Pod "pod-subpath-test-configmap-fpmg" satisfied condition "success or failure"
Nov  7 12:36:54.353: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-subpath-test-configmap-fpmg container test-container-subpath-configmap-fpmg: <nil>
STEP: delete the pod
Nov  7 12:36:54.416: INFO: Waiting for pod pod-subpath-test-configmap-fpmg to disappear
Nov  7 12:36:54.421: INFO: Pod pod-subpath-test-configmap-fpmg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fpmg
Nov  7 12:36:54.422: INFO: Deleting pod "pod-subpath-test-configmap-fpmg" in namespace "e2e-tests-subpath-jrgrb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:36:54.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jrgrb" for this suite.
Nov  7 12:37:00.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:37:00.461: INFO: namespace: e2e-tests-subpath-jrgrb, resource: bindings, ignored listing per whitelist
Nov  7 12:37:00.588: INFO: namespace e2e-tests-subpath-jrgrb deletion completed in 6.158353615s

• [SLOW TEST:30.551 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:37:00.588: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-j4smp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j4smp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  7 12:37:00.791: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  7 12:37:22.941: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.30:8080/dial?request=hostName&protocol=http&host=100.96.1.29&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-j4smp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 12:37:22.941: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 12:37:23.324: INFO: Waiting for endpoints: map[]
Nov  7 12:37:23.327: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.30:8080/dial?request=hostName&protocol=http&host=100.96.0.15&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-j4smp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 12:37:23.328: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 12:37:23.750: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:37:23.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j4smp" for this suite.
Nov  7 12:37:45.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:37:45.870: INFO: namespace: e2e-tests-pod-network-test-j4smp, resource: bindings, ignored listing per whitelist
Nov  7 12:37:45.999: INFO: namespace e2e-tests-pod-network-test-j4smp deletion completed in 22.245299382s

• [SLOW TEST:45.411 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:37:46.000: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nsl2m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Nov  7 12:37:46.204: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov  7 12:37:46.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:37:47.020: INFO: stderr: ""
Nov  7 12:37:47.020: INFO: stdout: "service/redis-slave created\n"
Nov  7 12:37:47.020: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov  7 12:37:47.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:37:47.241: INFO: stderr: ""
Nov  7 12:37:47.241: INFO: stdout: "service/redis-master created\n"
Nov  7 12:37:47.241: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  7 12:37:47.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:37:47.441: INFO: stderr: ""
Nov  7 12:37:47.441: INFO: stdout: "service/frontend created\n"
Nov  7 12:37:47.441: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov  7 12:37:47.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:37:47.651: INFO: stderr: ""
Nov  7 12:37:47.651: INFO: stdout: "deployment.extensions/frontend created\n"
Nov  7 12:37:47.651: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  7 12:37:47.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:37:47.886: INFO: stderr: ""
Nov  7 12:37:47.886: INFO: stdout: "deployment.extensions/redis-master created\n"
Nov  7 12:37:47.886: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov  7 12:37:47.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:37:48.322: INFO: stderr: ""
Nov  7 12:37:48.322: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Nov  7 12:37:48.322: INFO: Waiting for all frontend pods to be Running.
Nov  7 12:38:08.376: INFO: Waiting for frontend to serve content.
Nov  7 12:38:13.438: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Nov  7 12:38:18.530: INFO: Trying to add a new entry to the guestbook.
Nov  7 12:38:18.595: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov  7 12:38:18.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:38:18.861: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 12:38:18.861: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  7 12:38:18.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:38:18.975: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 12:38:18.975: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  7 12:38:18.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:38:19.121: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 12:38:19.121: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  7 12:38:19.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:38:19.296: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 12:38:19.296: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  7 12:38:19.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:38:19.802: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 12:38:19.802: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  7 12:38:19.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nsl2m'
Nov  7 12:38:20.351: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 12:38:20.351: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:38:20.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nsl2m" for this suite.
Nov  7 12:38:58.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:38:58.444: INFO: namespace: e2e-tests-kubectl-nsl2m, resource: bindings, ignored listing per whitelist
Nov  7 12:38:58.516: INFO: namespace e2e-tests-kubectl-nsl2m deletion completed in 38.151343873s

• [SLOW TEST:72.516 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:38:58.517: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6rtj6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  7 12:38:58.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6rtj6'
Nov  7 12:38:58.824: INFO: stderr: ""
Nov  7 12:38:58.824: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Nov  7 12:38:58.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6rtj6'
Nov  7 12:39:07.956: INFO: stderr: ""
Nov  7 12:39:07.956: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:39:07.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6rtj6" for this suite.
Nov  7 12:39:13.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:39:14.118: INFO: namespace: e2e-tests-kubectl-6rtj6, resource: bindings, ignored listing per whitelist
Nov  7 12:39:14.162: INFO: namespace e2e-tests-kubectl-6rtj6 deletion completed in 6.201611965s

• [SLOW TEST:15.645 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:39:14.162: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-swmfd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 12:39:14.384: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  7 12:39:14.395: INFO: Number of nodes with available pods: 0
Nov  7 12:39:14.395: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 12:39:15.404: INFO: Number of nodes with available pods: 0
Nov  7 12:39:15.404: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 12:39:16.404: INFO: Number of nodes with available pods: 2
Nov  7 12:39:16.404: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  7 12:39:16.423: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:16.424: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:17.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:17.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:18.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:18.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:19.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:19.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:20.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:20.432: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:21.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:21.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:22.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:22.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:23.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:23.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:24.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:24.432: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:25.439: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:25.439: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:26.434: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:26.434: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:27.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:27.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:28.439: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:28.439: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:29.439: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:29.439: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:30.435: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:30.435: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:31.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:31.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:32.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:32.432: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:33.438: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:33.438: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:34.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:34.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:35.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:35.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:36.434: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:36.434: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:37.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:37.432: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:38.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:38.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:39.437: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:39.438: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:40.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:40.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:41.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:41.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:42.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:42.432: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:43.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:43.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:44.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:44.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:45.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:45.432: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:46.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:46.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:47.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:47.432: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:48.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:48.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:49.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:49.432: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:50.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:50.433: INFO: Wrong image for pod: daemon-set-tqb9k. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:50.433: INFO: Pod daemon-set-tqb9k is not available
Nov  7 12:39:51.438: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:51.438: INFO: Pod daemon-set-9lthk is not available
Nov  7 12:39:52.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:52.432: INFO: Pod daemon-set-9lthk is not available
Nov  7 12:39:53.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:54.455: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:55.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:56.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:57.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:58.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:39:59.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:00.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:01.441: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:02.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:03.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:04.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:05.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:06.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:07.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:08.495: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:09.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:10.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:11.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:12.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:13.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:14.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:15.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:16.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:17.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:18.432: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:19.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:20.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:21.434: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:22.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:23.439: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:24.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:24.433: INFO: Pod daemon-set-8mpg6 is not available
Nov  7 12:40:25.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:25.434: INFO: Pod daemon-set-8mpg6 is not available
Nov  7 12:40:26.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:26.433: INFO: Pod daemon-set-8mpg6 is not available
Nov  7 12:40:27.433: INFO: Wrong image for pod: daemon-set-8mpg6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  7 12:40:27.433: INFO: Pod daemon-set-8mpg6 is not available
Nov  7 12:40:28.433: INFO: Pod daemon-set-2455s is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  7 12:40:28.445: INFO: Number of nodes with available pods: 1
Nov  7 12:40:28.445: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 12:40:29.452: INFO: Number of nodes with available pods: 1
Nov  7 12:40:29.452: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 12:40:30.452: INFO: Number of nodes with available pods: 2
Nov  7 12:40:30.452: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-swmfd, will wait for the garbage collector to delete the pods
Nov  7 12:40:30.524: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.568456ms
Nov  7 12:40:30.625: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.53984ms
Nov  7 12:40:34.430: INFO: Number of nodes with available pods: 0
Nov  7 12:40:34.430: INFO: Number of running nodes: 0, number of available pods: 0
Nov  7 12:40:34.432: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-swmfd/daemonsets","resourceVersion":"7632"},"items":null}

Nov  7 12:40:34.435: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-swmfd/pods","resourceVersion":"7632"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:40:34.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-swmfd" for this suite.
Nov  7 12:40:40.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:40:40.649: INFO: namespace: e2e-tests-daemonsets-swmfd, resource: bindings, ignored listing per whitelist
Nov  7 12:40:40.699: INFO: namespace e2e-tests-daemonsets-swmfd deletion completed in 6.245028434s

• [SLOW TEST:86.537 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:40:40.700: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-hdg7v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 12:40:40.937: INFO: (0) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.31866ms)
Nov  7 12:40:40.981: INFO: (1) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.345383ms)
Nov  7 12:40:40.989: INFO: (2) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.156938ms)
Nov  7 12:40:40.995: INFO: (3) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.372805ms)
Nov  7 12:40:41.000: INFO: (4) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.133274ms)
Nov  7 12:40:41.005: INFO: (5) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.980318ms)
Nov  7 12:40:41.010: INFO: (6) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.852592ms)
Nov  7 12:40:41.016: INFO: (7) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.323438ms)
Nov  7 12:40:41.022: INFO: (8) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.217439ms)
Nov  7 12:40:41.027: INFO: (9) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.348079ms)
Nov  7 12:40:41.095: INFO: (10) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 67.659312ms)
Nov  7 12:40:41.100: INFO: (11) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.054907ms)
Nov  7 12:40:41.105: INFO: (12) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.783552ms)
Nov  7 12:40:41.151: INFO: (13) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.971113ms)
Nov  7 12:40:41.157: INFO: (14) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.997487ms)
Nov  7 12:40:41.169: INFO: (15) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.379571ms)
Nov  7 12:40:41.180: INFO: (16) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.667246ms)
Nov  7 12:40:41.185: INFO: (17) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.234927ms)
Nov  7 12:40:41.191: INFO: (18) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.071052ms)
Nov  7 12:40:41.197: INFO: (19) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.135759ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:40:41.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-hdg7v" for this suite.
Nov  7 12:40:47.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:40:47.335: INFO: namespace: e2e-tests-proxy-hdg7v, resource: bindings, ignored listing per whitelist
Nov  7 12:40:47.356: INFO: namespace e2e-tests-proxy-hdg7v deletion completed in 6.156570109s

• [SLOW TEST:6.656 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:40:47.356: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-mlqrn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1107 12:40:57.738780      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  7 12:40:57.738: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:40:57.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mlqrn" for this suite.
Nov  7 12:41:03.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:41:03.798: INFO: namespace: e2e-tests-gc-mlqrn, resource: bindings, ignored listing per whitelist
Nov  7 12:41:03.892: INFO: namespace e2e-tests-gc-mlqrn deletion completed in 6.150069418s

• [SLOW TEST:16.536 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:41:03.893: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-g5lfn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-6wd8
STEP: Creating a pod to test atomic-volume-subpath
Nov  7 12:41:04.250: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6wd8" in namespace "e2e-tests-subpath-g5lfn" to be "success or failure"
Nov  7 12:41:04.255: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.806206ms
Nov  7 12:41:06.258: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008068628s
Nov  7 12:41:08.261: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 4.010681516s
Nov  7 12:41:10.264: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 6.014210447s
Nov  7 12:41:12.268: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 8.017428729s
Nov  7 12:41:14.275: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 10.025099061s
Nov  7 12:41:16.278: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 12.02799901s
Nov  7 12:41:18.282: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 14.032057271s
Nov  7 12:41:20.286: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 16.036202619s
Nov  7 12:41:22.295: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 18.045222683s
Nov  7 12:41:24.300: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 20.049373056s
Nov  7 12:41:26.304: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Running", Reason="", readiness=false. Elapsed: 22.053759507s
Nov  7 12:41:28.308: INFO: Pod "pod-subpath-test-secret-6wd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.058190255s
STEP: Saw pod success
Nov  7 12:41:28.309: INFO: Pod "pod-subpath-test-secret-6wd8" satisfied condition "success or failure"
Nov  7 12:41:28.313: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-subpath-test-secret-6wd8 container test-container-subpath-secret-6wd8: <nil>
STEP: delete the pod
Nov  7 12:41:28.380: INFO: Waiting for pod pod-subpath-test-secret-6wd8 to disappear
Nov  7 12:41:28.414: INFO: Pod pod-subpath-test-secret-6wd8 no longer exists
STEP: Deleting pod pod-subpath-test-secret-6wd8
Nov  7 12:41:28.414: INFO: Deleting pod "pod-subpath-test-secret-6wd8" in namespace "e2e-tests-subpath-g5lfn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:41:28.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-g5lfn" for this suite.
Nov  7 12:41:34.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:41:34.547: INFO: namespace: e2e-tests-subpath-g5lfn, resource: bindings, ignored listing per whitelist
Nov  7 12:41:34.549: INFO: namespace e2e-tests-subpath-g5lfn deletion completed in 6.121706465s

• [SLOW TEST:30.656 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:41:34.549: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-v9zh7
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-75fab1f3-e28a-11e8-bb28-1ed0160468e8
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:41:36.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v9zh7" for this suite.
Nov  7 12:41:58.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:41:58.917: INFO: namespace: e2e-tests-configmap-v9zh7, resource: bindings, ignored listing per whitelist
Nov  7 12:41:59.019: INFO: namespace e2e-tests-configmap-v9zh7 deletion completed in 22.148983215s

• [SLOW TEST:24.470 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:41:59.020: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-f2spc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:41:59.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-f2spc" for this suite.
Nov  7 12:42:05.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:42:05.340: INFO: namespace: e2e-tests-services-f2spc, resource: bindings, ignored listing per whitelist
Nov  7 12:42:05.384: INFO: namespace e2e-tests-services-f2spc deletion completed in 6.156204531s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.365 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:42:05.385: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cgqgh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8860a215-e28a-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 12:42:05.629: INFO: Waiting up to 5m0s for pod "pod-secrets-886128dc-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-cgqgh" to be "success or failure"
Nov  7 12:42:05.633: INFO: Pod "pod-secrets-886128dc-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.523508ms
Nov  7 12:42:07.638: INFO: Pod "pod-secrets-886128dc-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009333566s
Nov  7 12:42:09.645: INFO: Pod "pod-secrets-886128dc-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016201208s
STEP: Saw pod success
Nov  7 12:42:09.645: INFO: Pod "pod-secrets-886128dc-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:42:09.648: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-secrets-886128dc-e28a-11e8-bb28-1ed0160468e8 container secret-volume-test: <nil>
STEP: delete the pod
Nov  7 12:42:09.705: INFO: Waiting for pod pod-secrets-886128dc-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:42:09.711: INFO: Pod pod-secrets-886128dc-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:42:09.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cgqgh" for this suite.
Nov  7 12:42:15.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:42:15.912: INFO: namespace: e2e-tests-secrets-cgqgh, resource: bindings, ignored listing per whitelist
Nov  7 12:42:15.998: INFO: namespace e2e-tests-secrets-cgqgh deletion completed in 6.281033248s

• [SLOW TEST:10.613 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:42:15.998: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gj4fd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8eb47ba4-e28a-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 12:42:16.244: INFO: Waiting up to 5m0s for pod "pod-configmaps-8eb4fa57-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-gj4fd" to be "success or failure"
Nov  7 12:42:16.247: INFO: Pod "pod-configmaps-8eb4fa57-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.347684ms
Nov  7 12:42:18.295: INFO: Pod "pod-configmaps-8eb4fa57-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050701239s
STEP: Saw pod success
Nov  7 12:42:18.295: INFO: Pod "pod-configmaps-8eb4fa57-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:42:18.338: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-8eb4fa57-e28a-11e8-bb28-1ed0160468e8 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 12:42:18.362: INFO: Waiting for pod pod-configmaps-8eb4fa57-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:42:18.365: INFO: Pod pod-configmaps-8eb4fa57-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:42:18.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gj4fd" for this suite.
Nov  7 12:42:24.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:42:24.649: INFO: namespace: e2e-tests-configmap-gj4fd, resource: bindings, ignored listing per whitelist
Nov  7 12:42:24.657: INFO: namespace e2e-tests-configmap-gj4fd deletion completed in 6.287861267s

• [SLOW TEST:8.659 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:42:24.660: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4qpp7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 12:42:24.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93da5b18-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-4qpp7" to be "success or failure"
Nov  7 12:42:24.881: INFO: Pod "downwardapi-volume-93da5b18-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206787ms
Nov  7 12:42:26.885: INFO: Pod "downwardapi-volume-93da5b18-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006337957s
STEP: Saw pod success
Nov  7 12:42:26.885: INFO: Pod "downwardapi-volume-93da5b18-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:42:26.887: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-93da5b18-e28a-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 12:42:26.904: INFO: Waiting for pod downwardapi-volume-93da5b18-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:42:26.940: INFO: Pod downwardapi-volume-93da5b18-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:42:26.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4qpp7" for this suite.
Nov  7 12:42:32.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:42:33.193: INFO: namespace: e2e-tests-downward-api-4qpp7, resource: bindings, ignored listing per whitelist
Nov  7 12:42:33.214: INFO: namespace e2e-tests-downward-api-4qpp7 deletion completed in 6.267806044s

• [SLOW TEST:8.555 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:42:33.215: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-tvdrq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-98f9398a-e28a-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 12:42:33.474: INFO: Waiting up to 5m0s for pod "pod-secrets-98f9cef2-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-tvdrq" to be "success or failure"
Nov  7 12:42:33.477: INFO: Pod "pod-secrets-98f9cef2-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.03204ms
Nov  7 12:42:35.481: INFO: Pod "pod-secrets-98f9cef2-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007051819s
STEP: Saw pod success
Nov  7 12:42:35.481: INFO: Pod "pod-secrets-98f9cef2-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:42:35.484: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-secrets-98f9cef2-e28a-11e8-bb28-1ed0160468e8 container secret-volume-test: <nil>
STEP: delete the pod
Nov  7 12:42:35.512: INFO: Waiting for pod pod-secrets-98f9cef2-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:42:35.520: INFO: Pod pod-secrets-98f9cef2-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:42:35.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tvdrq" for this suite.
Nov  7 12:42:41.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:42:41.627: INFO: namespace: e2e-tests-secrets-tvdrq, resource: bindings, ignored listing per whitelist
Nov  7 12:42:41.696: INFO: namespace e2e-tests-secrets-tvdrq deletion completed in 6.168782647s

• [SLOW TEST:8.481 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:42:41.697: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-25hrk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  7 12:42:42.047: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-25hrk,SelfLink:/api/v1/namespaces/e2e-tests-watch-25hrk/configmaps/e2e-watch-test-label-changed,UID:9e03fb35-e28a-11e8-b11f-bea865258d09,ResourceVersion:8159,Generation:0,CreationTimestamp:2018-11-07 12:42:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  7 12:42:42.047: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-25hrk,SelfLink:/api/v1/namespaces/e2e-tests-watch-25hrk/configmaps/e2e-watch-test-label-changed,UID:9e03fb35-e28a-11e8-b11f-bea865258d09,ResourceVersion:8160,Generation:0,CreationTimestamp:2018-11-07 12:42:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  7 12:42:42.048: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-25hrk,SelfLink:/api/v1/namespaces/e2e-tests-watch-25hrk/configmaps/e2e-watch-test-label-changed,UID:9e03fb35-e28a-11e8-b11f-bea865258d09,ResourceVersion:8161,Generation:0,CreationTimestamp:2018-11-07 12:42:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  7 12:42:52.071: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-25hrk,SelfLink:/api/v1/namespaces/e2e-tests-watch-25hrk/configmaps/e2e-watch-test-label-changed,UID:9e03fb35-e28a-11e8-b11f-bea865258d09,ResourceVersion:8182,Generation:0,CreationTimestamp:2018-11-07 12:42:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  7 12:42:52.071: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-25hrk,SelfLink:/api/v1/namespaces/e2e-tests-watch-25hrk/configmaps/e2e-watch-test-label-changed,UID:9e03fb35-e28a-11e8-b11f-bea865258d09,ResourceVersion:8183,Generation:0,CreationTimestamp:2018-11-07 12:42:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  7 12:42:52.071: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-25hrk,SelfLink:/api/v1/namespaces/e2e-tests-watch-25hrk/configmaps/e2e-watch-test-label-changed,UID:9e03fb35-e28a-11e8-b11f-bea865258d09,ResourceVersion:8184,Generation:0,CreationTimestamp:2018-11-07 12:42:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:42:52.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-25hrk" for this suite.
Nov  7 12:42:58.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:42:58.200: INFO: namespace: e2e-tests-watch-25hrk, resource: bindings, ignored listing per whitelist
Nov  7 12:42:58.325: INFO: namespace e2e-tests-watch-25hrk deletion completed in 6.250155255s

• [SLOW TEST:16.629 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:42:58.326: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-p8fzw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 12:42:58.549: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7ebef6b-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-p8fzw" to be "success or failure"
Nov  7 12:42:58.552: INFO: Pod "downwardapi-volume-a7ebef6b-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.131893ms
Nov  7 12:43:00.556: INFO: Pod "downwardapi-volume-a7ebef6b-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007456579s
Nov  7 12:43:02.560: INFO: Pod "downwardapi-volume-a7ebef6b-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011772725s
STEP: Saw pod success
Nov  7 12:43:02.561: INFO: Pod "downwardapi-volume-a7ebef6b-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:43:02.568: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-a7ebef6b-e28a-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 12:43:02.606: INFO: Waiting for pod downwardapi-volume-a7ebef6b-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:43:02.611: INFO: Pod downwardapi-volume-a7ebef6b-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:43:02.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p8fzw" for this suite.
Nov  7 12:43:08.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:43:08.731: INFO: namespace: e2e-tests-downward-api-p8fzw, resource: bindings, ignored listing per whitelist
Nov  7 12:43:08.753: INFO: namespace e2e-tests-downward-api-p8fzw deletion completed in 6.138950223s

• [SLOW TEST:10.427 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:43:08.753: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fgvbn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ae3e0444-e28a-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 12:43:09.155: INFO: Waiting up to 5m0s for pod "pod-secrets-ae3e90ef-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-fgvbn" to be "success or failure"
Nov  7 12:43:09.157: INFO: Pod "pod-secrets-ae3e90ef-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.493181ms
Nov  7 12:43:11.161: INFO: Pod "pod-secrets-ae3e90ef-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006221254s
STEP: Saw pod success
Nov  7 12:43:11.161: INFO: Pod "pod-secrets-ae3e90ef-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:43:11.164: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-secrets-ae3e90ef-e28a-11e8-bb28-1ed0160468e8 container secret-volume-test: <nil>
STEP: delete the pod
Nov  7 12:43:11.184: INFO: Waiting for pod pod-secrets-ae3e90ef-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:43:11.187: INFO: Pod pod-secrets-ae3e90ef-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:43:11.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fgvbn" for this suite.
Nov  7 12:43:17.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:43:17.399: INFO: namespace: e2e-tests-secrets-fgvbn, resource: bindings, ignored listing per whitelist
Nov  7 12:43:17.402: INFO: namespace e2e-tests-secrets-fgvbn deletion completed in 6.210088329s

• [SLOW TEST:8.649 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:43:17.402: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-tl2zm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b347e615-e28a-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 12:43:17.609: INFO: Waiting up to 5m0s for pod "pod-secrets-b3487548-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-tl2zm" to be "success or failure"
Nov  7 12:43:17.612: INFO: Pod "pod-secrets-b3487548-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.802751ms
Nov  7 12:43:19.616: INFO: Pod "pod-secrets-b3487548-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007548719s
STEP: Saw pod success
Nov  7 12:43:19.617: INFO: Pod "pod-secrets-b3487548-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:43:19.620: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-secrets-b3487548-e28a-11e8-bb28-1ed0160468e8 container secret-volume-test: <nil>
STEP: delete the pod
Nov  7 12:43:19.640: INFO: Waiting for pod pod-secrets-b3487548-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:43:19.643: INFO: Pod pod-secrets-b3487548-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:43:19.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tl2zm" for this suite.
Nov  7 12:43:25.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:43:25.939: INFO: namespace: e2e-tests-secrets-tl2zm, resource: bindings, ignored listing per whitelist
Nov  7 12:43:25.947: INFO: namespace e2e-tests-secrets-tl2zm deletion completed in 6.295756141s

• [SLOW TEST:8.544 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:43:25.947: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-8pd49
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 12:43:44.185: INFO: Container started at 2018-11-07 12:43:27 +0000 UTC, pod became ready at 2018-11-07 12:43:42 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:43:44.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8pd49" for this suite.
Nov  7 12:44:06.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:44:06.361: INFO: namespace: e2e-tests-container-probe-8pd49, resource: bindings, ignored listing per whitelist
Nov  7 12:44:06.399: INFO: namespace e2e-tests-container-probe-8pd49 deletion completed in 22.160629486s

• [SLOW TEST:40.452 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:44:06.399: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2kqcf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-d07cc285-e28a-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 12:44:06.611: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d07d6b50-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-2kqcf" to be "success or failure"
Nov  7 12:44:06.613: INFO: Pod "pod-projected-secrets-d07d6b50-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.481947ms
Nov  7 12:44:08.617: INFO: Pod "pod-projected-secrets-d07d6b50-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00640994s
STEP: Saw pod success
Nov  7 12:44:08.617: INFO: Pod "pod-projected-secrets-d07d6b50-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:44:08.620: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-secrets-d07d6b50-e28a-11e8-bb28-1ed0160468e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  7 12:44:08.647: INFO: Waiting for pod pod-projected-secrets-d07d6b50-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:44:08.657: INFO: Pod pod-projected-secrets-d07d6b50-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:44:08.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2kqcf" for this suite.
Nov  7 12:44:14.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:44:14.693: INFO: namespace: e2e-tests-projected-2kqcf, resource: bindings, ignored listing per whitelist
Nov  7 12:44:14.833: INFO: namespace e2e-tests-projected-2kqcf deletion completed in 6.160338969s

• [SLOW TEST:8.434 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:44:14.834: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-psv6w
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-d58c5d3c-e28a-11e8-bb28-1ed0160468e8
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-d58c5d3c-e28a-11e8-bb28-1ed0160468e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:44:19.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-psv6w" for this suite.
Nov  7 12:44:41.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:44:41.424: INFO: namespace: e2e-tests-configmap-psv6w, resource: bindings, ignored listing per whitelist
Nov  7 12:44:41.506: INFO: namespace e2e-tests-configmap-psv6w deletion completed in 22.201832594s

• [SLOW TEST:26.672 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:44:41.506: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-hz2pq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Nov  7 12:44:41.762: INFO: Waiting up to 5m0s for pod "var-expansion-e570a791-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-var-expansion-hz2pq" to be "success or failure"
Nov  7 12:44:41.766: INFO: Pod "var-expansion-e570a791-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.622463ms
Nov  7 12:44:43.771: INFO: Pod "var-expansion-e570a791-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008826406s
STEP: Saw pod success
Nov  7 12:44:43.771: INFO: Pod "var-expansion-e570a791-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:44:43.774: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod var-expansion-e570a791-e28a-11e8-bb28-1ed0160468e8 container dapi-container: <nil>
STEP: delete the pod
Nov  7 12:44:43.795: INFO: Waiting for pod var-expansion-e570a791-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:44:43.799: INFO: Pod var-expansion-e570a791-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:44:43.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-hz2pq" for this suite.
Nov  7 12:44:49.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:44:50.047: INFO: namespace: e2e-tests-var-expansion-hz2pq, resource: bindings, ignored listing per whitelist
Nov  7 12:44:50.050: INFO: namespace e2e-tests-var-expansion-hz2pq deletion completed in 6.223681174s

• [SLOW TEST:8.544 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:44:50.050: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-46qc4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Nov  7 12:44:50.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:50.541: INFO: stderr: ""
Nov  7 12:44:50.541: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  7 12:44:50.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:50.662: INFO: stderr: ""
Nov  7 12:44:50.662: INFO: stdout: "update-demo-nautilus-6q6l6 update-demo-nautilus-sh2hn "
Nov  7 12:44:50.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-6q6l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:50.798: INFO: stderr: ""
Nov  7 12:44:50.798: INFO: stdout: ""
Nov  7 12:44:50.798: INFO: update-demo-nautilus-6q6l6 is created but not running
Nov  7 12:44:55.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:55.909: INFO: stderr: ""
Nov  7 12:44:55.909: INFO: stdout: "update-demo-nautilus-6q6l6 update-demo-nautilus-sh2hn "
Nov  7 12:44:55.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-6q6l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:56.032: INFO: stderr: ""
Nov  7 12:44:56.032: INFO: stdout: "true"
Nov  7 12:44:56.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-6q6l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:56.132: INFO: stderr: ""
Nov  7 12:44:56.132: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 12:44:56.132: INFO: validating pod update-demo-nautilus-6q6l6
Nov  7 12:44:56.222: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 12:44:56.222: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 12:44:56.222: INFO: update-demo-nautilus-6q6l6 is verified up and running
Nov  7 12:44:56.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-sh2hn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:56.342: INFO: stderr: ""
Nov  7 12:44:56.342: INFO: stdout: "true"
Nov  7 12:44:56.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-sh2hn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:56.437: INFO: stderr: ""
Nov  7 12:44:56.437: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 12:44:56.437: INFO: validating pod update-demo-nautilus-sh2hn
Nov  7 12:44:56.527: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 12:44:56.527: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 12:44:56.527: INFO: update-demo-nautilus-sh2hn is verified up and running
STEP: using delete to clean up resources
Nov  7 12:44:56.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:56.640: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 12:44:56.640: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  7 12:44:56.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-46qc4'
Nov  7 12:44:56.950: INFO: stderr: "No resources found.\n"
Nov  7 12:44:56.950: INFO: stdout: ""
Nov  7 12:44:56.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -l name=update-demo --namespace=e2e-tests-kubectl-46qc4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  7 12:44:57.190: INFO: stderr: ""
Nov  7 12:44:57.190: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:44:57.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-46qc4" for this suite.
Nov  7 12:45:19.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:45:19.314: INFO: namespace: e2e-tests-kubectl-46qc4, resource: bindings, ignored listing per whitelist
Nov  7 12:45:19.371: INFO: namespace e2e-tests-kubectl-46qc4 deletion completed in 22.176676889s

• [SLOW TEST:29.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:45:19.371: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-t9mg2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-fc04e93f-e28a-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 12:45:19.647: INFO: Waiting up to 5m0s for pod "pod-configmaps-fc059646-e28a-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-t9mg2" to be "success or failure"
Nov  7 12:45:19.651: INFO: Pod "pod-configmaps-fc059646-e28a-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.095343ms
Nov  7 12:45:21.657: INFO: Pod "pod-configmaps-fc059646-e28a-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010388001s
STEP: Saw pod success
Nov  7 12:45:21.658: INFO: Pod "pod-configmaps-fc059646-e28a-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:45:21.660: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-fc059646-e28a-11e8-bb28-1ed0160468e8 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 12:45:21.686: INFO: Waiting for pod pod-configmaps-fc059646-e28a-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:45:21.694: INFO: Pod pod-configmaps-fc059646-e28a-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:45:21.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t9mg2" for this suite.
Nov  7 12:45:27.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:45:27.748: INFO: namespace: e2e-tests-configmap-t9mg2, resource: bindings, ignored listing per whitelist
Nov  7 12:45:27.941: INFO: namespace e2e-tests-configmap-t9mg2 deletion completed in 6.23758048s

• [SLOW TEST:8.571 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:45:27.943: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-sc42w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  7 12:45:28.192: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  7 12:45:28.199: INFO: Waiting for terminating namespaces to be deleted...
Nov  7 12:45:28.202: INFO: 
Logging pods the kubelet thinks is on node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 before test
Nov  7 12:45:28.212: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-07 12:27:22 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.212: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  7 12:45:28.212: INFO: calico-node-9gx88 from kube-system started at 2018-11-07 11:49:48 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.212: INFO: 	Container calico-node ready: true, restart count 0
Nov  7 12:45:28.212: INFO: kube-proxy-hpqpq from kube-system started at 2018-11-07 11:50:08 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.213: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  7 12:45:28.213: INFO: node-exporter-rcks9 from kube-system started at 2018-11-07 11:50:08 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.213: INFO: 	Container node-exporter ready: true, restart count 0
Nov  7 12:45:28.213: INFO: sonobuoy-e2e-job-11d5393ce95f4a43 from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 12:45:28.213: INFO: 	Container e2e ready: true, restart count 0
Nov  7 12:45:28.213: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 12:45:28.213: INFO: sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-vf5bm from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 12:45:28.213: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  7 12:45:28.213: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 12:45:28.213: INFO: 
Logging pods the kubelet thinks is on node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 before test
Nov  7 12:45:28.351: INFO: sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-6kbp8 from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  7 12:45:28.351: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 12:45:28.351: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6584cc89bc-2pdr5 from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Nov  7 12:45:28.351: INFO: node-exporter-fsx8z from kube-system started at 2018-11-07 11:50:04 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container node-exporter ready: true, restart count 0
Nov  7 12:45:28.351: INFO: metrics-server-798b4c47df-rk5ck from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container metrics-server ready: true, restart count 0
Nov  7 12:45:28.351: INFO: kube-proxy-94vmw from kube-system started at 2018-11-07 11:50:04 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  7 12:45:28.351: INFO: addons-kubernetes-dashboard-789b6fcb7f-7jndw from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container main ready: true, restart count 0
Nov  7 12:45:28.351: INFO: vpn-shoot-74f549f48c-dkl4f from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container vpn-shoot ready: true, restart count 0
Nov  7 12:45:28.351: INFO: coredns-996685c97-zcd9g from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container coredns ready: true, restart count 0
Nov  7 12:45:28.351: INFO: calico-node-lsrvf from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container calico-node ready: true, restart count 0
Nov  7 12:45:28.351: INFO: addons-nginx-ingress-controller-5d8ff96544-94wtl from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:28.351: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1564d83ce0f4e46b], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:45:29.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-sc42w" for this suite.
Nov  7 12:45:35.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:45:35.448: INFO: namespace: e2e-tests-sched-pred-sc42w, resource: bindings, ignored listing per whitelist
Nov  7 12:45:35.625: INFO: namespace e2e-tests-sched-pred-sc42w deletion completed in 6.241327503s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.682 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:45:35.625: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-xstvv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  7 12:45:35.841: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  7 12:45:35.850: INFO: Waiting for terminating namespaces to be deleted...
Nov  7 12:45:35.862: INFO: 
Logging pods the kubelet thinks is on node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 before test
Nov  7 12:45:35.874: INFO: calico-node-9gx88 from kube-system started at 2018-11-07 11:49:48 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.874: INFO: 	Container calico-node ready: true, restart count 0
Nov  7 12:45:35.874: INFO: kube-proxy-hpqpq from kube-system started at 2018-11-07 11:50:08 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.874: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  7 12:45:35.874: INFO: node-exporter-rcks9 from kube-system started at 2018-11-07 11:50:08 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.874: INFO: 	Container node-exporter ready: true, restart count 0
Nov  7 12:45:35.874: INFO: sonobuoy-e2e-job-11d5393ce95f4a43 from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 12:45:35.874: INFO: 	Container e2e ready: true, restart count 0
Nov  7 12:45:35.874: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 12:45:35.874: INFO: sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-vf5bm from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 12:45:35.874: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  7 12:45:35.874: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 12:45:35.874: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-07 12:27:22 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.874: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  7 12:45:35.874: INFO: 
Logging pods the kubelet thinks is on node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 before test
Nov  7 12:45:35.950: INFO: addons-nginx-ingress-controller-5d8ff96544-94wtl from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Nov  7 12:45:35.950: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6584cc89bc-2pdr5 from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Nov  7 12:45:35.950: INFO: node-exporter-fsx8z from kube-system started at 2018-11-07 11:50:04 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container node-exporter ready: true, restart count 0
Nov  7 12:45:35.950: INFO: sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-6kbp8 from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  7 12:45:35.950: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 12:45:35.950: INFO: addons-kubernetes-dashboard-789b6fcb7f-7jndw from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container main ready: true, restart count 0
Nov  7 12:45:35.950: INFO: vpn-shoot-74f549f48c-dkl4f from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container vpn-shoot ready: true, restart count 0
Nov  7 12:45:35.950: INFO: metrics-server-798b4c47df-rk5ck from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container metrics-server ready: true, restart count 0
Nov  7 12:45:35.950: INFO: kube-proxy-94vmw from kube-system started at 2018-11-07 11:50:04 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  7 12:45:35.950: INFO: coredns-996685c97-zcd9g from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container coredns ready: true, restart count 0
Nov  7 12:45:35.950: INFO: calico-node-lsrvf from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 12:45:35.950: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-06f4aa35-e28b-11e8-bb28-1ed0160468e8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-06f4aa35-e28b-11e8-bb28-1ed0160468e8 off the node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
STEP: verifying the node doesn't have the label kubernetes.io/e2e-06f4aa35-e28b-11e8-bb28-1ed0160468e8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:45:40.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xstvv" for this suite.
Nov  7 12:46:10.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:46:10.271: INFO: namespace: e2e-tests-sched-pred-xstvv, resource: bindings, ignored listing per whitelist
Nov  7 12:46:10.297: INFO: namespace e2e-tests-sched-pred-xstvv deletion completed in 30.237281465s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:34.672 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:46:10.297: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-tfc9m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:47:10.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tfc9m" for this suite.
Nov  7 12:47:32.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:47:32.728: INFO: namespace: e2e-tests-container-probe-tfc9m, resource: bindings, ignored listing per whitelist
Nov  7 12:47:32.748: INFO: namespace e2e-tests-container-probe-tfc9m deletion completed in 22.199210275s

• [SLOW TEST:82.451 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:47:32.749: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-87lpz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 12:47:35.009: INFO: Waiting up to 5m0s for pod "client-envvars-4cb4dd9d-e28b-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-pods-87lpz" to be "success or failure"
Nov  7 12:47:35.014: INFO: Pod "client-envvars-4cb4dd9d-e28b-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.91846ms
Nov  7 12:47:37.037: INFO: Pod "client-envvars-4cb4dd9d-e28b-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02815614s
STEP: Saw pod success
Nov  7 12:47:37.037: INFO: Pod "client-envvars-4cb4dd9d-e28b-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:47:37.041: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod client-envvars-4cb4dd9d-e28b-11e8-bb28-1ed0160468e8 container env3cont: <nil>
STEP: delete the pod
Nov  7 12:47:37.061: INFO: Waiting for pod client-envvars-4cb4dd9d-e28b-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:47:37.068: INFO: Pod client-envvars-4cb4dd9d-e28b-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:47:37.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-87lpz" for this suite.
Nov  7 12:48:19.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:48:19.108: INFO: namespace: e2e-tests-pods-87lpz, resource: bindings, ignored listing per whitelist
Nov  7 12:48:19.241: INFO: namespace e2e-tests-pods-87lpz deletion completed in 42.170077776s

• [SLOW TEST:46.492 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:48:19.242: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-zsmfm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zsmfm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  7 12:48:19.499: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  7 12:48:43.578: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.0.26:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zsmfm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 12:48:43.578: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 12:48:44.006: INFO: Found all expected endpoints: [netserver-0]
Nov  7 12:48:44.009: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.1.62:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zsmfm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 12:48:44.010: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 12:48:44.485: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:48:44.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zsmfm" for this suite.
Nov  7 12:49:06.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:49:06.686: INFO: namespace: e2e-tests-pod-network-test-zsmfm, resource: bindings, ignored listing per whitelist
Nov  7 12:49:06.770: INFO: namespace e2e-tests-pod-network-test-zsmfm deletion completed in 22.231364727s

• [SLOW TEST:47.529 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:49:06.771: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wlhnn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Nov  7 12:49:06.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-wlhnn'
Nov  7 12:49:07.549: INFO: stderr: ""
Nov  7 12:49:07.549: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Nov  7 12:49:08.553: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 12:49:08.553: INFO: Found 0 / 1
Nov  7 12:49:09.553: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 12:49:09.553: INFO: Found 1 / 1
Nov  7 12:49:09.553: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  7 12:49:09.557: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 12:49:09.557: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Nov  7 12:49:09.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 logs redis-master-z7wnr redis-master --namespace=e2e-tests-kubectl-wlhnn'
Nov  7 12:49:09.683: INFO: stderr: ""
Nov  7 12:49:09.683: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Nov 12:49:08.552 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Nov 12:49:08.552 # Server started, Redis version 3.2.12\n1:M 07 Nov 12:49:08.552 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Nov 12:49:08.552 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Nov  7 12:49:09.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 log redis-master-z7wnr redis-master --namespace=e2e-tests-kubectl-wlhnn --tail=1'
Nov  7 12:49:09.809: INFO: stderr: ""
Nov  7 12:49:09.809: INFO: stdout: "1:M 07 Nov 12:49:08.552 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Nov  7 12:49:09.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 log redis-master-z7wnr redis-master --namespace=e2e-tests-kubectl-wlhnn --limit-bytes=1'
Nov  7 12:49:09.948: INFO: stderr: ""
Nov  7 12:49:09.948: INFO: stdout: " "
STEP: exposing timestamps
Nov  7 12:49:09.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 log redis-master-z7wnr redis-master --namespace=e2e-tests-kubectl-wlhnn --tail=1 --timestamps'
Nov  7 12:49:10.099: INFO: stderr: ""
Nov  7 12:49:10.099: INFO: stdout: "2018-11-07T12:49:08.552491353Z 1:M 07 Nov 12:49:08.552 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Nov  7 12:49:12.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 log redis-master-z7wnr redis-master --namespace=e2e-tests-kubectl-wlhnn --since=1s'
Nov  7 12:49:12.720: INFO: stderr: ""
Nov  7 12:49:12.720: INFO: stdout: ""
Nov  7 12:49:12.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 log redis-master-z7wnr redis-master --namespace=e2e-tests-kubectl-wlhnn --since=24h'
Nov  7 12:49:12.833: INFO: stderr: ""
Nov  7 12:49:12.833: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Nov 12:49:08.552 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Nov 12:49:08.552 # Server started, Redis version 3.2.12\n1:M 07 Nov 12:49:08.552 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Nov 12:49:08.552 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Nov  7 12:49:12.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wlhnn'
Nov  7 12:49:12.940: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 12:49:12.941: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Nov  7 12:49:12.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-wlhnn'
Nov  7 12:49:13.156: INFO: stderr: "No resources found.\n"
Nov  7 12:49:13.156: INFO: stdout: ""
Nov  7 12:49:13.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -l name=nginx --namespace=e2e-tests-kubectl-wlhnn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  7 12:49:13.319: INFO: stderr: ""
Nov  7 12:49:13.319: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:49:13.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wlhnn" for this suite.
Nov  7 12:49:19.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:49:19.472: INFO: namespace: e2e-tests-kubectl-wlhnn, resource: bindings, ignored listing per whitelist
Nov  7 12:49:19.494: INFO: namespace e2e-tests-kubectl-wlhnn deletion completed in 6.171572325s

• [SLOW TEST:12.723 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:49:19.495: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fw6gl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  7 12:49:19.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-fw6gl'
Nov  7 12:49:19.853: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  7 12:49:19.853: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Nov  7 12:49:19.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-fw6gl'
Nov  7 12:49:19.986: INFO: stderr: ""
Nov  7 12:49:19.986: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:49:19.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fw6gl" for this suite.
Nov  7 12:49:42.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:49:42.115: INFO: namespace: e2e-tests-kubectl-fw6gl, resource: bindings, ignored listing per whitelist
Nov  7 12:49:42.185: INFO: namespace e2e-tests-kubectl-fw6gl deletion completed in 22.19414152s

• [SLOW TEST:22.691 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:49:42.186: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-wbpt4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wbpt4
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-wbpt4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-wbpt4
Nov  7 12:49:42.441: INFO: Found 0 stateful pods, waiting for 1
Nov  7 12:49:52.445: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  7 12:49:52.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 12:49:52.956: INFO: stderr: ""
Nov  7 12:49:52.956: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 12:49:52.956: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 12:49:52.960: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  7 12:50:02.964: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  7 12:50:02.964: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 12:50:03.040: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:03.040: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:03.040: INFO: 
Nov  7 12:50:03.040: INFO: StatefulSet ss has not reached scale 3, at 1
Nov  7 12:50:04.046: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996170547s
Nov  7 12:50:05.050: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990792219s
Nov  7 12:50:06.054: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986681955s
Nov  7 12:50:07.059: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982218071s
Nov  7 12:50:08.063: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977998239s
Nov  7 12:50:09.138: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97350054s
Nov  7 12:50:10.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.898912308s
Nov  7 12:50:11.147: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.894318876s
Nov  7 12:50:12.152: INFO: Verifying statefulset ss doesn't scale past 3 for another 889.657845ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-wbpt4
Nov  7 12:50:13.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:50:13.718: INFO: stderr: ""
Nov  7 12:50:13.718: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  7 12:50:13.718: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  7 12:50:13.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:50:14.219: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Nov  7 12:50:14.219: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  7 12:50:14.219: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  7 12:50:14.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:50:14.761: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Nov  7 12:50:14.761: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  7 12:50:14.761: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  7 12:50:14.766: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:50:14.766: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 12:50:14.766: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  7 12:50:14.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 12:50:15.192: INFO: stderr: ""
Nov  7 12:50:15.192: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 12:50:15.192: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 12:50:15.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 12:50:15.796: INFO: stderr: ""
Nov  7 12:50:15.796: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 12:50:15.796: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 12:50:15.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 12:50:16.330: INFO: stderr: ""
Nov  7 12:50:16.331: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 12:50:16.331: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 12:50:16.331: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 12:50:16.335: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov  7 12:50:26.344: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  7 12:50:26.344: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  7 12:50:26.344: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  7 12:50:26.352: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:26.352: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:26.352: INFO: ss-1  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:26.352: INFO: ss-2  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:26.352: INFO: 
Nov  7 12:50:26.352: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  7 12:50:27.357: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:27.357: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:27.357: INFO: ss-1  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:27.357: INFO: ss-2  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:27.358: INFO: 
Nov  7 12:50:27.358: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  7 12:50:28.362: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:28.362: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:28.362: INFO: ss-1  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:28.362: INFO: ss-2  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:28.362: INFO: 
Nov  7 12:50:28.362: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  7 12:50:29.367: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:29.367: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:29.367: INFO: ss-1  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:29.367: INFO: 
Nov  7 12:50:29.367: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  7 12:50:30.372: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:30.372: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:30.372: INFO: ss-1  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:30.372: INFO: 
Nov  7 12:50:30.372: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  7 12:50:31.396: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:31.396: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:31.396: INFO: ss-1  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:31.396: INFO: 
Nov  7 12:50:31.396: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  7 12:50:32.400: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:32.400: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:32.400: INFO: ss-1  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:32.400: INFO: 
Nov  7 12:50:32.400: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  7 12:50:33.437: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:33.437: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:33.437: INFO: ss-1  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:03 +0000 UTC  }]
Nov  7 12:50:33.437: INFO: 
Nov  7 12:50:33.437: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  7 12:50:34.442: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:34.442: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:34.442: INFO: 
Nov  7 12:50:34.442: INFO: StatefulSet ss has not reached scale 0, at 1
Nov  7 12:50:35.446: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Nov  7 12:50:35.446: INFO: ss-0  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:50:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 12:49:42 +0000 UTC  }]
Nov  7 12:50:35.447: INFO: 
Nov  7 12:50:35.447: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-wbpt4
Nov  7 12:50:36.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:50:36.667: INFO: rc: 1
Nov  7 12:50:36.667: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc421427200 exit status 1 <nil> <nil> true [0xc420facee0 0xc420facef8 0xc420facf10] [0xc420facee0 0xc420facef8 0xc420facf10] [0xc420facef0 0xc420facf08] [0x8fd520 0x8fd520] 0xc421daf020 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Nov  7 12:50:46.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:50:46.760: INFO: rc: 1
Nov  7 12:50:46.760: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d99da0 exit status 1 <nil> <nil> true [0xc4221482b8 0xc4221482d0 0xc4221482e8] [0xc4221482b8 0xc4221482d0 0xc4221482e8] [0xc4221482c8 0xc4221482e0] [0x8fd520 0x8fd520] 0xc421e3d8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:50:56.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:50:56.874: INFO: rc: 1
Nov  7 12:50:56.874: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421427620 exit status 1 <nil> <nil> true [0xc420facf18 0xc420facf30 0xc420facf48] [0xc420facf18 0xc420facf30 0xc420facf48] [0xc420facf28 0xc420facf40] [0x8fd520 0x8fd520] 0xc421daf140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:51:06.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:51:07.137: INFO: rc: 1
Nov  7 12:51:07.137: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216222a0 exit status 1 <nil> <nil> true [0xc4221482f0 0xc422148308 0xc422148320] [0xc4221482f0 0xc422148308 0xc422148320] [0xc422148300 0xc422148318] [0x8fd520 0x8fd520] 0xc421e3da40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:51:17.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:51:17.238: INFO: rc: 1
Nov  7 12:51:17.238: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216226c0 exit status 1 <nil> <nil> true [0xc422148328 0xc422148340 0xc422148358] [0xc422148328 0xc422148340 0xc422148358] [0xc422148338 0xc422148350] [0x8fd520 0x8fd520] 0xc421e3db60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:51:27.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:51:27.331: INFO: rc: 1
Nov  7 12:51:27.331: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421622ab0 exit status 1 <nil> <nil> true [0xc422148360 0xc422148378 0xc422148390] [0xc422148360 0xc422148378 0xc422148390] [0xc422148370 0xc422148388] [0x8fd520 0x8fd520] 0xc421e3dc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:51:37.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:51:37.422: INFO: rc: 1
Nov  7 12:51:37.422: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d98390 exit status 1 <nil> <nil> true [0xc4208dc220 0xc4208dc2c8 0xc4208dc338] [0xc4208dc220 0xc4208dc2c8 0xc4208dc338] [0xc4208dc2a0 0xc4208dc320] [0x8fd520 0x8fd520] 0xc420eff560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:51:47.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:51:47.515: INFO: rc: 1
Nov  7 12:51:47.515: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c63c0 exit status 1 <nil> <nil> true [0xc4200ca228 0xc4200ca460 0xc4200ca590] [0xc4200ca228 0xc4200ca460 0xc4200ca590] [0xc4200ca428 0xc4200ca4f8] [0x8fd520 0x8fd520] 0xc421b926c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:51:57.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:51:57.614: INFO: rc: 1
Nov  7 12:51:57.614: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c69f0 exit status 1 <nil> <nil> true [0xc4200ca638 0xc4200ca690 0xc4200ca740] [0xc4200ca638 0xc4200ca690 0xc4200ca740] [0xc4200ca680 0xc4200ca728] [0x8fd520 0x8fd520] 0xc421b93080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:52:07.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:52:07.709: INFO: rc: 1
Nov  7 12:52:07.710: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c6de0 exit status 1 <nil> <nil> true [0xc4200ca748 0xc4200ca818 0xc4200cad00] [0xc4200ca748 0xc4200ca818 0xc4200cad00] [0xc4200ca7a8 0xc4200cacd8] [0x8fd520 0x8fd520] 0xc421b938c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:52:17.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:52:17.834: INFO: rc: 1
Nov  7 12:52:17.834: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d98780 exit status 1 <nil> <nil> true [0xc4208dc358 0xc4208dc430 0xc4208dc4b0] [0xc4208dc358 0xc4208dc430 0xc4208dc4b0] [0xc4208dc410 0xc4208dc478] [0x8fd520 0x8fd520] 0xc420effc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:52:27.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:52:27.921: INFO: rc: 1
Nov  7 12:52:27.922: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c7320 exit status 1 <nil> <nil> true [0xc4200cad20 0xc4200cad80 0xc4200cadb0] [0xc4200cad20 0xc4200cad80 0xc4200cadb0] [0xc4200cad58 0xc4200cada8] [0x8fd520 0x8fd520] 0xc42167a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:52:37.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:52:38.033: INFO: rc: 1
Nov  7 12:52:38.033: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d98b40 exit status 1 <nil> <nil> true [0xc4208dc4c8 0xc4208dc528 0xc4208dc5e8] [0xc4208dc4c8 0xc4208dc528 0xc4208dc5e8] [0xc4208dc508 0xc4208dc5a0] [0x8fd520 0x8fd520] 0xc4215b45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:52:48.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:52:48.138: INFO: rc: 1
Nov  7 12:52:48.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c77d0 exit status 1 <nil> <nil> true [0xc4200cade0 0xc4200cb0e8 0xc4200cb2f0] [0xc4200cade0 0xc4200cb0e8 0xc4200cb2f0] [0xc4200cb070 0xc4200cb220] [0x8fd520 0x8fd520] 0xc42167a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:52:58.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:52:58.227: INFO: rc: 1
Nov  7 12:52:58.227: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d98f00 exit status 1 <nil> <nil> true [0xc4208dc600 0xc4208dc690 0xc4208dc6a8] [0xc4208dc600 0xc4208dc690 0xc4208dc6a8] [0xc4208dc650 0xc4208dc6a0] [0x8fd520 0x8fd520] 0xc4215b5bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:53:08.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:53:08.325: INFO: rc: 1
Nov  7 12:53:08.325: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c7bc0 exit status 1 <nil> <nil> true [0xc4200cb368 0xc4200cb770 0xc4200cb7a8] [0xc4200cb368 0xc4200cb770 0xc4200cb7a8] [0xc4200cb758 0xc4200cb788] [0x8fd520 0x8fd520] 0xc42167b4a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:53:18.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:53:18.421: INFO: rc: 1
Nov  7 12:53:18.421: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d992f0 exit status 1 <nil> <nil> true [0xc4208dc6b8 0xc4208dc708 0xc4208dc748] [0xc4208dc6b8 0xc4208dc708 0xc4208dc748] [0xc4208dc6f8 0xc4208dc720] [0x8fd520 0x8fd520] 0xc420f4a900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:53:28.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:53:28.565: INFO: rc: 1
Nov  7 12:53:28.566: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d99aa0 exit status 1 <nil> <nil> true [0xc4208dc768 0xc4208dc7c0 0xc4208dc870] [0xc4208dc768 0xc4208dc7c0 0xc4208dc870] [0xc4208dc7a0 0xc4208dc830] [0x8fd520 0x8fd520] 0xc4215dc660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:53:38.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:53:38.675: INFO: rc: 1
Nov  7 12:53:38.676: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421b50000 exit status 1 <nil> <nil> true [0xc4200cb7d8 0xc4200cb8e8 0xc42097c4f0] [0xc4200cb7d8 0xc4200cb8e8 0xc42097c4f0] [0xc4200cb830 0xc42000e010] [0x8fd520 0x8fd520] 0xc42167bf20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:53:48.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:53:48.762: INFO: rc: 1
Nov  7 12:53:48.762: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c63f0 exit status 1 <nil> <nil> true [0xc4200ca2f8 0xc4200ca4a0 0xc4200ca638] [0xc4200ca2f8 0xc4200ca4a0 0xc4200ca638] [0xc4200ca460 0xc4200ca590] [0x8fd520 0x8fd520] 0xc4215dc660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:53:58.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:53:58.853: INFO: rc: 1
Nov  7 12:53:58.854: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c69c0 exit status 1 <nil> <nil> true [0xc4200ca678 0xc4200ca708 0xc4200ca748] [0xc4200ca678 0xc4200ca708 0xc4200ca748] [0xc4200ca690 0xc4200ca740] [0x8fd520 0x8fd520] 0xc420f4b920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:54:08.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:54:08.944: INFO: rc: 1
Nov  7 12:54:08.944: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c6e10 exit status 1 <nil> <nil> true [0xc4200ca788 0xc4200ca930 0xc4200cad20] [0xc4200ca788 0xc4200ca930 0xc4200cad20] [0xc4200ca818 0xc4200cad00] [0x8fd520 0x8fd520] 0xc4215b4c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:54:18.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:54:19.038: INFO: rc: 1
Nov  7 12:54:19.038: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c7380 exit status 1 <nil> <nil> true [0xc4200cad40 0xc4200cad90 0xc4200cade0] [0xc4200cad40 0xc4200cad90 0xc4200cade0] [0xc4200cad80 0xc4200cadb0] [0x8fd520 0x8fd520] 0xc4215b5e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:54:29.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:54:29.139: INFO: rc: 1
Nov  7 12:54:29.139: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d98420 exit status 1 <nil> <nil> true [0xc4208dc210 0xc4208dc2a0 0xc4208dc320] [0xc4208dc210 0xc4208dc2a0 0xc4208dc320] [0xc4208dc268 0xc4208dc2d0] [0x8fd520 0x8fd520] 0xc421b926c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:54:39.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:54:39.229: INFO: rc: 1
Nov  7 12:54:39.229: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d98750 exit status 1 <nil> <nil> true [0xc4208dc338 0xc4208dc410 0xc4208dc478] [0xc4208dc338 0xc4208dc410 0xc4208dc478] [0xc4208dc408 0xc4208dc458] [0x8fd520 0x8fd520] 0xc421b92c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:54:49.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:54:49.318: INFO: rc: 1
Nov  7 12:54:49.318: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d98b70 exit status 1 <nil> <nil> true [0xc4208dc4b0 0xc4208dc508 0xc4208dc5a0] [0xc4208dc4b0 0xc4208dc508 0xc4208dc5a0] [0xc4208dc500 0xc4208dc540] [0x8fd520 0x8fd520] 0xc421b93560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:54:59.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:54:59.405: INFO: rc: 1
Nov  7 12:54:59.405: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c78c0 exit status 1 <nil> <nil> true [0xc4200caf58 0xc4200cb1a0 0xc4200cb368] [0xc4200caf58 0xc4200cb1a0 0xc4200cb368] [0xc4200cb0e8 0xc4200cb2f0] [0x8fd520 0x8fd520] 0xc42167a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:55:09.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:55:09.538: INFO: rc: 1
Nov  7 12:55:09.538: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d98f60 exit status 1 <nil> <nil> true [0xc4208dc5e8 0xc4208dc650 0xc4208dc6a0] [0xc4208dc5e8 0xc4208dc650 0xc4208dc6a0] [0xc4208dc648 0xc4208dc698] [0x8fd520 0x8fd520] 0xc421b93ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:55:19.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:55:19.626: INFO: rc: 1
Nov  7 12:55:19.626: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220c7d70 exit status 1 <nil> <nil> true [0xc4200cb378 0xc4200cb780 0xc4200cb7f8] [0xc4200cb378 0xc4200cb780 0xc4200cb7f8] [0xc4200cb770 0xc4200cb7a8] [0x8fd520 0x8fd520] 0xc42167b4a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:55:29.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:55:29.737: INFO: rc: 1
Nov  7 12:55:29.737: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d99620 exit status 1 <nil> <nil> true [0xc4208dc6a8 0xc4208dc6f8 0xc4208dc720] [0xc4208dc6a8 0xc4208dc6f8 0xc4208dc720] [0xc4208dc6f0 0xc4208dc718] [0x8fd520 0x8fd520] 0xc420eff7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov  7 12:55:39.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-wbpt4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 12:55:39.854: INFO: rc: 1
Nov  7 12:55:39.854: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Nov  7 12:55:39.854: INFO: Scaling statefulset ss to 0
Nov  7 12:55:39.864: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  7 12:55:39.867: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wbpt4
Nov  7 12:55:39.870: INFO: Scaling statefulset ss to 0
Nov  7 12:55:39.880: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 12:55:39.883: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:55:39.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wbpt4" for this suite.
Nov  7 12:55:45.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:55:46.067: INFO: namespace: e2e-tests-statefulset-wbpt4, resource: bindings, ignored listing per whitelist
Nov  7 12:55:46.067: INFO: namespace e2e-tests-statefulset-wbpt4 deletion completed in 6.17129527s

• [SLOW TEST:363.882 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:55:46.068: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-25lsp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  7 12:55:46.338: INFO: Waiting up to 5m0s for pod "pod-718f4585-e28c-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-25lsp" to be "success or failure"
Nov  7 12:55:46.342: INFO: Pod "pod-718f4585-e28c-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.751476ms
Nov  7 12:55:48.346: INFO: Pod "pod-718f4585-e28c-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006525041s
Nov  7 12:55:50.350: INFO: Pod "pod-718f4585-e28c-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011010389s
STEP: Saw pod success
Nov  7 12:55:50.350: INFO: Pod "pod-718f4585-e28c-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:55:50.354: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-718f4585-e28c-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 12:55:50.374: INFO: Waiting for pod pod-718f4585-e28c-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:55:50.379: INFO: Pod pod-718f4585-e28c-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:55:50.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-25lsp" for this suite.
Nov  7 12:55:56.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:55:56.497: INFO: namespace: e2e-tests-emptydir-25lsp, resource: bindings, ignored listing per whitelist
Nov  7 12:55:56.557: INFO: namespace e2e-tests-emptydir-25lsp deletion completed in 6.173657328s

• [SLOW TEST:10.489 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:55:56.557: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rmwrv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  7 12:55:59.334: INFO: Successfully updated pod "labelsupdate77cc56ea-e28c-11e8-bb28-1ed0160468e8"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:56:01.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rmwrv" for this suite.
Nov  7 12:56:23.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:56:23.522: INFO: namespace: e2e-tests-projected-rmwrv, resource: bindings, ignored listing per whitelist
Nov  7 12:56:23.533: INFO: namespace e2e-tests-projected-rmwrv deletion completed in 22.167851076s

• [SLOW TEST:26.977 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:56:23.534: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-9s6wl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Nov  7 12:56:23.904: INFO: Waiting up to 5m0s for pod "client-containers-87f36b85-e28c-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-containers-9s6wl" to be "success or failure"
Nov  7 12:56:23.909: INFO: Pod "client-containers-87f36b85-e28c-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.228175ms
Nov  7 12:56:25.914: INFO: Pod "client-containers-87f36b85-e28c-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00967634s
Nov  7 12:56:27.918: INFO: Pod "client-containers-87f36b85-e28c-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013462176s
STEP: Saw pod success
Nov  7 12:56:27.918: INFO: Pod "client-containers-87f36b85-e28c-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 12:56:27.920: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod client-containers-87f36b85-e28c-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 12:56:27.938: INFO: Waiting for pod client-containers-87f36b85-e28c-11e8-bb28-1ed0160468e8 to disappear
Nov  7 12:56:27.940: INFO: Pod client-containers-87f36b85-e28c-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 12:56:27.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9s6wl" for this suite.
Nov  7 12:56:33.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 12:56:33.980: INFO: namespace: e2e-tests-containers-9s6wl, resource: bindings, ignored listing per whitelist
Nov  7 12:56:34.113: INFO: namespace e2e-tests-containers-9s6wl deletion completed in 6.167852454s

• [SLOW TEST:10.579 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 12:56:34.114: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-x5c4v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-x5c4v
Nov  7 12:56:36.393: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-x5c4v
STEP: checking the pod's current state and verifying that restartCount is present
Nov  7 12:56:36.436: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:00:37.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-x5c4v" for this suite.
Nov  7 13:00:43.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:00:43.703: INFO: namespace: e2e-tests-container-probe-x5c4v, resource: bindings, ignored listing per whitelist
Nov  7 13:00:43.824: INFO: namespace e2e-tests-container-probe-x5c4v deletion completed in 6.218634423s

• [SLOW TEST:249.710 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:00:43.824: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-ng4vv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-ng4vv
Nov  7 13:00:48.143: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-ng4vv
STEP: checking the pod's current state and verifying that restartCount is present
Nov  7 13:00:48.146: INFO: Initial restart count of pod liveness-http is 0
Nov  7 13:01:00.236: INFO: Restart count of pod e2e-tests-container-probe-ng4vv/liveness-http is now 1 (12.089758231s elapsed)
Nov  7 13:01:20.365: INFO: Restart count of pod e2e-tests-container-probe-ng4vv/liveness-http is now 2 (32.218972579s elapsed)
Nov  7 13:01:40.543: INFO: Restart count of pod e2e-tests-container-probe-ng4vv/liveness-http is now 3 (52.397358662s elapsed)
Nov  7 13:02:00.592: INFO: Restart count of pod e2e-tests-container-probe-ng4vv/liveness-http is now 4 (1m12.446470508s elapsed)
Nov  7 13:03:00.963: INFO: Restart count of pod e2e-tests-container-probe-ng4vv/liveness-http is now 5 (2m12.817382186s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:03:00.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ng4vv" for this suite.
Nov  7 13:03:07.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:03:07.085: INFO: namespace: e2e-tests-container-probe-ng4vv, resource: bindings, ignored listing per whitelist
Nov  7 13:03:07.138: INFO: namespace e2e-tests-container-probe-ng4vv deletion completed in 6.147792873s

• [SLOW TEST:143.315 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:03:07.139: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-6h7s2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  7 13:03:07.350: INFO: Number of nodes with available pods: 0
Nov  7 13:03:07.350: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:03:08.357: INFO: Number of nodes with available pods: 0
Nov  7 13:03:08.357: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:03:09.358: INFO: Number of nodes with available pods: 2
Nov  7 13:03:09.358: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  7 13:03:09.404: INFO: Number of nodes with available pods: 1
Nov  7 13:03:09.404: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:03:10.413: INFO: Number of nodes with available pods: 1
Nov  7 13:03:10.413: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:03:11.439: INFO: Number of nodes with available pods: 2
Nov  7 13:03:11.439: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-6h7s2, will wait for the garbage collector to delete the pods
Nov  7 13:03:11.503: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.451695ms
Nov  7 13:03:11.604: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.658782ms
Nov  7 13:03:48.007: INFO: Number of nodes with available pods: 0
Nov  7 13:03:48.007: INFO: Number of running nodes: 0, number of available pods: 0
Nov  7 13:03:48.011: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6h7s2/daemonsets","resourceVersion":"11229"},"items":null}

Nov  7 13:03:48.013: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6h7s2/pods","resourceVersion":"11229"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:03:48.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6h7s2" for this suite.
Nov  7 13:03:54.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:03:54.179: INFO: namespace: e2e-tests-daemonsets-6h7s2, resource: bindings, ignored listing per whitelist
Nov  7 13:03:54.223: INFO: namespace e2e-tests-daemonsets-6h7s2 deletion completed in 6.197315798s

• [SLOW TEST:47.085 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:03:54.224: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-9pxsf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  7 13:04:00.467: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  7 13:04:00.470: INFO: Pod pod-with-poststart-http-hook still exists
Nov  7 13:04:02.471: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  7 13:04:02.536: INFO: Pod pod-with-poststart-http-hook still exists
Nov  7 13:04:04.471: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  7 13:04:04.475: INFO: Pod pod-with-poststart-http-hook still exists
Nov  7 13:04:06.471: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  7 13:04:06.474: INFO: Pod pod-with-poststart-http-hook still exists
Nov  7 13:04:08.471: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  7 13:04:08.535: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:04:08.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9pxsf" for this suite.
Nov  7 13:04:30.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:04:30.646: INFO: namespace: e2e-tests-container-lifecycle-hook-9pxsf, resource: bindings, ignored listing per whitelist
Nov  7 13:04:30.713: INFO: namespace e2e-tests-container-lifecycle-hook-9pxsf deletion completed in 22.174119296s

• [SLOW TEST:36.490 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:04:30.714: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-knbkr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Nov  7 13:04:30.957: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-030573999 proxy --unix-socket=/tmp/kubectl-proxy-unix340633922/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:04:31.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-knbkr" for this suite.
Nov  7 13:04:37.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:04:37.213: INFO: namespace: e2e-tests-kubectl-knbkr, resource: bindings, ignored listing per whitelist
Nov  7 13:04:37.327: INFO: namespace e2e-tests-kubectl-knbkr deletion completed in 6.28257052s

• [SLOW TEST:6.614 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:04:37.328: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-cgkt5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Nov  7 13:04:38.149: INFO: created pod pod-service-account-defaultsa
Nov  7 13:04:38.149: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  7 13:04:38.154: INFO: created pod pod-service-account-mountsa
Nov  7 13:04:38.154: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  7 13:04:38.158: INFO: created pod pod-service-account-nomountsa
Nov  7 13:04:38.158: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  7 13:04:38.162: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  7 13:04:38.162: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  7 13:04:38.166: INFO: created pod pod-service-account-mountsa-mountspec
Nov  7 13:04:38.166: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  7 13:04:38.173: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  7 13:04:38.173: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  7 13:04:38.180: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  7 13:04:38.180: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  7 13:04:38.188: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  7 13:04:38.188: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  7 13:04:38.193: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  7 13:04:38.193: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:04:38.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-cgkt5" for this suite.
Nov  7 13:04:44.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:04:44.396: INFO: namespace: e2e-tests-svcaccounts-cgkt5, resource: bindings, ignored listing per whitelist
Nov  7 13:04:44.425: INFO: namespace e2e-tests-svcaccounts-cgkt5 deletion completed in 6.228477353s

• [SLOW TEST:7.098 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:04:44.426: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2llhj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  7 13:04:44.674: INFO: Waiting up to 5m0s for pod "pod-b26ef707-e28d-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-2llhj" to be "success or failure"
Nov  7 13:04:44.677: INFO: Pod "pod-b26ef707-e28d-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.565794ms
Nov  7 13:04:46.736: INFO: Pod "pod-b26ef707-e28d-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.061901837s
STEP: Saw pod success
Nov  7 13:04:46.736: INFO: Pod "pod-b26ef707-e28d-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:04:46.740: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-b26ef707-e28d-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:04:46.760: INFO: Waiting for pod pod-b26ef707-e28d-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:04:46.777: INFO: Pod pod-b26ef707-e28d-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:04:46.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2llhj" for this suite.
Nov  7 13:04:52.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:04:52.998: INFO: namespace: e2e-tests-emptydir-2llhj, resource: bindings, ignored listing per whitelist
Nov  7 13:04:53.012: INFO: namespace e2e-tests-emptydir-2llhj deletion completed in 6.230662764s

• [SLOW TEST:8.586 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:04:53.012: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-rszpn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1107 13:04:59.245352      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  7 13:04:59.245: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:04:59.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rszpn" for this suite.
Nov  7 13:05:05.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:05:05.352: INFO: namespace: e2e-tests-gc-rszpn, resource: bindings, ignored listing per whitelist
Nov  7 13:05:05.434: INFO: namespace e2e-tests-gc-rszpn deletion completed in 6.186615634s

• [SLOW TEST:12.423 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:05:05.437: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hhmk9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:05:05.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 version --client'
Nov  7 13:05:05.913: INFO: stderr: ""
Nov  7 13:05:05.913: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Nov  7 13:05:05.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-hhmk9'
Nov  7 13:05:06.483: INFO: stderr: ""
Nov  7 13:05:06.483: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov  7 13:05:06.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-hhmk9'
Nov  7 13:05:06.704: INFO: stderr: ""
Nov  7 13:05:06.704: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  7 13:05:07.712: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 13:05:07.712: INFO: Found 0 / 1
Nov  7 13:05:08.709: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 13:05:08.709: INFO: Found 1 / 1
Nov  7 13:05:08.709: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  7 13:05:08.712: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 13:05:08.712: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  7 13:05:08.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 describe pod redis-master-m2lrw --namespace=e2e-tests-kubectl-hhmk9'
Nov  7 13:05:08.826: INFO: stderr: ""
Nov  7 13:05:08.826: INFO: stdout: "Name:               redis-master-m2lrw\nNamespace:          e2e-tests-kubectl-hhmk9\nPriority:           0\nPriorityClassName:  <none>\nNode:               shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/10.250.0.3\nStart Time:         Wed, 07 Nov 2018 13:05:06 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 100.96.1.90/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 100.96.1.90\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://a90d6156554ba537035667f4566c63eb440fe011841b4bab3dffe24d61d44aab\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 07 Nov 2018 13:05:07 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-6qnpf (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-6qnpf:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-6qnpf\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                             Message\n  ----    ------     ----  ----                                                             -------\n  Normal  Scheduled  2s    default-scheduler                                                Successfully assigned e2e-tests-kubectl-hhmk9/redis-master-m2lrw to shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6\n  Normal  Pulled     1s    kubelet, shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Created container\n  Normal  Started    1s    kubelet, shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6  Started container\n"
Nov  7 13:05:08.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 describe rc redis-master --namespace=e2e-tests-kubectl-hhmk9'
Nov  7 13:05:08.996: INFO: stderr: ""
Nov  7 13:05:08.996: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-hhmk9\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-m2lrw\n"
Nov  7 13:05:08.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 describe service redis-master --namespace=e2e-tests-kubectl-hhmk9'
Nov  7 13:05:09.108: INFO: stderr: ""
Nov  7 13:05:09.108: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-hhmk9\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.70.100.213\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.90:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  7 13:05:09.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 describe node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6'
Nov  7 13:05:09.271: INFO: stderr: ""
Nov  7 13:05:09.271: INFO: stdout: "Name:               shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-standard-2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=europe-west1\n                    failure-domain.beta.kubernetes.io/zone=europe-west1-c\n                    kubernetes.io/hostname=shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\n                    worker.garden.sapcloud.io/group=worker-ehel0\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.3/32\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 07 Nov 2018 11:49:48 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 07 Nov 2018 11:49:59 +0000   Wed, 07 Nov 2018 11:49:59 +0000   RouteCreated                 RouteController created a route\n  OutOfDisk            False   Wed, 07 Nov 2018 13:05:00 +0000   Wed, 07 Nov 2018 11:49:48 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Wed, 07 Nov 2018 13:05:00 +0000   Wed, 07 Nov 2018 11:49:48 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 07 Nov 2018 13:05:00 +0000   Wed, 07 Nov 2018 11:49:48 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 07 Nov 2018 13:05:00 +0000   Wed, 07 Nov 2018 11:49:48 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 07 Nov 2018 13:05:00 +0000   Wed, 07 Nov 2018 11:50:08 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.250.0.3\n  ExternalIP:   35.205.67.202\n  InternalDNS:  shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6.c.sap-se-gcp-scp-k8s-staging.internal\n  Hostname:     shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6.c.sap-se-gcp-scp-k8s-staging.internal\nCapacity:\n attachable-volumes-gce-pd:  64\n cpu:                        2\n ephemeral-storage:          48375392Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     7655144Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  64\n cpu:                        2\n ephemeral-storage:          47059581301\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     6504168Ki\n pods:                       110\nSystem Info:\n Machine ID:                 9db653e41a8eda3d412abbe548f3c4e6\n System UUID:                9DB653E4-1A8E-DA3D-412A-BBE548F3C4E6\n Boot ID:                    c8c35e99-4995-49f5-9c28-0523622f88a4\n Kernel Version:             4.14.67-coreos\n OS Image:                   Container Linux by CoreOS 1855.4.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.12.2\n Kube-Proxy Version:         v1.12.2\nPodCIDR:                     100.96.1.0/24\nProviderID:                  gce://sap-se-gcp-scp-k8s-staging/europe-west1-c/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-hhmk9    redis-master-m2lrw                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-e2e-job-11d5393ce95f4a43                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-vf5bm    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-9gx88                                          250m (12%)    500m (25%)  100Mi (1%)       700Mi (11%)\n  kube-system                kube-proxy-hpqpq                                           50m (2%)      100m (5%)   64Mi (1%)        256Mi (4%)\n  kube-system                node-exporter-rcks9                                        10m (0%)      20m (1%)    10Mi (0%)        50Mi (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        310m (15%)  620m (31%)\n  memory                     174Mi (2%)  1006Mi (15%)\n  attachable-volumes-gce-pd  0           0\nEvents:                      <none>\n"
Nov  7 13:05:09.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 describe namespace e2e-tests-kubectl-hhmk9'
Nov  7 13:05:09.382: INFO: stderr: ""
Nov  7 13:05:09.382: INFO: stdout: "Name:         e2e-tests-kubectl-hhmk9\nLabels:       e2e-framework=kubectl\n              e2e-run=90991240-e288-11e8-bb28-1ed0160468e8\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:05:09.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hhmk9" for this suite.
Nov  7 13:05:31.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:05:31.458: INFO: namespace: e2e-tests-kubectl-hhmk9, resource: bindings, ignored listing per whitelist
Nov  7 13:05:31.528: INFO: namespace e2e-tests-kubectl-hhmk9 deletion completed in 22.142712158s

• [SLOW TEST:26.091 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:05:31.528: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-fr42m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:05:31.775: INFO: Creating ReplicaSet my-hostname-basic-ce82e990-e28d-11e8-bb28-1ed0160468e8
Nov  7 13:05:31.782: INFO: Pod name my-hostname-basic-ce82e990-e28d-11e8-bb28-1ed0160468e8: Found 0 pods out of 1
Nov  7 13:05:36.786: INFO: Pod name my-hostname-basic-ce82e990-e28d-11e8-bb28-1ed0160468e8: Found 1 pods out of 1
Nov  7 13:05:36.786: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-ce82e990-e28d-11e8-bb28-1ed0160468e8" is running
Nov  7 13:05:36.790: INFO: Pod "my-hostname-basic-ce82e990-e28d-11e8-bb28-1ed0160468e8-wdcqf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-07 13:05:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-07 13:05:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-07 13:05:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-07 13:05:31 +0000 UTC Reason: Message:}])
Nov  7 13:05:36.790: INFO: Trying to dial the pod
Nov  7 13:05:41.886: INFO: Controller my-hostname-basic-ce82e990-e28d-11e8-bb28-1ed0160468e8: Got expected result from replica 1 [my-hostname-basic-ce82e990-e28d-11e8-bb28-1ed0160468e8-wdcqf]: "my-hostname-basic-ce82e990-e28d-11e8-bb28-1ed0160468e8-wdcqf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:05:41.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-fr42m" for this suite.
Nov  7 13:05:47.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:05:47.916: INFO: namespace: e2e-tests-replicaset-fr42m, resource: bindings, ignored listing per whitelist
Nov  7 13:05:48.015: INFO: namespace e2e-tests-replicaset-fr42m deletion completed in 6.124770984s

• [SLOW TEST:16.487 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:05:48.016: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vbhdc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  7 13:05:48.267: INFO: Waiting up to 5m0s for pod "pod-d856920b-e28d-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-vbhdc" to be "success or failure"
Nov  7 13:05:48.270: INFO: Pod "pod-d856920b-e28d-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.439834ms
Nov  7 13:05:50.274: INFO: Pod "pod-d856920b-e28d-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006223958s
STEP: Saw pod success
Nov  7 13:05:50.274: INFO: Pod "pod-d856920b-e28d-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:05:50.276: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-d856920b-e28d-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:05:50.292: INFO: Waiting for pod pod-d856920b-e28d-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:05:50.297: INFO: Pod pod-d856920b-e28d-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:05:50.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vbhdc" for this suite.
Nov  7 13:05:56.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:05:56.465: INFO: namespace: e2e-tests-emptydir-vbhdc, resource: bindings, ignored listing per whitelist
Nov  7 13:05:56.493: INFO: namespace e2e-tests-emptydir-vbhdc deletion completed in 6.190111182s

• [SLOW TEST:8.478 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:05:56.494: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2xqfc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Nov  7 13:05:56.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 api-versions'
Nov  7 13:05:56.804: INFO: stderr: ""
Nov  7 13:05:56.804: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:05:56.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2xqfc" for this suite.
Nov  7 13:06:02.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:06:02.948: INFO: namespace: e2e-tests-kubectl-2xqfc, resource: bindings, ignored listing per whitelist
Nov  7 13:06:02.990: INFO: namespace e2e-tests-kubectl-2xqfc deletion completed in 6.181671559s

• [SLOW TEST:6.497 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:06:02.990: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gqddh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-e142998d-e28d-11e8-bb28-1ed0160468e8
STEP: Creating configMap with name cm-test-opt-upd-e14299cb-e28d-11e8-bb28-1ed0160468e8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e142998d-e28d-11e8-bb28-1ed0160468e8
STEP: Updating configmap cm-test-opt-upd-e14299cb-e28d-11e8-bb28-1ed0160468e8
STEP: Creating configMap with name cm-test-opt-create-e14299e3-e28d-11e8-bb28-1ed0160468e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:07:22.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gqddh" for this suite.
Nov  7 13:07:44.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:07:44.425: INFO: namespace: e2e-tests-projected-gqddh, resource: bindings, ignored listing per whitelist
Nov  7 13:07:44.616: INFO: namespace e2e-tests-projected-gqddh deletion completed in 22.265707158s

• [SLOW TEST:101.625 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:07:44.616: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qvfgr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Nov  7 13:07:44.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:07:45.020: INFO: stderr: ""
Nov  7 13:07:45.020: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  7 13:07:45.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:07:45.130: INFO: stderr: ""
Nov  7 13:07:45.130: INFO: stdout: "update-demo-nautilus-gdrbs update-demo-nautilus-lxgv6 "
Nov  7 13:07:45.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-gdrbs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:07:45.236: INFO: stderr: ""
Nov  7 13:07:45.236: INFO: stdout: ""
Nov  7 13:07:45.236: INFO: update-demo-nautilus-gdrbs is created but not running
Nov  7 13:07:50.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:07:50.341: INFO: stderr: ""
Nov  7 13:07:50.341: INFO: stdout: "update-demo-nautilus-gdrbs update-demo-nautilus-lxgv6 "
Nov  7 13:07:50.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-gdrbs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:07:50.438: INFO: stderr: ""
Nov  7 13:07:50.438: INFO: stdout: "true"
Nov  7 13:07:50.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-gdrbs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:07:50.550: INFO: stderr: ""
Nov  7 13:07:50.550: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 13:07:50.550: INFO: validating pod update-demo-nautilus-gdrbs
Nov  7 13:07:50.640: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 13:07:50.640: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 13:07:50.640: INFO: update-demo-nautilus-gdrbs is verified up and running
Nov  7 13:07:50.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-lxgv6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:07:50.738: INFO: stderr: ""
Nov  7 13:07:50.738: INFO: stdout: "true"
Nov  7 13:07:50.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-lxgv6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:07:50.840: INFO: stderr: ""
Nov  7 13:07:50.840: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 13:07:50.840: INFO: validating pod update-demo-nautilus-lxgv6
Nov  7 13:07:50.928: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 13:07:50.928: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 13:07:50.928: INFO: update-demo-nautilus-lxgv6 is verified up and running
STEP: rolling-update to new replication controller
Nov  7 13:07:50.930: INFO: scanned /root for discovery docs: <nil>
Nov  7 13:07:50.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:08:13.404: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  7 13:08:13.404: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  7 13:08:13.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:08:13.513: INFO: stderr: ""
Nov  7 13:08:13.513: INFO: stdout: "update-demo-kitten-j7sxm update-demo-kitten-k5bfq "
Nov  7 13:08:13.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-kitten-j7sxm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:08:13.616: INFO: stderr: ""
Nov  7 13:08:13.616: INFO: stdout: "true"
Nov  7 13:08:13.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-kitten-j7sxm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:08:13.718: INFO: stderr: ""
Nov  7 13:08:13.718: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  7 13:08:13.718: INFO: validating pod update-demo-kitten-j7sxm
Nov  7 13:08:13.807: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  7 13:08:13.807: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  7 13:08:13.807: INFO: update-demo-kitten-j7sxm is verified up and running
Nov  7 13:08:13.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-kitten-k5bfq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:08:13.913: INFO: stderr: ""
Nov  7 13:08:13.913: INFO: stdout: "true"
Nov  7 13:08:13.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-kitten-k5bfq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qvfgr'
Nov  7 13:08:14.027: INFO: stderr: ""
Nov  7 13:08:14.027: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  7 13:08:14.027: INFO: validating pod update-demo-kitten-k5bfq
Nov  7 13:08:14.124: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  7 13:08:14.124: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  7 13:08:14.124: INFO: update-demo-kitten-k5bfq is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:08:14.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qvfgr" for this suite.
Nov  7 13:08:36.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:08:36.188: INFO: namespace: e2e-tests-kubectl-qvfgr, resource: bindings, ignored listing per whitelist
Nov  7 13:08:36.298: INFO: namespace e2e-tests-kubectl-qvfgr deletion completed in 22.170044675s

• [SLOW TEST:51.682 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:08:36.298: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-d7zl8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3ca41c0b-e28e-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:08:36.556: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ca530ef-e28e-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-d7zl8" to be "success or failure"
Nov  7 13:08:36.559: INFO: Pod "pod-configmaps-3ca530ef-e28e-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.230775ms
Nov  7 13:08:38.562: INFO: Pod "pod-configmaps-3ca530ef-e28e-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005826243s
STEP: Saw pod success
Nov  7 13:08:38.562: INFO: Pod "pod-configmaps-3ca530ef-e28e-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:08:38.565: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-3ca530ef-e28e-11e8-bb28-1ed0160468e8 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 13:08:38.581: INFO: Waiting for pod pod-configmaps-3ca530ef-e28e-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:08:38.584: INFO: Pod pod-configmaps-3ca530ef-e28e-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:08:38.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d7zl8" for this suite.
Nov  7 13:08:44.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:08:44.644: INFO: namespace: e2e-tests-configmap-d7zl8, resource: bindings, ignored listing per whitelist
Nov  7 13:08:44.758: INFO: namespace e2e-tests-configmap-d7zl8 deletion completed in 6.150846665s

• [SLOW TEST:8.460 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:08:44.759: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-5w8cc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:08:44.987: INFO: (0) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.529432ms)
Nov  7 13:08:45.031: INFO: (1) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.221262ms)
Nov  7 13:08:45.037: INFO: (2) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.471379ms)
Nov  7 13:08:45.042: INFO: (3) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.065545ms)
Nov  7 13:08:45.047: INFO: (4) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.484923ms)
Nov  7 13:08:45.091: INFO: (5) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.037788ms)
Nov  7 13:08:45.097: INFO: (6) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.12205ms)
Nov  7 13:08:45.102: INFO: (7) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.055361ms)
Nov  7 13:08:45.106: INFO: (8) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.449185ms)
Nov  7 13:08:45.139: INFO: (9) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 32.272904ms)
Nov  7 13:08:45.144: INFO: (10) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.427662ms)
Nov  7 13:08:45.149: INFO: (11) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.776092ms)
Nov  7 13:08:45.154: INFO: (12) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.107758ms)
Nov  7 13:08:45.159: INFO: (13) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.727707ms)
Nov  7 13:08:45.165: INFO: (14) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.225582ms)
Nov  7 13:08:45.169: INFO: (15) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.621791ms)
Nov  7 13:08:45.174: INFO: (16) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.493109ms)
Nov  7 13:08:45.179: INFO: (17) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.593409ms)
Nov  7 13:08:45.183: INFO: (18) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.815164ms)
Nov  7 13:08:45.188: INFO: (19) /api/v1/nodes/shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.453086ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:08:45.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5w8cc" for this suite.
Nov  7 13:08:51.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:08:51.403: INFO: namespace: e2e-tests-proxy-5w8cc, resource: bindings, ignored listing per whitelist
Nov  7 13:08:51.432: INFO: namespace e2e-tests-proxy-5w8cc deletion completed in 6.240992448s

• [SLOW TEST:6.674 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:08:51.437: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kjjtx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-45a4faa1-e28e-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:08:51.658: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-45a5a135-e28e-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-kjjtx" to be "success or failure"
Nov  7 13:08:51.661: INFO: Pod "pod-projected-secrets-45a5a135-e28e-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.370855ms
Nov  7 13:08:53.665: INFO: Pod "pod-projected-secrets-45a5a135-e28e-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007338373s
STEP: Saw pod success
Nov  7 13:08:53.665: INFO: Pod "pod-projected-secrets-45a5a135-e28e-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:08:53.669: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-secrets-45a5a135-e28e-11e8-bb28-1ed0160468e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  7 13:08:53.688: INFO: Waiting for pod pod-projected-secrets-45a5a135-e28e-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:08:53.697: INFO: Pod pod-projected-secrets-45a5a135-e28e-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:08:53.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kjjtx" for this suite.
Nov  7 13:08:59.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:08:59.739: INFO: namespace: e2e-tests-projected-kjjtx, resource: bindings, ignored listing per whitelist
Nov  7 13:08:59.884: INFO: namespace e2e-tests-projected-kjjtx deletion completed in 6.176213636s

• [SLOW TEST:8.448 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:08:59.885: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-nsl57
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nsl57
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  7 13:09:00.129: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  7 13:09:24.343: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.0.39 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nsl57 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:09:24.344: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:09:25.704: INFO: Found all expected endpoints: [netserver-0]
Nov  7 13:09:25.708: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.1.98 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nsl57 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:09:25.708: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:09:27.106: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:09:27.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nsl57" for this suite.
Nov  7 13:09:49.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:09:49.185: INFO: namespace: e2e-tests-pod-network-test-nsl57, resource: bindings, ignored listing per whitelist
Nov  7 13:09:49.262: INFO: namespace e2e-tests-pod-network-test-nsl57 deletion completed in 22.151139421s

• [SLOW TEST:49.377 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:09:49.262: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-x6n6j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-x6n6j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x6n6j to expose endpoints map[]
Nov  7 13:09:49.538: INFO: Get endpoints failed (2.959138ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov  7 13:09:50.542: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x6n6j exposes endpoints map[] (1.006715094s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-x6n6j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x6n6j to expose endpoints map[pod1:[100]]
Nov  7 13:09:52.569: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x6n6j exposes endpoints map[pod1:[100]] (2.021316829s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-x6n6j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x6n6j to expose endpoints map[pod1:[100] pod2:[101]]
Nov  7 13:09:54.599: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x6n6j exposes endpoints map[pod1:[100] pod2:[101]] (2.025691575s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-x6n6j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x6n6j to expose endpoints map[pod2:[101]]
Nov  7 13:09:54.614: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x6n6j exposes endpoints map[pod2:[101]] (8.525729ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-x6n6j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x6n6j to expose endpoints map[]
Nov  7 13:09:54.622: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x6n6j exposes endpoints map[] (3.978891ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:09:54.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-x6n6j" for this suite.
Nov  7 13:10:00.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:10:00.662: INFO: namespace: e2e-tests-services-x6n6j, resource: bindings, ignored listing per whitelist
Nov  7 13:10:00.792: INFO: namespace e2e-tests-services-x6n6j deletion completed in 6.155268564s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:11.530 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:10:00.793: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-pwlnj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  7 13:10:00.987: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-a,UID:6ef71de4-e28e-11e8-b11f-bea865258d09,ResourceVersion:12548,Generation:0,CreationTimestamp:2018-11-07 13:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  7 13:10:00.987: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-a,UID:6ef71de4-e28e-11e8-b11f-bea865258d09,ResourceVersion:12548,Generation:0,CreationTimestamp:2018-11-07 13:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  7 13:10:10.995: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-a,UID:6ef71de4-e28e-11e8-b11f-bea865258d09,ResourceVersion:12568,Generation:0,CreationTimestamp:2018-11-07 13:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  7 13:10:10.995: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-a,UID:6ef71de4-e28e-11e8-b11f-bea865258d09,ResourceVersion:12568,Generation:0,CreationTimestamp:2018-11-07 13:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  7 13:10:21.003: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-a,UID:6ef71de4-e28e-11e8-b11f-bea865258d09,ResourceVersion:12588,Generation:0,CreationTimestamp:2018-11-07 13:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  7 13:10:21.003: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-a,UID:6ef71de4-e28e-11e8-b11f-bea865258d09,ResourceVersion:12588,Generation:0,CreationTimestamp:2018-11-07 13:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  7 13:10:31.009: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-a,UID:6ef71de4-e28e-11e8-b11f-bea865258d09,ResourceVersion:12609,Generation:0,CreationTimestamp:2018-11-07 13:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  7 13:10:31.009: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-a,UID:6ef71de4-e28e-11e8-b11f-bea865258d09,ResourceVersion:12609,Generation:0,CreationTimestamp:2018-11-07 13:10:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  7 13:10:41.016: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-b,UID:86d2ac8e-e28e-11e8-b11f-bea865258d09,ResourceVersion:12629,Generation:0,CreationTimestamp:2018-11-07 13:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  7 13:10:41.016: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-b,UID:86d2ac8e-e28e-11e8-b11f-bea865258d09,ResourceVersion:12629,Generation:0,CreationTimestamp:2018-11-07 13:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  7 13:10:51.022: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-b,UID:86d2ac8e-e28e-11e8-b11f-bea865258d09,ResourceVersion:12649,Generation:0,CreationTimestamp:2018-11-07 13:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  7 13:10:51.022: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-pwlnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-pwlnj/configmaps/e2e-watch-test-configmap-b,UID:86d2ac8e-e28e-11e8-b11f-bea865258d09,ResourceVersion:12649,Generation:0,CreationTimestamp:2018-11-07 13:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:11:01.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-pwlnj" for this suite.
Nov  7 13:11:07.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:11:07.290: INFO: namespace: e2e-tests-watch-pwlnj, resource: bindings, ignored listing per whitelist
Nov  7 13:11:07.294: INFO: namespace e2e-tests-watch-pwlnj deletion completed in 6.259629252s

• [SLOW TEST:66.502 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:11:07.295: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-c9w75
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  7 13:11:07.544: INFO: Waiting up to 5m0s for pod "downward-api-96a441a6-e28e-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-c9w75" to be "success or failure"
Nov  7 13:11:07.547: INFO: Pod "downward-api-96a441a6-e28e-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.596315ms
Nov  7 13:11:09.553: INFO: Pod "downward-api-96a441a6-e28e-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008996229s
STEP: Saw pod success
Nov  7 13:11:09.553: INFO: Pod "downward-api-96a441a6-e28e-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:11:09.557: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downward-api-96a441a6-e28e-11e8-bb28-1ed0160468e8 container dapi-container: <nil>
STEP: delete the pod
Nov  7 13:11:09.605: INFO: Waiting for pod downward-api-96a441a6-e28e-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:11:09.615: INFO: Pod downward-api-96a441a6-e28e-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:11:09.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c9w75" for this suite.
Nov  7 13:11:15.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:11:15.792: INFO: namespace: e2e-tests-downward-api-c9w75, resource: bindings, ignored listing per whitelist
Nov  7 13:11:15.899: INFO: namespace e2e-tests-downward-api-c9w75 deletion completed in 6.276624467s

• [SLOW TEST:8.604 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:11:15.899: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-trg7t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:11:16.104: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Nov  7 13:11:16.113: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-trg7t/daemonsets","resourceVersion":"12725"},"items":null}

Nov  7 13:11:16.115: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-trg7t/pods","resourceVersion":"12725"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:11:16.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-trg7t" for this suite.
Nov  7 13:11:22.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:11:22.184: INFO: namespace: e2e-tests-daemonsets-trg7t, resource: bindings, ignored listing per whitelist
Nov  7 13:11:22.255: INFO: namespace e2e-tests-daemonsets-trg7t deletion completed in 6.128473353s

S [SKIPPING] [6.356 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Nov  7 13:11:16.104: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:11:22.256: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-bnkr2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  7 13:11:22.506: INFO: PodSpec: initContainers in spec.initContainers
Nov  7 13:12:08.434: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-9f903ebd-e28e-11e8-bb28-1ed0160468e8", GenerateName:"", Namespace:"e2e-tests-init-container-bnkr2", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-bnkr2/pods/pod-init-9f903ebd-e28e-11e8-bb28-1ed0160468e8", UID:"9f8ece2a-e28e-11e8-b11f-bea865258d09", ResourceVersion:"12850", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63677193082, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"506420004"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.102/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4vgcw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42212c980), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4vgcw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4vgcw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4vgcw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420763818), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4217021e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420763920)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420763960)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc420763968), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677193082, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677193082, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677193082, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677193082, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.3", PodIP:"100.96.1.102", StartTime:(*v1.Time)(0xc420e1dce0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420f87c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420f87c70)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://e4daa86fe7c017734295922e2f49df0a7e3b527a113c9fa101e9ce6ccfce9388"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420e1dd20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420e1dd00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:12:08.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bnkr2" for this suite.
Nov  7 13:12:30.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:12:30.607: INFO: namespace: e2e-tests-init-container-bnkr2, resource: bindings, ignored listing per whitelist
Nov  7 13:12:30.624: INFO: namespace e2e-tests-init-container-bnkr2 deletion completed in 22.186060852s

• [SLOW TEST:68.368 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:12:30.624: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b9frn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Nov  7 13:12:30.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 cluster-info'
Nov  7 13:12:30.983: INFO: stderr: ""
Nov  7 13:12:30.983: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:12:30.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b9frn" for this suite.
Nov  7 13:12:37.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:12:37.016: INFO: namespace: e2e-tests-kubectl-b9frn, resource: bindings, ignored listing per whitelist
Nov  7 13:12:37.217: INFO: namespace e2e-tests-kubectl-b9frn deletion completed in 6.230024275s

• [SLOW TEST:6.593 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:12:37.217: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lrtn8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  7 13:12:37.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lrtn8'
Nov  7 13:12:37.643: INFO: stderr: ""
Nov  7 13:12:37.643: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Nov  7 13:12:42.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lrtn8 -o json'
Nov  7 13:12:42.791: INFO: stderr: ""
Nov  7 13:12:42.791: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.1.103/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2018-11-07T13:12:37Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-lrtn8\",\n        \"resourceVersion\": \"12941\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-lrtn8/pods/e2e-test-nginx-pod\",\n        \"uid\": \"cc4a0535-e28e-11e8-b11f-bea865258d09\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-8vpq8\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-8vpq8\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-8vpq8\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-07T13:12:37Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-07T13:12:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-07T13:12:38Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-07T13:12:37Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://0c84665d61cbca73a9bddfc24c0bebfffa75702fa3d44145c22a0656592c657c\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-11-07T13:12:38Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.103\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-11-07T13:12:37Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  7 13:12:42.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 replace -f - --namespace=e2e-tests-kubectl-lrtn8'
Nov  7 13:12:43.032: INFO: stderr: ""
Nov  7 13:12:43.032: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Nov  7 13:12:43.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lrtn8'
Nov  7 13:12:47.972: INFO: stderr: ""
Nov  7 13:12:47.972: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:12:47.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lrtn8" for this suite.
Nov  7 13:12:53.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:12:54.094: INFO: namespace: e2e-tests-kubectl-lrtn8, resource: bindings, ignored listing per whitelist
Nov  7 13:12:54.112: INFO: namespace e2e-tests-kubectl-lrtn8 deletion completed in 6.136544971s

• [SLOW TEST:16.895 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:12:54.112: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-whm2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  7 13:12:58.467: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:12:58.474: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:00.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:00.479: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:02.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:02.479: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:04.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:04.479: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:06.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:06.480: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:08.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:08.478: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:10.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:10.479: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:12.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:12.478: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:14.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:14.477: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:16.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:16.478: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:18.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:18.479: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:20.475: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:20.479: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:22.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:22.479: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:24.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:24.482: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:26.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:26.479: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  7 13:13:28.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  7 13:13:28.479: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:13:28.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-whm2p" for this suite.
Nov  7 13:13:50.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:13:50.620: INFO: namespace: e2e-tests-container-lifecycle-hook-whm2p, resource: bindings, ignored listing per whitelist
Nov  7 13:13:50.657: INFO: namespace e2e-tests-container-lifecycle-hook-whm2p deletion completed in 22.17451942s

• [SLOW TEST:56.544 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:13:50.657: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-xlgr4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xlgr4
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-xlgr4
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-xlgr4
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-xlgr4
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-xlgr4
Nov  7 13:13:52.922: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-xlgr4, name: ss-0, uid: f8dd8723-e28e-11e8-b11f-bea865258d09, status phase: Pending. Waiting for statefulset controller to delete.
Nov  7 13:13:53.318: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-xlgr4, name: ss-0, uid: f8dd8723-e28e-11e8-b11f-bea865258d09, status phase: Failed. Waiting for statefulset controller to delete.
Nov  7 13:13:53.323: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-xlgr4, name: ss-0, uid: f8dd8723-e28e-11e8-b11f-bea865258d09, status phase: Failed. Waiting for statefulset controller to delete.
Nov  7 13:13:53.326: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-xlgr4
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-xlgr4
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-xlgr4 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  7 13:13:57.345: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xlgr4
Nov  7 13:13:57.350: INFO: Scaling statefulset ss to 0
Nov  7 13:14:07.364: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 13:14:07.368: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:14:07.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xlgr4" for this suite.
Nov  7 13:14:13.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:14:13.626: INFO: namespace: e2e-tests-statefulset-xlgr4, resource: bindings, ignored listing per whitelist
Nov  7 13:14:13.626: INFO: namespace e2e-tests-statefulset-xlgr4 deletion completed in 6.245185977s

• [SLOW TEST:22.969 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:14:13.626: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5grfw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  7 13:14:13.890: INFO: Waiting up to 5m0s for pod "pod-05b67521-e28f-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-5grfw" to be "success or failure"
Nov  7 13:14:13.893: INFO: Pod "pod-05b67521-e28f-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.852723ms
Nov  7 13:14:15.898: INFO: Pod "pod-05b67521-e28f-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008050271s
STEP: Saw pod success
Nov  7 13:14:15.898: INFO: Pod "pod-05b67521-e28f-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:14:15.902: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-05b67521-e28f-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:14:15.923: INFO: Waiting for pod pod-05b67521-e28f-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:14:15.926: INFO: Pod pod-05b67521-e28f-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:14:15.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5grfw" for this suite.
Nov  7 13:14:21.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:14:22.111: INFO: namespace: e2e-tests-emptydir-5grfw, resource: bindings, ignored listing per whitelist
Nov  7 13:14:22.116: INFO: namespace e2e-tests-emptydir-5grfw deletion completed in 6.186147899s

• [SLOW TEST:8.490 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:14:22.116: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jrxnc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:14:22.359: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ac29a92-e28f-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-jrxnc" to be "success or failure"
Nov  7 13:14:22.364: INFO: Pod "downwardapi-volume-0ac29a92-e28f-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.049358ms
Nov  7 13:14:24.372: INFO: Pod "downwardapi-volume-0ac29a92-e28f-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012821493s
STEP: Saw pod success
Nov  7 13:14:24.372: INFO: Pod "downwardapi-volume-0ac29a92-e28f-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:14:24.375: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-0ac29a92-e28f-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:14:24.449: INFO: Waiting for pod downwardapi-volume-0ac29a92-e28f-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:14:24.452: INFO: Pod downwardapi-volume-0ac29a92-e28f-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:14:24.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jrxnc" for this suite.
Nov  7 13:14:30.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:14:30.637: INFO: namespace: e2e-tests-downward-api-jrxnc, resource: bindings, ignored listing per whitelist
Nov  7 13:14:30.701: INFO: namespace e2e-tests-downward-api-jrxnc deletion completed in 6.244790581s

• [SLOW TEST:8.585 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:14:30.702: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-tl6f7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-tl6f7
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-tl6f7
STEP: Deleting pre-stop pod
Nov  7 13:14:42.037: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:14:42.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-tl6f7" for this suite.
Nov  7 13:15:20.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:15:20.132: INFO: namespace: e2e-tests-prestop-tl6f7, resource: bindings, ignored listing per whitelist
Nov  7 13:15:20.234: INFO: namespace e2e-tests-prestop-tl6f7 deletion completed in 38.18869003s

• [SLOW TEST:49.532 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:15:20.234: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-6j6b5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  7 13:15:20.481: INFO: Waiting up to 5m0s for pod "pod-2d674620-e28f-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-6j6b5" to be "success or failure"
Nov  7 13:15:20.486: INFO: Pod "pod-2d674620-e28f-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.070998ms
Nov  7 13:15:22.490: INFO: Pod "pod-2d674620-e28f-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008911517s
STEP: Saw pod success
Nov  7 13:15:22.490: INFO: Pod "pod-2d674620-e28f-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:15:22.493: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-2d674620-e28f-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:15:22.549: INFO: Waiting for pod pod-2d674620-e28f-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:15:22.553: INFO: Pod pod-2d674620-e28f-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:15:22.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6j6b5" for this suite.
Nov  7 13:15:28.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:15:28.667: INFO: namespace: e2e-tests-emptydir-6j6b5, resource: bindings, ignored listing per whitelist
Nov  7 13:15:28.834: INFO: namespace e2e-tests-emptydir-6j6b5 deletion completed in 6.26782538s

• [SLOW TEST:8.600 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:15:28.836: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-945t7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-32860e49-e28f-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:15:29.078: INFO: Waiting up to 5m0s for pod "pod-configmaps-3286da8e-e28f-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-945t7" to be "success or failure"
Nov  7 13:15:29.081: INFO: Pod "pod-configmaps-3286da8e-e28f-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.594194ms
Nov  7 13:15:31.085: INFO: Pod "pod-configmaps-3286da8e-e28f-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006784861s
STEP: Saw pod success
Nov  7 13:15:31.085: INFO: Pod "pod-configmaps-3286da8e-e28f-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:15:31.088: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-3286da8e-e28f-11e8-bb28-1ed0160468e8 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 13:15:31.105: INFO: Waiting for pod pod-configmaps-3286da8e-e28f-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:15:31.111: INFO: Pod pod-configmaps-3286da8e-e28f-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:15:31.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-945t7" for this suite.
Nov  7 13:15:37.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:15:37.159: INFO: namespace: e2e-tests-configmap-945t7, resource: bindings, ignored listing per whitelist
Nov  7 13:15:37.327: INFO: namespace e2e-tests-configmap-945t7 deletion completed in 6.199469112s

• [SLOW TEST:8.491 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:15:37.328: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-872sv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  7 13:15:37.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-872sv'
Nov  7 13:15:37.938: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  7 13:15:37.938: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Nov  7 13:15:37.945: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-hwr6f]
Nov  7 13:15:37.946: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-hwr6f" in namespace "e2e-tests-kubectl-872sv" to be "running and ready"
Nov  7 13:15:37.950: INFO: Pod "e2e-test-nginx-rc-hwr6f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008068ms
Nov  7 13:15:39.954: INFO: Pod "e2e-test-nginx-rc-hwr6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.007864563s
Nov  7 13:15:39.954: INFO: Pod "e2e-test-nginx-rc-hwr6f" satisfied condition "running and ready"
Nov  7 13:15:39.954: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-hwr6f]
Nov  7 13:15:39.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-872sv'
Nov  7 13:15:40.077: INFO: stderr: ""
Nov  7 13:15:40.077: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Nov  7 13:15:40.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-872sv'
Nov  7 13:15:40.183: INFO: stderr: ""
Nov  7 13:15:40.183: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:15:40.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-872sv" for this suite.
Nov  7 13:16:02.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:16:02.216: INFO: namespace: e2e-tests-kubectl-872sv, resource: bindings, ignored listing per whitelist
Nov  7 13:16:02.360: INFO: namespace e2e-tests-kubectl-872sv deletion completed in 22.171657476s

• [SLOW TEST:25.033 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:16:02.361: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-jz96g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-qj9t
STEP: Creating a pod to test atomic-volume-subpath
Nov  7 13:16:02.619: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-qj9t" in namespace "e2e-tests-subpath-jz96g" to be "success or failure"
Nov  7 13:16:02.625: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Pending", Reason="", readiness=false. Elapsed: 5.52044ms
Nov  7 13:16:04.629: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010026557s
Nov  7 13:16:06.634: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 4.01423545s
Nov  7 13:16:08.638: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 6.018552522s
Nov  7 13:16:10.642: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 8.022789461s
Nov  7 13:16:12.646: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 10.026917335s
Nov  7 13:16:14.653: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 12.03360663s
Nov  7 13:16:16.658: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 14.038263141s
Nov  7 13:16:18.662: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 16.042389s
Nov  7 13:16:20.667: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 18.04737365s
Nov  7 13:16:22.671: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 20.051423484s
Nov  7 13:16:24.675: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Running", Reason="", readiness=false. Elapsed: 22.055976136s
Nov  7 13:16:26.680: INFO: Pod "pod-subpath-test-downwardapi-qj9t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.060437268s
STEP: Saw pod success
Nov  7 13:16:26.680: INFO: Pod "pod-subpath-test-downwardapi-qj9t" satisfied condition "success or failure"
Nov  7 13:16:26.683: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-subpath-test-downwardapi-qj9t container test-container-subpath-downwardapi-qj9t: <nil>
STEP: delete the pod
Nov  7 13:16:26.706: INFO: Waiting for pod pod-subpath-test-downwardapi-qj9t to disappear
Nov  7 13:16:26.722: INFO: Pod pod-subpath-test-downwardapi-qj9t no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-qj9t
Nov  7 13:16:26.722: INFO: Deleting pod "pod-subpath-test-downwardapi-qj9t" in namespace "e2e-tests-subpath-jz96g"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:16:26.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jz96g" for this suite.
Nov  7 13:16:32.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:16:32.940: INFO: namespace: e2e-tests-subpath-jz96g, resource: bindings, ignored listing per whitelist
Nov  7 13:16:32.968: INFO: namespace e2e-tests-subpath-jz96g deletion completed in 6.240190636s

• [SLOW TEST:30.608 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:16:32.969: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-j7kgw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:16:33.177: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  7 13:16:33.184: INFO: Number of nodes with available pods: 0
Nov  7 13:16:33.184: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  7 13:16:33.201: INFO: Number of nodes with available pods: 0
Nov  7 13:16:33.201: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:34.234: INFO: Number of nodes with available pods: 0
Nov  7 13:16:34.234: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:35.206: INFO: Number of nodes with available pods: 1
Nov  7 13:16:35.206: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  7 13:16:35.222: INFO: Number of nodes with available pods: 1
Nov  7 13:16:35.222: INFO: Number of running nodes: 0, number of available pods: 1
Nov  7 13:16:36.226: INFO: Number of nodes with available pods: 0
Nov  7 13:16:36.226: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  7 13:16:36.233: INFO: Number of nodes with available pods: 0
Nov  7 13:16:36.233: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:37.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:37.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:38.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:38.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:39.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:39.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:40.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:40.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:41.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:41.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:42.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:42.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:43.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:43.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:44.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:44.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:45.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:45.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:46.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:46.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:47.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:47.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:48.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:48.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:49.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:49.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:50.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:50.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:51.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:51.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:52.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:52.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:53.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:53.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:54.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:54.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:55.241: INFO: Number of nodes with available pods: 0
Nov  7 13:16:55.241: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:56.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:56.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:57.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:57.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:58.237: INFO: Number of nodes with available pods: 0
Nov  7 13:16:58.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:16:59.238: INFO: Number of nodes with available pods: 0
Nov  7 13:16:59.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:00.237: INFO: Number of nodes with available pods: 0
Nov  7 13:17:00.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:01.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:01.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:02.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:02.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:03.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:03.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:04.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:04.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:05.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:05.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:06.237: INFO: Number of nodes with available pods: 0
Nov  7 13:17:06.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:07.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:07.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:08.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:08.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:09.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:09.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:10.237: INFO: Number of nodes with available pods: 0
Nov  7 13:17:10.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:11.237: INFO: Number of nodes with available pods: 0
Nov  7 13:17:11.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:12.240: INFO: Number of nodes with available pods: 0
Nov  7 13:17:12.240: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:13.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:13.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:14.239: INFO: Number of nodes with available pods: 0
Nov  7 13:17:14.239: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:15.237: INFO: Number of nodes with available pods: 0
Nov  7 13:17:15.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:16.237: INFO: Number of nodes with available pods: 0
Nov  7 13:17:16.237: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:17.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:17.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:18.239: INFO: Number of nodes with available pods: 0
Nov  7 13:17:18.239: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:19.238: INFO: Number of nodes with available pods: 0
Nov  7 13:17:19.238: INFO: Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 is running more than one daemon pod
Nov  7 13:17:20.237: INFO: Number of nodes with available pods: 1
Nov  7 13:17:20.237: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-j7kgw, will wait for the garbage collector to delete the pods
Nov  7 13:17:20.303: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.715317ms
Nov  7 13:17:20.404: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.24218ms
Nov  7 13:17:58.007: INFO: Number of nodes with available pods: 0
Nov  7 13:17:58.007: INFO: Number of running nodes: 0, number of available pods: 0
Nov  7 13:17:58.010: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-j7kgw/daemonsets","resourceVersion":"13863"},"items":null}

Nov  7 13:17:58.013: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-j7kgw/pods","resourceVersion":"13863"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:17:58.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-j7kgw" for this suite.
Nov  7 13:18:04.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:18:04.257: INFO: namespace: e2e-tests-daemonsets-j7kgw, resource: bindings, ignored listing per whitelist
Nov  7 13:18:04.262: INFO: namespace e2e-tests-daemonsets-j7kgw deletion completed in 6.229634016s

• [SLOW TEST:91.293 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:18:04.262: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-55vjz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:18:04.515: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  7 13:18:04.522: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  7 13:18:09.527: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  7 13:18:09.527: INFO: Creating deployment "test-rolling-update-deployment"
Nov  7 13:18:09.531: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  7 13:18:09.537: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  7 13:18:11.545: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  7 13:18:11.547: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  7 13:18:11.557: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-55vjz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-55vjz/deployments/test-rolling-update-deployment,UID:922912da-e28f-11e8-b11f-bea865258d09,ResourceVersion:13935,Generation:1,CreationTimestamp:2018-11-07 13:18:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-07 13:18:09 +0000 UTC 2018-11-07 13:18:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-07 13:18:11 +0000 UTC 2018-11-07 13:18:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  7 13:18:11.564: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-55vjz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-55vjz/replicasets/test-rolling-update-deployment-65b7695dcf,UID:922b88c2-e28f-11e8-b11f-bea865258d09,ResourceVersion:13928,Generation:1,CreationTimestamp:2018-11-07 13:18:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 922912da-e28f-11e8-b11f-bea865258d09 0xc42203b667 0xc42203b668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  7 13:18:11.564: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  7 13:18:11.564: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-55vjz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-55vjz/replicasets/test-rolling-update-controller,UID:8f2c519f-e28f-11e8-b11f-bea865258d09,ResourceVersion:13934,Generation:2,CreationTimestamp:2018-11-07 13:18:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 922912da-e28f-11e8-b11f-bea865258d09 0xc42203b43e 0xc42203b43f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  7 13:18:11.567: INFO: Pod "test-rolling-update-deployment-65b7695dcf-jgh4k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-jgh4k,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-55vjz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-55vjz/pods/test-rolling-update-deployment-65b7695dcf-jgh4k,UID:922c16e7-e28f-11e8-b11f-bea865258d09,ResourceVersion:13927,Generation:0,CreationTimestamp:2018-11-07 13:18:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.119/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 922b88c2-e28f-11e8-b11f-bea865258d09 0xc421c14287 0xc421c14288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s7wwb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s7wwb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-s7wwb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c143d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c147f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:18:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:18:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:18:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:18:09 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.119,StartTime:2018-11-07 13:18:09 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-07 13:18:10 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c600fe6641bb269f90ede5008bef35d5a494d4d2cbac656b6d75b975c8136991}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:18:11.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-55vjz" for this suite.
Nov  7 13:18:17.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:18:17.615: INFO: namespace: e2e-tests-deployment-55vjz, resource: bindings, ignored listing per whitelist
Nov  7 13:18:17.760: INFO: namespace e2e-tests-deployment-55vjz deletion completed in 6.188368201s

• [SLOW TEST:13.497 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:18:17.760: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-6db6c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-cmmv
STEP: Creating a pod to test atomic-volume-subpath
Nov  7 13:18:18.016: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cmmv" in namespace "e2e-tests-subpath-6db6c" to be "success or failure"
Nov  7 13:18:18.019: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.728597ms
Nov  7 13:18:20.026: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009084017s
Nov  7 13:18:22.030: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 4.013201681s
Nov  7 13:18:24.034: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 6.016881747s
Nov  7 13:18:26.038: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 8.021121527s
Nov  7 13:18:28.042: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 10.025303384s
Nov  7 13:18:30.046: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 12.029418127s
Nov  7 13:18:32.051: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 14.033837009s
Nov  7 13:18:34.055: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 16.038029498s
Nov  7 13:18:36.059: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 18.041800898s
Nov  7 13:18:38.063: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 20.045938942s
Nov  7 13:18:40.068: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Running", Reason="", readiness=false. Elapsed: 22.051228122s
Nov  7 13:18:42.072: INFO: Pod "pod-subpath-test-configmap-cmmv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.055398244s
STEP: Saw pod success
Nov  7 13:18:42.072: INFO: Pod "pod-subpath-test-configmap-cmmv" satisfied condition "success or failure"
Nov  7 13:18:42.075: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-subpath-test-configmap-cmmv container test-container-subpath-configmap-cmmv: <nil>
STEP: delete the pod
Nov  7 13:18:42.094: INFO: Waiting for pod pod-subpath-test-configmap-cmmv to disappear
Nov  7 13:18:42.100: INFO: Pod pod-subpath-test-configmap-cmmv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cmmv
Nov  7 13:18:42.100: INFO: Deleting pod "pod-subpath-test-configmap-cmmv" in namespace "e2e-tests-subpath-6db6c"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:18:42.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6db6c" for this suite.
Nov  7 13:18:48.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:18:48.250: INFO: namespace: e2e-tests-subpath-6db6c, resource: bindings, ignored listing per whitelist
Nov  7 13:18:48.270: INFO: namespace e2e-tests-subpath-6db6c deletion completed in 6.1606888s

• [SLOW TEST:30.510 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:18:48.270: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-v97j7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a9669973-e28f-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:18:48.518: INFO: Waiting up to 5m0s for pod "pod-secrets-a9673b8d-e28f-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-v97j7" to be "success or failure"
Nov  7 13:18:48.521: INFO: Pod "pod-secrets-a9673b8d-e28f-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.862657ms
Nov  7 13:18:50.526: INFO: Pod "pod-secrets-a9673b8d-e28f-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007480727s
STEP: Saw pod success
Nov  7 13:18:50.526: INFO: Pod "pod-secrets-a9673b8d-e28f-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:18:50.529: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-secrets-a9673b8d-e28f-11e8-bb28-1ed0160468e8 container secret-volume-test: <nil>
STEP: delete the pod
Nov  7 13:18:50.553: INFO: Waiting for pod pod-secrets-a9673b8d-e28f-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:18:50.556: INFO: Pod pod-secrets-a9673b8d-e28f-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:18:50.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v97j7" for this suite.
Nov  7 13:18:56.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:18:56.735: INFO: namespace: e2e-tests-secrets-v97j7, resource: bindings, ignored listing per whitelist
Nov  7 13:18:56.791: INFO: namespace e2e-tests-secrets-v97j7 deletion completed in 6.230237834s

• [SLOW TEST:8.521 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:18:56.791: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-km8n7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ae7e9303-e28f-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:18:57.064: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ae7f4b66-e28f-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-km8n7" to be "success or failure"
Nov  7 13:18:57.069: INFO: Pod "pod-projected-configmaps-ae7f4b66-e28f-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.27356ms
Nov  7 13:18:59.077: INFO: Pod "pod-projected-configmaps-ae7f4b66-e28f-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012724591s
STEP: Saw pod success
Nov  7 13:18:59.077: INFO: Pod "pod-projected-configmaps-ae7f4b66-e28f-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:18:59.134: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-configmaps-ae7f4b66-e28f-11e8-bb28-1ed0160468e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 13:18:59.152: INFO: Waiting for pod pod-projected-configmaps-ae7f4b66-e28f-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:18:59.164: INFO: Pod pod-projected-configmaps-ae7f4b66-e28f-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:18:59.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-km8n7" for this suite.
Nov  7 13:19:05.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:19:05.271: INFO: namespace: e2e-tests-projected-km8n7, resource: bindings, ignored listing per whitelist
Nov  7 13:19:05.370: INFO: namespace e2e-tests-projected-km8n7 deletion completed in 6.194878709s

• [SLOW TEST:8.578 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:19:05.370: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-6g9rt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-6g9rt
Nov  7 13:19:07.635: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-6g9rt
STEP: checking the pod's current state and verifying that restartCount is present
Nov  7 13:19:07.637: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:23:08.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6g9rt" for this suite.
Nov  7 13:23:14.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:23:14.780: INFO: namespace: e2e-tests-container-probe-6g9rt, resource: bindings, ignored listing per whitelist
Nov  7 13:23:14.908: INFO: namespace e2e-tests-container-probe-6g9rt deletion completed in 6.15277043s

• [SLOW TEST:249.538 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:23:14.908: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-whstr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  7 13:23:15.171: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-whstr,SelfLink:/api/v1/namespaces/e2e-tests-watch-whstr/configmaps/e2e-watch-test-watch-closed,UID:48555e57-e290-11e8-b11f-bea865258d09,ResourceVersion:14628,Generation:0,CreationTimestamp:2018-11-07 13:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  7 13:23:15.172: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-whstr,SelfLink:/api/v1/namespaces/e2e-tests-watch-whstr/configmaps/e2e-watch-test-watch-closed,UID:48555e57-e290-11e8-b11f-bea865258d09,ResourceVersion:14629,Generation:0,CreationTimestamp:2018-11-07 13:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  7 13:23:15.184: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-whstr,SelfLink:/api/v1/namespaces/e2e-tests-watch-whstr/configmaps/e2e-watch-test-watch-closed,UID:48555e57-e290-11e8-b11f-bea865258d09,ResourceVersion:14630,Generation:0,CreationTimestamp:2018-11-07 13:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  7 13:23:15.184: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-whstr,SelfLink:/api/v1/namespaces/e2e-tests-watch-whstr/configmaps/e2e-watch-test-watch-closed,UID:48555e57-e290-11e8-b11f-bea865258d09,ResourceVersion:14631,Generation:0,CreationTimestamp:2018-11-07 13:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:23:15.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-whstr" for this suite.
Nov  7 13:23:21.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:23:21.304: INFO: namespace: e2e-tests-watch-whstr, resource: bindings, ignored listing per whitelist
Nov  7 13:23:21.363: INFO: namespace e2e-tests-watch-whstr deletion completed in 6.174950475s

• [SLOW TEST:6.455 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:23:21.363: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dfncr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:23:21.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c2847f3-e290-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-dfncr" to be "success or failure"
Nov  7 13:23:21.576: INFO: Pod "downwardapi-volume-4c2847f3-e290-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.760572ms
Nov  7 13:23:23.579: INFO: Pod "downwardapi-volume-4c2847f3-e290-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005922736s
STEP: Saw pod success
Nov  7 13:23:23.579: INFO: Pod "downwardapi-volume-4c2847f3-e290-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:23:23.581: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-4c2847f3-e290-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:23:23.606: INFO: Waiting for pod downwardapi-volume-4c2847f3-e290-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:23:23.622: INFO: Pod downwardapi-volume-4c2847f3-e290-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:23:23.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dfncr" for this suite.
Nov  7 13:23:29.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:23:29.695: INFO: namespace: e2e-tests-downward-api-dfncr, resource: bindings, ignored listing per whitelist
Nov  7 13:23:29.793: INFO: namespace e2e-tests-downward-api-dfncr deletion completed in 6.168304197s

• [SLOW TEST:8.431 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:23:29.797: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-95gbx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:23:30.070: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5138a63b-e290-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-95gbx" to be "success or failure"
Nov  7 13:23:30.073: INFO: Pod "downwardapi-volume-5138a63b-e290-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.734878ms
Nov  7 13:23:32.079: INFO: Pod "downwardapi-volume-5138a63b-e290-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008644764s
STEP: Saw pod success
Nov  7 13:23:32.079: INFO: Pod "downwardapi-volume-5138a63b-e290-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:23:32.082: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-5138a63b-e290-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:23:32.122: INFO: Waiting for pod downwardapi-volume-5138a63b-e290-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:23:32.127: INFO: Pod downwardapi-volume-5138a63b-e290-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:23:32.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-95gbx" for this suite.
Nov  7 13:23:38.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:23:38.240: INFO: namespace: e2e-tests-projected-95gbx, resource: bindings, ignored listing per whitelist
Nov  7 13:23:38.402: INFO: namespace e2e-tests-projected-95gbx deletion completed in 6.266892288s

• [SLOW TEST:8.605 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:23:38.406: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-kt245
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  7 13:23:38.615: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  7 13:23:38.623: INFO: Waiting for terminating namespaces to be deleted...
Nov  7 13:23:38.625: INFO: 
Logging pods the kubelet thinks is on node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 before test
Nov  7 13:23:38.641: INFO: sonobuoy-e2e-job-11d5393ce95f4a43 from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 13:23:38.641: INFO: 	Container e2e ready: true, restart count 0
Nov  7 13:23:38.641: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 13:23:38.641: INFO: sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-vf5bm from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 13:23:38.641: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  7 13:23:38.641: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 13:23:38.641: INFO: calico-node-9gx88 from kube-system started at 2018-11-07 11:49:48 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.641: INFO: 	Container calico-node ready: true, restart count 0
Nov  7 13:23:38.641: INFO: kube-proxy-hpqpq from kube-system started at 2018-11-07 11:50:08 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.641: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  7 13:23:38.641: INFO: node-exporter-rcks9 from kube-system started at 2018-11-07 11:50:08 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.641: INFO: 	Container node-exporter ready: true, restart count 0
Nov  7 13:23:38.641: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-07 12:27:22 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.641: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  7 13:23:38.641: INFO: 
Logging pods the kubelet thinks is on node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86 before test
Nov  7 13:23:38.693: INFO: coredns-996685c97-zcd9g from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.693: INFO: 	Container coredns ready: true, restart count 0
Nov  7 13:23:38.693: INFO: calico-node-lsrvf from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.693: INFO: 	Container calico-node ready: true, restart count 0
Nov  7 13:23:38.693: INFO: addons-nginx-ingress-controller-5d8ff96544-94wtl from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.693: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Nov  7 13:23:38.693: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6584cc89bc-2pdr5 from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.693: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Nov  7 13:23:38.693: INFO: node-exporter-fsx8z from kube-system started at 2018-11-07 11:50:04 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.693: INFO: 	Container node-exporter ready: true, restart count 0
Nov  7 13:23:38.693: INFO: sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-6kbp8 from heptio-sonobuoy started at 2018-11-07 12:27:26 +0000 UTC (2 container statuses recorded)
Nov  7 13:23:38.693: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  7 13:23:38.694: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  7 13:23:38.694: INFO: kube-proxy-94vmw from kube-system started at 2018-11-07 11:50:04 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.694: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  7 13:23:38.694: INFO: addons-kubernetes-dashboard-789b6fcb7f-7jndw from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.694: INFO: 	Container main ready: true, restart count 0
Nov  7 13:23:38.694: INFO: vpn-shoot-74f549f48c-dkl4f from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.694: INFO: 	Container vpn-shoot ready: true, restart count 0
Nov  7 13:23:38.694: INFO: metrics-server-798b4c47df-rk5ck from kube-system started at 2018-11-07 11:49:44 +0000 UTC (1 container statuses recorded)
Nov  7 13:23:38.694: INFO: 	Container metrics-server ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
STEP: verifying the node has the label node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.724: INFO: Pod sonobuoy requesting resource cpu=0m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
Nov  7 13:23:38.725: INFO: Pod sonobuoy-e2e-job-11d5393ce95f4a43 requesting resource cpu=0m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
Nov  7 13:23:38.725: INFO: Pod sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-6kbp8 requesting resource cpu=0m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod sonobuoy-systemd-logs-daemon-set-ec58654ad60246c8-vf5bm requesting resource cpu=0m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
Nov  7 13:23:38.725: INFO: Pod addons-kubernetes-dashboard-789b6fcb7f-7jndw requesting resource cpu=50m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod addons-nginx-ingress-controller-5d8ff96544-94wtl requesting resource cpu=100m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-6584cc89bc-2pdr5 requesting resource cpu=0m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod calico-node-9gx88 requesting resource cpu=250m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
Nov  7 13:23:38.725: INFO: Pod calico-node-lsrvf requesting resource cpu=250m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod coredns-996685c97-zcd9g requesting resource cpu=100m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod kube-proxy-94vmw requesting resource cpu=50m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod kube-proxy-hpqpq requesting resource cpu=50m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
Nov  7 13:23:38.725: INFO: Pod metrics-server-798b4c47df-rk5ck requesting resource cpu=0m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod node-exporter-fsx8z requesting resource cpu=10m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
Nov  7 13:23:38.725: INFO: Pod node-exporter-rcks9 requesting resource cpu=10m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
Nov  7 13:23:38.725: INFO: Pod vpn-shoot-74f549f48c-dkl4f requesting resource cpu=100m on Node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-56625114-e290-11e8-bb28-1ed0160468e8.1564da521fc7e37e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kt245/filler-pod-56625114-e290-11e8-bb28-1ed0160468e8 to shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-56625114-e290-11e8-bb28-1ed0160468e8.1564da525536a654], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-56625114-e290-11e8-bb28-1ed0160468e8.1564da525982b291], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-56625114-e290-11e8-bb28-1ed0160468e8.1564da526386e609], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-56633f70-e290-11e8-bb28-1ed0160468e8.1564da5220107a6b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kt245/filler-pod-56633f70-e290-11e8-bb28-1ed0160468e8 to shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-56633f70-e290-11e8-bb28-1ed0160468e8.1564da525273f924], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-56633f70-e290-11e8-bb28-1ed0160468e8.1564da525705ce14], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-56633f70-e290-11e8-bb28-1ed0160468e8.1564da5264be56ea], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1564da5299066f2a], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:23:41.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-kt245" for this suite.
Nov  7 13:23:47.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:23:48.054: INFO: namespace: e2e-tests-sched-pred-kt245, resource: bindings, ignored listing per whitelist
Nov  7 13:23:48.115: INFO: namespace e2e-tests-sched-pred-kt245 deletion completed in 6.23527056s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.709 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:23:48.115: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-f9f9x
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:23:48.387: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:23:49.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-f9f9x" for this suite.
Nov  7 13:23:55.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:23:55.769: INFO: namespace: e2e-tests-custom-resource-definition-f9f9x, resource: bindings, ignored listing per whitelist
Nov  7 13:23:55.772: INFO: namespace e2e-tests-custom-resource-definition-f9f9x deletion completed in 6.244104014s

• [SLOW TEST:7.656 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:23:55.772: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-mzmdp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Nov  7 13:23:58.032: INFO: Pod pod-hostip-60b0788f-e290-11e8-bb28-1ed0160468e8 has hostIP: 10.250.0.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:23:58.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mzmdp" for this suite.
Nov  7 13:24:20.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:24:20.066: INFO: namespace: e2e-tests-pods-mzmdp, resource: bindings, ignored listing per whitelist
Nov  7 13:24:20.213: INFO: namespace e2e-tests-pods-mzmdp deletion completed in 22.177814188s

• [SLOW TEST:24.441 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:24:20.213: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xptmn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  7 13:24:20.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xptmn'
Nov  7 13:24:20.614: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  7 13:24:20.614: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Nov  7 13:24:22.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-xptmn'
Nov  7 13:24:22.733: INFO: stderr: ""
Nov  7 13:24:22.733: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:24:22.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xptmn" for this suite.
Nov  7 13:26:26.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:26:26.867: INFO: namespace: e2e-tests-kubectl-xptmn, resource: bindings, ignored listing per whitelist
Nov  7 13:26:27.077: INFO: namespace e2e-tests-kubectl-xptmn deletion completed in 2m4.340362528s

• [SLOW TEST:126.864 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:26:27.078: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-qplpk
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-bae0c0be-e290-11e8-bb28-1ed0160468e8
STEP: Creating configMap with name cm-test-opt-upd-bae0c100-e290-11e8-bb28-1ed0160468e8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-bae0c0be-e290-11e8-bb28-1ed0160468e8
STEP: Updating configmap cm-test-opt-upd-bae0c100-e290-11e8-bb28-1ed0160468e8
STEP: Creating configMap with name cm-test-opt-create-bae0c111-e290-11e8-bb28-1ed0160468e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:27:42.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qplpk" for this suite.
Nov  7 13:28:00.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:28:01.063: INFO: namespace: e2e-tests-configmap-qplpk, resource: bindings, ignored listing per whitelist
Nov  7 13:28:01.095: INFO: namespace e2e-tests-configmap-qplpk deletion completed in 18.108263111s

• [SLOW TEST:94.017 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:28:01.095: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-mxvk2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:28:01.343: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2e9ae0f-e290-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-mxvk2" to be "success or failure"
Nov  7 13:28:01.346: INFO: Pod "downwardapi-volume-f2e9ae0f-e290-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.090722ms
Nov  7 13:28:03.350: INFO: Pod "downwardapi-volume-f2e9ae0f-e290-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006980497s
STEP: Saw pod success
Nov  7 13:28:03.350: INFO: Pod "downwardapi-volume-f2e9ae0f-e290-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:28:03.353: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-f2e9ae0f-e290-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:28:03.371: INFO: Waiting for pod downwardapi-volume-f2e9ae0f-e290-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:28:03.376: INFO: Pod downwardapi-volume-f2e9ae0f-e290-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:28:03.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mxvk2" for this suite.
Nov  7 13:28:09.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:28:09.574: INFO: namespace: e2e-tests-downward-api-mxvk2, resource: bindings, ignored listing per whitelist
Nov  7 13:28:09.592: INFO: namespace e2e-tests-downward-api-mxvk2 deletion completed in 6.2058309s

• [SLOW TEST:8.497 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:28:09.592: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vtbdn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Nov  7 13:28:09.850: INFO: namespace e2e-tests-kubectl-vtbdn
Nov  7 13:28:09.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-vtbdn'
Nov  7 13:28:10.579: INFO: stderr: ""
Nov  7 13:28:10.579: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  7 13:28:11.583: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 13:28:11.583: INFO: Found 0 / 1
Nov  7 13:28:12.583: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 13:28:12.583: INFO: Found 1 / 1
Nov  7 13:28:12.583: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  7 13:28:12.588: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 13:28:12.588: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  7 13:28:12.588: INFO: wait on redis-master startup in e2e-tests-kubectl-vtbdn 
Nov  7 13:28:12.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 logs redis-master-hs2t5 redis-master --namespace=e2e-tests-kubectl-vtbdn'
Nov  7 13:28:12.699: INFO: stderr: ""
Nov  7 13:28:12.699: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Nov 13:28:11.645 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Nov 13:28:11.645 # Server started, Redis version 3.2.12\n1:M 07 Nov 13:28:11.645 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Nov 13:28:11.645 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Nov  7 13:28:12.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-vtbdn'
Nov  7 13:28:12.811: INFO: stderr: ""
Nov  7 13:28:12.811: INFO: stdout: "service/rm2 exposed\n"
Nov  7 13:28:12.814: INFO: Service rm2 in namespace e2e-tests-kubectl-vtbdn found.
STEP: exposing service
Nov  7 13:28:14.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-vtbdn'
Nov  7 13:28:14.940: INFO: stderr: ""
Nov  7 13:28:14.940: INFO: stdout: "service/rm3 exposed\n"
Nov  7 13:28:14.942: INFO: Service rm3 in namespace e2e-tests-kubectl-vtbdn found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:28:16.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vtbdn" for this suite.
Nov  7 13:28:38.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:28:39.107: INFO: namespace: e2e-tests-kubectl-vtbdn, resource: bindings, ignored listing per whitelist
Nov  7 13:28:39.126: INFO: namespace e2e-tests-kubectl-vtbdn deletion completed in 22.173244942s

• [SLOW TEST:29.534 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:28:39.127: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-knqn7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:28:39.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09968993-e291-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-knqn7" to be "success or failure"
Nov  7 13:28:39.390: INFO: Pod "downwardapi-volume-09968993-e291-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.922848ms
Nov  7 13:28:41.396: INFO: Pod "downwardapi-volume-09968993-e291-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009582461s
STEP: Saw pod success
Nov  7 13:28:41.397: INFO: Pod "downwardapi-volume-09968993-e291-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:28:41.400: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-09968993-e291-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:28:41.439: INFO: Waiting for pod downwardapi-volume-09968993-e291-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:28:41.452: INFO: Pod downwardapi-volume-09968993-e291-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:28:41.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-knqn7" for this suite.
Nov  7 13:28:47.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:28:47.499: INFO: namespace: e2e-tests-projected-knqn7, resource: bindings, ignored listing per whitelist
Nov  7 13:28:47.605: INFO: namespace e2e-tests-projected-knqn7 deletion completed in 6.146820437s

• [SLOW TEST:8.478 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:28:47.606: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-rxplm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-zfshf
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Nov  7 13:28:57.079: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-sx72h
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:29:14.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-rxplm" for this suite.
Nov  7 13:29:20.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:29:20.467: INFO: namespace: e2e-tests-namespaces-rxplm, resource: bindings, ignored listing per whitelist
Nov  7 13:29:20.479: INFO: namespace e2e-tests-namespaces-rxplm deletion completed in 6.334003574s
STEP: Destroying namespace "e2e-tests-nsdeletetest-zfshf" for this suite.
Nov  7 13:29:20.482: INFO: Namespace e2e-tests-nsdeletetest-zfshf was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-sx72h" for this suite.
Nov  7 13:29:26.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:29:26.619: INFO: namespace: e2e-tests-nsdeletetest-sx72h, resource: bindings, ignored listing per whitelist
Nov  7 13:29:26.649: INFO: namespace e2e-tests-nsdeletetest-sx72h deletion completed in 6.166838142s

• [SLOW TEST:39.043 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:29:26.649: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qwglb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-25e4f467-e291-11e8-bb28-1ed0160468e8
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-25e4f467-e291-11e8-bb28-1ed0160468e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:29:31.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qwglb" for this suite.
Nov  7 13:29:53.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:29:53.382: INFO: namespace: e2e-tests-projected-qwglb, resource: bindings, ignored listing per whitelist
Nov  7 13:29:53.385: INFO: namespace e2e-tests-projected-qwglb deletion completed in 22.23978082s

• [SLOW TEST:26.736 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:29:53.385: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6hvj6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  7 13:29:53.588: INFO: Waiting up to 5m0s for pod "downward-api-35d11847-e291-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-6hvj6" to be "success or failure"
Nov  7 13:29:53.591: INFO: Pod "downward-api-35d11847-e291-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.735227ms
Nov  7 13:29:55.596: INFO: Pod "downward-api-35d11847-e291-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007920786s
Nov  7 13:29:57.602: INFO: Pod "downward-api-35d11847-e291-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013131707s
STEP: Saw pod success
Nov  7 13:29:57.602: INFO: Pod "downward-api-35d11847-e291-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:29:57.606: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downward-api-35d11847-e291-11e8-bb28-1ed0160468e8 container dapi-container: <nil>
STEP: delete the pod
Nov  7 13:29:57.625: INFO: Waiting for pod downward-api-35d11847-e291-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:29:57.628: INFO: Pod downward-api-35d11847-e291-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:29:57.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6hvj6" for this suite.
Nov  7 13:30:03.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:30:03.709: INFO: namespace: e2e-tests-downward-api-6hvj6, resource: bindings, ignored listing per whitelist
Nov  7 13:30:03.816: INFO: namespace e2e-tests-downward-api-6hvj6 deletion completed in 6.184516797s

• [SLOW TEST:10.431 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:30:03.816: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2j254
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Nov  7 13:30:04.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 --namespace=e2e-tests-kubectl-2j254 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  7 13:30:06.737: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  7 13:30:06.737: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:30:09.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2j254" for this suite.
Nov  7 13:30:15.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:30:15.587: INFO: namespace: e2e-tests-kubectl-2j254, resource: bindings, ignored listing per whitelist
Nov  7 13:30:15.665: INFO: namespace e2e-tests-kubectl-2j254 deletion completed in 6.222763214s

• [SLOW TEST:11.848 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:30:15.665: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7pzm8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4318b4a0-e291-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:30:15.872: INFO: Waiting up to 5m0s for pod "pod-configmaps-4319507d-e291-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-7pzm8" to be "success or failure"
Nov  7 13:30:15.875: INFO: Pod "pod-configmaps-4319507d-e291-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.458028ms
Nov  7 13:30:17.878: INFO: Pod "pod-configmaps-4319507d-e291-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005964799s
STEP: Saw pod success
Nov  7 13:30:17.878: INFO: Pod "pod-configmaps-4319507d-e291-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:30:17.881: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-4319507d-e291-11e8-bb28-1ed0160468e8 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 13:30:17.898: INFO: Waiting for pod pod-configmaps-4319507d-e291-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:30:17.908: INFO: Pod pod-configmaps-4319507d-e291-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:30:17.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7pzm8" for this suite.
Nov  7 13:30:23.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:30:24.111: INFO: namespace: e2e-tests-configmap-7pzm8, resource: bindings, ignored listing per whitelist
Nov  7 13:30:24.111: INFO: namespace e2e-tests-configmap-7pzm8 deletion completed in 6.192083992s

• [SLOW TEST:8.446 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:30:24.111: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dwv2v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  7 13:30:24.355: INFO: Waiting up to 5m0s for pod "pod-4827807a-e291-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-dwv2v" to be "success or failure"
Nov  7 13:30:24.359: INFO: Pod "pod-4827807a-e291-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.558699ms
Nov  7 13:30:26.363: INFO: Pod "pod-4827807a-e291-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007412455s
Nov  7 13:30:28.432: INFO: Pod "pod-4827807a-e291-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077140007s
STEP: Saw pod success
Nov  7 13:30:28.432: INFO: Pod "pod-4827807a-e291-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:30:28.436: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-4827807a-e291-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:30:28.455: INFO: Waiting for pod pod-4827807a-e291-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:30:28.459: INFO: Pod pod-4827807a-e291-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:30:28.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dwv2v" for this suite.
Nov  7 13:30:34.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:30:34.571: INFO: namespace: e2e-tests-emptydir-dwv2v, resource: bindings, ignored listing per whitelist
Nov  7 13:30:34.648: INFO: namespace e2e-tests-emptydir-dwv2v deletion completed in 6.184842092s

• [SLOW TEST:10.537 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:30:34.649: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-qkg72
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qkg72
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qkg72
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qkg72
Nov  7 13:30:34.918: INFO: Found 0 stateful pods, waiting for 1
Nov  7 13:30:44.922: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  7 13:30:44.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 13:30:45.509: INFO: stderr: ""
Nov  7 13:30:45.509: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 13:30:45.509: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 13:30:45.515: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  7 13:30:55.519: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  7 13:30:55.519: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 13:30:55.539: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999995s
Nov  7 13:30:56.543: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997105263s
Nov  7 13:30:57.547: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992627768s
Nov  7 13:30:58.551: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989253197s
Nov  7 13:30:59.555: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.985291489s
Nov  7 13:31:00.559: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.981412493s
Nov  7 13:31:01.590: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.976865429s
Nov  7 13:31:02.595: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.946111371s
Nov  7 13:31:03.599: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.941420828s
Nov  7 13:31:04.633: INFO: Verifying statefulset ss doesn't scale past 1 for another 936.585557ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qkg72
Nov  7 13:31:05.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:31:06.151: INFO: stderr: ""
Nov  7 13:31:06.151: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  7 13:31:06.151: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  7 13:31:06.157: INFO: Found 1 stateful pods, waiting for 3
Nov  7 13:31:16.161: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 13:31:16.161: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  7 13:31:16.161: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  7 13:31:16.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 13:31:16.606: INFO: stderr: ""
Nov  7 13:31:16.606: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 13:31:16.606: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 13:31:16.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 13:31:17.213: INFO: stderr: ""
Nov  7 13:31:17.213: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 13:31:17.213: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 13:31:17.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  7 13:31:17.693: INFO: stderr: ""
Nov  7 13:31:17.693: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  7 13:31:17.693: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  7 13:31:17.693: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 13:31:17.697: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  7 13:31:27.733: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  7 13:31:27.733: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  7 13:31:27.733: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  7 13:31:27.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999608s
Nov  7 13:31:28.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995586388s
Nov  7 13:31:29.751: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991044545s
Nov  7 13:31:30.756: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986981383s
Nov  7 13:31:31.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982190699s
Nov  7 13:31:32.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977716113s
Nov  7 13:31:33.771: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972905368s
Nov  7 13:31:34.776: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96766808s
Nov  7 13:31:35.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962382708s
Nov  7 13:31:36.833: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.959785ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qkg72
Nov  7 13:31:37.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:31:38.361: INFO: stderr: ""
Nov  7 13:31:38.361: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  7 13:31:38.361: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  7 13:31:38.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:31:38.857: INFO: stderr: ""
Nov  7 13:31:38.857: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  7 13:31:38.857: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  7 13:31:38.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:31:39.477: INFO: rc: 1
Nov  7 13:31:39.477: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: container not running (2d5476604a8dbf89181752e87736de49a0657b8729749db57af5caafe603c00c)
 [] <nil> 0xc42248c750 exit status 1 <nil> <nil> true [0xc420fad148 0xc420fad160 0xc420fad178] [0xc420fad148 0xc420fad160 0xc420fad178] [0xc420fad158 0xc420fad170] [0x8fd520 0x8fd520] 0xc4225579e0 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (2d5476604a8dbf89181752e87736de49a0657b8729749db57af5caafe603c00c)

error:
exit status 1

Nov  7 13:31:49.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:31:49.569: INFO: rc: 1
Nov  7 13:31:49.569: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42247b7a0 exit status 1 <nil> <nil> true [0xc4211d7928 0xc4211d7940 0xc4211d7960] [0xc4211d7928 0xc4211d7940 0xc4211d7960] [0xc4211d7938 0xc4211d7950] [0x8fd520 0x8fd520] 0xc42205bb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:31:59.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:31:59.654: INFO: rc: 1
Nov  7 13:31:59.654: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0a480 exit status 1 <nil> <nil> true [0xc42097c4f0 0xc42097c588 0xc42097c5d0] [0xc42097c4f0 0xc42097c588 0xc42097c5d0] [0xc42097c578 0xc42097c5b0] [0x8fd520 0x8fd520] 0xc422280060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:32:09.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:32:09.749: INFO: rc: 1
Nov  7 13:32:09.750: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421fa83c0 exit status 1 <nil> <nil> true [0xc42000e010 0xc4200ca428 0xc4200ca4f8] [0xc42000e010 0xc4200ca428 0xc4200ca4f8] [0xc4200ca2f8 0xc4200ca4a0] [0x8fd520 0x8fd520] 0xc422034060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:32:19.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:32:19.845: INFO: rc: 1
Nov  7 13:32:19.845: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421fa8ae0 exit status 1 <nil> <nil> true [0xc4200ca590 0xc4200ca680 0xc4200ca728] [0xc4200ca590 0xc4200ca680 0xc4200ca728] [0xc4200ca678 0xc4200ca708] [0x8fd520 0x8fd520] 0xc4220342a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:32:29.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:32:30.136: INFO: rc: 1
Nov  7 13:32:30.137: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0a8a0 exit status 1 <nil> <nil> true [0xc42097c618 0xc42097c808 0xc42097c950] [0xc42097c618 0xc42097c808 0xc42097c950] [0xc42097c7c0 0xc42097c938] [0x8fd520 0x8fd520] 0xc422280180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:32:40.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:32:40.231: INFO: rc: 1
Nov  7 13:32:40.231: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421fa8f60 exit status 1 <nil> <nil> true [0xc4200ca740 0xc4200ca7a8 0xc4200cacd8] [0xc4200ca740 0xc4200ca7a8 0xc4200cacd8] [0xc4200ca788 0xc4200ca930] [0x8fd520 0x8fd520] 0xc4220343c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:32:50.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:32:50.335: INFO: rc: 1
Nov  7 13:32:50.335: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421fa93b0 exit status 1 <nil> <nil> true [0xc4200cad00 0xc4200cad58 0xc4200cada8] [0xc4200cad00 0xc4200cad58 0xc4200cada8] [0xc4200cad40 0xc4200cad90] [0x8fd520 0x8fd520] 0xc422034540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:33:00.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:33:00.424: INFO: rc: 1
Nov  7 13:33:00.424: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0ac90 exit status 1 <nil> <nil> true [0xc42097c9e8 0xc42097cdd0 0xc42097cf68] [0xc42097c9e8 0xc42097cdd0 0xc42097cf68] [0xc42097cc58 0xc42097cf18] [0x8fd520 0x8fd520] 0xc4222802a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:33:10.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:33:10.515: INFO: rc: 1
Nov  7 13:33:10.515: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0b8c0 exit status 1 <nil> <nil> true [0xc42097d090 0xc42097d188 0xc42097d408] [0xc42097d090 0xc42097d188 0xc42097d408] [0xc42097d150 0xc42097d360] [0x8fd520 0x8fd520] 0xc4222803c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:33:20.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:33:20.602: INFO: rc: 1
Nov  7 13:33:20.602: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421fa9830 exit status 1 <nil> <nil> true [0xc4200cadb0 0xc4200cb070 0xc4200cb220] [0xc4200cadb0 0xc4200cb070 0xc4200cb220] [0xc4200caf58 0xc4200cb1a0] [0x8fd520 0x8fd520] 0xc4220346c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:33:30.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:33:30.695: INFO: rc: 1
Nov  7 13:33:30.695: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421fa9bc0 exit status 1 <nil> <nil> true [0xc4200cb2f0 0xc4200cb758 0xc4200cb788] [0xc4200cb2f0 0xc4200cb758 0xc4200cb788] [0xc4200cb378 0xc4200cb780] [0x8fd520 0x8fd520] 0xc4220347e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:33:40.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:33:40.792: INFO: rc: 1
Nov  7 13:33:40.793: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0bd70 exit status 1 <nil> <nil> true [0xc42097d4b8 0xc42097d5d0 0xc42097d6c0] [0xc42097d4b8 0xc42097d5d0 0xc42097d6c0] [0xc42097d538 0xc42097d638] [0x8fd520 0x8fd520] 0xc422280540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:33:50.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:33:50.888: INFO: rc: 1
Nov  7 13:33:50.888: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422170210 exit status 1 <nil> <nil> true [0xc42097d720 0xc42097d7d8 0xc42097d958] [0xc42097d720 0xc42097d7d8 0xc42097d958] [0xc42097d760 0xc42097d910] [0x8fd520 0x8fd520] 0xc422280660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:34:00.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:34:00.983: INFO: rc: 1
Nov  7 13:34:00.983: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0a4b0 exit status 1 <nil> <nil> true [0xc42097c4f0 0xc42097c588 0xc42097c5d0] [0xc42097c4f0 0xc42097c588 0xc42097c5d0] [0xc42097c578 0xc42097c5b0] [0x8fd520 0x8fd520] 0xc422280060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:34:10.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:34:11.081: INFO: rc: 1
Nov  7 13:34:11.081: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422170570 exit status 1 <nil> <nil> true [0xc4200ca228 0xc4200ca460 0xc4200ca590] [0xc4200ca228 0xc4200ca460 0xc4200ca590] [0xc4200ca428 0xc4200ca4f8] [0x8fd520 0x8fd520] 0xc422034060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:34:21.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:34:21.169: INFO: rc: 1
Nov  7 13:34:21.169: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422170990 exit status 1 <nil> <nil> true [0xc4200ca638 0xc4200ca690 0xc4200ca740] [0xc4200ca638 0xc4200ca690 0xc4200ca740] [0xc4200ca680 0xc4200ca728] [0x8fd520 0x8fd520] 0xc4220342a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:34:31.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:34:31.335: INFO: rc: 1
Nov  7 13:34:31.335: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0a900 exit status 1 <nil> <nil> true [0xc42097c618 0xc42097c808 0xc42097c950] [0xc42097c618 0xc42097c808 0xc42097c950] [0xc42097c7c0 0xc42097c938] [0x8fd520 0x8fd520] 0xc422280180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:34:41.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:34:41.501: INFO: rc: 1
Nov  7 13:34:41.501: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0b530 exit status 1 <nil> <nil> true [0xc42097c9e8 0xc42097cdd0 0xc42097cf68] [0xc42097c9e8 0xc42097cdd0 0xc42097cf68] [0xc42097cc58 0xc42097cf18] [0x8fd520 0x8fd520] 0xc4222802a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:34:51.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:34:51.634: INFO: rc: 1
Nov  7 13:34:51.634: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422170d80 exit status 1 <nil> <nil> true [0xc4200ca748 0xc4200ca818 0xc4200cad00] [0xc4200ca748 0xc4200ca818 0xc4200cad00] [0xc4200ca7a8 0xc4200cacd8] [0x8fd520 0x8fd520] 0xc4220343c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:35:01.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:35:01.726: INFO: rc: 1
Nov  7 13:35:01.726: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4221711a0 exit status 1 <nil> <nil> true [0xc4200cad20 0xc4200cad80 0xc4200cadb0] [0xc4200cad20 0xc4200cad80 0xc4200cadb0] [0xc4200cad58 0xc4200cada8] [0x8fd520 0x8fd520] 0xc422034540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:35:11.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:35:11.835: INFO: rc: 1
Nov  7 13:35:11.835: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422171980 exit status 1 <nil> <nil> true [0xc4200cade0 0xc4200cb0e8 0xc4200cb2f0] [0xc4200cade0 0xc4200cb0e8 0xc4200cb2f0] [0xc4200cb070 0xc4200cb220] [0x8fd520 0x8fd520] 0xc4220346c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:35:21.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:35:21.960: INFO: rc: 1
Nov  7 13:35:21.960: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422171d10 exit status 1 <nil> <nil> true [0xc4200cb368 0xc4200cb770 0xc4200cb7a8] [0xc4200cb368 0xc4200cb770 0xc4200cb7a8] [0xc4200cb758 0xc4200cb788] [0x8fd520 0x8fd520] 0xc4220347e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:35:31.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:35:32.050: INFO: rc: 1
Nov  7 13:35:32.051: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0ba40 exit status 1 <nil> <nil> true [0xc42097d090 0xc42097d188 0xc42097d408] [0xc42097d090 0xc42097d188 0xc42097d408] [0xc42097d150 0xc42097d360] [0x8fd520 0x8fd520] 0xc4222803c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:35:42.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:35:42.138: INFO: rc: 1
Nov  7 13:35:42.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421fa8180 exit status 1 <nil> <nil> true [0xc4200cb7d8 0xc4200cb8e8 0xc4208dc220] [0xc4200cb7d8 0xc4200cb8e8 0xc4208dc220] [0xc4200cb830 0xc4208dc210] [0x8fd520 0x8fd520] 0xc422034900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:35:52.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:35:52.235: INFO: rc: 1
Nov  7 13:35:52.235: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421fa8900 exit status 1 <nil> <nil> true [0xc4208dc268 0xc4208dc2d0 0xc4208dc358] [0xc4208dc268 0xc4208dc2d0 0xc4208dc358] [0xc4208dc2c8 0xc4208dc338] [0x8fd520 0x8fd520] 0xc422034a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:36:02.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:36:02.335: INFO: rc: 1
Nov  7 13:36:02.335: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422170540 exit status 1 <nil> <nil> true [0xc4200ca228 0xc4200ca460 0xc4200ca590] [0xc4200ca228 0xc4200ca460 0xc4200ca590] [0xc4200ca428 0xc4200ca4f8] [0x8fd520 0x8fd520] 0xc422280060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:36:12.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:36:12.433: INFO: rc: 1
Nov  7 13:36:12.433: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0a480 exit status 1 <nil> <nil> true [0xc42097c4f0 0xc42097c588 0xc42097c5d0] [0xc42097c4f0 0xc42097c588 0xc42097c5d0] [0xc42097c578 0xc42097c5b0] [0x8fd520 0x8fd520] 0xc422034060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:36:22.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:36:22.523: INFO: rc: 1
Nov  7 13:36:22.523: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0a8d0 exit status 1 <nil> <nil> true [0xc42097c618 0xc42097c808 0xc42097c950] [0xc42097c618 0xc42097c808 0xc42097c950] [0xc42097c7c0 0xc42097c938] [0x8fd520 0x8fd520] 0xc4220342a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:36:32.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:36:32.647: INFO: rc: 1
Nov  7 13:36:32.647: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0b500 exit status 1 <nil> <nil> true [0xc42097c9e8 0xc42097cdd0 0xc42097cf68] [0xc42097c9e8 0xc42097cdd0 0xc42097cf68] [0xc42097cc58 0xc42097cf18] [0x8fd520 0x8fd520] 0xc4220343c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov  7 13:36:42.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 exec --namespace=e2e-tests-statefulset-qkg72 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  7 13:36:42.735: INFO: rc: 1
Nov  7 13:36:42.735: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Nov  7 13:36:42.735: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  7 13:36:42.745: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qkg72
Nov  7 13:36:42.747: INFO: Scaling statefulset ss to 0
Nov  7 13:36:42.755: INFO: Waiting for statefulset status.replicas updated to 0
Nov  7 13:36:42.757: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:36:42.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qkg72" for this suite.
Nov  7 13:36:48.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:36:48.876: INFO: namespace: e2e-tests-statefulset-qkg72, resource: bindings, ignored listing per whitelist
Nov  7 13:36:48.918: INFO: namespace e2e-tests-statefulset-qkg72 deletion completed in 6.149631899s

• [SLOW TEST:374.269 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:36:48.919: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h9xc8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2d85e07e-e292-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:36:49.176: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2d868624-e292-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-h9xc8" to be "success or failure"
Nov  7 13:36:49.178: INFO: Pod "pod-projected-secrets-2d868624-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.813989ms
Nov  7 13:36:51.183: INFO: Pod "pod-projected-secrets-2d868624-e292-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007069323s
STEP: Saw pod success
Nov  7 13:36:51.183: INFO: Pod "pod-projected-secrets-2d868624-e292-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:36:51.186: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-secrets-2d868624-e292-11e8-bb28-1ed0160468e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  7 13:36:51.210: INFO: Waiting for pod pod-projected-secrets-2d868624-e292-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:36:51.212: INFO: Pod pod-projected-secrets-2d868624-e292-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:36:51.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h9xc8" for this suite.
Nov  7 13:36:57.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:36:57.312: INFO: namespace: e2e-tests-projected-h9xc8, resource: bindings, ignored listing per whitelist
Nov  7 13:36:57.329: INFO: namespace e2e-tests-projected-h9xc8 deletion completed in 6.1074513s

• [SLOW TEST:8.410 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:36:57.329: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-l96hm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:36:57.552: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"328236a0-e292-11e8-b11f-bea865258d09", Controller:(*bool)(0xc4212062b6), BlockOwnerDeletion:(*bool)(0xc4212062b7)}}
Nov  7 13:36:57.556: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3280c390-e292-11e8-b11f-bea865258d09", Controller:(*bool)(0xc4211dc60e), BlockOwnerDeletion:(*bool)(0xc4211dc60f)}}
Nov  7 13:36:57.563: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"3281561f-e292-11e8-b11f-bea865258d09", Controller:(*bool)(0xc4211dc7fe), BlockOwnerDeletion:(*bool)(0xc4211dc7ff)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:37:02.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l96hm" for this suite.
Nov  7 13:37:08.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:37:08.782: INFO: namespace: e2e-tests-gc-l96hm, resource: bindings, ignored listing per whitelist
Nov  7 13:37:08.822: INFO: namespace e2e-tests-gc-l96hm deletion completed in 6.244862436s

• [SLOW TEST:11.493 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:37:08.822: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-6qftk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-6qftk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6qftk to expose endpoints map[]
Nov  7 13:37:09.039: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6qftk exposes endpoints map[] (5.562563ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-6qftk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6qftk to expose endpoints map[pod1:[80]]
Nov  7 13:37:12.101: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6qftk exposes endpoints map[pod1:[80]] (3.056403532s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-6qftk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6qftk to expose endpoints map[pod1:[80] pod2:[80]]
Nov  7 13:37:14.144: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6qftk exposes endpoints map[pod1:[80] pod2:[80]] (2.038359944s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-6qftk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6qftk to expose endpoints map[pod2:[80]]
Nov  7 13:37:15.234: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6qftk exposes endpoints map[pod2:[80]] (1.085594151s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-6qftk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6qftk to expose endpoints map[]
Nov  7 13:37:15.242: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6qftk exposes endpoints map[] (3.391718ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:37:15.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-6qftk" for this suite.
Nov  7 13:37:37.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:37:37.461: INFO: namespace: e2e-tests-services-6qftk, resource: bindings, ignored listing per whitelist
Nov  7 13:37:37.490: INFO: namespace e2e-tests-services-6qftk deletion completed in 22.223547058s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:28.667 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:37:37.490: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bgrbw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:37:37.749: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a7a19bc-e292-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-bgrbw" to be "success or failure"
Nov  7 13:37:37.754: INFO: Pod "downwardapi-volume-4a7a19bc-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.562896ms
Nov  7 13:37:39.758: INFO: Pod "downwardapi-volume-4a7a19bc-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008791336s
Nov  7 13:37:41.762: INFO: Pod "downwardapi-volume-4a7a19bc-e292-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013039087s
STEP: Saw pod success
Nov  7 13:37:41.762: INFO: Pod "downwardapi-volume-4a7a19bc-e292-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:37:41.765: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-4a7a19bc-e292-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:37:41.786: INFO: Waiting for pod downwardapi-volume-4a7a19bc-e292-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:37:41.790: INFO: Pod downwardapi-volume-4a7a19bc-e292-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:37:41.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bgrbw" for this suite.
Nov  7 13:37:47.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:37:47.873: INFO: namespace: e2e-tests-projected-bgrbw, resource: bindings, ignored listing per whitelist
Nov  7 13:37:48.007: INFO: namespace e2e-tests-projected-bgrbw deletion completed in 6.197512358s

• [SLOW TEST:10.517 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:37:48.007: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-v9jwm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-v9jwm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  7 13:37:48.256: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  7 13:38:12.320: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.146:8080/dial?request=hostName&protocol=udp&host=100.96.1.145&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-v9jwm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:38:12.320: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:38:12.706: INFO: Waiting for endpoints: map[]
Nov  7 13:38:12.711: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.146:8080/dial?request=hostName&protocol=udp&host=100.96.0.44&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-v9jwm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:38:12.711: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:38:13.200: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:38:13.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-v9jwm" for this suite.
Nov  7 13:38:35.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:38:35.398: INFO: namespace: e2e-tests-pod-network-test-v9jwm, resource: bindings, ignored listing per whitelist
Nov  7 13:38:35.445: INFO: namespace e2e-tests-pod-network-test-v9jwm deletion completed in 22.241181853s

• [SLOW TEST:47.438 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:38:35.447: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-lp4wt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6d005b18-e292-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:38:35.675: INFO: Waiting up to 5m0s for pod "pod-secrets-6d00f61f-e292-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-lp4wt" to be "success or failure"
Nov  7 13:38:35.678: INFO: Pod "pod-secrets-6d00f61f-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.950439ms
Nov  7 13:38:37.683: INFO: Pod "pod-secrets-6d00f61f-e292-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00831678s
STEP: Saw pod success
Nov  7 13:38:37.683: INFO: Pod "pod-secrets-6d00f61f-e292-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:38:37.687: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-secrets-6d00f61f-e292-11e8-bb28-1ed0160468e8 container secret-volume-test: <nil>
STEP: delete the pod
Nov  7 13:38:37.709: INFO: Waiting for pod pod-secrets-6d00f61f-e292-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:38:37.714: INFO: Pod pod-secrets-6d00f61f-e292-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:38:37.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lp4wt" for this suite.
Nov  7 13:38:43.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:38:43.801: INFO: namespace: e2e-tests-secrets-lp4wt, resource: bindings, ignored listing per whitelist
Nov  7 13:38:43.925: INFO: namespace e2e-tests-secrets-lp4wt deletion completed in 6.207115307s

• [SLOW TEST:8.479 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:38:43.926: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-pln9n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  7 13:38:48.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:38:48.215: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:38:50.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:38:50.219: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:38:52.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:38:52.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:38:54.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:38:54.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:38:56.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:38:56.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:38:58.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:38:58.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:00.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:00.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:02.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:02.221: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:04.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:04.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:06.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:06.233: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:08.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:08.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:10.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:10.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:12.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:12.221: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:14.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:14.221: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:16.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:16.220: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  7 13:39:18.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  7 13:39:18.220: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:39:18.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pln9n" for this suite.
Nov  7 13:39:40.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:39:40.377: INFO: namespace: e2e-tests-container-lifecycle-hook-pln9n, resource: bindings, ignored listing per whitelist
Nov  7 13:39:40.400: INFO: namespace e2e-tests-container-lifecycle-hook-pln9n deletion completed in 22.163535879s

• [SLOW TEST:56.474 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:39:40.400: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4rvcd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1107 13:40:20.832997      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  7 13:40:20.833: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:40:20.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4rvcd" for this suite.
Nov  7 13:40:26.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:40:27.035: INFO: namespace: e2e-tests-gc-4rvcd, resource: bindings, ignored listing per whitelist
Nov  7 13:40:27.082: INFO: namespace e2e-tests-gc-4rvcd deletion completed in 6.24597508s

• [SLOW TEST:46.682 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:40:27.082: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-xxrm7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-gw4cj
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-g9khc
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:40:33.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-xxrm7" for this suite.
Nov  7 13:40:39.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:40:39.708: INFO: namespace: e2e-tests-namespaces-xxrm7, resource: bindings, ignored listing per whitelist
Nov  7 13:40:39.798: INFO: namespace e2e-tests-namespaces-xxrm7 deletion completed in 6.162443244s
STEP: Destroying namespace "e2e-tests-nsdeletetest-gw4cj" for this suite.
Nov  7 13:40:39.801: INFO: Namespace e2e-tests-nsdeletetest-gw4cj was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-g9khc" for this suite.
Nov  7 13:40:45.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:40:45.916: INFO: namespace: e2e-tests-nsdeletetest-g9khc, resource: bindings, ignored listing per whitelist
Nov  7 13:40:45.921: INFO: namespace e2e-tests-nsdeletetest-g9khc deletion completed in 6.119242338s

• [SLOW TEST:18.839 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:40:45.921: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-gvw7r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  7 13:40:50.170: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:50.171: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:50.529: INFO: Exec stderr: ""
Nov  7 13:40:50.529: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:50.529: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:50.944: INFO: Exec stderr: ""
Nov  7 13:40:50.945: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:50.945: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:51.386: INFO: Exec stderr: ""
Nov  7 13:40:51.386: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:51.386: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:51.854: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  7 13:40:51.854: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:51.854: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:52.225: INFO: Exec stderr: ""
Nov  7 13:40:52.226: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:52.226: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:52.693: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  7 13:40:52.693: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:52.693: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:53.126: INFO: Exec stderr: ""
Nov  7 13:40:53.126: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:53.126: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:53.496: INFO: Exec stderr: ""
Nov  7 13:40:53.496: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:53.496: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:53.937: INFO: Exec stderr: ""
Nov  7 13:40:53.937: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gvw7r PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  7 13:40:53.937: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
Nov  7 13:40:54.415: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:40:54.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-gvw7r" for this suite.
Nov  7 13:41:40.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:41:40.590: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-gvw7r, resource: bindings, ignored listing per whitelist
Nov  7 13:41:40.601: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-gvw7r deletion completed in 46.182389592s

• [SLOW TEST:54.680 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:41:40.602: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dcxwd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:41:40.850: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db6098f3-e292-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-dcxwd" to be "success or failure"
Nov  7 13:41:40.853: INFO: Pod "downwardapi-volume-db6098f3-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.710133ms
Nov  7 13:41:42.858: INFO: Pod "downwardapi-volume-db6098f3-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007794482s
Nov  7 13:41:44.862: INFO: Pod "downwardapi-volume-db6098f3-e292-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012192516s
STEP: Saw pod success
Nov  7 13:41:44.862: INFO: Pod "downwardapi-volume-db6098f3-e292-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:41:44.865: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-db6098f3-e292-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:41:44.885: INFO: Waiting for pod downwardapi-volume-db6098f3-e292-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:41:44.888: INFO: Pod downwardapi-volume-db6098f3-e292-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:41:44.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dcxwd" for this suite.
Nov  7 13:41:50.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:41:50.976: INFO: namespace: e2e-tests-projected-dcxwd, resource: bindings, ignored listing per whitelist
Nov  7 13:41:51.066: INFO: namespace e2e-tests-projected-dcxwd deletion completed in 6.172157729s

• [SLOW TEST:10.465 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:41:51.066: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-t7q2b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:41:51.329: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  7 13:41:56.333: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  7 13:41:56.333: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  7 13:41:56.391: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-t7q2b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t7q2b/deployments/test-cleanup-deployment,UID:e49b97c0-e292-11e8-b11f-bea865258d09,ResourceVersion:17732,Generation:1,CreationTimestamp:2018-11-07 13:41:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Nov  7 13:41:56.395: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Nov  7 13:41:56.395: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov  7 13:41:56.395: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-t7q2b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t7q2b/replicasets/test-cleanup-controller,UID:e19dfd27-e292-11e8-b11f-bea865258d09,ResourceVersion:17733,Generation:1,CreationTimestamp:2018-11-07 13:41:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment e49b97c0-e292-11e8-b11f-bea865258d09 0xc421c29d27 0xc421c29d28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  7 13:41:56.400: INFO: Pod "test-cleanup-controller-rf8m6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-rf8m6,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-t7q2b,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t7q2b/pods/test-cleanup-controller-rf8m6,UID:e19f9db9-e292-11e8-b11f-bea865258d09,ResourceVersion:17723,Generation:0,CreationTimestamp:2018-11-07 13:41:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.159/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller e19dfd27-e292-11e8-b11f-bea865258d09 0xc42108a3a7 0xc42108a3a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sxdmx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sxdmx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sxdmx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42108a410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42108a430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:41:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:41:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:41:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:41:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.159,StartTime:2018-11-07 13:41:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:41:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://e26c88904405f245e95dd95447ce780dd3263e1f9af966d19a9732f0a511708a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:41:56.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-t7q2b" for this suite.
Nov  7 13:42:02.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:42:02.600: INFO: namespace: e2e-tests-deployment-t7q2b, resource: bindings, ignored listing per whitelist
Nov  7 13:42:02.641: INFO: namespace e2e-tests-deployment-t7q2b deletion completed in 6.234979123s

• [SLOW TEST:11.575 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:42:02.642: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-sv95t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-sv95t
I1107 13:42:02.863329      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-sv95t, replica count: 1
I1107 13:42:03.913820      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1107 13:42:04.914143      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  7 13:42:05.022: INFO: Created: latency-svc-dw64p
Nov  7 13:42:05.030: INFO: Got endpoints: latency-svc-dw64p [16.647294ms]
Nov  7 13:42:05.038: INFO: Created: latency-svc-jk6vp
Nov  7 13:42:05.050: INFO: Got endpoints: latency-svc-jk6vp [19.054828ms]
Nov  7 13:42:05.051: INFO: Created: latency-svc-qbds4
Nov  7 13:42:05.065: INFO: Created: latency-svc-m4mh8
Nov  7 13:42:05.065: INFO: Created: latency-svc-9kzrt
Nov  7 13:42:05.065: INFO: Got endpoints: latency-svc-9kzrt [33.998835ms]
Nov  7 13:42:05.066: INFO: Got endpoints: latency-svc-qbds4 [33.021602ms]
Nov  7 13:42:05.069: INFO: Got endpoints: latency-svc-m4mh8 [37.99521ms]
Nov  7 13:42:05.069: INFO: Created: latency-svc-922mt
Nov  7 13:42:05.074: INFO: Created: latency-svc-n7bxp
Nov  7 13:42:05.074: INFO: Got endpoints: latency-svc-922mt [42.860254ms]
Nov  7 13:42:05.079: INFO: Got endpoints: latency-svc-n7bxp [47.588509ms]
Nov  7 13:42:05.080: INFO: Created: latency-svc-hk67b
Nov  7 13:42:05.081: INFO: Got endpoints: latency-svc-hk67b [49.216985ms]
Nov  7 13:42:05.084: INFO: Created: latency-svc-76x5m
Nov  7 13:42:05.089: INFO: Created: latency-svc-plktk
Nov  7 13:42:05.089: INFO: Got endpoints: latency-svc-76x5m [57.27611ms]
Nov  7 13:42:05.093: INFO: Got endpoints: latency-svc-plktk [60.946797ms]
Nov  7 13:42:05.093: INFO: Created: latency-svc-tgjlq
Nov  7 13:42:05.097: INFO: Created: latency-svc-hvzfd
Nov  7 13:42:05.098: INFO: Got endpoints: latency-svc-tgjlq [66.075666ms]
Nov  7 13:42:05.132: INFO: Got endpoints: latency-svc-hvzfd [99.957195ms]
Nov  7 13:42:05.134: INFO: Created: latency-svc-vtmwc
Nov  7 13:42:05.139: INFO: Got endpoints: latency-svc-vtmwc [106.623967ms]
Nov  7 13:42:05.139: INFO: Created: latency-svc-mb2qp
Nov  7 13:42:05.144: INFO: Created: latency-svc-th4kd
Nov  7 13:42:05.144: INFO: Got endpoints: latency-svc-mb2qp [112.188846ms]
Nov  7 13:42:05.149: INFO: Got endpoints: latency-svc-th4kd [116.497593ms]
Nov  7 13:42:05.150: INFO: Created: latency-svc-7kmwc
Nov  7 13:42:05.162: INFO: Got endpoints: latency-svc-7kmwc [129.733845ms]
Nov  7 13:42:05.163: INFO: Created: latency-svc-mps92
Nov  7 13:42:05.169: INFO: Created: latency-svc-d58bc
Nov  7 13:42:05.169: INFO: Got endpoints: latency-svc-mps92 [118.269596ms]
Nov  7 13:42:05.174: INFO: Got endpoints: latency-svc-d58bc [108.649756ms]
Nov  7 13:42:05.174: INFO: Created: latency-svc-wncr8
Nov  7 13:42:05.180: INFO: Created: latency-svc-pg8pv
Nov  7 13:42:05.180: INFO: Got endpoints: latency-svc-wncr8 [113.897ms]
Nov  7 13:42:05.185: INFO: Created: latency-svc-d7vcr
Nov  7 13:42:05.185: INFO: Got endpoints: latency-svc-pg8pv [115.852018ms]
Nov  7 13:42:05.190: INFO: Created: latency-svc-5j48s
Nov  7 13:42:05.191: INFO: Got endpoints: latency-svc-d7vcr [116.340018ms]
Nov  7 13:42:05.192: INFO: Got endpoints: latency-svc-5j48s [113.028758ms]
Nov  7 13:42:05.196: INFO: Created: latency-svc-zhch7
Nov  7 13:42:05.201: INFO: Got endpoints: latency-svc-zhch7 [119.044071ms]
Nov  7 13:42:05.201: INFO: Created: latency-svc-fc66g
Nov  7 13:42:05.207: INFO: Created: latency-svc-dhskb
Nov  7 13:42:05.207: INFO: Got endpoints: latency-svc-fc66g [117.05155ms]
Nov  7 13:42:05.212: INFO: Got endpoints: latency-svc-dhskb [119.210848ms]
Nov  7 13:42:05.212: INFO: Created: latency-svc-ffwkq
Nov  7 13:42:05.231: INFO: Got endpoints: latency-svc-ffwkq [133.131462ms]
Nov  7 13:42:05.234: INFO: Created: latency-svc-n4zp9
Nov  7 13:42:05.239: INFO: Got endpoints: latency-svc-n4zp9 [107.046756ms]
Nov  7 13:42:05.240: INFO: Created: latency-svc-lls8g
Nov  7 13:42:05.245: INFO: Got endpoints: latency-svc-lls8g [106.544256ms]
Nov  7 13:42:05.246: INFO: Created: latency-svc-wd2vm
Nov  7 13:42:05.251: INFO: Got endpoints: latency-svc-wd2vm [106.157552ms]
Nov  7 13:42:05.251: INFO: Created: latency-svc-cb9br
Nov  7 13:42:05.256: INFO: Created: latency-svc-m897x
Nov  7 13:42:05.257: INFO: Got endpoints: latency-svc-cb9br [107.764522ms]
Nov  7 13:42:05.261: INFO: Created: latency-svc-wpf24
Nov  7 13:42:05.262: INFO: Got endpoints: latency-svc-m897x [99.835267ms]
Nov  7 13:42:05.269: INFO: Got endpoints: latency-svc-wpf24 [99.608691ms]
Nov  7 13:42:05.270: INFO: Created: latency-svc-vzdxk
Nov  7 13:42:05.273: INFO: Got endpoints: latency-svc-vzdxk [99.445338ms]
Nov  7 13:42:05.293: INFO: Created: latency-svc-wr4sn
Nov  7 13:42:05.299: INFO: Created: latency-svc-965n7
Nov  7 13:42:05.299: INFO: Got endpoints: latency-svc-wr4sn [118.967146ms]
Nov  7 13:42:05.304: INFO: Created: latency-svc-72r45
Nov  7 13:42:05.304: INFO: Got endpoints: latency-svc-965n7 [118.943676ms]
Nov  7 13:42:05.308: INFO: Created: latency-svc-zljxz
Nov  7 13:42:05.313: INFO: Created: latency-svc-fngfn
Nov  7 13:42:05.318: INFO: Created: latency-svc-ts4b6
Nov  7 13:42:05.333: INFO: Got endpoints: latency-svc-72r45 [142.105496ms]
Nov  7 13:42:05.333: INFO: Created: latency-svc-s6fk4
Nov  7 13:42:05.343: INFO: Created: latency-svc-8v854
Nov  7 13:42:05.349: INFO: Created: latency-svc-cj4t5
Nov  7 13:42:05.357: INFO: Created: latency-svc-hb6tg
Nov  7 13:42:05.361: INFO: Created: latency-svc-sq8mx
Nov  7 13:42:05.365: INFO: Created: latency-svc-h6v86
Nov  7 13:42:05.377: INFO: Created: latency-svc-vgqbg
Nov  7 13:42:05.377: INFO: Got endpoints: latency-svc-zljxz [184.678794ms]
Nov  7 13:42:05.381: INFO: Created: latency-svc-hkbzs
Nov  7 13:42:05.386: INFO: Created: latency-svc-5dpnm
Nov  7 13:42:05.390: INFO: Created: latency-svc-g2t88
Nov  7 13:42:05.395: INFO: Created: latency-svc-mlbcr
Nov  7 13:42:05.431: INFO: Got endpoints: latency-svc-fngfn [230.51577ms]
Nov  7 13:42:05.432: INFO: Created: latency-svc-725tv
Nov  7 13:42:05.436: INFO: Created: latency-svc-jww8z
Nov  7 13:42:05.441: INFO: Created: latency-svc-gshdz
Nov  7 13:42:05.482: INFO: Got endpoints: latency-svc-ts4b6 [274.947463ms]
Nov  7 13:42:05.492: INFO: Created: latency-svc-c27bl
Nov  7 13:42:05.526: INFO: Got endpoints: latency-svc-s6fk4 [313.654604ms]
Nov  7 13:42:05.535: INFO: Created: latency-svc-qlrlh
Nov  7 13:42:05.576: INFO: Got endpoints: latency-svc-8v854 [344.810366ms]
Nov  7 13:42:05.587: INFO: Created: latency-svc-lcdtz
Nov  7 13:42:05.626: INFO: Got endpoints: latency-svc-cj4t5 [387.100777ms]
Nov  7 13:42:05.635: INFO: Created: latency-svc-6mp8w
Nov  7 13:42:05.679: INFO: Got endpoints: latency-svc-hb6tg [433.55061ms]
Nov  7 13:42:05.691: INFO: Created: latency-svc-2dxwh
Nov  7 13:42:05.727: INFO: Got endpoints: latency-svc-sq8mx [475.928871ms]
Nov  7 13:42:05.735: INFO: Created: latency-svc-cnzc9
Nov  7 13:42:05.777: INFO: Got endpoints: latency-svc-h6v86 [519.853829ms]
Nov  7 13:42:05.788: INFO: Created: latency-svc-pkslh
Nov  7 13:42:05.827: INFO: Got endpoints: latency-svc-vgqbg [565.07341ms]
Nov  7 13:42:05.836: INFO: Created: latency-svc-k6qmh
Nov  7 13:42:05.876: INFO: Got endpoints: latency-svc-hkbzs [607.824479ms]
Nov  7 13:42:05.885: INFO: Created: latency-svc-whdsl
Nov  7 13:42:05.926: INFO: Got endpoints: latency-svc-5dpnm [652.993661ms]
Nov  7 13:42:05.938: INFO: Created: latency-svc-mhmq5
Nov  7 13:42:05.977: INFO: Got endpoints: latency-svc-g2t88 [677.778892ms]
Nov  7 13:42:05.986: INFO: Created: latency-svc-dk9sg
Nov  7 13:42:06.027: INFO: Got endpoints: latency-svc-mlbcr [723.172581ms]
Nov  7 13:42:06.035: INFO: Created: latency-svc-hf254
Nov  7 13:42:06.077: INFO: Got endpoints: latency-svc-725tv [744.070506ms]
Nov  7 13:42:06.085: INFO: Created: latency-svc-wsnpq
Nov  7 13:42:06.127: INFO: Got endpoints: latency-svc-jww8z [749.307108ms]
Nov  7 13:42:06.135: INFO: Created: latency-svc-fm2vf
Nov  7 13:42:06.176: INFO: Got endpoints: latency-svc-gshdz [744.959224ms]
Nov  7 13:42:06.185: INFO: Created: latency-svc-bhq2r
Nov  7 13:42:06.227: INFO: Got endpoints: latency-svc-c27bl [744.79902ms]
Nov  7 13:42:06.235: INFO: Created: latency-svc-w9lq6
Nov  7 13:42:06.276: INFO: Got endpoints: latency-svc-qlrlh [749.309062ms]
Nov  7 13:42:06.285: INFO: Created: latency-svc-d8l47
Nov  7 13:42:06.327: INFO: Got endpoints: latency-svc-lcdtz [750.051703ms]
Nov  7 13:42:06.334: INFO: Created: latency-svc-8sv6w
Nov  7 13:42:06.380: INFO: Got endpoints: latency-svc-6mp8w [753.485962ms]
Nov  7 13:42:06.388: INFO: Created: latency-svc-42b8f
Nov  7 13:42:06.491: INFO: Got endpoints: latency-svc-2dxwh [811.681881ms]
Nov  7 13:42:06.491: INFO: Got endpoints: latency-svc-cnzc9 [764.5683ms]
Nov  7 13:42:06.501: INFO: Created: latency-svc-b55wx
Nov  7 13:42:06.507: INFO: Created: latency-svc-qdzgq
Nov  7 13:42:06.592: INFO: Got endpoints: latency-svc-k6qmh [764.714855ms]
Nov  7 13:42:06.592: INFO: Got endpoints: latency-svc-pkslh [815.340188ms]
Nov  7 13:42:06.602: INFO: Created: latency-svc-95lrp
Nov  7 13:42:06.606: INFO: Created: latency-svc-7bfb2
Nov  7 13:42:06.691: INFO: Got endpoints: latency-svc-whdsl [814.679313ms]
Nov  7 13:42:06.692: INFO: Got endpoints: latency-svc-dk9sg [715.080707ms]
Nov  7 13:42:06.725: INFO: Created: latency-svc-gmm6h
Nov  7 13:42:06.726: INFO: Got endpoints: latency-svc-mhmq5 [799.667661ms]
Nov  7 13:42:06.735: INFO: Created: latency-svc-s5dbh
Nov  7 13:42:06.745: INFO: Created: latency-svc-ktk8w
Nov  7 13:42:06.776: INFO: Got endpoints: latency-svc-hf254 [749.295552ms]
Nov  7 13:42:06.794: INFO: Created: latency-svc-9kv9s
Nov  7 13:42:06.827: INFO: Got endpoints: latency-svc-wsnpq [749.443582ms]
Nov  7 13:42:06.839: INFO: Created: latency-svc-wtbjr
Nov  7 13:42:06.877: INFO: Got endpoints: latency-svc-fm2vf [749.832077ms]
Nov  7 13:42:06.886: INFO: Created: latency-svc-wx2tx
Nov  7 13:42:06.926: INFO: Got endpoints: latency-svc-bhq2r [750.058703ms]
Nov  7 13:42:06.935: INFO: Created: latency-svc-m6xzx
Nov  7 13:42:06.977: INFO: Got endpoints: latency-svc-w9lq6 [749.852287ms]
Nov  7 13:42:06.985: INFO: Created: latency-svc-b4lhs
Nov  7 13:42:07.027: INFO: Got endpoints: latency-svc-d8l47 [750.859995ms]
Nov  7 13:42:07.036: INFO: Created: latency-svc-kcszk
Nov  7 13:42:07.077: INFO: Got endpoints: latency-svc-8sv6w [750.165182ms]
Nov  7 13:42:07.085: INFO: Created: latency-svc-cv5fz
Nov  7 13:42:07.126: INFO: Got endpoints: latency-svc-42b8f [746.116704ms]
Nov  7 13:42:07.135: INFO: Created: latency-svc-ddhm8
Nov  7 13:42:07.177: INFO: Got endpoints: latency-svc-b55wx [685.578491ms]
Nov  7 13:42:07.185: INFO: Created: latency-svc-7zv2k
Nov  7 13:42:07.227: INFO: Got endpoints: latency-svc-qdzgq [735.345886ms]
Nov  7 13:42:07.235: INFO: Created: latency-svc-cx2hf
Nov  7 13:42:07.277: INFO: Got endpoints: latency-svc-95lrp [684.643381ms]
Nov  7 13:42:07.285: INFO: Created: latency-svc-bfdlk
Nov  7 13:42:07.327: INFO: Got endpoints: latency-svc-7bfb2 [734.521297ms]
Nov  7 13:42:07.335: INFO: Created: latency-svc-ccr9j
Nov  7 13:42:07.377: INFO: Got endpoints: latency-svc-gmm6h [685.349925ms]
Nov  7 13:42:07.386: INFO: Created: latency-svc-krf4d
Nov  7 13:42:07.427: INFO: Got endpoints: latency-svc-s5dbh [735.037564ms]
Nov  7 13:42:07.435: INFO: Created: latency-svc-75z7k
Nov  7 13:42:07.476: INFO: Got endpoints: latency-svc-ktk8w [750.360096ms]
Nov  7 13:42:07.484: INFO: Created: latency-svc-msjhj
Nov  7 13:42:07.527: INFO: Got endpoints: latency-svc-9kv9s [750.506646ms]
Nov  7 13:42:07.535: INFO: Created: latency-svc-zbt4k
Nov  7 13:42:07.576: INFO: Got endpoints: latency-svc-wtbjr [749.198857ms]
Nov  7 13:42:07.590: INFO: Created: latency-svc-m64pc
Nov  7 13:42:07.627: INFO: Got endpoints: latency-svc-wx2tx [750.807524ms]
Nov  7 13:42:07.637: INFO: Created: latency-svc-f4m8w
Nov  7 13:42:07.676: INFO: Got endpoints: latency-svc-m6xzx [749.596965ms]
Nov  7 13:42:07.685: INFO: Created: latency-svc-mttn4
Nov  7 13:42:07.727: INFO: Got endpoints: latency-svc-b4lhs [750.501283ms]
Nov  7 13:42:07.736: INFO: Created: latency-svc-ldw8x
Nov  7 13:42:07.776: INFO: Got endpoints: latency-svc-kcszk [749.459091ms]
Nov  7 13:42:07.784: INFO: Created: latency-svc-p6mc4
Nov  7 13:42:07.826: INFO: Got endpoints: latency-svc-cv5fz [749.562841ms]
Nov  7 13:42:07.835: INFO: Created: latency-svc-d2xfm
Nov  7 13:42:07.878: INFO: Got endpoints: latency-svc-ddhm8 [752.056852ms]
Nov  7 13:42:07.887: INFO: Created: latency-svc-jwpfp
Nov  7 13:42:07.926: INFO: Got endpoints: latency-svc-7zv2k [749.474439ms]
Nov  7 13:42:07.939: INFO: Created: latency-svc-x4q9s
Nov  7 13:42:07.976: INFO: Got endpoints: latency-svc-cx2hf [749.353527ms]
Nov  7 13:42:07.987: INFO: Created: latency-svc-vkzkv
Nov  7 13:42:08.027: INFO: Got endpoints: latency-svc-bfdlk [749.903961ms]
Nov  7 13:42:08.035: INFO: Created: latency-svc-v4xgw
Nov  7 13:42:08.077: INFO: Got endpoints: latency-svc-ccr9j [749.908804ms]
Nov  7 13:42:08.087: INFO: Created: latency-svc-8h6sv
Nov  7 13:42:08.126: INFO: Got endpoints: latency-svc-krf4d [749.581858ms]
Nov  7 13:42:08.141: INFO: Created: latency-svc-ljnxv
Nov  7 13:42:08.177: INFO: Got endpoints: latency-svc-75z7k [749.759052ms]
Nov  7 13:42:08.186: INFO: Created: latency-svc-vwn9x
Nov  7 13:42:08.226: INFO: Got endpoints: latency-svc-msjhj [749.780456ms]
Nov  7 13:42:08.235: INFO: Created: latency-svc-mhpbd
Nov  7 13:42:08.276: INFO: Got endpoints: latency-svc-zbt4k [749.403352ms]
Nov  7 13:42:08.285: INFO: Created: latency-svc-pvdxd
Nov  7 13:42:08.326: INFO: Got endpoints: latency-svc-m64pc [750.284845ms]
Nov  7 13:42:08.334: INFO: Created: latency-svc-r5zs5
Nov  7 13:42:08.377: INFO: Got endpoints: latency-svc-f4m8w [749.06856ms]
Nov  7 13:42:08.385: INFO: Created: latency-svc-ctblx
Nov  7 13:42:08.426: INFO: Got endpoints: latency-svc-mttn4 [749.671942ms]
Nov  7 13:42:08.435: INFO: Created: latency-svc-wkczp
Nov  7 13:42:08.477: INFO: Got endpoints: latency-svc-ldw8x [749.839765ms]
Nov  7 13:42:08.485: INFO: Created: latency-svc-ks88b
Nov  7 13:42:08.526: INFO: Got endpoints: latency-svc-p6mc4 [750.162158ms]
Nov  7 13:42:08.535: INFO: Created: latency-svc-6hmph
Nov  7 13:42:08.577: INFO: Got endpoints: latency-svc-d2xfm [750.732362ms]
Nov  7 13:42:08.585: INFO: Created: latency-svc-59894
Nov  7 13:42:08.627: INFO: Got endpoints: latency-svc-jwpfp [748.016431ms]
Nov  7 13:42:08.635: INFO: Created: latency-svc-m8psx
Nov  7 13:42:08.676: INFO: Got endpoints: latency-svc-x4q9s [749.938132ms]
Nov  7 13:42:08.691: INFO: Created: latency-svc-hrd5j
Nov  7 13:42:08.727: INFO: Got endpoints: latency-svc-vkzkv [750.107982ms]
Nov  7 13:42:08.735: INFO: Created: latency-svc-dgrcb
Nov  7 13:42:08.776: INFO: Got endpoints: latency-svc-v4xgw [749.343447ms]
Nov  7 13:42:08.784: INFO: Created: latency-svc-48hst
Nov  7 13:42:08.827: INFO: Got endpoints: latency-svc-8h6sv [749.980787ms]
Nov  7 13:42:08.835: INFO: Created: latency-svc-b96gr
Nov  7 13:42:08.877: INFO: Got endpoints: latency-svc-ljnxv [750.241897ms]
Nov  7 13:42:08.888: INFO: Created: latency-svc-d9lct
Nov  7 13:42:08.927: INFO: Got endpoints: latency-svc-vwn9x [750.49708ms]
Nov  7 13:42:08.935: INFO: Created: latency-svc-d66zb
Nov  7 13:42:08.977: INFO: Got endpoints: latency-svc-mhpbd [750.304173ms]
Nov  7 13:42:08.987: INFO: Created: latency-svc-xmd7d
Nov  7 13:42:09.026: INFO: Got endpoints: latency-svc-pvdxd [750.107537ms]
Nov  7 13:42:09.037: INFO: Created: latency-svc-ksvqc
Nov  7 13:42:09.077: INFO: Got endpoints: latency-svc-r5zs5 [750.21144ms]
Nov  7 13:42:09.085: INFO: Created: latency-svc-flb62
Nov  7 13:42:09.129: INFO: Got endpoints: latency-svc-ctblx [751.935254ms]
Nov  7 13:42:09.139: INFO: Created: latency-svc-cr954
Nov  7 13:42:09.190: INFO: Got endpoints: latency-svc-wkczp [764.14359ms]
Nov  7 13:42:09.199: INFO: Created: latency-svc-9ddvn
Nov  7 13:42:09.226: INFO: Got endpoints: latency-svc-ks88b [749.14757ms]
Nov  7 13:42:09.237: INFO: Created: latency-svc-qvpmx
Nov  7 13:42:09.290: INFO: Got endpoints: latency-svc-6hmph [763.718332ms]
Nov  7 13:42:09.298: INFO: Created: latency-svc-mtfjx
Nov  7 13:42:09.326: INFO: Got endpoints: latency-svc-59894 [748.987ms]
Nov  7 13:42:09.337: INFO: Created: latency-svc-2rg5r
Nov  7 13:42:09.389: INFO: Got endpoints: latency-svc-m8psx [762.820166ms]
Nov  7 13:42:09.398: INFO: Created: latency-svc-bdnh4
Nov  7 13:42:09.426: INFO: Got endpoints: latency-svc-hrd5j [749.957115ms]
Nov  7 13:42:09.435: INFO: Created: latency-svc-r4jq8
Nov  7 13:42:09.490: INFO: Got endpoints: latency-svc-dgrcb [763.65644ms]
Nov  7 13:42:09.499: INFO: Created: latency-svc-jc8xt
Nov  7 13:42:09.526: INFO: Got endpoints: latency-svc-48hst [750.236241ms]
Nov  7 13:42:09.535: INFO: Created: latency-svc-4rnq4
Nov  7 13:42:09.589: INFO: Got endpoints: latency-svc-b96gr [762.524081ms]
Nov  7 13:42:09.598: INFO: Created: latency-svc-t9z8m
Nov  7 13:42:09.626: INFO: Got endpoints: latency-svc-d9lct [749.570663ms]
Nov  7 13:42:09.636: INFO: Created: latency-svc-xjr6x
Nov  7 13:42:09.689: INFO: Got endpoints: latency-svc-d66zb [761.449608ms]
Nov  7 13:42:09.697: INFO: Created: latency-svc-dkjbx
Nov  7 13:42:09.727: INFO: Got endpoints: latency-svc-xmd7d [749.836537ms]
Nov  7 13:42:09.735: INFO: Created: latency-svc-nnj5c
Nov  7 13:42:09.790: INFO: Got endpoints: latency-svc-ksvqc [763.252093ms]
Nov  7 13:42:09.798: INFO: Created: latency-svc-k94dv
Nov  7 13:42:09.892: INFO: Got endpoints: latency-svc-flb62 [814.709319ms]
Nov  7 13:42:09.892: INFO: Got endpoints: latency-svc-cr954 [763.169112ms]
Nov  7 13:42:09.901: INFO: Created: latency-svc-54lzk
Nov  7 13:42:09.914: INFO: Created: latency-svc-d5nfz
Nov  7 13:42:09.991: INFO: Got endpoints: latency-svc-9ddvn [800.742233ms]
Nov  7 13:42:09.992: INFO: Got endpoints: latency-svc-qvpmx [766.146119ms]
Nov  7 13:42:10.008: INFO: Created: latency-svc-9prj6
Nov  7 13:42:10.088: INFO: Created: latency-svc-c6rvl
Nov  7 13:42:10.090: INFO: Got endpoints: latency-svc-mtfjx [800.021487ms]
Nov  7 13:42:10.091: INFO: Got endpoints: latency-svc-2rg5r [764.635952ms]
Nov  7 13:42:10.103: INFO: Created: latency-svc-g2d9l
Nov  7 13:42:10.109: INFO: Created: latency-svc-5h879
Nov  7 13:42:10.192: INFO: Got endpoints: latency-svc-bdnh4 [802.270567ms]
Nov  7 13:42:10.193: INFO: Got endpoints: latency-svc-r4jq8 [766.718827ms]
Nov  7 13:42:10.201: INFO: Created: latency-svc-fjrng
Nov  7 13:42:10.207: INFO: Created: latency-svc-2qdsr
Nov  7 13:42:10.226: INFO: Got endpoints: latency-svc-jc8xt [735.292378ms]
Nov  7 13:42:10.290: INFO: Got endpoints: latency-svc-4rnq4 [763.747639ms]
Nov  7 13:42:10.297: INFO: Created: latency-svc-9mjgm
Nov  7 13:42:10.302: INFO: Created: latency-svc-qvscv
Nov  7 13:42:10.327: INFO: Got endpoints: latency-svc-t9z8m [737.395108ms]
Nov  7 13:42:10.335: INFO: Created: latency-svc-v2bmr
Nov  7 13:42:10.388: INFO: Got endpoints: latency-svc-xjr6x [762.164707ms]
Nov  7 13:42:10.397: INFO: Created: latency-svc-7bct9
Nov  7 13:42:10.427: INFO: Got endpoints: latency-svc-dkjbx [738.019778ms]
Nov  7 13:42:10.435: INFO: Created: latency-svc-n7w66
Nov  7 13:42:10.489: INFO: Got endpoints: latency-svc-nnj5c [761.79022ms]
Nov  7 13:42:10.497: INFO: Created: latency-svc-2qz24
Nov  7 13:42:10.526: INFO: Got endpoints: latency-svc-k94dv [736.593373ms]
Nov  7 13:42:10.536: INFO: Created: latency-svc-wbfcd
Nov  7 13:42:10.588: INFO: Got endpoints: latency-svc-54lzk [696.361505ms]
Nov  7 13:42:10.597: INFO: Created: latency-svc-c9x98
Nov  7 13:42:10.626: INFO: Got endpoints: latency-svc-d5nfz [734.305867ms]
Nov  7 13:42:10.636: INFO: Created: latency-svc-rb2q2
Nov  7 13:42:10.690: INFO: Got endpoints: latency-svc-9prj6 [698.563279ms]
Nov  7 13:42:10.699: INFO: Created: latency-svc-65xjv
Nov  7 13:42:10.729: INFO: Got endpoints: latency-svc-c6rvl [736.71204ms]
Nov  7 13:42:10.739: INFO: Created: latency-svc-h8dnk
Nov  7 13:42:10.792: INFO: Got endpoints: latency-svc-g2d9l [701.909424ms]
Nov  7 13:42:10.802: INFO: Created: latency-svc-d9pr7
Nov  7 13:42:10.826: INFO: Got endpoints: latency-svc-5h879 [735.177453ms]
Nov  7 13:42:10.837: INFO: Created: latency-svc-glt4d
Nov  7 13:42:10.889: INFO: Got endpoints: latency-svc-fjrng [696.842849ms]
Nov  7 13:42:10.901: INFO: Created: latency-svc-gttd4
Nov  7 13:42:10.926: INFO: Got endpoints: latency-svc-2qdsr [733.264546ms]
Nov  7 13:42:10.935: INFO: Created: latency-svc-lrj9t
Nov  7 13:42:10.990: INFO: Got endpoints: latency-svc-9mjgm [764.071898ms]
Nov  7 13:42:11.001: INFO: Created: latency-svc-tzdss
Nov  7 13:42:11.027: INFO: Got endpoints: latency-svc-qvscv [736.263723ms]
Nov  7 13:42:11.035: INFO: Created: latency-svc-p8twb
Nov  7 13:42:11.091: INFO: Got endpoints: latency-svc-v2bmr [763.762427ms]
Nov  7 13:42:11.099: INFO: Created: latency-svc-gvqh8
Nov  7 13:42:11.127: INFO: Got endpoints: latency-svc-7bct9 [738.1794ms]
Nov  7 13:42:11.136: INFO: Created: latency-svc-n658m
Nov  7 13:42:11.191: INFO: Got endpoints: latency-svc-n7w66 [764.412891ms]
Nov  7 13:42:11.202: INFO: Created: latency-svc-k59zt
Nov  7 13:42:11.226: INFO: Got endpoints: latency-svc-2qz24 [737.582373ms]
Nov  7 13:42:11.235: INFO: Created: latency-svc-n4rzv
Nov  7 13:42:11.289: INFO: Got endpoints: latency-svc-wbfcd [762.260768ms]
Nov  7 13:42:11.300: INFO: Created: latency-svc-mfnrv
Nov  7 13:42:11.326: INFO: Got endpoints: latency-svc-c9x98 [737.93338ms]
Nov  7 13:42:11.335: INFO: Created: latency-svc-xdbnn
Nov  7 13:42:11.395: INFO: Got endpoints: latency-svc-rb2q2 [768.024797ms]
Nov  7 13:42:11.489: INFO: Created: latency-svc-p8dzv
Nov  7 13:42:11.491: INFO: Got endpoints: latency-svc-65xjv [800.652365ms]
Nov  7 13:42:11.491: INFO: Got endpoints: latency-svc-h8dnk [761.465211ms]
Nov  7 13:42:11.501: INFO: Created: latency-svc-8wv8s
Nov  7 13:42:11.591: INFO: Created: latency-svc-72wwt
Nov  7 13:42:11.591: INFO: Got endpoints: latency-svc-d9pr7 [799.001692ms]
Nov  7 13:42:11.591: INFO: Got endpoints: latency-svc-glt4d [764.857043ms]
Nov  7 13:42:11.694: INFO: Got endpoints: latency-svc-gttd4 [804.770181ms]
Nov  7 13:42:11.695: INFO: Got endpoints: latency-svc-lrj9t [768.62047ms]
Nov  7 13:42:11.700: INFO: Created: latency-svc-ldrnc
Nov  7 13:42:11.712: INFO: Created: latency-svc-xg77t
Nov  7 13:42:11.791: INFO: Got endpoints: latency-svc-tzdss [800.742425ms]
Nov  7 13:42:11.791: INFO: Got endpoints: latency-svc-p8twb [764.836167ms]
Nov  7 13:42:11.794: INFO: Created: latency-svc-t8mnz
Nov  7 13:42:11.801: INFO: Created: latency-svc-t67m2
Nov  7 13:42:11.805: INFO: Created: latency-svc-wmm4b
Nov  7 13:42:11.811: INFO: Created: latency-svc-zjlrb
Nov  7 13:42:11.889: INFO: Got endpoints: latency-svc-gvqh8 [798.26857ms]
Nov  7 13:42:11.891: INFO: Got endpoints: latency-svc-n658m [764.507864ms]
Nov  7 13:42:11.905: INFO: Created: latency-svc-n6zn4
Nov  7 13:42:11.910: INFO: Created: latency-svc-r8cb4
Nov  7 13:42:11.927: INFO: Got endpoints: latency-svc-k59zt [735.285456ms]
Nov  7 13:42:11.937: INFO: Created: latency-svc-8kw2c
Nov  7 13:42:11.990: INFO: Got endpoints: latency-svc-n4rzv [763.410204ms]
Nov  7 13:42:11.998: INFO: Created: latency-svc-7qfld
Nov  7 13:42:12.064: INFO: Got endpoints: latency-svc-mfnrv [775.28623ms]
Nov  7 13:42:12.091: INFO: Got endpoints: latency-svc-xdbnn [764.590381ms]
Nov  7 13:42:12.094: INFO: Created: latency-svc-bf8nc
Nov  7 13:42:12.099: INFO: Created: latency-svc-6fkb4
Nov  7 13:42:12.126: INFO: Got endpoints: latency-svc-p8dzv [731.206474ms]
Nov  7 13:42:12.134: INFO: Created: latency-svc-tph28
Nov  7 13:42:12.189: INFO: Got endpoints: latency-svc-8wv8s [698.882133ms]
Nov  7 13:42:12.201: INFO: Created: latency-svc-qndkz
Nov  7 13:42:12.227: INFO: Got endpoints: latency-svc-72wwt [735.560355ms]
Nov  7 13:42:12.235: INFO: Created: latency-svc-rkz2r
Nov  7 13:42:12.290: INFO: Got endpoints: latency-svc-ldrnc [698.452074ms]
Nov  7 13:42:12.299: INFO: Created: latency-svc-mqd5m
Nov  7 13:42:12.326: INFO: Got endpoints: latency-svc-xg77t [735.012579ms]
Nov  7 13:42:12.335: INFO: Created: latency-svc-g9cn7
Nov  7 13:42:12.390: INFO: Got endpoints: latency-svc-t8mnz [696.611853ms]
Nov  7 13:42:12.401: INFO: Created: latency-svc-bw76n
Nov  7 13:42:12.427: INFO: Got endpoints: latency-svc-t67m2 [731.593463ms]
Nov  7 13:42:12.435: INFO: Created: latency-svc-9s6mb
Nov  7 13:42:12.490: INFO: Got endpoints: latency-svc-wmm4b [698.976206ms]
Nov  7 13:42:12.499: INFO: Created: latency-svc-2b9pp
Nov  7 13:42:12.527: INFO: Got endpoints: latency-svc-zjlrb [735.247216ms]
Nov  7 13:42:12.535: INFO: Created: latency-svc-88ff2
Nov  7 13:42:12.590: INFO: Got endpoints: latency-svc-n6zn4 [701.033209ms]
Nov  7 13:42:12.598: INFO: Created: latency-svc-mzsf9
Nov  7 13:42:12.627: INFO: Got endpoints: latency-svc-r8cb4 [735.43914ms]
Nov  7 13:42:12.635: INFO: Created: latency-svc-klpkd
Nov  7 13:42:12.677: INFO: Got endpoints: latency-svc-8kw2c [749.935781ms]
Nov  7 13:42:12.696: INFO: Created: latency-svc-5v866
Nov  7 13:42:12.727: INFO: Got endpoints: latency-svc-7qfld [737.338495ms]
Nov  7 13:42:12.736: INFO: Created: latency-svc-t7jbb
Nov  7 13:42:12.790: INFO: Got endpoints: latency-svc-bf8nc [725.745029ms]
Nov  7 13:42:12.800: INFO: Created: latency-svc-sfbgv
Nov  7 13:42:12.827: INFO: Got endpoints: latency-svc-6fkb4 [735.946598ms]
Nov  7 13:42:12.838: INFO: Created: latency-svc-pl2rf
Nov  7 13:42:12.890: INFO: Got endpoints: latency-svc-tph28 [764.142102ms]
Nov  7 13:42:12.926: INFO: Got endpoints: latency-svc-qndkz [736.453403ms]
Nov  7 13:42:12.992: INFO: Got endpoints: latency-svc-rkz2r [765.615086ms]
Nov  7 13:42:13.092: INFO: Got endpoints: latency-svc-g9cn7 [766.050707ms]
Nov  7 13:42:13.092: INFO: Got endpoints: latency-svc-mqd5m [802.46687ms]
Nov  7 13:42:13.192: INFO: Got endpoints: latency-svc-bw76n [801.141978ms]
Nov  7 13:42:13.192: INFO: Got endpoints: latency-svc-9s6mb [765.241183ms]
Nov  7 13:42:13.292: INFO: Got endpoints: latency-svc-88ff2 [765.344847ms]
Nov  7 13:42:13.294: INFO: Got endpoints: latency-svc-2b9pp [803.996936ms]
Nov  7 13:42:13.392: INFO: Got endpoints: latency-svc-mzsf9 [801.466346ms]
Nov  7 13:42:13.392: INFO: Got endpoints: latency-svc-klpkd [764.769437ms]
Nov  7 13:42:13.426: INFO: Got endpoints: latency-svc-5v866 [749.68016ms]
Nov  7 13:42:13.490: INFO: Got endpoints: latency-svc-t7jbb [763.232844ms]
Nov  7 13:42:13.526: INFO: Got endpoints: latency-svc-sfbgv [736.032374ms]
Nov  7 13:42:13.577: INFO: Got endpoints: latency-svc-pl2rf [749.379514ms]
Nov  7 13:42:13.577: INFO: Latencies: [19.054828ms 33.021602ms 33.998835ms 37.99521ms 42.860254ms 47.588509ms 49.216985ms 57.27611ms 60.946797ms 66.075666ms 99.445338ms 99.608691ms 99.835267ms 99.957195ms 106.157552ms 106.544256ms 106.623967ms 107.046756ms 107.764522ms 108.649756ms 112.188846ms 113.028758ms 113.897ms 115.852018ms 116.340018ms 116.497593ms 117.05155ms 118.269596ms 118.943676ms 118.967146ms 119.044071ms 119.210848ms 129.733845ms 133.131462ms 142.105496ms 184.678794ms 230.51577ms 274.947463ms 313.654604ms 344.810366ms 387.100777ms 433.55061ms 475.928871ms 519.853829ms 565.07341ms 607.824479ms 652.993661ms 677.778892ms 684.643381ms 685.349925ms 685.578491ms 696.361505ms 696.611853ms 696.842849ms 698.452074ms 698.563279ms 698.882133ms 698.976206ms 701.033209ms 701.909424ms 715.080707ms 723.172581ms 725.745029ms 731.206474ms 731.593463ms 733.264546ms 734.305867ms 734.521297ms 735.012579ms 735.037564ms 735.177453ms 735.247216ms 735.285456ms 735.292378ms 735.345886ms 735.43914ms 735.560355ms 735.946598ms 736.032374ms 736.263723ms 736.453403ms 736.593373ms 736.71204ms 737.338495ms 737.395108ms 737.582373ms 737.93338ms 738.019778ms 738.1794ms 744.070506ms 744.79902ms 744.959224ms 746.116704ms 748.016431ms 748.987ms 749.06856ms 749.14757ms 749.198857ms 749.295552ms 749.307108ms 749.309062ms 749.343447ms 749.353527ms 749.379514ms 749.403352ms 749.443582ms 749.459091ms 749.474439ms 749.562841ms 749.570663ms 749.581858ms 749.596965ms 749.671942ms 749.68016ms 749.759052ms 749.780456ms 749.832077ms 749.836537ms 749.839765ms 749.852287ms 749.903961ms 749.908804ms 749.935781ms 749.938132ms 749.957115ms 749.980787ms 750.051703ms 750.058703ms 750.107537ms 750.107982ms 750.162158ms 750.165182ms 750.21144ms 750.236241ms 750.241897ms 750.284845ms 750.304173ms 750.360096ms 750.49708ms 750.501283ms 750.506646ms 750.732362ms 750.807524ms 750.859995ms 751.935254ms 752.056852ms 753.485962ms 761.449608ms 761.465211ms 761.79022ms 762.164707ms 762.260768ms 762.524081ms 762.820166ms 763.169112ms 763.232844ms 763.252093ms 763.410204ms 763.65644ms 763.718332ms 763.747639ms 763.762427ms 764.071898ms 764.142102ms 764.14359ms 764.412891ms 764.507864ms 764.5683ms 764.590381ms 764.635952ms 764.714855ms 764.769437ms 764.836167ms 764.857043ms 765.241183ms 765.344847ms 765.615086ms 766.050707ms 766.146119ms 766.718827ms 768.024797ms 768.62047ms 775.28623ms 798.26857ms 799.001692ms 799.667661ms 800.021487ms 800.652365ms 800.742233ms 800.742425ms 801.141978ms 801.466346ms 802.270567ms 802.46687ms 803.996936ms 804.770181ms 811.681881ms 814.679313ms 814.709319ms 815.340188ms]
Nov  7 13:42:13.577: INFO: 50 %ile: 749.309062ms
Nov  7 13:42:13.577: INFO: 90 %ile: 768.024797ms
Nov  7 13:42:13.577: INFO: 99 %ile: 814.709319ms
Nov  7 13:42:13.577: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:42:13.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-sv95t" for this suite.
Nov  7 13:42:29.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:42:29.629: INFO: namespace: e2e-tests-svc-latency-sv95t, resource: bindings, ignored listing per whitelist
Nov  7 13:42:29.765: INFO: namespace e2e-tests-svc-latency-sv95t deletion completed in 16.175199441s

• [SLOW TEST:27.123 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:42:29.766: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7jddf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f8acb431-e292-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:42:30.006: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f8ad2209-e292-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-7jddf" to be "success or failure"
Nov  7 13:42:30.017: INFO: Pod "pod-projected-configmaps-f8ad2209-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.555257ms
Nov  7 13:42:32.021: INFO: Pod "pod-projected-configmaps-f8ad2209-e292-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015484556s
STEP: Saw pod success
Nov  7 13:42:32.021: INFO: Pod "pod-projected-configmaps-f8ad2209-e292-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:42:32.024: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-configmaps-f8ad2209-e292-11e8-bb28-1ed0160468e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 13:42:32.045: INFO: Waiting for pod pod-projected-configmaps-f8ad2209-e292-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:42:32.048: INFO: Pod pod-projected-configmaps-f8ad2209-e292-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:42:32.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7jddf" for this suite.
Nov  7 13:42:38.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:42:38.190: INFO: namespace: e2e-tests-projected-7jddf, resource: bindings, ignored listing per whitelist
Nov  7 13:42:38.211: INFO: namespace e2e-tests-projected-7jddf deletion completed in 6.157116113s

• [SLOW TEST:8.446 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:42:38.211: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9wq4l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-fdb6c260-e292-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:42:38.461: INFO: Waiting up to 5m0s for pod "pod-configmaps-fdb754de-e292-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-9wq4l" to be "success or failure"
Nov  7 13:42:38.464: INFO: Pod "pod-configmaps-fdb754de-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.823085ms
Nov  7 13:42:40.468: INFO: Pod "pod-configmaps-fdb754de-e292-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007018181s
Nov  7 13:42:42.472: INFO: Pod "pod-configmaps-fdb754de-e292-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011125953s
STEP: Saw pod success
Nov  7 13:42:42.472: INFO: Pod "pod-configmaps-fdb754de-e292-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:42:42.475: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-fdb754de-e292-11e8-bb28-1ed0160468e8 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 13:42:42.495: INFO: Waiting for pod pod-configmaps-fdb754de-e292-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:42:42.504: INFO: Pod pod-configmaps-fdb754de-e292-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:42:42.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9wq4l" for this suite.
Nov  7 13:42:48.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:42:48.664: INFO: namespace: e2e-tests-configmap-9wq4l, resource: bindings, ignored listing per whitelist
Nov  7 13:42:48.712: INFO: namespace e2e-tests-configmap-9wq4l deletion completed in 6.195819078s

• [SLOW TEST:10.501 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:42:48.712: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5v7d5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-5v7d5/secret-test-03f59453-e293-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:42:48.941: INFO: Waiting up to 5m0s for pod "pod-configmaps-03f620c1-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-5v7d5" to be "success or failure"
Nov  7 13:42:48.945: INFO: Pod "pod-configmaps-03f620c1-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030202ms
Nov  7 13:42:50.950: INFO: Pod "pod-configmaps-03f620c1-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008625905s
STEP: Saw pod success
Nov  7 13:42:50.950: INFO: Pod "pod-configmaps-03f620c1-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:42:50.953: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-03f620c1-e293-11e8-bb28-1ed0160468e8 container env-test: <nil>
STEP: delete the pod
Nov  7 13:42:51.034: INFO: Waiting for pod pod-configmaps-03f620c1-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:42:51.048: INFO: Pod pod-configmaps-03f620c1-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:42:51.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5v7d5" for this suite.
Nov  7 13:42:57.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:42:57.255: INFO: namespace: e2e-tests-secrets-5v7d5, resource: bindings, ignored listing per whitelist
Nov  7 13:42:57.284: INFO: namespace e2e-tests-secrets-5v7d5 deletion completed in 6.21992872s

• [SLOW TEST:8.572 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:42:57.285: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4lgg9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:42:57.497: INFO: Waiting up to 5m0s for pod "downwardapi-volume-090fe727-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-4lgg9" to be "success or failure"
Nov  7 13:42:57.501: INFO: Pod "downwardapi-volume-090fe727-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.420128ms
Nov  7 13:42:59.504: INFO: Pod "downwardapi-volume-090fe727-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006380146s
Nov  7 13:43:01.508: INFO: Pod "downwardapi-volume-090fe727-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010589757s
STEP: Saw pod success
Nov  7 13:43:01.508: INFO: Pod "downwardapi-volume-090fe727-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:43:01.511: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-090fe727-e293-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:43:01.550: INFO: Waiting for pod downwardapi-volume-090fe727-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:43:01.557: INFO: Pod downwardapi-volume-090fe727-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:43:01.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4lgg9" for this suite.
Nov  7 13:43:07.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:43:07.639: INFO: namespace: e2e-tests-downward-api-4lgg9, resource: bindings, ignored listing per whitelist
Nov  7 13:43:07.801: INFO: namespace e2e-tests-downward-api-4lgg9 deletion completed in 6.240098832s

• [SLOW TEST:10.516 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:43:07.802: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-kc2jm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-lq9sl in namespace e2e-tests-proxy-kc2jm
I1107 13:43:08.040114      15 runners.go:180] Created replication controller with name: proxy-service-lq9sl, namespace: e2e-tests-proxy-kc2jm, replica count: 1
I1107 13:43:09.091180      15 runners.go:180] proxy-service-lq9sl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1107 13:43:10.091368      15 runners.go:180] proxy-service-lq9sl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1107 13:43:11.091817      15 runners.go:180] proxy-service-lq9sl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1107 13:43:12.092152      15 runners.go:180] proxy-service-lq9sl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1107 13:43:13.092392      15 runners.go:180] proxy-service-lq9sl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1107 13:43:14.092624      15 runners.go:180] proxy-service-lq9sl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1107 13:43:15.092941      15 runners.go:180] proxy-service-lq9sl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1107 13:43:16.093154      15 runners.go:180] proxy-service-lq9sl Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  7 13:43:16.096: INFO: setup took 8.071812515s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  7 13:43:16.106: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 8.924833ms)
Nov  7 13:43:16.128: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 30.591488ms)
Nov  7 13:43:16.128: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 31.157519ms)
Nov  7 13:43:16.128: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 30.634185ms)
Nov  7 13:43:16.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 92.172933ms)
Nov  7 13:43:16.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 91.946811ms)
Nov  7 13:43:16.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 92.203739ms)
Nov  7 13:43:16.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 92.310231ms)
Nov  7 13:43:16.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 92.171673ms)
Nov  7 13:43:16.190: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 92.999325ms)
Nov  7 13:43:16.190: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 93.153771ms)
Nov  7 13:43:16.194: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 97.793709ms)
Nov  7 13:43:16.196: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 99.431533ms)
Nov  7 13:43:16.196: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 99.143682ms)
Nov  7 13:43:16.196: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 99.569461ms)
Nov  7 13:43:16.196: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 98.912903ms)
Nov  7 13:43:16.204: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 7.674523ms)
Nov  7 13:43:16.204: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 8.188756ms)
Nov  7 13:43:16.204: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 8.262318ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 8.727641ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 8.617728ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 8.160724ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 8.828633ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 8.628528ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 8.777207ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 8.507548ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 9.022125ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.487962ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 8.97261ms)
Nov  7 13:43:16.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 8.607347ms)
Nov  7 13:43:16.206: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.965454ms)
Nov  7 13:43:16.206: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 10.059448ms)
Nov  7 13:43:16.214: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 6.992979ms)
Nov  7 13:43:16.214: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.090343ms)
Nov  7 13:43:16.214: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.787448ms)
Nov  7 13:43:16.214: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.075ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 8.702518ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.364856ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 8.351851ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 8.413714ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 8.634511ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 8.764345ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 8.715637ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 8.547996ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 9.23769ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 9.608787ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 9.814282ms)
Nov  7 13:43:16.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.452652ms)
Nov  7 13:43:16.223: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 5.502033ms)
Nov  7 13:43:16.224: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 6.401596ms)
Nov  7 13:43:16.224: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.465618ms)
Nov  7 13:43:16.224: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 7.389843ms)
Nov  7 13:43:16.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 7.019166ms)
Nov  7 13:43:16.224: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.353523ms)
Nov  7 13:43:16.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 8.050627ms)
Nov  7 13:43:16.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.046789ms)
Nov  7 13:43:16.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 7.710052ms)
Nov  7 13:43:16.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 8.049698ms)
Nov  7 13:43:16.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 7.673771ms)
Nov  7 13:43:16.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 8.056546ms)
Nov  7 13:43:16.227: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.805175ms)
Nov  7 13:43:16.228: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 10.539988ms)
Nov  7 13:43:16.228: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 11.252628ms)
Nov  7 13:43:16.229: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 11.654542ms)
Nov  7 13:43:16.237: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 8.220015ms)
Nov  7 13:43:16.237: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.346992ms)
Nov  7 13:43:16.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 8.068847ms)
Nov  7 13:43:16.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.021601ms)
Nov  7 13:43:16.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 8.419046ms)
Nov  7 13:43:16.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 8.620428ms)
Nov  7 13:43:16.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 8.920189ms)
Nov  7 13:43:16.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 8.444929ms)
Nov  7 13:43:16.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 9.303254ms)
Nov  7 13:43:16.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 8.972192ms)
Nov  7 13:43:16.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 9.030057ms)
Nov  7 13:43:16.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 9.721534ms)
Nov  7 13:43:16.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 9.445297ms)
Nov  7 13:43:16.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 9.854411ms)
Nov  7 13:43:16.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 10.167176ms)
Nov  7 13:43:16.241: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 11.164474ms)
Nov  7 13:43:16.246: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 5.261303ms)
Nov  7 13:43:16.247: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 6.100906ms)
Nov  7 13:43:16.247: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 6.099494ms)
Nov  7 13:43:16.248: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 6.373697ms)
Nov  7 13:43:16.248: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 6.373324ms)
Nov  7 13:43:16.248: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 6.782336ms)
Nov  7 13:43:16.248: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 6.611796ms)
Nov  7 13:43:16.248: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 6.934748ms)
Nov  7 13:43:16.249: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 7.575586ms)
Nov  7 13:43:16.249: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 7.743357ms)
Nov  7 13:43:16.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 8.404832ms)
Nov  7 13:43:16.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 8.201471ms)
Nov  7 13:43:16.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 8.824914ms)
Nov  7 13:43:16.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 8.792692ms)
Nov  7 13:43:16.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 9.062101ms)
Nov  7 13:43:16.251: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 9.203882ms)
Nov  7 13:43:16.257: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 6.491244ms)
Nov  7 13:43:16.258: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 7.145712ms)
Nov  7 13:43:16.258: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 7.088939ms)
Nov  7 13:43:16.258: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.158964ms)
Nov  7 13:43:16.258: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.270365ms)
Nov  7 13:43:16.259: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 7.588159ms)
Nov  7 13:43:16.259: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 7.759746ms)
Nov  7 13:43:16.259: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 7.572568ms)
Nov  7 13:43:16.291: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 39.970663ms)
Nov  7 13:43:16.291: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 40.278499ms)
Nov  7 13:43:16.291: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 39.884585ms)
Nov  7 13:43:16.292: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 41.045598ms)
Nov  7 13:43:16.292: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 41.409888ms)
Nov  7 13:43:16.292: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 41.076422ms)
Nov  7 13:43:16.292: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 41.017595ms)
Nov  7 13:43:16.294: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 43.053514ms)
Nov  7 13:43:16.301: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 6.357652ms)
Nov  7 13:43:16.301: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 5.936203ms)
Nov  7 13:43:16.302: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 7.860243ms)
Nov  7 13:43:16.302: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.505726ms)
Nov  7 13:43:16.302: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 7.432639ms)
Nov  7 13:43:16.302: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 7.841831ms)
Nov  7 13:43:16.303: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.468802ms)
Nov  7 13:43:16.303: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 8.30573ms)
Nov  7 13:43:16.303: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.730317ms)
Nov  7 13:43:16.303: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 7.993827ms)
Nov  7 13:43:16.303: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.707776ms)
Nov  7 13:43:16.303: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 8.472008ms)
Nov  7 13:43:16.303: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 7.928753ms)
Nov  7 13:43:16.345: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 50.114261ms)
Nov  7 13:43:16.345: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 50.18245ms)
Nov  7 13:43:16.345: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 50.252829ms)
Nov  7 13:43:16.354: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.311281ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 8.602528ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 8.803015ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 9.104033ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 8.737203ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 9.0593ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.794409ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.026273ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 8.934578ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 9.442604ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 9.093725ms)
Nov  7 13:43:16.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 9.261817ms)
Nov  7 13:43:16.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 9.963ms)
Nov  7 13:43:16.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 10.123071ms)
Nov  7 13:43:16.357: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 10.798304ms)
Nov  7 13:43:16.357: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 11.379876ms)
Nov  7 13:43:16.363: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 5.045323ms)
Nov  7 13:43:16.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 6.994917ms)
Nov  7 13:43:16.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.028432ms)
Nov  7 13:43:16.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 8.20995ms)
Nov  7 13:43:16.366: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.65266ms)
Nov  7 13:43:16.366: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.643449ms)
Nov  7 13:43:16.366: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 7.538425ms)
Nov  7 13:43:16.366: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 7.443792ms)
Nov  7 13:43:16.366: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 7.87971ms)
Nov  7 13:43:16.366: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.212495ms)
Nov  7 13:43:16.409: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 51.054229ms)
Nov  7 13:43:16.409: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 51.744676ms)
Nov  7 13:43:16.451: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 92.555486ms)
Nov  7 13:43:16.451: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 93.009632ms)
Nov  7 13:43:16.451: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 93.262004ms)
Nov  7 13:43:16.452: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 92.985963ms)
Nov  7 13:43:16.459: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 6.297893ms)
Nov  7 13:43:16.459: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 6.942446ms)
Nov  7 13:43:16.459: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 6.675852ms)
Nov  7 13:43:16.459: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.436446ms)
Nov  7 13:43:16.459: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 6.88862ms)
Nov  7 13:43:16.460: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 7.157521ms)
Nov  7 13:43:16.460: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 7.972698ms)
Nov  7 13:43:16.460: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.994583ms)
Nov  7 13:43:16.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 8.240474ms)
Nov  7 13:43:16.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 8.751041ms)
Nov  7 13:43:16.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 8.396ms)
Nov  7 13:43:16.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 9.36657ms)
Nov  7 13:43:16.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 9.12031ms)
Nov  7 13:43:16.462: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 9.132591ms)
Nov  7 13:43:16.462: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 9.804152ms)
Nov  7 13:43:16.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 10.425627ms)
Nov  7 13:43:16.470: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 6.74513ms)
Nov  7 13:43:16.470: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 7.444125ms)
Nov  7 13:43:16.470: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 7.138883ms)
Nov  7 13:43:16.470: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 6.962887ms)
Nov  7 13:43:16.471: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.328503ms)
Nov  7 13:43:16.471: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.69685ms)
Nov  7 13:43:16.471: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 7.590936ms)
Nov  7 13:43:16.472: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 8.853376ms)
Nov  7 13:43:16.472: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 9.160702ms)
Nov  7 13:43:16.472: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 9.297571ms)
Nov  7 13:43:16.473: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.255528ms)
Nov  7 13:43:16.473: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 9.941776ms)
Nov  7 13:43:16.473: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 10.225406ms)
Nov  7 13:43:16.473: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 9.729992ms)
Nov  7 13:43:16.473: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 10.271867ms)
Nov  7 13:43:16.474: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 11.241082ms)
Nov  7 13:43:16.483: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.496272ms)
Nov  7 13:43:16.483: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 8.33173ms)
Nov  7 13:43:16.483: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.624366ms)
Nov  7 13:43:16.483: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 8.487016ms)
Nov  7 13:43:16.484: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 8.507906ms)
Nov  7 13:43:16.484: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 8.880473ms)
Nov  7 13:43:16.484: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 8.202608ms)
Nov  7 13:43:16.484: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 8.673213ms)
Nov  7 13:43:16.484: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 8.36686ms)
Nov  7 13:43:16.484: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 9.31973ms)
Nov  7 13:43:16.484: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.995646ms)
Nov  7 13:43:16.484: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 9.228401ms)
Nov  7 13:43:16.527: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 51.236722ms)
Nov  7 13:43:16.527: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 51.75048ms)
Nov  7 13:43:16.527: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 51.473937ms)
Nov  7 13:43:16.527: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 51.603031ms)
Nov  7 13:43:16.537: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 9.110259ms)
Nov  7 13:43:16.537: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.570569ms)
Nov  7 13:43:16.537: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 9.462741ms)
Nov  7 13:43:16.537: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 9.691537ms)
Nov  7 13:43:16.538: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 10.161564ms)
Nov  7 13:43:16.538: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 10.303798ms)
Nov  7 13:43:16.538: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 10.510059ms)
Nov  7 13:43:16.538: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 10.755257ms)
Nov  7 13:43:16.538: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 10.757535ms)
Nov  7 13:43:16.538: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 10.909097ms)
Nov  7 13:43:16.538: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 10.660361ms)
Nov  7 13:43:16.538: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 10.862625ms)
Nov  7 13:43:16.540: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 12.443027ms)
Nov  7 13:43:16.540: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 12.923643ms)
Nov  7 13:43:16.541: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 13.251507ms)
Nov  7 13:43:16.540: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 12.882073ms)
Nov  7 13:43:16.547: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 5.967076ms)
Nov  7 13:43:16.548: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 7.508842ms)
Nov  7 13:43:16.548: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 7.415668ms)
Nov  7 13:43:16.549: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 7.941026ms)
Nov  7 13:43:16.549: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 8.106472ms)
Nov  7 13:43:16.550: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 8.655581ms)
Nov  7 13:43:16.550: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 9.292693ms)
Nov  7 13:43:16.550: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 8.989288ms)
Nov  7 13:43:16.550: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 8.90122ms)
Nov  7 13:43:16.550: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 9.069743ms)
Nov  7 13:43:16.551: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 9.725882ms)
Nov  7 13:43:16.551: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 9.962023ms)
Nov  7 13:43:16.551: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.63349ms)
Nov  7 13:43:16.551: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 9.675278ms)
Nov  7 13:43:16.551: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 10.402393ms)
Nov  7 13:43:16.552: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 10.986792ms)
Nov  7 13:43:16.563: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 9.924014ms)
Nov  7 13:43:16.563: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 10.785502ms)
Nov  7 13:43:16.563: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 10.504052ms)
Nov  7 13:43:16.563: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 10.411744ms)
Nov  7 13:43:16.563: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 10.126112ms)
Nov  7 13:43:16.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 10.694943ms)
Nov  7 13:43:16.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 10.71185ms)
Nov  7 13:43:16.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 10.948778ms)
Nov  7 13:43:16.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 11.300589ms)
Nov  7 13:43:16.567: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 13.613176ms)
Nov  7 13:43:16.567: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 14.227896ms)
Nov  7 13:43:16.567: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 13.990593ms)
Nov  7 13:43:16.567: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 14.408504ms)
Nov  7 13:43:16.567: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 14.516305ms)
Nov  7 13:43:16.567: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 14.663545ms)
Nov  7 13:43:16.568: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 14.254176ms)
Nov  7 13:43:16.579: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 11.258794ms)
Nov  7 13:43:16.580: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 11.354293ms)
Nov  7 13:43:16.580: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 11.786635ms)
Nov  7 13:43:16.580: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 11.679457ms)
Nov  7 13:43:16.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 12.510896ms)
Nov  7 13:43:16.580: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 11.614209ms)
Nov  7 13:43:16.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 12.984006ms)
Nov  7 13:43:16.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 12.896465ms)
Nov  7 13:43:16.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 13.097152ms)
Nov  7 13:43:16.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 12.180113ms)
Nov  7 13:43:16.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 13.241674ms)
Nov  7 13:43:16.582: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 13.5663ms)
Nov  7 13:43:16.582: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 13.475773ms)
Nov  7 13:43:16.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 14.93347ms)
Nov  7 13:43:16.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 15.250322ms)
Nov  7 13:43:16.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 16.077664ms)
Nov  7 13:43:16.595: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 10.402803ms)
Nov  7 13:43:16.595: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 10.44974ms)
Nov  7 13:43:16.595: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 10.562695ms)
Nov  7 13:43:16.595: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 11.175303ms)
Nov  7 13:43:16.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 11.305599ms)
Nov  7 13:43:16.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 11.366892ms)
Nov  7 13:43:16.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 11.244532ms)
Nov  7 13:43:16.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 11.695878ms)
Nov  7 13:43:16.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 11.826953ms)
Nov  7 13:43:16.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 12.050998ms)
Nov  7 13:43:16.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 12.004764ms)
Nov  7 13:43:16.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 11.886349ms)
Nov  7 13:43:16.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 13.219561ms)
Nov  7 13:43:16.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 13.99817ms)
Nov  7 13:43:16.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 13.553536ms)
Nov  7 13:43:16.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 13.71346ms)
Nov  7 13:43:16.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.015771ms)
Nov  7 13:43:16.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 9.0255ms)
Nov  7 13:43:16.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.508428ms)
Nov  7 13:43:16.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 9.592726ms)
Nov  7 13:43:16.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 9.81257ms)
Nov  7 13:43:16.609: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 9.929176ms)
Nov  7 13:43:16.609: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 9.530287ms)
Nov  7 13:43:16.609: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 9.668948ms)
Nov  7 13:43:16.609: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 10.00725ms)
Nov  7 13:43:16.609: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 9.821337ms)
Nov  7 13:43:16.609: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 9.815677ms)
Nov  7 13:43:16.609: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 9.65026ms)
Nov  7 13:43:16.611: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 11.700342ms)
Nov  7 13:43:16.611: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 11.98581ms)
Nov  7 13:43:16.611: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 12.454115ms)
Nov  7 13:43:16.612: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 13.147683ms)
Nov  7 13:43:16.621: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94/proxy/rewriteme"... (200; 8.986726ms)
Nov  7 13:43:16.621: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:462/proxy/: tls qux (200; 8.92061ms)
Nov  7 13:43:16.621: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname2/proxy/: tls qux (200; 9.16142ms)
Nov  7 13:43:16.621: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:460/proxy/: tls baz (200; 8.84363ms)
Nov  7 13:43:16.621: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:1080/proxy/... (200; 8.926912ms)
Nov  7 13:43:16.622: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/https:proxy-service-lq9sl:tlsportname1/proxy/: tls baz (200; 9.715106ms)
Nov  7 13:43:16.622: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:1080/proxy/rewri... (200; 9.78623ms)
Nov  7 13:43:16.622: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/https:proxy-service-lq9sl-frq94:443/proxy/... (200; 10.111346ms)
Nov  7 13:43:16.622: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:162/proxy/: bar (200; 9.960836ms)
Nov  7 13:43:16.622: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:160/proxy/: foo (200; 10.469428ms)
Nov  7 13:43:16.622: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/proxy-service-lq9sl-frq94:160/proxy/: foo (200; 10.211469ms)
Nov  7 13:43:16.622: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/pods/http:proxy-service-lq9sl-frq94:162/proxy/: bar (200; 10.265928ms)
Nov  7 13:43:16.664: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname2/proxy/: bar (200; 51.406723ms)
Nov  7 13:43:16.664: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/http:proxy-service-lq9sl:portname1/proxy/: foo (200; 51.580921ms)
Nov  7 13:43:16.664: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname2/proxy/: bar (200; 51.551863ms)
Nov  7 13:43:16.664: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kc2jm/services/proxy-service-lq9sl:portname1/proxy/: foo (200; 51.989576ms)
STEP: deleting { ReplicationController} proxy-service-lq9sl in namespace e2e-tests-proxy-kc2jm, will wait for the garbage collector to delete the pods
Nov  7 13:43:16.723: INFO: Deleting { ReplicationController} proxy-service-lq9sl took: 5.862637ms
Nov  7 13:43:16.824: INFO: Terminating { ReplicationController} proxy-service-lq9sl pods took: 100.288139ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:43:28.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-kc2jm" for this suite.
Nov  7 13:43:34.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:43:34.257: INFO: namespace: e2e-tests-proxy-kc2jm, resource: bindings, ignored listing per whitelist
Nov  7 13:43:34.318: INFO: namespace e2e-tests-proxy-kc2jm deletion completed in 6.28963955s

• [SLOW TEST:26.516 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:43:34.320: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-brxjr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-brxjr/configmap-test-1f22ff04-e293-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:43:34.535: INFO: Waiting up to 5m0s for pod "pod-configmaps-1f238bd6-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-brxjr" to be "success or failure"
Nov  7 13:43:34.543: INFO: Pod "pod-configmaps-1f238bd6-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.084316ms
Nov  7 13:43:36.547: INFO: Pod "pod-configmaps-1f238bd6-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011642727s
STEP: Saw pod success
Nov  7 13:43:36.547: INFO: Pod "pod-configmaps-1f238bd6-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:43:36.550: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-1f238bd6-e293-11e8-bb28-1ed0160468e8 container env-test: <nil>
STEP: delete the pod
Nov  7 13:43:36.573: INFO: Waiting for pod pod-configmaps-1f238bd6-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:43:36.575: INFO: Pod pod-configmaps-1f238bd6-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:43:36.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-brxjr" for this suite.
Nov  7 13:43:42.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:43:42.621: INFO: namespace: e2e-tests-configmap-brxjr, resource: bindings, ignored listing per whitelist
Nov  7 13:43:42.808: INFO: namespace e2e-tests-configmap-brxjr deletion completed in 6.214987783s

• [SLOW TEST:8.487 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:43:42.809: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-g4tn7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-g4tn7.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-g4tn7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-g4tn7.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-g4tn7.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-g4tn7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-g4tn7.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  7 13:43:56.307: INFO: DNS probes using e2e-tests-dns-g4tn7/dns-test-24308fc6-e293-11e8-bb28-1ed0160468e8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:43:56.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-g4tn7" for this suite.
Nov  7 13:44:02.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:44:02.542: INFO: namespace: e2e-tests-dns-g4tn7, resource: bindings, ignored listing per whitelist
Nov  7 13:44:02.593: INFO: namespace e2e-tests-dns-g4tn7 deletion completed in 6.23471117s

• [SLOW TEST:19.784 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:44:02.593: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8kl47
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  7 13:44:02.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-8kl47'
Nov  7 13:44:03.364: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  7 13:44:03.364: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Nov  7 13:44:07.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-8kl47'
Nov  7 13:44:07.496: INFO: stderr: ""
Nov  7 13:44:07.496: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:44:07.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8kl47" for this suite.
Nov  7 13:44:29.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:44:29.642: INFO: namespace: e2e-tests-kubectl-8kl47, resource: bindings, ignored listing per whitelist
Nov  7 13:44:29.692: INFO: namespace e2e-tests-kubectl-8kl47 deletion completed in 22.192142035s

• [SLOW TEST:27.099 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:44:29.692: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-d54h2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-d54h2/configmap-test-40240e2c-e293-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:44:29.907: INFO: Waiting up to 5m0s for pod "pod-configmaps-4024a198-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-configmap-d54h2" to be "success or failure"
Nov  7 13:44:29.913: INFO: Pod "pod-configmaps-4024a198-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.669352ms
Nov  7 13:44:31.917: INFO: Pod "pod-configmaps-4024a198-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010121568s
STEP: Saw pod success
Nov  7 13:44:31.917: INFO: Pod "pod-configmaps-4024a198-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:44:31.920: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-configmaps-4024a198-e293-11e8-bb28-1ed0160468e8 container env-test: <nil>
STEP: delete the pod
Nov  7 13:44:31.941: INFO: Waiting for pod pod-configmaps-4024a198-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:44:31.950: INFO: Pod pod-configmaps-4024a198-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:44:31.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d54h2" for this suite.
Nov  7 13:44:37.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:44:38.107: INFO: namespace: e2e-tests-configmap-d54h2, resource: bindings, ignored listing per whitelist
Nov  7 13:44:38.131: INFO: namespace e2e-tests-configmap-d54h2 deletion completed in 6.17561972s

• [SLOW TEST:8.439 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:44:38.132: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-m5l8v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Nov  7 13:44:38.387: INFO: Waiting up to 5m0s for pod "client-containers-453268b3-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-containers-m5l8v" to be "success or failure"
Nov  7 13:44:38.392: INFO: Pod "client-containers-453268b3-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.369939ms
Nov  7 13:44:40.431: INFO: Pod "client-containers-453268b3-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044258521s
STEP: Saw pod success
Nov  7 13:44:40.431: INFO: Pod "client-containers-453268b3-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:44:40.435: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod client-containers-453268b3-e293-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:44:40.456: INFO: Waiting for pod client-containers-453268b3-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:44:40.461: INFO: Pod client-containers-453268b3-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:44:40.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-m5l8v" for this suite.
Nov  7 13:44:46.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:44:46.494: INFO: namespace: e2e-tests-containers-m5l8v, resource: bindings, ignored listing per whitelist
Nov  7 13:44:46.592: INFO: namespace e2e-tests-containers-m5l8v deletion completed in 6.127228879s

• [SLOW TEST:8.460 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:44:46.592: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-m96jd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Nov  7 13:44:46.850: INFO: Waiting up to 5m0s for pod "client-containers-4a3dd399-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-containers-m96jd" to be "success or failure"
Nov  7 13:44:46.859: INFO: Pod "client-containers-4a3dd399-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.709287ms
Nov  7 13:44:48.864: INFO: Pod "client-containers-4a3dd399-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007706867s
STEP: Saw pod success
Nov  7 13:44:48.864: INFO: Pod "client-containers-4a3dd399-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:44:48.867: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod client-containers-4a3dd399-e293-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:44:48.887: INFO: Waiting for pod client-containers-4a3dd399-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:44:48.904: INFO: Pod client-containers-4a3dd399-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:44:48.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-m96jd" for this suite.
Nov  7 13:44:54.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:44:55.118: INFO: namespace: e2e-tests-containers-m96jd, resource: bindings, ignored listing per whitelist
Nov  7 13:44:55.149: INFO: namespace e2e-tests-containers-m96jd deletion completed in 6.240682709s

• [SLOW TEST:8.557 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:44:55.149: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hghwr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-4f58e4b3-e293-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:44:55.419: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4f596ed0-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-hghwr" to be "success or failure"
Nov  7 13:44:55.424: INFO: Pod "pod-projected-secrets-4f596ed0-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.143508ms
Nov  7 13:44:57.428: INFO: Pod "pod-projected-secrets-4f596ed0-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009284327s
STEP: Saw pod success
Nov  7 13:44:57.428: INFO: Pod "pod-projected-secrets-4f596ed0-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:44:57.431: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-secrets-4f596ed0-e293-11e8-bb28-1ed0160468e8 container secret-volume-test: <nil>
STEP: delete the pod
Nov  7 13:44:57.448: INFO: Waiting for pod pod-projected-secrets-4f596ed0-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:44:57.457: INFO: Pod pod-projected-secrets-4f596ed0-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:44:57.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hghwr" for this suite.
Nov  7 13:45:03.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:45:03.611: INFO: namespace: e2e-tests-projected-hghwr, resource: bindings, ignored listing per whitelist
Nov  7 13:45:03.634: INFO: namespace e2e-tests-projected-hghwr deletion completed in 6.167675544s

• [SLOW TEST:8.485 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:45:03.635: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-d5spk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W1107 13:45:04.964339      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  7 13:45:04.964: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:45:04.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-d5spk" for this suite.
Nov  7 13:45:11.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:45:11.151: INFO: namespace: e2e-tests-gc-d5spk, resource: bindings, ignored listing per whitelist
Nov  7 13:45:11.208: INFO: namespace e2e-tests-gc-d5spk deletion completed in 6.240364501s

• [SLOW TEST:7.573 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:45:11.209: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-65ldb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-58e945ea-e293-11e8-bb28-1ed0160468e8
Nov  7 13:45:11.463: INFO: Pod name my-hostname-basic-58e945ea-e293-11e8-bb28-1ed0160468e8: Found 0 pods out of 1
Nov  7 13:45:16.468: INFO: Pod name my-hostname-basic-58e945ea-e293-11e8-bb28-1ed0160468e8: Found 1 pods out of 1
Nov  7 13:45:16.468: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-58e945ea-e293-11e8-bb28-1ed0160468e8" are running
Nov  7 13:45:16.471: INFO: Pod "my-hostname-basic-58e945ea-e293-11e8-bb28-1ed0160468e8-cs9zx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-07 13:45:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-07 13:45:13 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-07 13:45:13 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-07 13:45:11 +0000 UTC Reason: Message:}])
Nov  7 13:45:16.471: INFO: Trying to dial the pod
Nov  7 13:45:21.568: INFO: Controller my-hostname-basic-58e945ea-e293-11e8-bb28-1ed0160468e8: Got expected result from replica 1 [my-hostname-basic-58e945ea-e293-11e8-bb28-1ed0160468e8-cs9zx]: "my-hostname-basic-58e945ea-e293-11e8-bb28-1ed0160468e8-cs9zx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:45:21.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-65ldb" for this suite.
Nov  7 13:45:27.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:45:27.820: INFO: namespace: e2e-tests-replication-controller-65ldb, resource: bindings, ignored listing per whitelist
Nov  7 13:45:27.829: INFO: namespace e2e-tests-replication-controller-65ldb deletion completed in 6.256916085s

• [SLOW TEST:16.620 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:45:27.829: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6fn66
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  7 13:45:30.841: INFO: Successfully updated pod "annotationupdate62d0fc90-e293-11e8-bb28-1ed0160468e8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:45:32.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6fn66" for this suite.
Nov  7 13:45:54.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:45:54.989: INFO: namespace: e2e-tests-downward-api-6fn66, resource: bindings, ignored listing per whitelist
Nov  7 13:45:55.180: INFO: namespace e2e-tests-downward-api-6fn66 deletion completed in 22.233599805s

• [SLOW TEST:27.351 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:45:55.181: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-8lvpd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:45:55.516: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  7 13:46:00.521: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  7 13:46:00.521: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  7 13:46:02.525: INFO: Creating deployment "test-rollover-deployment"
Nov  7 13:46:02.534: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  7 13:46:04.541: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  7 13:46:04.551: INFO: Ensure that both replica sets have 1 created replica
Nov  7 13:46:04.557: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  7 13:46:04.565: INFO: Updating deployment test-rollover-deployment
Nov  7 13:46:04.565: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  7 13:46:06.631: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  7 13:46:06.738: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  7 13:46:06.746: INFO: all replica sets need to contain the pod-template-hash label
Nov  7 13:46:06.746: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195164, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  7 13:46:08.754: INFO: all replica sets need to contain the pod-template-hash label
Nov  7 13:46:08.754: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195166, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  7 13:46:10.753: INFO: all replica sets need to contain the pod-template-hash label
Nov  7 13:46:10.753: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195166, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  7 13:46:12.753: INFO: all replica sets need to contain the pod-template-hash label
Nov  7 13:46:12.753: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195166, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  7 13:46:14.832: INFO: all replica sets need to contain the pod-template-hash label
Nov  7 13:46:14.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195166, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  7 13:46:16.843: INFO: all replica sets need to contain the pod-template-hash label
Nov  7 13:46:16.843: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195166, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195162, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  7 13:46:18.755: INFO: 
Nov  7 13:46:18.755: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  7 13:46:18.764: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-8lvpd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8lvpd/deployments/test-rollover-deployment,UID:7758bf03-e293-11e8-b11f-bea865258d09,ResourceVersion:19956,Generation:2,CreationTimestamp:2018-11-07 13:46:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-07 13:46:02 +0000 UTC 2018-11-07 13:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-07 13:46:16 +0000 UTC 2018-11-07 13:46:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  7 13:46:18.769: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-8lvpd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8lvpd/replicasets/test-rollover-deployment-5b76ff8c4,UID:78900880-e293-11e8-b11f-bea865258d09,ResourceVersion:19949,Generation:2,CreationTimestamp:2018-11-07 13:46:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 7758bf03-e293-11e8-b11f-bea865258d09 0xc421d153b7 0xc421d153b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  7 13:46:18.769: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  7 13:46:18.769: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-8lvpd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8lvpd/replicasets/test-rollover-controller,UID:7329dd50-e293-11e8-b11f-bea865258d09,ResourceVersion:19955,Generation:2,CreationTimestamp:2018-11-07 13:45:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 7758bf03-e293-11e8-b11f-bea865258d09 0xc421d14eee 0xc421d14eef}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  7 13:46:18.769: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-8lvpd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8lvpd/replicasets/test-rollover-deployment-6975f4fb87,UID:775b5cb4-e293-11e8-b11f-bea865258d09,ResourceVersion:19913,Generation:2,CreationTimestamp:2018-11-07 13:46:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 7758bf03-e293-11e8-b11f-bea865258d09 0xc421d15997 0xc421d15998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  7 13:46:18.773: INFO: Pod "test-rollover-deployment-5b76ff8c4-vhcf9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-vhcf9,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-8lvpd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8lvpd/pods/test-rollover-deployment-5b76ff8c4-vhcf9,UID:78933c73-e293-11e8-b11f-bea865258d09,ResourceVersion:19926,Generation:0,CreationTimestamp:2018-11-07 13:46:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.179/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 78900880-e293-11e8-b11f-bea865258d09 0xc420cf3ef0 0xc420cf3ef1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s4cjh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s4cjh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-s4cjh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211dc0a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211dc0c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:46:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:46:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:46:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:46:04 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.179,StartTime:2018-11-07 13:46:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-07 13:46:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8414fda0f1999a1ab24c9b46048d19db7de4158fd1186c461fbb2d22077bb809}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:46:18.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8lvpd" for this suite.
Nov  7 13:46:24.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:46:24.841: INFO: namespace: e2e-tests-deployment-8lvpd, resource: bindings, ignored listing per whitelist
Nov  7 13:46:24.930: INFO: namespace e2e-tests-deployment-8lvpd deletion completed in 6.153055311s

• [SLOW TEST:29.750 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:46:24.931: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-gsdrf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  7 13:46:29.163: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-84d5880e-e293-11e8-bb28-1ed0160468e8,GenerateName:,Namespace:e2e-tests-events-gsdrf,SelfLink:/api/v1/namespaces/e2e-tests-events-gsdrf/pods/send-events-84d5880e-e293-11e8-bb28-1ed0160468e8,UID:84d498c6-e293-11e8-b11f-bea865258d09,ResourceVersion:20000,Generation:0,CreationTimestamp:2018-11-07 13:46:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 145658254,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.180/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qtkcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qtkcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-qtkcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c28940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c28960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:46:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:46:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:46:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:46:25 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.180,StartTime:2018-11-07 13:46:25 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-11-07 13:46:26 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://386359903cfff95b02c0327a8dd24a759c8d1acdbe597edfd92713670a3bcc67}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Nov  7 13:46:31.188: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  7 13:46:33.193: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:46:33.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-gsdrf" for this suite.
Nov  7 13:47:13.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:47:13.266: INFO: namespace: e2e-tests-events-gsdrf, resource: bindings, ignored listing per whitelist
Nov  7 13:47:13.413: INFO: namespace e2e-tests-events-gsdrf deletion completed in 40.18097316s

• [SLOW TEST:48.482 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:47:13.413: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xnfwp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a1c4ba14-e293-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:47:13.698: INFO: Waiting up to 5m0s for pod "pod-secrets-a1c54a4f-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-xnfwp" to be "success or failure"
Nov  7 13:47:13.703: INFO: Pod "pod-secrets-a1c54a4f-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.5571ms
Nov  7 13:47:15.708: INFO: Pod "pod-secrets-a1c54a4f-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009393044s
STEP: Saw pod success
Nov  7 13:47:15.708: INFO: Pod "pod-secrets-a1c54a4f-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:47:15.711: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-secrets-a1c54a4f-e293-11e8-bb28-1ed0160468e8 container secret-env-test: <nil>
STEP: delete the pod
Nov  7 13:47:15.731: INFO: Waiting for pod pod-secrets-a1c54a4f-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:47:15.735: INFO: Pod pod-secrets-a1c54a4f-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:47:15.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xnfwp" for this suite.
Nov  7 13:47:21.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:47:21.853: INFO: namespace: e2e-tests-secrets-xnfwp, resource: bindings, ignored listing per whitelist
Nov  7 13:47:21.924: INFO: namespace e2e-tests-secrets-xnfwp deletion completed in 6.18493195s

• [SLOW TEST:8.511 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:47:21.925: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jmw9h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a6d32eab-e293-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:47:22.182: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a6d3bd77-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-jmw9h" to be "success or failure"
Nov  7 13:47:22.189: INFO: Pod "pod-projected-secrets-a6d3bd77-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.418089ms
Nov  7 13:47:24.193: INFO: Pod "pod-projected-secrets-a6d3bd77-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010689407s
STEP: Saw pod success
Nov  7 13:47:24.193: INFO: Pod "pod-projected-secrets-a6d3bd77-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:47:24.196: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-secrets-a6d3bd77-e293-11e8-bb28-1ed0160468e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  7 13:47:24.217: INFO: Waiting for pod pod-projected-secrets-a6d3bd77-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:47:24.225: INFO: Pod pod-projected-secrets-a6d3bd77-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:47:24.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jmw9h" for this suite.
Nov  7 13:47:30.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:47:30.336: INFO: namespace: e2e-tests-projected-jmw9h, resource: bindings, ignored listing per whitelist
Nov  7 13:47:30.423: INFO: namespace e2e-tests-projected-jmw9h deletion completed in 6.188107595s

• [SLOW TEST:8.499 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:47:30.424: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-hjt4v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Nov  7 13:47:30.679: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-hjt4v" to be "success or failure"
Nov  7 13:47:30.682: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.860644ms
Nov  7 13:47:32.687: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007983663s
STEP: Saw pod success
Nov  7 13:47:32.687: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  7 13:47:32.690: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  7 13:47:32.739: INFO: Waiting for pod pod-host-path-test to disappear
Nov  7 13:47:32.750: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:47:32.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-hjt4v" for this suite.
Nov  7 13:47:38.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:47:38.930: INFO: namespace: e2e-tests-hostpath-hjt4v, resource: bindings, ignored listing per whitelist
Nov  7 13:47:39.009: INFO: namespace e2e-tests-hostpath-hjt4v deletion completed in 6.254198914s

• [SLOW TEST:8.585 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:47:39.009: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k8xxq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Nov  7 13:47:39.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:39.582: INFO: stderr: ""
Nov  7 13:47:39.582: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  7 13:47:39.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:39.880: INFO: stderr: ""
Nov  7 13:47:39.880: INFO: stdout: "update-demo-nautilus-8pnvz update-demo-nautilus-nqb4z "
Nov  7 13:47:39.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-8pnvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:40.200: INFO: stderr: ""
Nov  7 13:47:40.200: INFO: stdout: ""
Nov  7 13:47:40.200: INFO: update-demo-nautilus-8pnvz is created but not running
Nov  7 13:47:45.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:45.300: INFO: stderr: ""
Nov  7 13:47:45.300: INFO: stdout: "update-demo-nautilus-8pnvz update-demo-nautilus-nqb4z "
Nov  7 13:47:45.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-8pnvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:45.394: INFO: stderr: ""
Nov  7 13:47:45.394: INFO: stdout: "true"
Nov  7 13:47:45.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-8pnvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:45.490: INFO: stderr: ""
Nov  7 13:47:45.490: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 13:47:45.490: INFO: validating pod update-demo-nautilus-8pnvz
Nov  7 13:47:45.584: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 13:47:45.584: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 13:47:45.585: INFO: update-demo-nautilus-8pnvz is verified up and running
Nov  7 13:47:45.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-nqb4z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:45.683: INFO: stderr: ""
Nov  7 13:47:45.683: INFO: stdout: "true"
Nov  7 13:47:45.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-nqb4z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:45.780: INFO: stderr: ""
Nov  7 13:47:45.780: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 13:47:45.780: INFO: validating pod update-demo-nautilus-nqb4z
Nov  7 13:47:45.869: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 13:47:45.869: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 13:47:45.869: INFO: update-demo-nautilus-nqb4z is verified up and running
STEP: scaling down the replication controller
Nov  7 13:47:45.870: INFO: scanned /root for discovery docs: <nil>
Nov  7 13:47:45.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:47.017: INFO: stderr: ""
Nov  7 13:47:47.017: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  7 13:47:47.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:47.128: INFO: stderr: ""
Nov  7 13:47:47.128: INFO: stdout: "update-demo-nautilus-8pnvz update-demo-nautilus-nqb4z "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  7 13:47:52.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:52.230: INFO: stderr: ""
Nov  7 13:47:52.231: INFO: stdout: "update-demo-nautilus-nqb4z "
Nov  7 13:47:52.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-nqb4z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:52.340: INFO: stderr: ""
Nov  7 13:47:52.340: INFO: stdout: "true"
Nov  7 13:47:52.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-nqb4z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:52.437: INFO: stderr: ""
Nov  7 13:47:52.437: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 13:47:52.437: INFO: validating pod update-demo-nautilus-nqb4z
Nov  7 13:47:52.443: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 13:47:52.444: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 13:47:52.444: INFO: update-demo-nautilus-nqb4z is verified up and running
STEP: scaling up the replication controller
Nov  7 13:47:52.446: INFO: scanned /root for discovery docs: <nil>
Nov  7 13:47:52.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:53.633: INFO: stderr: ""
Nov  7 13:47:53.633: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  7 13:47:53.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:53.736: INFO: stderr: ""
Nov  7 13:47:53.736: INFO: stdout: "update-demo-nautilus-hkkxw update-demo-nautilus-nqb4z "
Nov  7 13:47:53.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-hkkxw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:53.835: INFO: stderr: ""
Nov  7 13:47:53.835: INFO: stdout: ""
Nov  7 13:47:53.835: INFO: update-demo-nautilus-hkkxw is created but not running
Nov  7 13:47:58.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:58.940: INFO: stderr: ""
Nov  7 13:47:58.940: INFO: stdout: "update-demo-nautilus-hkkxw update-demo-nautilus-nqb4z "
Nov  7 13:47:58.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-hkkxw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:59.040: INFO: stderr: ""
Nov  7 13:47:59.040: INFO: stdout: "true"
Nov  7 13:47:59.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-hkkxw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:59.199: INFO: stderr: ""
Nov  7 13:47:59.200: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 13:47:59.200: INFO: validating pod update-demo-nautilus-hkkxw
Nov  7 13:47:59.287: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 13:47:59.287: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 13:47:59.287: INFO: update-demo-nautilus-hkkxw is verified up and running
Nov  7 13:47:59.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-nqb4z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:59.454: INFO: stderr: ""
Nov  7 13:47:59.458: INFO: stdout: "true"
Nov  7 13:47:59.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods update-demo-nautilus-nqb4z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:59.564: INFO: stderr: ""
Nov  7 13:47:59.565: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  7 13:47:59.565: INFO: validating pod update-demo-nautilus-nqb4z
Nov  7 13:47:59.570: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  7 13:47:59.570: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  7 13:47:59.570: INFO: update-demo-nautilus-nqb4z is verified up and running
STEP: using delete to clean up resources
Nov  7 13:47:59.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:59.673: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 13:47:59.673: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  7 13:47:59.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-k8xxq'
Nov  7 13:47:59.854: INFO: stderr: "No resources found.\n"
Nov  7 13:47:59.855: INFO: stdout: ""
Nov  7 13:47:59.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -l name=update-demo --namespace=e2e-tests-kubectl-k8xxq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  7 13:48:00.115: INFO: stderr: ""
Nov  7 13:48:00.115: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:48:00.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k8xxq" for this suite.
Nov  7 13:48:22.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:48:22.332: INFO: namespace: e2e-tests-kubectl-k8xxq, resource: bindings, ignored listing per whitelist
Nov  7 13:48:22.365: INFO: namespace e2e-tests-kubectl-k8xxq deletion completed in 22.245065242s

• [SLOW TEST:43.356 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:48:22.365: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7jflx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:48:22.621: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cad9dc97-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-7jflx" to be "success or failure"
Nov  7 13:48:22.625: INFO: Pod "downwardapi-volume-cad9dc97-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.628587ms
Nov  7 13:48:24.633: INFO: Pod "downwardapi-volume-cad9dc97-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012234705s
Nov  7 13:48:26.637: INFO: Pod "downwardapi-volume-cad9dc97-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015984374s
STEP: Saw pod success
Nov  7 13:48:26.637: INFO: Pod "downwardapi-volume-cad9dc97-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:48:26.641: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-cad9dc97-e293-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:48:26.660: INFO: Waiting for pod downwardapi-volume-cad9dc97-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:48:26.665: INFO: Pod downwardapi-volume-cad9dc97-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:48:26.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7jflx" for this suite.
Nov  7 13:48:32.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:48:32.901: INFO: namespace: e2e-tests-projected-7jflx, resource: bindings, ignored listing per whitelist
Nov  7 13:48:32.905: INFO: namespace e2e-tests-projected-7jflx deletion completed in 6.231511165s

• [SLOW TEST:10.539 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:48:32.905: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-knkpj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-knkpj
Nov  7 13:48:35.185: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-knkpj
STEP: checking the pod's current state and verifying that restartCount is present
Nov  7 13:48:35.188: INFO: Initial restart count of pod liveness-http is 0
Nov  7 13:48:55.296: INFO: Restart count of pod e2e-tests-container-probe-knkpj/liveness-http is now 1 (20.108110284s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:48:55.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-knkpj" for this suite.
Nov  7 13:49:01.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:49:01.476: INFO: namespace: e2e-tests-container-probe-knkpj, resource: bindings, ignored listing per whitelist
Nov  7 13:49:01.513: INFO: namespace e2e-tests-container-probe-knkpj deletion completed in 6.179885475s

• [SLOW TEST:28.608 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:49:01.514: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mbj9r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  7 13:49:04.362: INFO: Successfully updated pod "annotationupdatee22a2f52-e293-11e8-bb28-1ed0160468e8"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:49:06.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mbj9r" for this suite.
Nov  7 13:49:28.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:49:28.569: INFO: namespace: e2e-tests-projected-mbj9r, resource: bindings, ignored listing per whitelist
Nov  7 13:49:28.577: INFO: namespace e2e-tests-projected-mbj9r deletion completed in 22.186876792s

• [SLOW TEST:27.063 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:49:28.577: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xcqs8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f248e999-e293-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:49:28.783: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f2498801-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-xcqs8" to be "success or failure"
Nov  7 13:49:28.786: INFO: Pod "pod-projected-configmaps-f2498801-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.764868ms
Nov  7 13:49:30.791: INFO: Pod "pod-projected-configmaps-f2498801-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007588437s
STEP: Saw pod success
Nov  7 13:49:30.791: INFO: Pod "pod-projected-configmaps-f2498801-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:49:30.795: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-configmaps-f2498801-e293-11e8-bb28-1ed0160468e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 13:49:30.818: INFO: Waiting for pod pod-projected-configmaps-f2498801-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:49:30.840: INFO: Pod pod-projected-configmaps-f2498801-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:49:30.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xcqs8" for this suite.
Nov  7 13:49:36.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:49:36.970: INFO: namespace: e2e-tests-projected-xcqs8, resource: bindings, ignored listing per whitelist
Nov  7 13:49:37.037: INFO: namespace e2e-tests-projected-xcqs8 deletion completed in 6.193172081s

• [SLOW TEST:8.460 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:49:37.038: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qpggd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-h6lzw
STEP: Creating secret with name secret-test-f75aaa4b-e293-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 13:49:37.433: INFO: Waiting up to 5m0s for pod "pod-secrets-f7715bb7-e293-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-secrets-qpggd" to be "success or failure"
Nov  7 13:49:37.436: INFO: Pod "pod-secrets-f7715bb7-e293-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.547117ms
Nov  7 13:49:39.440: INFO: Pod "pod-secrets-f7715bb7-e293-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006440938s
STEP: Saw pod success
Nov  7 13:49:39.440: INFO: Pod "pod-secrets-f7715bb7-e293-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:49:39.443: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-secrets-f7715bb7-e293-11e8-bb28-1ed0160468e8 container secret-volume-test: <nil>
STEP: delete the pod
Nov  7 13:49:39.462: INFO: Waiting for pod pod-secrets-f7715bb7-e293-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:49:39.465: INFO: Pod pod-secrets-f7715bb7-e293-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:49:39.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qpggd" for this suite.
Nov  7 13:49:45.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:49:45.610: INFO: namespace: e2e-tests-secrets-qpggd, resource: bindings, ignored listing per whitelist
Nov  7 13:49:45.682: INFO: namespace e2e-tests-secrets-qpggd deletion completed in 6.198848188s
STEP: Destroying namespace "e2e-tests-secret-namespace-h6lzw" for this suite.
Nov  7 13:49:51.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:49:51.704: INFO: namespace: e2e-tests-secret-namespace-h6lzw, resource: bindings, ignored listing per whitelist
Nov  7 13:49:51.845: INFO: namespace e2e-tests-secret-namespace-h6lzw deletion completed in 6.163114613s

• [SLOW TEST:14.807 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:49:51.845: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qr2b9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  7 13:49:52.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-qr2b9'
Nov  7 13:49:52.160: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  7 13:49:52.160: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Nov  7 13:49:52.237: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Nov  7 13:49:52.244: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  7 13:49:52.254: INFO: scanned /root for discovery docs: <nil>
Nov  7 13:49:52.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-qr2b9'
Nov  7 13:50:05.146: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  7 13:50:05.146: INFO: stdout: "Created e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c\nScaling up e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Nov  7 13:50:05.146: INFO: stdout: "Created e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c\nScaling up e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Nov  7 13:50:05.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qr2b9'
Nov  7 13:50:05.263: INFO: stderr: ""
Nov  7 13:50:05.263: INFO: stdout: "e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c-mqpvz "
Nov  7 13:50:05.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c-mqpvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qr2b9'
Nov  7 13:50:05.365: INFO: stderr: ""
Nov  7 13:50:05.365: INFO: stdout: "true"
Nov  7 13:50:05.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c-mqpvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qr2b9'
Nov  7 13:50:05.466: INFO: stderr: ""
Nov  7 13:50:05.466: INFO: stdout: "nginx:1.14-alpine"
Nov  7 13:50:05.466: INFO: e2e-test-nginx-rc-0ffc2f88a9afe3c70488d1ee0cc0dd2c-mqpvz is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Nov  7 13:50:05.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qr2b9'
Nov  7 13:50:05.570: INFO: stderr: ""
Nov  7 13:50:05.570: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:50:05.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qr2b9" for this suite.
Nov  7 13:50:11.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:50:11.824: INFO: namespace: e2e-tests-kubectl-qr2b9, resource: bindings, ignored listing per whitelist
Nov  7 13:50:11.856: INFO: namespace e2e-tests-kubectl-qr2b9 deletion completed in 6.2746419s

• [SLOW TEST:20.011 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:50:11.856: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-775vv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1107 13:50:22.082385      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  7 13:50:22.082: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:50:22.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-775vv" for this suite.
Nov  7 13:50:28.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:50:28.217: INFO: namespace: e2e-tests-gc-775vv, resource: bindings, ignored listing per whitelist
Nov  7 13:50:28.245: INFO: namespace e2e-tests-gc-775vv deletion completed in 6.158537686s

• [SLOW TEST:16.389 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:50:28.245: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-45tjl
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-15e1c99d-e294-11e8-bb28-1ed0160468e8
STEP: Creating secret with name s-test-opt-upd-15e1c9e6-e294-11e8-bb28-1ed0160468e8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-15e1c99d-e294-11e8-bb28-1ed0160468e8
STEP: Updating secret s-test-opt-upd-15e1c9e6-e294-11e8-bb28-1ed0160468e8
STEP: Creating secret with name s-test-opt-create-15e1c9f9-e294-11e8-bb28-1ed0160468e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:50:34.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-45tjl" for this suite.
Nov  7 13:50:56.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:50:57.080: INFO: namespace: e2e-tests-secrets-45tjl, resource: bindings, ignored listing per whitelist
Nov  7 13:50:57.114: INFO: namespace e2e-tests-secrets-45tjl deletion completed in 22.222834078s

• [SLOW TEST:28.869 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:50:57.114: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jhzzf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  7 13:50:57.363: INFO: Waiting up to 5m0s for pod "pod-2715c0b6-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-jhzzf" to be "success or failure"
Nov  7 13:50:57.366: INFO: Pod "pod-2715c0b6-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.927653ms
Nov  7 13:50:59.370: INFO: Pod "pod-2715c0b6-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006446678s
STEP: Saw pod success
Nov  7 13:50:59.370: INFO: Pod "pod-2715c0b6-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:50:59.372: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-2715c0b6-e294-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:50:59.394: INFO: Waiting for pod pod-2715c0b6-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:50:59.396: INFO: Pod pod-2715c0b6-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:50:59.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jhzzf" for this suite.
Nov  7 13:51:05.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:51:05.571: INFO: namespace: e2e-tests-emptydir-jhzzf, resource: bindings, ignored listing per whitelist
Nov  7 13:51:05.609: INFO: namespace e2e-tests-emptydir-jhzzf deletion completed in 6.208503336s

• [SLOW TEST:8.495 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:51:05.610: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qcrlp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:51:05.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 version'
Nov  7 13:51:05.904: INFO: stderr: ""
Nov  7 13:51:05.904: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.2\", GitCommit:\"17c77c7898218073f14c8d573582e8d2313dc740\", GitTreeState:\"clean\", BuildDate:\"2018-10-24T06:43:59Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:51:05.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qcrlp" for this suite.
Nov  7 13:51:11.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:51:12.055: INFO: namespace: e2e-tests-kubectl-qcrlp, resource: bindings, ignored listing per whitelist
Nov  7 13:51:12.087: INFO: namespace e2e-tests-kubectl-qcrlp deletion completed in 6.178914099s

• [SLOW TEST:6.477 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:51:12.087: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-thp6d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  7 13:51:16.949: INFO: Successfully updated pod "pod-update-3001d24a-e294-11e8-bb28-1ed0160468e8"
STEP: verifying the updated pod is in kubernetes
Nov  7 13:51:16.955: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:51:16.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-thp6d" for this suite.
Nov  7 13:51:38.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:51:39.063: INFO: namespace: e2e-tests-pods-thp6d, resource: bindings, ignored listing per whitelist
Nov  7 13:51:39.130: INFO: namespace e2e-tests-pods-thp6d deletion completed in 22.170737355s

• [SLOW TEST:27.043 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:51:39.130: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-88hnz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  7 13:51:43.455: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:43.458: INFO: Pod pod-with-prestop-http-hook still exists
Nov  7 13:51:45.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:45.462: INFO: Pod pod-with-prestop-http-hook still exists
Nov  7 13:51:47.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:47.463: INFO: Pod pod-with-prestop-http-hook still exists
Nov  7 13:51:49.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:49.463: INFO: Pod pod-with-prestop-http-hook still exists
Nov  7 13:51:51.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:51.462: INFO: Pod pod-with-prestop-http-hook still exists
Nov  7 13:51:53.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:53.462: INFO: Pod pod-with-prestop-http-hook still exists
Nov  7 13:51:55.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:55.462: INFO: Pod pod-with-prestop-http-hook still exists
Nov  7 13:51:57.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:57.463: INFO: Pod pod-with-prestop-http-hook still exists
Nov  7 13:51:59.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  7 13:51:59.462: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:51:59.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-88hnz" for this suite.
Nov  7 13:52:21.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:52:21.553: INFO: namespace: e2e-tests-container-lifecycle-hook-88hnz, resource: bindings, ignored listing per whitelist
Nov  7 13:52:21.691: INFO: namespace e2e-tests-container-lifecycle-hook-88hnz deletion completed in 22.213634228s

• [SLOW TEST:42.560 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:52:21.691: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qgnvc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:52:21.900: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5978bb11-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-qgnvc" to be "success or failure"
Nov  7 13:52:21.907: INFO: Pod "downwardapi-volume-5978bb11-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.432294ms
Nov  7 13:52:23.911: INFO: Pod "downwardapi-volume-5978bb11-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011176592s
Nov  7 13:52:25.915: INFO: Pod "downwardapi-volume-5978bb11-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015349362s
STEP: Saw pod success
Nov  7 13:52:25.915: INFO: Pod "downwardapi-volume-5978bb11-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:52:25.918: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-5978bb11-e294-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:52:25.966: INFO: Waiting for pod downwardapi-volume-5978bb11-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:52:25.972: INFO: Pod downwardapi-volume-5978bb11-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:52:25.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qgnvc" for this suite.
Nov  7 13:52:31.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:52:32.065: INFO: namespace: e2e-tests-projected-qgnvc, resource: bindings, ignored listing per whitelist
Nov  7 13:52:32.111: INFO: namespace e2e-tests-projected-qgnvc deletion completed in 6.135582495s

• [SLOW TEST:10.420 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:52:32.112: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-psvnw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Nov  7 13:52:32.372: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-030573999 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:52:32.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-psvnw" for this suite.
Nov  7 13:52:38.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:52:38.591: INFO: namespace: e2e-tests-kubectl-psvnw, resource: bindings, ignored listing per whitelist
Nov  7 13:52:38.629: INFO: namespace e2e-tests-kubectl-psvnw deletion completed in 6.168687514s

• [SLOW TEST:6.518 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:52:38.630: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kvdqk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  7 13:52:38.900: INFO: Waiting up to 5m0s for pod "downward-api-639aad5a-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-kvdqk" to be "success or failure"
Nov  7 13:52:38.905: INFO: Pod "downward-api-639aad5a-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.069624ms
Nov  7 13:52:40.910: INFO: Pod "downward-api-639aad5a-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010115286s
STEP: Saw pod success
Nov  7 13:52:40.910: INFO: Pod "downward-api-639aad5a-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:52:40.913: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downward-api-639aad5a-e294-11e8-bb28-1ed0160468e8 container dapi-container: <nil>
STEP: delete the pod
Nov  7 13:52:40.939: INFO: Waiting for pod downward-api-639aad5a-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:52:40.941: INFO: Pod downward-api-639aad5a-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:52:40.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kvdqk" for this suite.
Nov  7 13:52:47.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:52:47.173: INFO: namespace: e2e-tests-downward-api-kvdqk, resource: bindings, ignored listing per whitelist
Nov  7 13:52:47.184: INFO: namespace e2e-tests-downward-api-kvdqk deletion completed in 6.238284224s

• [SLOW TEST:8.554 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:52:47.184: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-2ptks
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Nov  7 13:52:49.444: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-68aface2-e294-11e8-bb28-1ed0160468e8", GenerateName:"", Namespace:"e2e-tests-pods-2ptks", SelfLink:"/api/v1/namespaces/e2e-tests-pods-2ptks/pods/pod-submit-remove-68aface2-e294-11e8-bb28-1ed0160468e8", UID:"68af799a-e294-11e8-b11f-bea865258d09", ResourceVersion:"21240", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63677195567, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"418090955"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp", "cni.projectcalico.org/podIP":"100.96.1.201/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5g5gw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422722a00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5g5gw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc422d8ecf8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42236ea80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422d8ed30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422d8ed50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc422d8ed58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195567, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195569, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195569, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677195567, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.3", PodIP:"100.96.1.201", StartTime:(*v1.Time)(0xc422c20e60), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc422c20e80), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1", ContainerID:"docker://1b7b323bd1c1279f21c3e59e702a906146d675bfd8e847ac5c88f04b0cef70a1"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:52:57.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2ptks" for this suite.
Nov  7 13:53:03.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:53:04.069: INFO: namespace: e2e-tests-pods-2ptks, resource: bindings, ignored listing per whitelist
Nov  7 13:53:04.183: INFO: namespace e2e-tests-pods-2ptks deletion completed in 6.201186049s

• [SLOW TEST:16.998 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:53:04.183: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-bxgb5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  7 13:53:04.473: INFO: Waiting up to 5m0s for pod "downward-api-72d92e58-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-bxgb5" to be "success or failure"
Nov  7 13:53:04.477: INFO: Pod "downward-api-72d92e58-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.384134ms
Nov  7 13:53:06.481: INFO: Pod "downward-api-72d92e58-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007405707s
Nov  7 13:53:08.485: INFO: Pod "downward-api-72d92e58-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011650191s
STEP: Saw pod success
Nov  7 13:53:08.485: INFO: Pod "downward-api-72d92e58-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:53:08.532: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downward-api-72d92e58-e294-11e8-bb28-1ed0160468e8 container dapi-container: <nil>
STEP: delete the pod
Nov  7 13:53:08.569: INFO: Waiting for pod downward-api-72d92e58-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:53:08.574: INFO: Pod downward-api-72d92e58-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:53:08.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bxgb5" for this suite.
Nov  7 13:53:14.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:53:14.658: INFO: namespace: e2e-tests-downward-api-bxgb5, resource: bindings, ignored listing per whitelist
Nov  7 13:53:14.766: INFO: namespace e2e-tests-downward-api-bxgb5 deletion completed in 6.185584351s

• [SLOW TEST:10.583 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:53:14.767: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vprpx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-79256443-e294-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 13:53:15.044: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-792606af-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-vprpx" to be "success or failure"
Nov  7 13:53:15.048: INFO: Pod "pod-projected-configmaps-792606af-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.080421ms
Nov  7 13:53:17.055: INFO: Pod "pod-projected-configmaps-792606af-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010482402s
STEP: Saw pod success
Nov  7 13:53:17.055: INFO: Pod "pod-projected-configmaps-792606af-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:53:17.059: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-configmaps-792606af-e294-11e8-bb28-1ed0160468e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 13:53:17.078: INFO: Waiting for pod pod-projected-configmaps-792606af-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:53:17.080: INFO: Pod pod-projected-configmaps-792606af-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:53:17.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vprpx" for this suite.
Nov  7 13:53:23.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:53:23.160: INFO: namespace: e2e-tests-projected-vprpx, resource: bindings, ignored listing per whitelist
Nov  7 13:53:23.236: INFO: namespace e2e-tests-projected-vprpx deletion completed in 6.15137096s

• [SLOW TEST:8.470 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:53:23.238: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-h4cmj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  7 13:53:23.448: INFO: Waiting up to 5m0s for pod "pod-7e289e2f-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-h4cmj" to be "success or failure"
Nov  7 13:53:23.452: INFO: Pod "pod-7e289e2f-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.683255ms
Nov  7 13:53:25.457: INFO: Pod "pod-7e289e2f-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00827898s
STEP: Saw pod success
Nov  7 13:53:25.457: INFO: Pod "pod-7e289e2f-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:53:25.460: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-7e289e2f-e294-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:53:25.481: INFO: Waiting for pod pod-7e289e2f-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:53:25.487: INFO: Pod pod-7e289e2f-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:53:25.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h4cmj" for this suite.
Nov  7 13:53:31.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:53:31.646: INFO: namespace: e2e-tests-emptydir-h4cmj, resource: bindings, ignored listing per whitelist
Nov  7 13:53:31.670: INFO: namespace e2e-tests-emptydir-h4cmj deletion completed in 6.168004636s

• [SLOW TEST:8.433 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:53:31.671: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-h7tq6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 13:53:31.885: INFO: Creating deployment "nginx-deployment"
Nov  7 13:53:31.896: INFO: Waiting for observed generation 1
Nov  7 13:53:33.905: INFO: Waiting for all required pods to come up
Nov  7 13:53:33.910: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  7 13:53:35.946: INFO: Waiting for deployment "nginx-deployment" to complete
Nov  7 13:53:35.957: INFO: Updating deployment "nginx-deployment" with a non-existent image
Nov  7 13:53:35.975: INFO: Updating deployment nginx-deployment
Nov  7 13:53:35.975: INFO: Waiting for observed generation 2
Nov  7 13:53:37.984: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  7 13:53:37.987: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  7 13:53:37.990: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov  7 13:53:38.000: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  7 13:53:38.000: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  7 13:53:38.002: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov  7 13:53:38.008: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Nov  7 13:53:38.009: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Nov  7 13:53:38.015: INFO: Updating deployment nginx-deployment
Nov  7 13:53:38.015: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Nov  7 13:53:38.020: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  7 13:53:38.023: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  7 13:53:38.042: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7tq6/deployments/nginx-deployment,UID:832f97e8-e294-11e8-b11f-bea865258d09,ResourceVersion:21536,Generation:3,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2018-11-07 13:53:36 +0000 UTC 2018-11-07 13:53:31 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2018-11-07 13:53:38 +0000 UTC 2018-11-07 13:53:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Nov  7 13:53:38.047: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7tq6/replicasets/nginx-deployment-7dc8f79789,UID:859efc1d-e294-11e8-b11f-bea865258d09,ResourceVersion:21529,Generation:3,CreationTimestamp:2018-11-07 13:53:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 832f97e8-e294-11e8-b11f-bea865258d09 0xc4200556c7 0xc4200556c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  7 13:53:38.047: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Nov  7 13:53:38.048: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7tq6/replicasets/nginx-deployment-7f9675fb8b,UID:8330dfd5-e294-11e8-b11f-bea865258d09,ResourceVersion:21528,Generation:3,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 832f97e8-e294-11e8-b11f-bea865258d09 0xc420055b67 0xc420055b68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Nov  7 13:53:38.062: INFO: Pod "nginx-deployment-7dc8f79789-2wtl9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2wtl9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-2wtl9,UID:86db6b43-e294-11e8-b11f-bea865258d09,ResourceVersion:21548,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc4219b6ae7 0xc4219b6ae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4219b6f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4219b6fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.065: INFO: Pod "nginx-deployment-7dc8f79789-52x6q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-52x6q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-52x6q,UID:86db93fc-e294-11e8-b11f-bea865258d09,ResourceVersion:21550,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc4219b7047 0xc4219b7048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4219b7100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4219b7120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.065: INFO: Pod "nginx-deployment-7dc8f79789-58gbr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-58gbr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-58gbr,UID:85a3032e-e294-11e8-b11f-bea865258d09,ResourceVersion:21522,Generation:0,CreationTimestamp:2018-11-07 13:53:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.212/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc4219b72e7 0xc4219b72e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4219b73b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4219b7470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2018-11-07 13:53:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.065: INFO: Pod "nginx-deployment-7dc8f79789-7t8bg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7t8bg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-7t8bg,UID:86dbd6f9-e294-11e8-b11f-bea865258d09,ResourceVersion:21553,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc4219b7da0 0xc4219b7da1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4219b7ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4219b7ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.067: INFO: Pod "nginx-deployment-7dc8f79789-c4gjc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-c4gjc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-c4gjc,UID:86d83ac5-e294-11e8-b11f-bea865258d09,ResourceVersion:21540,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc4219b7f47 0xc4219b7f48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4208f6110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4208f6140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.067: INFO: Pod "nginx-deployment-7dc8f79789-cp2vt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cp2vt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-cp2vt,UID:85a3889b-e294-11e8-b11f-bea865258d09,ResourceVersion:21520,Generation:0,CreationTimestamp:2018-11-07 13:53:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.57/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc4208f6350 0xc4208f6351}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4208f6900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4208f6930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2018-11-07 13:53:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.068: INFO: Pod "nginx-deployment-7dc8f79789-kkk99" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kkk99,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-kkk99,UID:85a01736-e294-11e8-b11f-bea865258d09,ResourceVersion:21523,Generation:0,CreationTimestamp:2018-11-07 13:53:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.213/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc4208f6c20 0xc4208f6c21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4208f77d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42092e580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2018-11-07 13:53:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.068: INFO: Pod "nginx-deployment-7dc8f79789-ln6xt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ln6xt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-ln6xt,UID:86d99ece-e294-11e8-b11f-bea865258d09,ResourceVersion:21549,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc42092f370 0xc42092f371}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42092f690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42092f8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.068: INFO: Pod "nginx-deployment-7dc8f79789-qghxn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qghxn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-qghxn,UID:86dbb91c-e294-11e8-b11f-bea865258d09,ResourceVersion:21551,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc42092fc60 0xc42092fc61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a78140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a78160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.068: INFO: Pod "nginx-deployment-7dc8f79789-rdlf5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rdlf5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-rdlf5,UID:86d9d803-e294-11e8-b11f-bea865258d09,ResourceVersion:21542,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc420a781c7 0xc420a781c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a78270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a78340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.069: INFO: Pod "nginx-deployment-7dc8f79789-wgr8s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wgr8s,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-wgr8s,UID:859f86ad-e294-11e8-b11f-bea865258d09,ResourceVersion:21519,Generation:0,CreationTimestamp:2018-11-07 13:53:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.56/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc420a783d0 0xc420a783d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a78450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a78480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2018-11-07 13:53:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.069: INFO: Pod "nginx-deployment-7dc8f79789-xw8g5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xw8g5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7dc8f79789-xw8g5,UID:85a008c1-e294-11e8-b11f-bea865258d09,ResourceVersion:21521,Generation:0,CreationTimestamp:2018-11-07 13:53:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.211/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 859efc1d-e294-11e8-b11f-bea865258d09 0xc420a785f0 0xc420a785f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a78760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a78780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2018-11-07 13:53:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.069: INFO: Pod "nginx-deployment-7f9675fb8b-2mtlt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2mtlt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-2mtlt,UID:83345817-e294-11e8-b11f-bea865258d09,ResourceVersion:21450,Generation:0,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.54/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a78880 0xc420a78881}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a78920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a78940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.54,StartTime:2018-11-07 13:53:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:53:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://8269666ed4e1f636fd0e86dce99722d02f8aba032a0bcac5b76c870a559388f7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.070: INFO: Pod "nginx-deployment-7f9675fb8b-htbkp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-htbkp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-htbkp,UID:86daf1e7-e294-11e8-b11f-bea865258d09,ResourceVersion:21555,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a78ab0 0xc420a78ab1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a78b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a78ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.070: INFO: Pod "nginx-deployment-7f9675fb8b-j5n7j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j5n7j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-j5n7j,UID:86daba80-e294-11e8-b11f-bea865258d09,ResourceVersion:21547,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a78c30 0xc420a78c31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a78d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a78dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.070: INFO: Pod "nginx-deployment-7f9675fb8b-j75n5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j75n5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-j75n5,UID:833544f4-e294-11e8-b11f-bea865258d09,ResourceVersion:21468,Generation:0,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.209/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a79070 0xc420a79071}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a790f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a79130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.209,StartTime:2018-11-07 13:53:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:53:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://db06f1c7ad392c7708c0dd55b37f4b0e22aedc85a0079e3cff3887325a5a9370}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.070: INFO: Pod "nginx-deployment-7f9675fb8b-kfj4f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kfj4f,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-kfj4f,UID:86d8a49f-e294-11e8-b11f-bea865258d09,ResourceVersion:21541,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a79200 0xc420a79201}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a79270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a792a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.071: INFO: Pod "nginx-deployment-7f9675fb8b-kwzl8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kwzl8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-kwzl8,UID:833461ec-e294-11e8-b11f-bea865258d09,ResourceVersion:21462,Generation:0,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.207/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a79340 0xc420a79341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a793a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a793c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.207,StartTime:2018-11-07 13:53:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:53:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://422c73896c77cf9d27577bc9e54dd92261c695fb2597e94396189bd53d3467fb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.071: INFO: Pod "nginx-deployment-7f9675fb8b-mp7fr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mp7fr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-mp7fr,UID:83334483-e294-11e8-b11f-bea865258d09,ResourceVersion:21465,Generation:0,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.205/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a794b0 0xc420a794b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a79510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a79540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.205,StartTime:2018-11-07 13:53:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:53:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://13d470fca763f2937fb1a9056911754e7f2922304b1a7a202e451f4315211c75}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.075: INFO: Pod "nginx-deployment-7f9675fb8b-pwx7n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pwx7n,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-pwx7n,UID:86d86f92-e294-11e8-b11f-bea865258d09,ResourceVersion:21538,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a799f0 0xc420a799f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a79a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a79b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.075: INFO: Pod "nginx-deployment-7f9675fb8b-rjt6p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rjt6p,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-rjt6p,UID:86dac23f-e294-11e8-b11f-bea865258d09,ResourceVersion:21552,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a79d00 0xc420a79d01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a79eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a9c240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.075: INFO: Pod "nginx-deployment-7f9675fb8b-rpr5p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rpr5p,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-rpr5p,UID:83326b59-e294-11e8-b11f-bea865258d09,ResourceVersion:21471,Generation:0,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.206/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a9c9d0 0xc420a9c9d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a9cc60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a9cec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.206,StartTime:2018-11-07 13:53:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:53:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://ec9e08290487ba7175bc9a9b33a92e54b559422024d15ad9a9736777d40d9ea5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.076: INFO: Pod "nginx-deployment-7f9675fb8b-sdw8q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sdw8q,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-sdw8q,UID:8335a12f-e294-11e8-b11f-bea865258d09,ResourceVersion:21459,Generation:0,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.55/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a9d390 0xc420a9d391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a9d4d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a9d600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.55,StartTime:2018-11-07 13:53:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:53:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://fa6d56cb01e850bda924659524b0222faa22ae3791b203ce44a9919fd3b2aa6e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.076: INFO: Pod "nginx-deployment-7f9675fb8b-sz9kt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sz9kt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-sz9kt,UID:86d7b9c4-e294-11e8-b11f-bea865258d09,ResourceVersion:21532,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a9d940 0xc420a9d941}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a9d9c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a9da50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.076: INFO: Pod "nginx-deployment-7f9675fb8b-v79th" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-v79th,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-v79th,UID:86daeee7-e294-11e8-b11f-bea865258d09,ResourceVersion:21554,Generation:0,CreationTimestamp:2018-11-07 13:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420a9de40 0xc420a9de41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420a9dee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420a9df80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.076: INFO: Pod "nginx-deployment-7f9675fb8b-xksdp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xksdp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-xksdp,UID:833343c3-e294-11e8-b11f-bea865258d09,ResourceVersion:21456,Generation:0,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.52/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420762290 0xc420762291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4207623e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420762480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.52,StartTime:2018-11-07 13:53:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:53:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://ab3686c2b6f93545aa51fe35be436f95ba359ff303117cd44b1f6a3ba2406650}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  7 13:53:38.076: INFO: Pod "nginx-deployment-7f9675fb8b-zqbt5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zqbt5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-h7tq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7tq6/pods/nginx-deployment-7f9675fb8b-zqbt5,UID:83346f91-e294-11e8-b11f-bea865258d09,ResourceVersion:21453,Generation:0,CreationTimestamp:2018-11-07 13:53:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.53/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8330dfd5-e294-11e8-b11f-bea865258d09 0xc420762980 0xc420762981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jrxps {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jrxps,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jrxps true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-ksv86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420762be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420762c00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-07 13:53:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.53,StartTime:2018-11-07 13:53:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-07 13:53:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b91c0a1f7dd2f9dcd14631fda270df09898f7580749f742204f07cf5cc1193d1 docker://b6803d69ca74287757a4105051c4e8b3daac1e8a02245a30cf22526c859a531d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:53:38.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h7tq6" for this suite.
Nov  7 13:53:44.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:53:44.961: INFO: namespace: e2e-tests-deployment-h7tq6, resource: bindings, ignored listing per whitelist
Nov  7 13:53:45.000: INFO: namespace e2e-tests-deployment-h7tq6 deletion completed in 6.907467916s

• [SLOW TEST:13.330 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:53:45.001: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-cws8h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Nov  7 13:53:45.258: INFO: Waiting up to 5m0s for pod "var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-var-expansion-cws8h" to be "success or failure"
Nov  7 13:53:45.262: INFO: Pod "var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.791656ms
Nov  7 13:53:47.268: INFO: Pod "var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009930421s
Nov  7 13:53:49.280: INFO: Pod "var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021475435s
Nov  7 13:53:51.283: INFO: Pod "var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025015851s
Nov  7 13:53:53.330: INFO: Pod "var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.072069173s
STEP: Saw pod success
Nov  7 13:53:53.330: INFO: Pod "var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:53:53.333: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8 container dapi-container: <nil>
STEP: delete the pod
Nov  7 13:53:53.359: INFO: Waiting for pod var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:53:53.375: INFO: Pod var-expansion-8b2869c8-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:53:53.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-cws8h" for this suite.
Nov  7 13:53:59.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:53:59.494: INFO: namespace: e2e-tests-var-expansion-cws8h, resource: bindings, ignored listing per whitelist
Nov  7 13:53:59.532: INFO: namespace e2e-tests-var-expansion-cws8h deletion completed in 6.148445892s

• [SLOW TEST:14.531 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:53:59.532: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jvxbm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:53:59.769: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93ceac3b-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-jvxbm" to be "success or failure"
Nov  7 13:53:59.774: INFO: Pod "downwardapi-volume-93ceac3b-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.627496ms
Nov  7 13:54:01.779: INFO: Pod "downwardapi-volume-93ceac3b-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009868102s
STEP: Saw pod success
Nov  7 13:54:01.780: INFO: Pod "downwardapi-volume-93ceac3b-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:54:01.785: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-93ceac3b-e294-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:54:01.813: INFO: Waiting for pod downwardapi-volume-93ceac3b-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:54:01.824: INFO: Pod downwardapi-volume-93ceac3b-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:54:01.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jvxbm" for this suite.
Nov  7 13:54:07.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:54:08.124: INFO: namespace: e2e-tests-downward-api-jvxbm, resource: bindings, ignored listing per whitelist
Nov  7 13:54:08.145: INFO: namespace e2e-tests-downward-api-jvxbm deletion completed in 6.289099685s

• [SLOW TEST:8.613 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:54:08.146: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-ppfbf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Nov  7 13:54:08.933: INFO: Waiting up to 5m0s for pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-ww25f" in namespace "e2e-tests-svcaccounts-ppfbf" to be "success or failure"
Nov  7 13:54:08.936: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-ww25f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.938681ms
Nov  7 13:54:10.940: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-ww25f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007020286s
Nov  7 13:54:12.944: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-ww25f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01077423s
STEP: Saw pod success
Nov  7 13:54:12.944: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-ww25f" satisfied condition "success or failure"
Nov  7 13:54:12.947: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-ww25f container token-test: <nil>
STEP: delete the pod
Nov  7 13:54:13.066: INFO: Waiting for pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-ww25f to disappear
Nov  7 13:54:13.070: INFO: Pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-ww25f no longer exists
STEP: Creating a pod to test consume service account root CA
Nov  7 13:54:13.078: INFO: Waiting up to 5m0s for pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-x6h7j" in namespace "e2e-tests-svcaccounts-ppfbf" to be "success or failure"
Nov  7 13:54:13.085: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-x6h7j": Phase="Pending", Reason="", readiness=false. Elapsed: 6.865904ms
Nov  7 13:54:15.090: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-x6h7j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011600372s
Nov  7 13:54:17.094: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-x6h7j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015939201s
STEP: Saw pod success
Nov  7 13:54:17.094: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-x6h7j" satisfied condition "success or failure"
Nov  7 13:54:17.097: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-x6h7j container root-ca-test: <nil>
STEP: delete the pod
Nov  7 13:54:17.146: INFO: Waiting for pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-x6h7j to disappear
Nov  7 13:54:17.149: INFO: Pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-x6h7j no longer exists
STEP: Creating a pod to test consume service account namespace
Nov  7 13:54:17.156: INFO: Waiting up to 5m0s for pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-4vvl5" in namespace "e2e-tests-svcaccounts-ppfbf" to be "success or failure"
Nov  7 13:54:17.164: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-4vvl5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.21137ms
Nov  7 13:54:19.168: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-4vvl5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01258486s
Nov  7 13:54:21.172: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-4vvl5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016513127s
STEP: Saw pod success
Nov  7 13:54:21.172: INFO: Pod "pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-4vvl5" satisfied condition "success or failure"
Nov  7 13:54:21.176: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-4vvl5 container namespace-test: <nil>
STEP: delete the pod
Nov  7 13:54:21.252: INFO: Waiting for pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-4vvl5 to disappear
Nov  7 13:54:21.255: INFO: Pod pod-service-account-9938ad32-e294-11e8-bb28-1ed0160468e8-4vvl5 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:54:21.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-ppfbf" for this suite.
Nov  7 13:54:27.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:54:27.352: INFO: namespace: e2e-tests-svcaccounts-ppfbf, resource: bindings, ignored listing per whitelist
Nov  7 13:54:27.452: INFO: namespace e2e-tests-svcaccounts-ppfbf deletion completed in 6.193487946s

• [SLOW TEST:19.306 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:54:27.453: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qtvk7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a4765935-e294-11e8-bb28-1ed0160468e8
STEP: Creating secret with name s-test-opt-upd-a4765997-e294-11e8-bb28-1ed0160468e8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a4765935-e294-11e8-bb28-1ed0160468e8
STEP: Updating secret s-test-opt-upd-a4765997-e294-11e8-bb28-1ed0160468e8
STEP: Creating secret with name s-test-opt-create-a47659bf-e294-11e8-bb28-1ed0160468e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:55:51.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qtvk7" for this suite.
Nov  7 13:56:13.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:56:13.164: INFO: namespace: e2e-tests-projected-qtvk7, resource: bindings, ignored listing per whitelist
Nov  7 13:56:13.216: INFO: namespace e2e-tests-projected-qtvk7 deletion completed in 22.176593669s

• [SLOW TEST:105.764 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:56:13.218: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-szvpf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 13:56:13.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e3797a4b-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-szvpf" to be "success or failure"
Nov  7 13:56:13.431: INFO: Pod "downwardapi-volume-e3797a4b-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.050324ms
Nov  7 13:56:15.435: INFO: Pod "downwardapi-volume-e3797a4b-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006609221s
STEP: Saw pod success
Nov  7 13:56:15.435: INFO: Pod "downwardapi-volume-e3797a4b-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:56:15.438: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-e3797a4b-e294-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 13:56:15.464: INFO: Waiting for pod downwardapi-volume-e3797a4b-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:56:15.476: INFO: Pod downwardapi-volume-e3797a4b-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:56:15.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-szvpf" for this suite.
Nov  7 13:56:21.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:56:21.572: INFO: namespace: e2e-tests-projected-szvpf, resource: bindings, ignored listing per whitelist
Nov  7 13:56:21.630: INFO: namespace e2e-tests-projected-szvpf deletion completed in 6.147224374s

• [SLOW TEST:8.412 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:56:21.631: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sqkgc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Nov  7 13:56:21.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-sqkgc'
Nov  7 13:56:22.558: INFO: stderr: ""
Nov  7 13:56:22.558: INFO: stdout: "pod/pause created\n"
Nov  7 13:56:22.558: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  7 13:56:22.558: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-sqkgc" to be "running and ready"
Nov  7 13:56:22.562: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.981924ms
Nov  7 13:56:24.566: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.008025899s
Nov  7 13:56:24.566: INFO: Pod "pause" satisfied condition "running and ready"
Nov  7 13:56:24.566: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  7 13:56:24.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-sqkgc'
Nov  7 13:56:24.755: INFO: stderr: ""
Nov  7 13:56:24.755: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  7 13:56:24.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pod pause -L testing-label --namespace=e2e-tests-kubectl-sqkgc'
Nov  7 13:56:24.912: INFO: stderr: ""
Nov  7 13:56:24.912: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  7 13:56:24.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 label pods pause testing-label- --namespace=e2e-tests-kubectl-sqkgc'
Nov  7 13:56:25.069: INFO: stderr: ""
Nov  7 13:56:25.069: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  7 13:56:25.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pod pause -L testing-label --namespace=e2e-tests-kubectl-sqkgc'
Nov  7 13:56:25.223: INFO: stderr: ""
Nov  7 13:56:25.223: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Nov  7 13:56:25.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sqkgc'
Nov  7 13:56:25.406: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  7 13:56:25.406: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  7 13:56:25.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-sqkgc'
Nov  7 13:56:25.734: INFO: stderr: "No resources found.\n"
Nov  7 13:56:25.734: INFO: stdout: ""
Nov  7 13:56:25.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 get pods -l name=pause --namespace=e2e-tests-kubectl-sqkgc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  7 13:56:26.042: INFO: stderr: ""
Nov  7 13:56:26.042: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:56:26.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sqkgc" for this suite.
Nov  7 13:56:32.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:56:32.083: INFO: namespace: e2e-tests-kubectl-sqkgc, resource: bindings, ignored listing per whitelist
Nov  7 13:56:32.147: INFO: namespace e2e-tests-kubectl-sqkgc deletion completed in 6.101772958s

• [SLOW TEST:10.517 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:56:32.147: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jhdtv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  7 13:56:32.351: INFO: Waiting up to 5m0s for pod "pod-eec0e429-e294-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-jhdtv" to be "success or failure"
Nov  7 13:56:32.360: INFO: Pod "pod-eec0e429-e294-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.8361ms
Nov  7 13:56:34.430: INFO: Pod "pod-eec0e429-e294-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.079436633s
STEP: Saw pod success
Nov  7 13:56:34.430: INFO: Pod "pod-eec0e429-e294-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:56:34.433: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-eec0e429-e294-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:56:34.452: INFO: Waiting for pod pod-eec0e429-e294-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:56:34.462: INFO: Pod pod-eec0e429-e294-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:56:34.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jhdtv" for this suite.
Nov  7 13:56:40.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:56:40.520: INFO: namespace: e2e-tests-emptydir-jhdtv, resource: bindings, ignored listing per whitelist
Nov  7 13:56:40.616: INFO: namespace e2e-tests-emptydir-jhdtv deletion completed in 6.146688422s

• [SLOW TEST:8.469 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:56:40.616: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-ncxfh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-ncxfh
Nov  7 13:56:44.824: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-ncxfh
STEP: checking the pod's current state and verifying that restartCount is present
Nov  7 13:56:44.827: INFO: Initial restart count of pod liveness-exec is 0
Nov  7 13:57:37.058: INFO: Restart count of pod e2e-tests-container-probe-ncxfh/liveness-exec is now 1 (52.23088501s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:57:37.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ncxfh" for this suite.
Nov  7 13:57:43.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:57:43.218: INFO: namespace: e2e-tests-container-probe-ncxfh, resource: bindings, ignored listing per whitelist
Nov  7 13:57:43.280: INFO: namespace e2e-tests-container-probe-ncxfh deletion completed in 6.210961762s

• [SLOW TEST:62.664 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:57:43.280: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-q4str
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Nov  7 13:57:43.488: INFO: Waiting up to 5m0s for pod "var-expansion-192765e8-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-var-expansion-q4str" to be "success or failure"
Nov  7 13:57:43.491: INFO: Pod "var-expansion-192765e8-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.049376ms
Nov  7 13:57:45.496: INFO: Pod "var-expansion-192765e8-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007745737s
STEP: Saw pod success
Nov  7 13:57:45.496: INFO: Pod "var-expansion-192765e8-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:57:45.499: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod var-expansion-192765e8-e295-11e8-bb28-1ed0160468e8 container dapi-container: <nil>
STEP: delete the pod
Nov  7 13:57:45.519: INFO: Waiting for pod var-expansion-192765e8-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:57:45.526: INFO: Pod var-expansion-192765e8-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:57:45.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-q4str" for this suite.
Nov  7 13:57:51.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:57:51.643: INFO: namespace: e2e-tests-var-expansion-q4str, resource: bindings, ignored listing per whitelist
Nov  7 13:57:51.743: INFO: namespace e2e-tests-var-expansion-q4str deletion completed in 6.211677605s

• [SLOW TEST:8.462 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:57:51.743: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-wf5vt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  7 13:57:51.985: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:57:54.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wf5vt" for this suite.
Nov  7 13:58:00.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:58:01.014: INFO: namespace: e2e-tests-init-container-wf5vt, resource: bindings, ignored listing per whitelist
Nov  7 13:58:01.046: INFO: namespace e2e-tests-init-container-wf5vt deletion completed in 6.144671704s

• [SLOW TEST:9.302 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:58:01.046: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rmwvl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  7 13:58:03.934: INFO: Successfully updated pod "labelsupdate23c9e542-e295-11e8-bb28-1ed0160468e8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:58:05.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rmwvl" for this suite.
Nov  7 13:58:27.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:58:28.092: INFO: namespace: e2e-tests-downward-api-rmwvl, resource: bindings, ignored listing per whitelist
Nov  7 13:58:28.160: INFO: namespace e2e-tests-downward-api-rmwvl deletion completed in 22.19818829s

• [SLOW TEST:27.114 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:58:28.161: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ldhcc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  7 13:58:28.395: INFO: Waiting up to 5m0s for pod "pod-33eb7e7e-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-ldhcc" to be "success or failure"
Nov  7 13:58:28.398: INFO: Pod "pod-33eb7e7e-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.04349ms
Nov  7 13:58:30.403: INFO: Pod "pod-33eb7e7e-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007649411s
STEP: Saw pod success
Nov  7 13:58:30.403: INFO: Pod "pod-33eb7e7e-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:58:30.407: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-33eb7e7e-e295-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 13:58:30.434: INFO: Waiting for pod pod-33eb7e7e-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:58:30.437: INFO: Pod pod-33eb7e7e-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:58:30.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ldhcc" for this suite.
Nov  7 13:58:36.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:58:36.575: INFO: namespace: e2e-tests-emptydir-ldhcc, resource: bindings, ignored listing per whitelist
Nov  7 13:58:36.624: INFO: namespace e2e-tests-emptydir-ldhcc deletion completed in 6.183558278s

• [SLOW TEST:8.463 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:58:36.625: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ph8bq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  7 13:58:36.874: INFO: Waiting up to 5m0s for pod "downward-api-38f97e3e-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-downward-api-ph8bq" to be "success or failure"
Nov  7 13:58:36.877: INFO: Pod "downward-api-38f97e3e-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.541981ms
Nov  7 13:58:38.880: INFO: Pod "downward-api-38f97e3e-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005661296s
Nov  7 13:58:40.930: INFO: Pod "downward-api-38f97e3e-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056247031s
STEP: Saw pod success
Nov  7 13:58:40.930: INFO: Pod "downward-api-38f97e3e-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 13:58:40.934: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downward-api-38f97e3e-e295-11e8-bb28-1ed0160468e8 container dapi-container: <nil>
STEP: delete the pod
Nov  7 13:58:40.954: INFO: Waiting for pod downward-api-38f97e3e-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 13:58:40.958: INFO: Pod downward-api-38f97e3e-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:58:40.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ph8bq" for this suite.
Nov  7 13:58:46.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:58:47.009: INFO: namespace: e2e-tests-downward-api-ph8bq, resource: bindings, ignored listing per whitelist
Nov  7 13:58:47.137: INFO: namespace e2e-tests-downward-api-ph8bq deletion completed in 6.174745475s

• [SLOW TEST:10.512 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:58:47.138: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-k4crx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1107 13:59:17.873060      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  7 13:59:17.873: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:59:17.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k4crx" for this suite.
Nov  7 13:59:23.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:59:23.898: INFO: namespace: e2e-tests-gc-k4crx, resource: bindings, ignored listing per whitelist
Nov  7 13:59:24.057: INFO: namespace e2e-tests-gc-k4crx deletion completed in 6.180995991s

• [SLOW TEST:36.920 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:59:24.058: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-s2k9l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:59:24.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-s2k9l" for this suite.
Nov  7 13:59:46.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 13:59:46.432: INFO: namespace: e2e-tests-pods-s2k9l, resource: bindings, ignored listing per whitelist
Nov  7 13:59:46.439: INFO: namespace e2e-tests-pods-s2k9l deletion completed in 22.153817481s

• [SLOW TEST:22.381 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 13:59:46.439: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-v4ctg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  7 13:59:46.633: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 13:59:50.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-v4ctg" for this suite.
Nov  7 14:00:12.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:00:12.973: INFO: namespace: e2e-tests-init-container-v4ctg, resource: bindings, ignored listing per whitelist
Nov  7 14:00:13.095: INFO: namespace e2e-tests-init-container-v4ctg deletion completed in 22.262516873s

• [SLOW TEST:26.656 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:00:13.096: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-8xgpq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  7 14:00:13.319: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8xgpq,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xgpq/configmaps/e2e-watch-test-resource-version,UID:727271ff-e295-11e8-b11f-bea865258d09,ResourceVersion:22849,Generation:0,CreationTimestamp:2018-11-07 14:00:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  7 14:00:13.319: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8xgpq,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xgpq/configmaps/e2e-watch-test-resource-version,UID:727271ff-e295-11e8-b11f-bea865258d09,ResourceVersion:22850,Generation:0,CreationTimestamp:2018-11-07 14:00:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:00:13.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8xgpq" for this suite.
Nov  7 14:00:19.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:00:19.482: INFO: namespace: e2e-tests-watch-8xgpq, resource: bindings, ignored listing per whitelist
Nov  7 14:00:19.482: INFO: namespace e2e-tests-watch-8xgpq deletion completed in 6.159099838s

• [SLOW TEST:6.387 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:00:19.483: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-v5bw7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  7 14:00:19.679: INFO: Creating deployment "test-recreate-deployment"
Nov  7 14:00:19.683: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  7 14:00:19.688: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Nov  7 14:00:21.695: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  7 14:00:21.697: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  7 14:00:21.704: INFO: Updating deployment test-recreate-deployment
Nov  7 14:00:21.704: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  7 14:00:21.748: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-v5bw7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v5bw7/deployments/test-recreate-deployment,UID:76402d48-e295-11e8-b11f-bea865258d09,ResourceVersion:22905,Generation:2,CreationTimestamp:2018-11-07 14:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-11-07 14:00:21 +0000 UTC 2018-11-07 14:00:21 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-11-07 14:00:21 +0000 UTC 2018-11-07 14:00:19 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Nov  7 14:00:21.752: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-v5bw7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v5bw7/replicasets/test-recreate-deployment-7cf749666b,UID:7777a374-e295-11e8-b11f-bea865258d09,ResourceVersion:22904,Generation:1,CreationTimestamp:2018-11-07 14:00:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 76402d48-e295-11e8-b11f-bea865258d09 0xc4219b6637 0xc4219b6638}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  7 14:00:21.752: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  7 14:00:21.753: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-v5bw7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v5bw7/replicasets/test-recreate-deployment-79f694ff59,UID:764147e7-e295-11e8-b11f-bea865258d09,ResourceVersion:22898,Generation:2,CreationTimestamp:2018-11-07 14:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 76402d48-e295-11e8-b11f-bea865258d09 0xc4219b6547 0xc4219b6548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  7 14:00:21.756: INFO: Pod "test-recreate-deployment-7cf749666b-2f68r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-2f68r,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-v5bw7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v5bw7/pods/test-recreate-deployment-7cf749666b-2f68r,UID:777828d9-e295-11e8-b11f-bea865258d09,ResourceVersion:22901,Generation:0,CreationTimestamp:2018-11-07 14:00:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 7777a374-e295-11e8-b11f-bea865258d09 0xc4214ed507 0xc4214ed508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qcl8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qcl8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qcl8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214ed570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214ed590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:00:21.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-v5bw7" for this suite.
Nov  7 14:00:27.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:00:27.954: INFO: namespace: e2e-tests-deployment-v5bw7, resource: bindings, ignored listing per whitelist
Nov  7 14:00:27.972: INFO: namespace e2e-tests-deployment-v5bw7 deletion completed in 6.212925202s

• [SLOW TEST:8.490 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:00:27.973: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-s6dng
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Nov  7 14:00:28.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 create -f - --namespace=e2e-tests-kubectl-s6dng'
Nov  7 14:00:28.481: INFO: stderr: ""
Nov  7 14:00:28.481: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  7 14:00:29.488: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 14:00:29.488: INFO: Found 0 / 1
Nov  7 14:00:30.486: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 14:00:30.486: INFO: Found 0 / 1
Nov  7 14:00:31.492: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 14:00:31.492: INFO: Found 1 / 1
Nov  7 14:00:31.492: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  7 14:00:31.495: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 14:00:31.495: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  7 14:00:31.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030573999 patch pod redis-master-nmtgl --namespace=e2e-tests-kubectl-s6dng -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  7 14:00:31.747: INFO: stderr: ""
Nov  7 14:00:31.747: INFO: stdout: "pod/redis-master-nmtgl patched\n"
STEP: checking annotations
Nov  7 14:00:31.751: INFO: Selector matched 1 pods for map[app:redis]
Nov  7 14:00:31.751: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:00:31.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s6dng" for this suite.
Nov  7 14:00:53.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:00:53.951: INFO: namespace: e2e-tests-kubectl-s6dng, resource: bindings, ignored listing per whitelist
Nov  7 14:00:53.965: INFO: namespace e2e-tests-kubectl-s6dng deletion completed in 22.211203565s

• [SLOW TEST:25.992 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:00:53.965: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2klnp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-8acf76d7-e295-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 14:00:54.176: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8ad0071e-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-2klnp" to be "success or failure"
Nov  7 14:00:54.180: INFO: Pod "pod-projected-configmaps-8ad0071e-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.117318ms
Nov  7 14:00:56.184: INFO: Pod "pod-projected-configmaps-8ad0071e-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008024243s
Nov  7 14:00:58.189: INFO: Pod "pod-projected-configmaps-8ad0071e-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012651992s
STEP: Saw pod success
Nov  7 14:00:58.189: INFO: Pod "pod-projected-configmaps-8ad0071e-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 14:00:58.191: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-configmaps-8ad0071e-e295-11e8-bb28-1ed0160468e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 14:00:58.212: INFO: Waiting for pod pod-projected-configmaps-8ad0071e-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 14:00:58.214: INFO: Pod pod-projected-configmaps-8ad0071e-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:00:58.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2klnp" for this suite.
Nov  7 14:01:04.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:01:04.358: INFO: namespace: e2e-tests-projected-2klnp, resource: bindings, ignored listing per whitelist
Nov  7 14:01:04.467: INFO: namespace e2e-tests-projected-2klnp deletion completed in 6.249305816s

• [SLOW TEST:10.502 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:01:04.467: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-588dt
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  7 14:01:04.686: INFO: Waiting up to 5m0s for pod "pod-9113e93a-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-588dt" to be "success or failure"
Nov  7 14:01:04.689: INFO: Pod "pod-9113e93a-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.560271ms
Nov  7 14:01:06.693: INFO: Pod "pod-9113e93a-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006114909s
STEP: Saw pod success
Nov  7 14:01:06.693: INFO: Pod "pod-9113e93a-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 14:01:06.696: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-9113e93a-e295-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 14:01:06.717: INFO: Waiting for pod pod-9113e93a-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 14:01:06.720: INFO: Pod pod-9113e93a-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:01:06.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-588dt" for this suite.
Nov  7 14:01:12.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:01:12.868: INFO: namespace: e2e-tests-emptydir-588dt, resource: bindings, ignored listing per whitelist
Nov  7 14:01:12.903: INFO: namespace e2e-tests-emptydir-588dt deletion completed in 6.158044477s

• [SLOW TEST:8.436 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:01:12.904: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-nlk72
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  7 14:01:13.142: INFO: Waiting up to 5m0s for pod "pod-961e3b3e-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-nlk72" to be "success or failure"
Nov  7 14:01:13.145: INFO: Pod "pod-961e3b3e-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.82307ms
Nov  7 14:01:15.148: INFO: Pod "pod-961e3b3e-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006308917s
STEP: Saw pod success
Nov  7 14:01:15.148: INFO: Pod "pod-961e3b3e-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 14:01:15.151: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-961e3b3e-e295-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 14:01:15.175: INFO: Waiting for pod pod-961e3b3e-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 14:01:15.178: INFO: Pod pod-961e3b3e-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:01:15.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nlk72" for this suite.
Nov  7 14:01:21.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:01:21.341: INFO: namespace: e2e-tests-emptydir-nlk72, resource: bindings, ignored listing per whitelist
Nov  7 14:01:21.341: INFO: namespace e2e-tests-emptydir-nlk72 deletion completed in 6.160119793s

• [SLOW TEST:8.437 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:01:21.342: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-rbf7m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  7 14:01:21.573: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:01:25.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rbf7m" for this suite.
Nov  7 14:01:31.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:01:31.424: INFO: namespace: e2e-tests-init-container-rbf7m, resource: bindings, ignored listing per whitelist
Nov  7 14:01:31.433: INFO: namespace e2e-tests-init-container-rbf7m deletion completed in 6.194410269s

• [SLOW TEST:10.091 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:01:31.434: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6fnvl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  7 14:01:31.641: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a124f003-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-6fnvl" to be "success or failure"
Nov  7 14:01:31.644: INFO: Pod "downwardapi-volume-a124f003-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.812873ms
Nov  7 14:01:33.650: INFO: Pod "downwardapi-volume-a124f003-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008583091s
STEP: Saw pod success
Nov  7 14:01:33.650: INFO: Pod "downwardapi-volume-a124f003-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 14:01:33.653: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod downwardapi-volume-a124f003-e295-11e8-bb28-1ed0160468e8 container client-container: <nil>
STEP: delete the pod
Nov  7 14:01:33.676: INFO: Waiting for pod downwardapi-volume-a124f003-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 14:01:33.688: INFO: Pod downwardapi-volume-a124f003-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:01:33.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6fnvl" for this suite.
Nov  7 14:01:39.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:01:39.923: INFO: namespace: e2e-tests-projected-6fnvl, resource: bindings, ignored listing per whitelist
Nov  7 14:01:40.037: INFO: namespace e2e-tests-projected-6fnvl deletion completed in 6.33128617s

• [SLOW TEST:8.604 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:01:40.038: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jnwqv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a645ab25-e295-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 14:01:40.248: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a6462e6b-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-jnwqv" to be "success or failure"
Nov  7 14:01:40.250: INFO: Pod "pod-projected-configmaps-a6462e6b-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.632666ms
Nov  7 14:01:42.254: INFO: Pod "pod-projected-configmaps-a6462e6b-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006455194s
Nov  7 14:01:44.258: INFO: Pod "pod-projected-configmaps-a6462e6b-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010300063s
STEP: Saw pod success
Nov  7 14:01:44.258: INFO: Pod "pod-projected-configmaps-a6462e6b-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 14:01:44.261: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-configmaps-a6462e6b-e295-11e8-bb28-1ed0160468e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 14:01:44.282: INFO: Waiting for pod pod-projected-configmaps-a6462e6b-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 14:01:44.287: INFO: Pod pod-projected-configmaps-a6462e6b-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:01:44.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jnwqv" for this suite.
Nov  7 14:01:50.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:01:50.379: INFO: namespace: e2e-tests-projected-jnwqv, resource: bindings, ignored listing per whitelist
Nov  7 14:01:50.412: INFO: namespace e2e-tests-projected-jnwqv deletion completed in 6.116394038s

• [SLOW TEST:10.374 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:01:50.413: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vhfcn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ac7a4b25-e295-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume secrets
Nov  7 14:01:50.661: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac7af7b1-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-vhfcn" to be "success or failure"
Nov  7 14:01:50.664: INFO: Pod "pod-projected-secrets-ac7af7b1-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.456983ms
Nov  7 14:01:52.683: INFO: Pod "pod-projected-secrets-ac7af7b1-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021596628s
Nov  7 14:01:54.730: INFO: Pod "pod-projected-secrets-ac7af7b1-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068474163s
STEP: Saw pod success
Nov  7 14:01:54.730: INFO: Pod "pod-projected-secrets-ac7af7b1-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 14:01:54.733: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-secrets-ac7af7b1-e295-11e8-bb28-1ed0160468e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  7 14:01:54.755: INFO: Waiting for pod pod-projected-secrets-ac7af7b1-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 14:01:54.758: INFO: Pod pod-projected-secrets-ac7af7b1-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:01:54.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vhfcn" for this suite.
Nov  7 14:02:00.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:02:00.851: INFO: namespace: e2e-tests-projected-vhfcn, resource: bindings, ignored listing per whitelist
Nov  7 14:02:00.867: INFO: namespace e2e-tests-projected-vhfcn deletion completed in 6.104697766s

• [SLOW TEST:10.454 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:02:00.867: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dqbvl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b2b14eb8-e295-11e8-bb28-1ed0160468e8
STEP: Creating a pod to test consume configMaps
Nov  7 14:02:01.086: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b2b1d532-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-projected-dqbvl" to be "success or failure"
Nov  7 14:02:01.089: INFO: Pod "pod-projected-configmaps-b2b1d532-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.724418ms
Nov  7 14:02:03.095: INFO: Pod "pod-projected-configmaps-b2b1d532-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008884657s
Nov  7 14:02:05.099: INFO: Pod "pod-projected-configmaps-b2b1d532-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013111566s
STEP: Saw pod success
Nov  7 14:02:05.100: INFO: Pod "pod-projected-configmaps-b2b1d532-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 14:02:05.103: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-projected-configmaps-b2b1d532-e295-11e8-bb28-1ed0160468e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  7 14:02:05.121: INFO: Waiting for pod pod-projected-configmaps-b2b1d532-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 14:02:05.123: INFO: Pod pod-projected-configmaps-b2b1d532-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:02:05.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dqbvl" for this suite.
Nov  7 14:02:11.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:02:11.312: INFO: namespace: e2e-tests-projected-dqbvl, resource: bindings, ignored listing per whitelist
Nov  7 14:02:11.689: INFO: namespace e2e-tests-projected-dqbvl deletion completed in 6.549787199s

• [SLOW TEST:10.822 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  7 14:02:11.689: INFO: >>> kubeConfig: /tmp/kubeconfig-030573999
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xbcmv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  7 14:02:12.004: INFO: Waiting up to 5m0s for pod "pod-b9338b3b-e295-11e8-bb28-1ed0160468e8" in namespace "e2e-tests-emptydir-xbcmv" to be "success or failure"
Nov  7 14:02:12.008: INFO: Pod "pod-b9338b3b-e295-11e8-bb28-1ed0160468e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.988813ms
Nov  7 14:02:14.011: INFO: Pod "pod-b9338b3b-e295-11e8-bb28-1ed0160468e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006684904s
STEP: Saw pod success
Nov  7 14:02:14.011: INFO: Pod "pod-b9338b3b-e295-11e8-bb28-1ed0160468e8" satisfied condition "success or failure"
Nov  7 14:02:14.014: INFO: Trying to get logs from node shoot--core--conf-gcp-worker-ehel0-z1-679d99dcf5-gchr6 pod pod-b9338b3b-e295-11e8-bb28-1ed0160468e8 container test-container: <nil>
STEP: delete the pod
Nov  7 14:02:14.052: INFO: Waiting for pod pod-b9338b3b-e295-11e8-bb28-1ed0160468e8 to disappear
Nov  7 14:02:14.079: INFO: Pod pod-b9338b3b-e295-11e8-bb28-1ed0160468e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  7 14:02:14.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xbcmv" for this suite.
Nov  7 14:02:20.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  7 14:02:20.173: INFO: namespace: e2e-tests-emptydir-xbcmv, resource: bindings, ignored listing per whitelist
Nov  7 14:02:20.296: INFO: namespace e2e-tests-emptydir-xbcmv deletion completed in 6.196644523s

• [SLOW TEST:8.607 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSNov  7 14:02:20.296: INFO: Running AfterSuite actions on all node
Nov  7 14:02:20.296: INFO: Running AfterSuite actions on node 1
Nov  7 14:02:20.296: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5658.838 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h34m20.064537083s
Test Suite Passed
