Nov 13 09:00:40.251: INFO: Overriding default scale value of zero to 1
Nov 13 09:00:40.251: INFO: Overriding default milliseconds value of zero to 5000
I1113 09:00:40.863768      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-071128755
I1113 09:00:40.863876      15 e2e.go:304] Starting e2e run "9818ee70-e722-11e8-baa5-625675597e81" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1542099640 - Will randomize all specs
Will run 188 of 1814 specs

Nov 13 09:00:41.032: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:00:41.034: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov 13 09:00:41.047: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 13 09:00:41.077: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 13 09:00:41.077: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Nov 13 09:00:41.077: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 13 09:00:41.149: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov 13 09:00:41.149: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Nov 13 09:00:41.149: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Nov 13 09:00:41.149: INFO: e2e test version: v1.12.1
Nov 13 09:00:41.150: INFO: kube-apiserver version: v1.12.2
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:00:41.151: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
Nov 13 09:00:41.354: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov 13 09:00:41.368: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vpm7x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Nov 13 09:00:41.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-vpm7x'
Nov 13 09:00:44.723: INFO: stderr: ""
Nov 13 09:00:44.723: INFO: stdout: "pod/pause created\n"
Nov 13 09:00:44.723: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 13 09:00:44.723: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-vpm7x" to be "running and ready"
Nov 13 09:00:44.751: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 28.491246ms
Nov 13 09:00:46.754: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03159374s
Nov 13 09:00:48.758: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.035012601s
Nov 13 09:00:48.758: INFO: Pod "pause" satisfied condition "running and ready"
Nov 13 09:00:48.758: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Nov 13 09:00:48.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-vpm7x'
Nov 13 09:00:48.859: INFO: stderr: ""
Nov 13 09:00:48.859: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov 13 09:00:48.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pod pause -L testing-label --namespace=e2e-tests-kubectl-vpm7x'
Nov 13 09:00:48.991: INFO: stderr: ""
Nov 13 09:00:48.991: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov 13 09:00:48.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 label pods pause testing-label- --namespace=e2e-tests-kubectl-vpm7x'
Nov 13 09:00:49.131: INFO: stderr: ""
Nov 13 09:00:49.131: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov 13 09:00:49.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pod pause -L testing-label --namespace=e2e-tests-kubectl-vpm7x'
Nov 13 09:00:49.220: INFO: stderr: ""
Nov 13 09:00:49.220: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Nov 13 09:00:49.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vpm7x'
Nov 13 09:00:49.313: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:00:49.313: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 13 09:00:49.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-vpm7x'
Nov 13 09:00:49.542: INFO: stderr: "No resources found.\n"
Nov 13 09:00:49.542: INFO: stdout: ""
Nov 13 09:00:49.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -l name=pause --namespace=e2e-tests-kubectl-vpm7x -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 13 09:00:49.633: INFO: stderr: ""
Nov 13 09:00:49.633: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:00:49.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vpm7x" for this suite.
Nov 13 09:00:55.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:00:55.878: INFO: namespace: e2e-tests-kubectl-vpm7x, resource: bindings, ignored listing per whitelist
Nov 13 09:00:55.930: INFO: namespace e2e-tests-kubectl-vpm7x deletion completed in 6.285711421s

• [SLOW TEST:14.779 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:00:55.931: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-vn4dv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 09:00:56.195: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov 13 09:00:56.232: INFO: Number of nodes with available pods: 0
Nov 13 09:00:56.232: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:00:57.239: INFO: Number of nodes with available pods: 0
Nov 13 09:00:57.239: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:00:58.245: INFO: Number of nodes with available pods: 0
Nov 13 09:00:58.245: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:00:59.238: INFO: Number of nodes with available pods: 0
Nov 13 09:00:59.238: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:01:00.243: INFO: Number of nodes with available pods: 1
Nov 13 09:01:00.243: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:01:01.239: INFO: Number of nodes with available pods: 2
Nov 13 09:01:01.239: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov 13 09:01:01.259: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:01.259: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:02.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:02.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:03.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:03.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:04.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:04.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:05.309: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:05.309: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:06.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:06.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:07.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:07.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:08.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:08.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:09.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:09.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:10.343: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:10.343: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:11.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:11.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:12.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:12.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:13.352: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:13.352: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:14.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:14.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:15.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:15.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:16.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:16.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:17.351: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:17.351: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:18.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:18.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:19.343: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:19.343: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:20.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:20.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:21.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:21.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:22.265: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:22.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:23.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:23.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:24.291: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:24.291: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:25.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:25.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:26.267: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:26.267: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:27.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:27.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:28.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:28.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:29.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:29.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:30.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:30.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:31.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:31.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:32.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:32.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:33.266: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:33.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:34.267: INFO: Wrong image for pod: daemon-set-b9xdz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:34.267: INFO: Pod daemon-set-b9xdz is not available
Nov 13 09:01:34.267: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:35.267: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:35.267: INFO: Pod daemon-set-k5ptf is not available
Nov 13 09:01:36.343: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:36.343: INFO: Pod daemon-set-k5ptf is not available
Nov 13 09:01:37.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:37.266: INFO: Pod daemon-set-k5ptf is not available
Nov 13 09:01:38.268: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:38.268: INFO: Pod daemon-set-k5ptf is not available
Nov 13 09:01:39.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:39.266: INFO: Pod daemon-set-k5ptf is not available
Nov 13 09:01:40.265: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:40.266: INFO: Pod daemon-set-k5ptf is not available
Nov 13 09:01:41.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:42.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:43.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:44.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:45.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:46.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:47.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:48.299: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:49.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:50.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:51.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:52.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:53.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:54.267: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:55.267: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:56.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:57.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:58.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:01:59.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:00.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:01.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:02.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:03.351: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:04.272: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:05.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:06.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:07.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:08.275: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:09.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:10.343: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:11.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:12.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:12.266: INFO: Pod daemon-set-cq2rp is not available
Nov 13 09:02:13.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:13.266: INFO: Pod daemon-set-cq2rp is not available
Nov 13 09:02:14.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:14.266: INFO: Pod daemon-set-cq2rp is not available
Nov 13 09:02:15.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:15.266: INFO: Pod daemon-set-cq2rp is not available
Nov 13 09:02:16.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:16.266: INFO: Pod daemon-set-cq2rp is not available
Nov 13 09:02:17.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:17.266: INFO: Pod daemon-set-cq2rp is not available
Nov 13 09:02:18.266: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:18.266: INFO: Pod daemon-set-cq2rp is not available
Nov 13 09:02:19.265: INFO: Wrong image for pod: daemon-set-cq2rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov 13 09:02:19.265: INFO: Pod daemon-set-cq2rp is not available
Nov 13 09:02:20.266: INFO: Pod daemon-set-r6mm6 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov 13 09:02:20.275: INFO: Number of nodes with available pods: 1
Nov 13 09:02:20.275: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:02:21.283: INFO: Number of nodes with available pods: 1
Nov 13 09:02:21.283: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:02:22.282: INFO: Number of nodes with available pods: 1
Nov 13 09:02:22.282: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:02:23.281: INFO: Number of nodes with available pods: 1
Nov 13 09:02:23.281: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:02:24.281: INFO: Number of nodes with available pods: 1
Nov 13 09:02:24.281: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:02:25.281: INFO: Number of nodes with available pods: 2
Nov 13 09:02:25.281: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-vn4dv, will wait for the garbage collector to delete the pods
Nov 13 09:02:25.352: INFO: Deleting {extensions DaemonSet} daemon-set took: 4.643467ms
Nov 13 09:02:25.452: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.204956ms
Nov 13 09:02:30.255: INFO: Number of nodes with available pods: 0
Nov 13 09:02:30.255: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 09:02:30.257: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vn4dv/daemonsets","resourceVersion":"3181"},"items":null}

Nov 13 09:02:30.259: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vn4dv/pods","resourceVersion":"3181"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:02:30.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vn4dv" for this suite.
Nov 13 09:02:36.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:02:36.978: INFO: namespace: e2e-tests-daemonsets-vn4dv, resource: bindings, ignored listing per whitelist
Nov 13 09:02:36.983: INFO: namespace e2e-tests-daemonsets-vn4dv deletion completed in 6.706756671s

• [SLOW TEST:101.053 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:02:36.984: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-7pl27
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1113 09:03:07.741318      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 09:03:07.741: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:03:07.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7pl27" for this suite.
Nov 13 09:03:13.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:03:13.805: INFO: namespace: e2e-tests-gc-7pl27, resource: bindings, ignored listing per whitelist
Nov 13 09:03:13.909: INFO: namespace e2e-tests-gc-7pl27 deletion completed in 6.165005547s

• [SLOW TEST:36.925 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:03:13.909: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-snfrt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Nov 13 09:03:14.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:14.408: INFO: stderr: ""
Nov 13 09:03:14.408: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 09:03:14.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:14.699: INFO: stderr: ""
Nov 13 09:03:14.699: INFO: stdout: "update-demo-nautilus-56hqw update-demo-nautilus-j6hlj "
Nov 13 09:03:14.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-56hqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:14.790: INFO: stderr: ""
Nov 13 09:03:14.790: INFO: stdout: ""
Nov 13 09:03:14.790: INFO: update-demo-nautilus-56hqw is created but not running
Nov 13 09:03:19.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:19.898: INFO: stderr: ""
Nov 13 09:03:19.898: INFO: stdout: "update-demo-nautilus-56hqw update-demo-nautilus-j6hlj "
Nov 13 09:03:19.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-56hqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:20.010: INFO: stderr: ""
Nov 13 09:03:20.010: INFO: stdout: ""
Nov 13 09:03:20.010: INFO: update-demo-nautilus-56hqw is created but not running
Nov 13 09:03:25.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:25.103: INFO: stderr: ""
Nov 13 09:03:25.103: INFO: stdout: "update-demo-nautilus-56hqw update-demo-nautilus-j6hlj "
Nov 13 09:03:25.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-56hqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:25.197: INFO: stderr: ""
Nov 13 09:03:25.197: INFO: stdout: "true"
Nov 13 09:03:25.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-56hqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:25.292: INFO: stderr: ""
Nov 13 09:03:25.292: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:03:25.292: INFO: validating pod update-demo-nautilus-56hqw
Nov 13 09:03:25.381: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:03:25.381: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:03:25.381: INFO: update-demo-nautilus-56hqw is verified up and running
Nov 13 09:03:25.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-j6hlj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:25.470: INFO: stderr: ""
Nov 13 09:03:25.471: INFO: stdout: "true"
Nov 13 09:03:25.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-j6hlj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:25.562: INFO: stderr: ""
Nov 13 09:03:25.562: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:03:25.562: INFO: validating pod update-demo-nautilus-j6hlj
Nov 13 09:03:25.650: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:03:25.650: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:03:25.650: INFO: update-demo-nautilus-j6hlj is verified up and running
STEP: rolling-update to new replication controller
Nov 13 09:03:25.652: INFO: scanned /root for discovery docs: <nil>
Nov 13 09:03:25.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:53.836: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 13 09:03:53.837: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 09:03:53.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:53.944: INFO: stderr: ""
Nov 13 09:03:53.944: INFO: stdout: "update-demo-kitten-4l2dc update-demo-kitten-srtnb "
Nov 13 09:03:53.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-kitten-4l2dc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:54.030: INFO: stderr: ""
Nov 13 09:03:54.030: INFO: stdout: "true"
Nov 13 09:03:54.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-kitten-4l2dc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:54.125: INFO: stderr: ""
Nov 13 09:03:54.125: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 13 09:03:54.126: INFO: validating pod update-demo-kitten-4l2dc
Nov 13 09:03:54.216: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 13 09:03:54.217: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 13 09:03:54.217: INFO: update-demo-kitten-4l2dc is verified up and running
Nov 13 09:03:54.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-kitten-srtnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:54.345: INFO: stderr: ""
Nov 13 09:03:54.345: INFO: stdout: "true"
Nov 13 09:03:54.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-kitten-srtnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-snfrt'
Nov 13 09:03:54.462: INFO: stderr: ""
Nov 13 09:03:54.462: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 13 09:03:54.463: INFO: validating pod update-demo-kitten-srtnb
Nov 13 09:03:54.552: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 13 09:03:54.552: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 13 09:03:54.552: INFO: update-demo-kitten-srtnb is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:03:54.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-snfrt" for this suite.
Nov 13 09:04:16.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:04:16.595: INFO: namespace: e2e-tests-kubectl-snfrt, resource: bindings, ignored listing per whitelist
Nov 13 09:04:16.741: INFO: namespace e2e-tests-kubectl-snfrt deletion completed in 22.186141098s

• [SLOW TEST:62.832 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:04:16.741: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-jwh2d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jwh2d
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Nov 13 09:04:17.056: INFO: Found 0 stateful pods, waiting for 3
Nov 13 09:04:27.061: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:04:27.061: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:04:27.061: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 13 09:04:37.060: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:04:37.060: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:04:37.060: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:04:37.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-jwh2d ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 09:04:38.437: INFO: stderr: ""
Nov 13 09:04:38.437: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 09:04:38.437: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov 13 09:04:48.465: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov 13 09:04:58.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-jwh2d ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:04:59.144: INFO: stderr: ""
Nov 13 09:04:59.144: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 13 09:04:59.144: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 13 09:05:09.176: INFO: Waiting for StatefulSet e2e-tests-statefulset-jwh2d/ss2 to complete update
Nov 13 09:05:09.176: INFO: Waiting for Pod e2e-tests-statefulset-jwh2d/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov 13 09:05:09.176: INFO: Waiting for Pod e2e-tests-statefulset-jwh2d/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov 13 09:05:19.191: INFO: Waiting for StatefulSet e2e-tests-statefulset-jwh2d/ss2 to complete update
Nov 13 09:05:19.191: INFO: Waiting for Pod e2e-tests-statefulset-jwh2d/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Nov 13 09:05:29.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-jwh2d ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 09:05:29.679: INFO: stderr: ""
Nov 13 09:05:29.679: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 09:05:29.679: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 09:05:39.708: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov 13 09:05:49.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-jwh2d ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:05:50.205: INFO: stderr: ""
Nov 13 09:05:50.205: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 13 09:05:50.205: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 13 09:06:00.231: INFO: Waiting for StatefulSet e2e-tests-statefulset-jwh2d/ss2 to complete update
Nov 13 09:06:00.232: INFO: Waiting for Pod e2e-tests-statefulset-jwh2d/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 13 09:06:00.232: INFO: Waiting for Pod e2e-tests-statefulset-jwh2d/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 13 09:06:10.238: INFO: Waiting for StatefulSet e2e-tests-statefulset-jwh2d/ss2 to complete update
Nov 13 09:06:10.238: INFO: Waiting for Pod e2e-tests-statefulset-jwh2d/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 13 09:06:20.238: INFO: Waiting for StatefulSet e2e-tests-statefulset-jwh2d/ss2 to complete update
Nov 13 09:06:20.238: INFO: Waiting for Pod e2e-tests-statefulset-jwh2d/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 13 09:06:30.237: INFO: Waiting for StatefulSet e2e-tests-statefulset-jwh2d/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 13 09:06:40.248: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jwh2d
Nov 13 09:06:40.251: INFO: Scaling statefulset ss2 to 0
Nov 13 09:07:00.265: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 09:07:00.345: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:07:00.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jwh2d" for this suite.
Nov 13 09:07:06.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:07:06.532: INFO: namespace: e2e-tests-statefulset-jwh2d, resource: bindings, ignored listing per whitelist
Nov 13 09:07:06.534: INFO: namespace e2e-tests-statefulset-jwh2d deletion completed in 6.149465256s

• [SLOW TEST:169.793 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:07:06.535: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5d86n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-7e8d9c52-e723-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 09:07:06.797: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-5d86n" to be "success or failure"
Nov 13 09:07:06.826: INFO: Pod "pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 28.53563ms
Nov 13 09:07:08.829: INFO: Pod "pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032119315s
Nov 13 09:07:10.833: INFO: Pod "pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035975932s
Nov 13 09:07:12.837: INFO: Pod "pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039722044s
Nov 13 09:07:14.840: INFO: Pod "pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042743556s
STEP: Saw pod success
Nov 13 09:07:14.840: INFO: Pod "pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:07:14.843: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 09:07:15.001: INFO: Waiting for pod pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81 to disappear
Nov 13 09:07:15.019: INFO: Pod pod-projected-configmaps-7e8e3e4a-e723-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:07:15.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5d86n" for this suite.
Nov 13 09:07:21.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:07:21.095: INFO: namespace: e2e-tests-projected-5d86n, resource: bindings, ignored listing per whitelist
Nov 13 09:07:21.125: INFO: namespace e2e-tests-projected-5d86n deletion completed in 6.103474198s

• [SLOW TEST:14.590 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:07:21.125: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-hmwt9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 13 09:07:33.446: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:33.489: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:35.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:35.493: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:37.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:37.492: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:39.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:39.492: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:41.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:41.493: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:43.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:43.493: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:45.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:45.493: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:47.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:47.548: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:49.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:49.492: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:51.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:51.493: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:53.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:53.493: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:55.506: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:55.533: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:57.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:57.493: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:07:59.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:07:59.492: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 09:08:01.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 09:08:01.500: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:08:01.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hmwt9" for this suite.
Nov 13 09:08:23.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:08:23.671: INFO: namespace: e2e-tests-container-lifecycle-hook-hmwt9, resource: bindings, ignored listing per whitelist
Nov 13 09:08:23.693: INFO: namespace e2e-tests-container-lifecycle-hook-hmwt9 deletion completed in 22.179453518s

• [SLOW TEST:62.568 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:08:23.694: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f94x6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 09:08:23.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac86c7c5-e723-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-f94x6" to be "success or failure"
Nov 13 09:08:23.939: INFO: Pod "downwardapi-volume-ac86c7c5-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 10.574313ms
Nov 13 09:08:25.943: INFO: Pod "downwardapi-volume-ac86c7c5-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014377835s
Nov 13 09:08:27.947: INFO: Pod "downwardapi-volume-ac86c7c5-e723-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018306166s
STEP: Saw pod success
Nov 13 09:08:27.947: INFO: Pod "downwardapi-volume-ac86c7c5-e723-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:08:27.950: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-ac86c7c5-e723-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 09:08:27.982: INFO: Waiting for pod downwardapi-volume-ac86c7c5-e723-11e8-baa5-625675597e81 to disappear
Nov 13 09:08:27.990: INFO: Pod downwardapi-volume-ac86c7c5-e723-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:08:27.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f94x6" for this suite.
Nov 13 09:08:34.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:08:34.145: INFO: namespace: e2e-tests-projected-f94x6, resource: bindings, ignored listing per whitelist
Nov 13 09:08:34.213: INFO: namespace e2e-tests-projected-f94x6 deletion completed in 6.219162895s

• [SLOW TEST:10.519 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:08:34.213: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8r69n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov 13 09:08:34.490: INFO: Waiting up to 5m0s for pod "downward-api-b2d32152-e723-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-8r69n" to be "success or failure"
Nov 13 09:08:34.495: INFO: Pod "downward-api-b2d32152-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.037252ms
Nov 13 09:08:36.499: INFO: Pod "downward-api-b2d32152-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008374117s
Nov 13 09:08:38.545: INFO: Pod "downward-api-b2d32152-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055073309s
Nov 13 09:08:40.549: INFO: Pod "downward-api-b2d32152-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058453181s
Nov 13 09:08:42.552: INFO: Pod "downward-api-b2d32152-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 8.062122896s
Nov 13 09:08:44.556: INFO: Pod "downward-api-b2d32152-e723-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.065609248s
STEP: Saw pod success
Nov 13 09:08:44.556: INFO: Pod "downward-api-b2d32152-e723-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:08:44.558: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downward-api-b2d32152-e723-11e8-baa5-625675597e81 container dapi-container: <nil>
STEP: delete the pod
Nov 13 09:08:44.667: INFO: Waiting for pod downward-api-b2d32152-e723-11e8-baa5-625675597e81 to disappear
Nov 13 09:08:44.675: INFO: Pod downward-api-b2d32152-e723-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:08:44.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8r69n" for this suite.
Nov 13 09:08:50.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:08:50.797: INFO: namespace: e2e-tests-downward-api-8r69n, resource: bindings, ignored listing per whitelist
Nov 13 09:08:50.836: INFO: namespace e2e-tests-downward-api-8r69n deletion completed in 6.150699414s

• [SLOW TEST:16.623 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:08:50.836: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bg46k
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Nov 13 09:08:51.094: INFO: Waiting up to 5m0s for pod "pod-bcb8b647-e723-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-bg46k" to be "success or failure"
Nov 13 09:08:51.110: INFO: Pod "pod-bcb8b647-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 15.263055ms
Nov 13 09:08:53.114: INFO: Pod "pod-bcb8b647-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019061059s
Nov 13 09:08:55.118: INFO: Pod "pod-bcb8b647-e723-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023131831s
STEP: Saw pod success
Nov 13 09:08:55.121: INFO: Pod "pod-bcb8b647-e723-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:08:55.123: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-bcb8b647-e723-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 09:08:55.173: INFO: Waiting for pod pod-bcb8b647-e723-11e8-baa5-625675597e81 to disappear
Nov 13 09:08:55.176: INFO: Pod pod-bcb8b647-e723-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:08:55.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bg46k" for this suite.
Nov 13 09:09:01.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:09:01.284: INFO: namespace: e2e-tests-emptydir-bg46k, resource: bindings, ignored listing per whitelist
Nov 13 09:09:01.324: INFO: namespace e2e-tests-emptydir-bg46k deletion completed in 6.144890995s

• [SLOW TEST:10.488 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:09:01.325: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4vwmq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov 13 09:09:01.624: INFO: Waiting up to 5m0s for pod "downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-4vwmq" to be "success or failure"
Nov 13 09:09:01.648: INFO: Pod "downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 24.644855ms
Nov 13 09:09:03.652: INFO: Pod "downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028198079s
Nov 13 09:09:05.655: INFO: Pod "downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031373039s
Nov 13 09:09:07.658: INFO: Pod "downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034409846s
STEP: Saw pod success
Nov 13 09:09:07.658: INFO: Pod "downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:09:07.746: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81 container dapi-container: <nil>
STEP: delete the pod
Nov 13 09:09:07.773: INFO: Waiting for pod downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81 to disappear
Nov 13 09:09:07.786: INFO: Pod downward-api-c2ff4e4d-e723-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:09:07.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4vwmq" for this suite.
Nov 13 09:09:13.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:09:13.915: INFO: namespace: e2e-tests-downward-api-4vwmq, resource: bindings, ignored listing per whitelist
Nov 13 09:09:13.965: INFO: namespace e2e-tests-downward-api-4vwmq deletion completed in 6.171644463s

• [SLOW TEST:12.641 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:09:13.965: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6lrqz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ca823af9-e723-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 09:09:14.229: INFO: Waiting up to 5m0s for pod "pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-6lrqz" to be "success or failure"
Nov 13 09:09:14.234: INFO: Pod "pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.519145ms
Nov 13 09:09:16.237: INFO: Pod "pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007598618s
Nov 13 09:09:18.240: INFO: Pod "pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010617948s
Nov 13 09:09:20.244: INFO: Pod "pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014103644s
STEP: Saw pod success
Nov 13 09:09:20.244: INFO: Pod "pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:09:20.246: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 09:09:20.267: INFO: Waiting for pod pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81 to disappear
Nov 13 09:09:20.271: INFO: Pod pod-configmaps-ca82a69b-e723-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:09:20.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6lrqz" for this suite.
Nov 13 09:09:26.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:09:26.382: INFO: namespace: e2e-tests-configmap-6lrqz, resource: bindings, ignored listing per whitelist
Nov 13 09:09:26.497: INFO: namespace e2e-tests-configmap-6lrqz deletion completed in 6.220020584s

• [SLOW TEST:12.532 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:09:26.497: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-tb59k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-tb59k
I1113 09:09:26.759320      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-tb59k, replica count: 1
I1113 09:09:27.810868      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 09:09:28.811026      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 09:09:29.811212      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 09:09:30.811401      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 13 09:09:30.932: INFO: Created: latency-svc-njwwb
Nov 13 09:09:30.947: INFO: Got endpoints: latency-svc-njwwb [35.982854ms]
Nov 13 09:09:30.987: INFO: Created: latency-svc-4cb4h
Nov 13 09:09:31.004: INFO: Created: latency-svc-vbq4q
Nov 13 09:09:31.004: INFO: Got endpoints: latency-svc-4cb4h [57.053461ms]
Nov 13 09:09:31.008: INFO: Got endpoints: latency-svc-vbq4q [60.735497ms]
Nov 13 09:09:31.027: INFO: Created: latency-svc-wmnd4
Nov 13 09:09:31.032: INFO: Got endpoints: latency-svc-wmnd4 [84.049726ms]
Nov 13 09:09:31.056: INFO: Created: latency-svc-p2x8t
Nov 13 09:09:31.069: INFO: Got endpoints: latency-svc-p2x8t [121.135691ms]
Nov 13 09:09:31.085: INFO: Created: latency-svc-4t4sb
Nov 13 09:09:31.148: INFO: Got endpoints: latency-svc-4t4sb [199.35306ms]
Nov 13 09:09:31.149: INFO: Created: latency-svc-lpmxg
Nov 13 09:09:31.205: INFO: Got endpoints: latency-svc-lpmxg [256.762325ms]
Nov 13 09:09:31.223: INFO: Created: latency-svc-glwsc
Nov 13 09:09:31.243: INFO: Got endpoints: latency-svc-glwsc [295.196503ms]
Nov 13 09:09:31.301: INFO: Created: latency-svc-8dhnc
Nov 13 09:09:31.318: INFO: Created: latency-svc-kmngd
Nov 13 09:09:31.318: INFO: Got endpoints: latency-svc-8dhnc [369.799837ms]
Nov 13 09:09:31.330: INFO: Got endpoints: latency-svc-kmngd [381.39685ms]
Nov 13 09:09:31.343: INFO: Created: latency-svc-4w4pc
Nov 13 09:09:31.365: INFO: Got endpoints: latency-svc-4w4pc [415.89789ms]
Nov 13 09:09:31.387: INFO: Created: latency-svc-hlcdq
Nov 13 09:09:31.398: INFO: Got endpoints: latency-svc-hlcdq [449.030415ms]
Nov 13 09:09:31.429: INFO: Created: latency-svc-thc8c
Nov 13 09:09:31.443: INFO: Created: latency-svc-hkpph
Nov 13 09:09:31.443: INFO: Got endpoints: latency-svc-thc8c [493.355151ms]
Nov 13 09:09:31.455: INFO: Got endpoints: latency-svc-hkpph [506.006076ms]
Nov 13 09:09:31.468: INFO: Created: latency-svc-2q9tt
Nov 13 09:09:31.497: INFO: Got endpoints: latency-svc-2q9tt [547.20288ms]
Nov 13 09:09:31.509: INFO: Created: latency-svc-gfbxq
Nov 13 09:09:31.521: INFO: Got endpoints: latency-svc-gfbxq [571.217418ms]
Nov 13 09:09:31.570: INFO: Created: latency-svc-pghrb
Nov 13 09:09:31.572: INFO: Got endpoints: latency-svc-pghrb [567.844685ms]
Nov 13 09:09:31.620: INFO: Created: latency-svc-68qtg
Nov 13 09:09:31.632: INFO: Got endpoints: latency-svc-68qtg [623.992137ms]
Nov 13 09:09:31.660: INFO: Created: latency-svc-hg822
Nov 13 09:09:31.755: INFO: Created: latency-svc-28blb
Nov 13 09:09:31.755: INFO: Created: latency-svc-6cc2d
Nov 13 09:09:31.755: INFO: Got endpoints: latency-svc-28blb [607.131371ms]
Nov 13 09:09:31.755: INFO: Got endpoints: latency-svc-hg822 [723.710517ms]
Nov 13 09:09:31.756: INFO: Got endpoints: latency-svc-6cc2d [686.482052ms]
Nov 13 09:09:31.827: INFO: Created: latency-svc-7hrql
Nov 13 09:09:31.827: INFO: Got endpoints: latency-svc-7hrql [621.918217ms]
Nov 13 09:09:31.874: INFO: Created: latency-svc-tnc6m
Nov 13 09:09:31.875: INFO: Got endpoints: latency-svc-tnc6m [631.070306ms]
Nov 13 09:09:31.888: INFO: Created: latency-svc-ffkzv
Nov 13 09:09:31.901: INFO: Got endpoints: latency-svc-ffkzv [582.284826ms]
Nov 13 09:09:31.933: INFO: Created: latency-svc-6tlf7
Nov 13 09:09:31.933: INFO: Got endpoints: latency-svc-6tlf7 [602.397524ms]
Nov 13 09:09:31.978: INFO: Created: latency-svc-rs5r8
Nov 13 09:09:31.978: INFO: Got endpoints: latency-svc-rs5r8 [613.331632ms]
Nov 13 09:09:32.021: INFO: Created: latency-svc-jwrdx
Nov 13 09:09:32.026: INFO: Got endpoints: latency-svc-jwrdx [627.674074ms]
Nov 13 09:09:32.043: INFO: Created: latency-svc-h6wvz
Nov 13 09:09:32.056: INFO: Got endpoints: latency-svc-h6wvz [612.833528ms]
Nov 13 09:09:32.071: INFO: Created: latency-svc-gqkgj
Nov 13 09:09:32.083: INFO: Got endpoints: latency-svc-gqkgj [627.784175ms]
Nov 13 09:09:32.096: INFO: Created: latency-svc-qttgf
Nov 13 09:09:32.143: INFO: Got endpoints: latency-svc-qttgf [646.251757ms]
Nov 13 09:09:32.162: INFO: Created: latency-svc-vcrrr
Nov 13 09:09:32.245: INFO: Got endpoints: latency-svc-vcrrr [723.420317ms]
Nov 13 09:09:32.324: INFO: Created: latency-svc-zngrw
Nov 13 09:09:32.336: INFO: Got endpoints: latency-svc-zngrw [763.653414ms]
Nov 13 09:09:32.336: INFO: Created: latency-svc-dnfnj
Nov 13 09:09:32.350: INFO: Got endpoints: latency-svc-dnfnj [717.583161ms]
Nov 13 09:09:32.367: INFO: Created: latency-svc-9mf2f
Nov 13 09:09:32.377: INFO: Got endpoints: latency-svc-9mf2f [622.234024ms]
Nov 13 09:09:32.390: INFO: Created: latency-svc-l87wb
Nov 13 09:09:32.411: INFO: Got endpoints: latency-svc-l87wb [655.301449ms]
Nov 13 09:09:32.483: INFO: Created: latency-svc-tbjhg
Nov 13 09:09:32.484: INFO: Got endpoints: latency-svc-tbjhg [728.50867ms]
Nov 13 09:09:32.517: INFO: Created: latency-svc-67pxq
Nov 13 09:09:32.528: INFO: Got endpoints: latency-svc-67pxq [701.0168ms]
Nov 13 09:09:32.541: INFO: Created: latency-svc-ghxcx
Nov 13 09:09:32.566: INFO: Created: latency-svc-kgxrw
Nov 13 09:09:32.566: INFO: Got endpoints: latency-svc-ghxcx [691.778409ms]
Nov 13 09:09:32.672: INFO: Created: latency-svc-h8vsk
Nov 13 09:09:32.672: INFO: Created: latency-svc-ndgz5
Nov 13 09:09:32.672: INFO: Got endpoints: latency-svc-ndgz5 [739.273978ms]
Nov 13 09:09:32.672: INFO: Created: latency-svc-68jrk
Nov 13 09:09:32.672: INFO: Got endpoints: latency-svc-68jrk [693.886831ms]
Nov 13 09:09:32.672: INFO: Got endpoints: latency-svc-kgxrw [761.067092ms]
Nov 13 09:09:32.685: INFO: Got endpoints: latency-svc-h8vsk [658.544483ms]
Nov 13 09:09:32.696: INFO: Created: latency-svc-776nv
Nov 13 09:09:32.710: INFO: Got endpoints: latency-svc-776nv [646.607766ms]
Nov 13 09:09:32.727: INFO: Created: latency-svc-5p4nq
Nov 13 09:09:32.768: INFO: Got endpoints: latency-svc-5p4nq [684.352937ms]
Nov 13 09:09:32.782: INFO: Created: latency-svc-kzv5f
Nov 13 09:09:32.790: INFO: Got endpoints: latency-svc-kzv5f [638.648887ms]
Nov 13 09:09:32.803: INFO: Created: latency-svc-95lpd
Nov 13 09:09:32.814: INFO: Got endpoints: latency-svc-95lpd [559.024503ms]
Nov 13 09:09:32.827: INFO: Created: latency-svc-2pjxd
Nov 13 09:09:32.839: INFO: Got endpoints: latency-svc-2pjxd [503.150254ms]
Nov 13 09:09:32.854: INFO: Created: latency-svc-d276g
Nov 13 09:09:32.865: INFO: Got endpoints: latency-svc-d276g [515.448474ms]
Nov 13 09:09:32.924: INFO: Created: latency-svc-tjfsq
Nov 13 09:09:32.955: INFO: Got endpoints: latency-svc-tjfsq [577.187282ms]
Nov 13 09:09:33.001: INFO: Created: latency-svc-hzmrq
Nov 13 09:09:33.022: INFO: Got endpoints: latency-svc-hzmrq [608.614995ms]
Nov 13 09:09:33.080: INFO: Created: latency-svc-58rgg
Nov 13 09:09:33.093: INFO: Got endpoints: latency-svc-58rgg [608.816411ms]
Nov 13 09:09:33.094: INFO: Created: latency-svc-f7jfv
Nov 13 09:09:33.105: INFO: Got endpoints: latency-svc-f7jfv [576.912499ms]
Nov 13 09:09:33.120: INFO: Created: latency-svc-bsmzl
Nov 13 09:09:33.140: INFO: Got endpoints: latency-svc-bsmzl [573.822175ms]
Nov 13 09:09:33.166: INFO: Created: latency-svc-zvdjl
Nov 13 09:09:33.206: INFO: Got endpoints: latency-svc-zvdjl [533.593093ms]
Nov 13 09:09:33.207: INFO: Created: latency-svc-vnvlj
Nov 13 09:09:33.213: INFO: Got endpoints: latency-svc-vnvlj [540.688964ms]
Nov 13 09:09:33.223: INFO: Created: latency-svc-jlt98
Nov 13 09:09:33.235: INFO: Got endpoints: latency-svc-jlt98 [562.748085ms]
Nov 13 09:09:33.250: INFO: Created: latency-svc-pcm9v
Nov 13 09:09:33.262: INFO: Got endpoints: latency-svc-pcm9v [577.567737ms]
Nov 13 09:09:33.301: INFO: Created: latency-svc-2h9gs
Nov 13 09:09:33.337: INFO: Got endpoints: latency-svc-2h9gs [626.664635ms]
Nov 13 09:09:33.338: INFO: Created: latency-svc-tnjh4
Nov 13 09:09:33.342: INFO: Got endpoints: latency-svc-tnjh4 [574.29132ms]
Nov 13 09:09:33.356: INFO: Created: latency-svc-lp6w9
Nov 13 09:09:33.377: INFO: Got endpoints: latency-svc-lp6w9 [586.748249ms]
Nov 13 09:09:33.398: INFO: Created: latency-svc-wg4rk
Nov 13 09:09:33.410: INFO: Got endpoints: latency-svc-wg4rk [595.387341ms]
Nov 13 09:09:33.423: INFO: Created: latency-svc-hbmpt
Nov 13 09:09:33.435: INFO: Got endpoints: latency-svc-hbmpt [595.945352ms]
Nov 13 09:09:33.463: INFO: Created: latency-svc-4pgjv
Nov 13 09:09:33.465: INFO: Got endpoints: latency-svc-4pgjv [599.308191ms]
Nov 13 09:09:33.482: INFO: Created: latency-svc-8v2g2
Nov 13 09:09:33.495: INFO: Got endpoints: latency-svc-8v2g2 [540.176415ms]
Nov 13 09:09:33.510: INFO: Created: latency-svc-m9grp
Nov 13 09:09:33.522: INFO: Got endpoints: latency-svc-m9grp [500.590227ms]
Nov 13 09:09:33.546: INFO: Created: latency-svc-zqmdt
Nov 13 09:09:33.562: INFO: Got endpoints: latency-svc-zqmdt [468.892407ms]
Nov 13 09:09:33.607: INFO: Created: latency-svc-zbdck
Nov 13 09:09:33.614: INFO: Got endpoints: latency-svc-zbdck [508.98641ms]
Nov 13 09:09:33.634: INFO: Created: latency-svc-m9ghk
Nov 13 09:09:33.646: INFO: Got endpoints: latency-svc-m9ghk [505.362774ms]
Nov 13 09:09:33.658: INFO: Created: latency-svc-pw49x
Nov 13 09:09:33.681: INFO: Got endpoints: latency-svc-pw49x [475.130471ms]
Nov 13 09:09:33.696: INFO: Created: latency-svc-sb4fg
Nov 13 09:09:33.738: INFO: Got endpoints: latency-svc-sb4fg [524.476566ms]
Nov 13 09:09:33.740: INFO: Created: latency-svc-mbcc2
Nov 13 09:09:33.751: INFO: Got endpoints: latency-svc-mbcc2 [515.85828ms]
Nov 13 09:09:33.760: INFO: Created: latency-svc-rhsxv
Nov 13 09:09:33.771: INFO: Got endpoints: latency-svc-rhsxv [509.137812ms]
Nov 13 09:09:33.784: INFO: Created: latency-svc-w6jqm
Nov 13 09:09:33.804: INFO: Got endpoints: latency-svc-w6jqm [467.350992ms]
Nov 13 09:09:33.818: INFO: Created: latency-svc-2nlnk
Nov 13 09:09:33.879: INFO: Got endpoints: latency-svc-2nlnk [536.715989ms]
Nov 13 09:09:33.880: INFO: Created: latency-svc-6vnft
Nov 13 09:09:33.884: INFO: Got endpoints: latency-svc-6vnft [506.589086ms]
Nov 13 09:09:33.896: INFO: Created: latency-svc-5mvb9
Nov 13 09:09:33.910: INFO: Got endpoints: latency-svc-5mvb9 [499.790218ms]
Nov 13 09:09:33.922: INFO: Created: latency-svc-knxqh
Nov 13 09:09:33.934: INFO: Got endpoints: latency-svc-knxqh [498.644407ms]
Nov 13 09:09:33.947: INFO: Created: latency-svc-kh5qh
Nov 13 09:09:33.959: INFO: Got endpoints: latency-svc-kh5qh [494.01656ms]
Nov 13 09:09:34.086: INFO: Created: latency-svc-6frhz
Nov 13 09:09:34.089: INFO: Got endpoints: latency-svc-6frhz [593.686773ms]
Nov 13 09:09:34.107: INFO: Created: latency-svc-64xhd
Nov 13 09:09:34.119: INFO: Got endpoints: latency-svc-64xhd [596.619207ms]
Nov 13 09:09:34.146: INFO: Created: latency-svc-9pkt9
Nov 13 09:09:34.158: INFO: Got endpoints: latency-svc-9pkt9 [595.858104ms]
Nov 13 09:09:34.175: INFO: Created: latency-svc-zp449
Nov 13 09:09:34.254: INFO: Got endpoints: latency-svc-zp449 [639.852659ms]
Nov 13 09:09:34.255: INFO: Created: latency-svc-jjd4z
Nov 13 09:09:34.260: INFO: Got endpoints: latency-svc-jjd4z [613.968101ms]
Nov 13 09:09:34.294: INFO: Created: latency-svc-2wjfn
Nov 13 09:09:34.306: INFO: Got endpoints: latency-svc-2wjfn [625.23182ms]
Nov 13 09:09:34.319: INFO: Created: latency-svc-prnmb
Nov 13 09:09:34.332: INFO: Got endpoints: latency-svc-prnmb [594.390714ms]
Nov 13 09:09:34.345: INFO: Created: latency-svc-pzqsj
Nov 13 09:09:34.381: INFO: Got endpoints: latency-svc-pzqsj [630.268181ms]
Nov 13 09:09:34.383: INFO: Created: latency-svc-wm6sw
Nov 13 09:09:34.387: INFO: Got endpoints: latency-svc-wm6sw [615.530434ms]
Nov 13 09:09:34.406: INFO: Created: latency-svc-csbms
Nov 13 09:09:34.418: INFO: Got endpoints: latency-svc-csbms [613.506918ms]
Nov 13 09:09:34.431: INFO: Created: latency-svc-hlv2x
Nov 13 09:09:34.444: INFO: Got endpoints: latency-svc-hlv2x [565.46134ms]
Nov 13 09:09:34.457: INFO: Created: latency-svc-vp8gh
Nov 13 09:09:34.470: INFO: Got endpoints: latency-svc-vp8gh [586.078249ms]
Nov 13 09:09:34.553: INFO: Created: latency-svc-8zsz8
Nov 13 09:09:34.555: INFO: Got endpoints: latency-svc-8zsz8 [645.007153ms]
Nov 13 09:09:34.573: INFO: Created: latency-svc-jchdh
Nov 13 09:09:34.604: INFO: Got endpoints: latency-svc-jchdh [669.563207ms]
Nov 13 09:09:34.628: INFO: Created: latency-svc-mgj49
Nov 13 09:09:34.640: INFO: Got endpoints: latency-svc-mgj49 [681.42343ms]
Nov 13 09:09:34.695: INFO: Created: latency-svc-jvhtn
Nov 13 09:09:34.697: INFO: Got endpoints: latency-svc-jvhtn [608.06059ms]
Nov 13 09:09:34.712: INFO: Created: latency-svc-2vhc5
Nov 13 09:09:34.723: INFO: Got endpoints: latency-svc-2vhc5 [604.13415ms]
Nov 13 09:09:34.735: INFO: Created: latency-svc-dftbs
Nov 13 09:09:34.749: INFO: Got endpoints: latency-svc-dftbs [590.456811ms]
Nov 13 09:09:34.784: INFO: Created: latency-svc-blct4
Nov 13 09:09:34.821: INFO: Got endpoints: latency-svc-blct4 [566.76107ms]
Nov 13 09:09:34.822: INFO: Created: latency-svc-th8n4
Nov 13 09:09:34.826: INFO: Got endpoints: latency-svc-th8n4 [566.277465ms]
Nov 13 09:09:34.838: INFO: Created: latency-svc-4f2lq
Nov 13 09:09:34.850: INFO: Got endpoints: latency-svc-4f2lq [543.752635ms]
Nov 13 09:09:34.863: INFO: Created: latency-svc-x8dqj
Nov 13 09:09:34.885: INFO: Got endpoints: latency-svc-x8dqj [553.02073ms]
Nov 13 09:09:34.960: INFO: Created: latency-svc-grx7x
Nov 13 09:09:34.974: INFO: Got endpoints: latency-svc-grx7x [592.552232ms]
Nov 13 09:09:34.974: INFO: Created: latency-svc-gcfsg
Nov 13 09:09:34.985: INFO: Got endpoints: latency-svc-gcfsg [598.012887ms]
Nov 13 09:09:34.998: INFO: Created: latency-svc-ttc9q
Nov 13 09:09:35.010: INFO: Got endpoints: latency-svc-ttc9q [592.051427ms]
Nov 13 09:09:35.029: INFO: Created: latency-svc-jfsqd
Nov 13 09:09:35.041: INFO: Got endpoints: latency-svc-jfsqd [596.524373ms]
Nov 13 09:09:35.103: INFO: Created: latency-svc-5t8wp
Nov 13 09:09:35.106: INFO: Got endpoints: latency-svc-5t8wp [635.774573ms]
Nov 13 09:09:35.128: INFO: Created: latency-svc-nqbdr
Nov 13 09:09:35.141: INFO: Got endpoints: latency-svc-nqbdr [585.979166ms]
Nov 13 09:09:35.164: INFO: Created: latency-svc-lttx6
Nov 13 09:09:35.237: INFO: Got endpoints: latency-svc-lttx6 [632.939945ms]
Nov 13 09:09:35.238: INFO: Created: latency-svc-qbq2g
Nov 13 09:09:35.246: INFO: Got endpoints: latency-svc-qbq2g [605.562867ms]
Nov 13 09:09:35.276: INFO: Created: latency-svc-czbvk
Nov 13 09:09:35.287: INFO: Got endpoints: latency-svc-czbvk [590.252211ms]
Nov 13 09:09:35.302: INFO: Created: latency-svc-486rb
Nov 13 09:09:35.314: INFO: Got endpoints: latency-svc-486rb [590.658816ms]
Nov 13 09:09:35.326: INFO: Created: latency-svc-smnhh
Nov 13 09:09:35.364: INFO: Got endpoints: latency-svc-smnhh [615.684971ms]
Nov 13 09:09:35.365: INFO: Created: latency-svc-vxg78
Nov 13 09:09:35.382: INFO: Got endpoints: latency-svc-vxg78 [561.225117ms]
Nov 13 09:09:35.396: INFO: Created: latency-svc-4r2hn
Nov 13 09:09:35.408: INFO: Got endpoints: latency-svc-4r2hn [582.284532ms]
Nov 13 09:09:35.429: INFO: Created: latency-svc-57b2b
Nov 13 09:09:35.504: INFO: Got endpoints: latency-svc-57b2b [653.76876ms]
Nov 13 09:09:35.505: INFO: Created: latency-svc-qtr2s
Nov 13 09:09:35.509: INFO: Got endpoints: latency-svc-qtr2s [623.536453ms]
Nov 13 09:09:35.532: INFO: Created: latency-svc-7r6vh
Nov 13 09:09:35.546: INFO: Got endpoints: latency-svc-7r6vh [571.926527ms]
Nov 13 09:09:35.563: INFO: Created: latency-svc-csztd
Nov 13 09:09:35.575: INFO: Got endpoints: latency-svc-csztd [590.026312ms]
Nov 13 09:09:35.589: INFO: Created: latency-svc-jbjjv
Nov 13 09:09:35.601: INFO: Got endpoints: latency-svc-jbjjv [591.505528ms]
Nov 13 09:09:35.629: INFO: Created: latency-svc-c977j
Nov 13 09:09:35.631: INFO: Got endpoints: latency-svc-c977j [589.79951ms]
Nov 13 09:09:35.649: INFO: Created: latency-svc-wxb6w
Nov 13 09:09:35.661: INFO: Got endpoints: latency-svc-wxb6w [555.001955ms]
Nov 13 09:09:35.678: INFO: Created: latency-svc-jrknh
Nov 13 09:09:35.699: INFO: Got endpoints: latency-svc-jrknh [558.608392ms]
Nov 13 09:09:35.721: INFO: Created: latency-svc-4k454
Nov 13 09:09:35.758: INFO: Got endpoints: latency-svc-4k454 [520.662505ms]
Nov 13 09:09:35.759: INFO: Created: latency-svc-x5knp
Nov 13 09:09:35.764: INFO: Got endpoints: latency-svc-x5knp [518.382782ms]
Nov 13 09:09:35.778: INFO: Created: latency-svc-c95nt
Nov 13 09:09:35.790: INFO: Got endpoints: latency-svc-c95nt [502.685623ms]
Nov 13 09:09:35.802: INFO: Created: latency-svc-8pqf9
Nov 13 09:09:35.814: INFO: Got endpoints: latency-svc-8pqf9 [499.789892ms]
Nov 13 09:09:35.828: INFO: Created: latency-svc-mslt2
Nov 13 09:09:35.840: INFO: Got endpoints: latency-svc-mslt2 [475.756648ms]
Nov 13 09:09:35.851: INFO: Created: latency-svc-vqp9g
Nov 13 09:09:35.899: INFO: Got endpoints: latency-svc-vqp9g [516.289861ms]
Nov 13 09:09:35.900: INFO: Created: latency-svc-v6phv
Nov 13 09:09:35.912: INFO: Got endpoints: latency-svc-v6phv [503.873635ms]
Nov 13 09:09:35.924: INFO: Created: latency-svc-kxn75
Nov 13 09:09:35.937: INFO: Got endpoints: latency-svc-kxn75 [432.410607ms]
Nov 13 09:09:35.981: INFO: Created: latency-svc-jpsxx
Nov 13 09:09:35.993: INFO: Got endpoints: latency-svc-jpsxx [483.906031ms]
Nov 13 09:09:36.067: INFO: Created: latency-svc-zjpdq
Nov 13 09:09:36.070: INFO: Got endpoints: latency-svc-zjpdq [523.662637ms]
Nov 13 09:09:36.086: INFO: Created: latency-svc-p9248
Nov 13 09:09:36.099: INFO: Got endpoints: latency-svc-p9248 [523.642537ms]
Nov 13 09:09:36.112: INFO: Created: latency-svc-glqvz
Nov 13 09:09:36.124: INFO: Got endpoints: latency-svc-glqvz [522.98593ms]
Nov 13 09:09:36.138: INFO: Created: latency-svc-2rs5b
Nov 13 09:09:36.158: INFO: Got endpoints: latency-svc-2rs5b [527.379076ms]
Nov 13 09:09:36.196: INFO: Created: latency-svc-6svrl
Nov 13 09:09:36.198: INFO: Got endpoints: latency-svc-6svrl [536.983573ms]
Nov 13 09:09:36.214: INFO: Created: latency-svc-schkc
Nov 13 09:09:36.240: INFO: Created: latency-svc-5wqg4
Nov 13 09:09:36.251: INFO: Got endpoints: latency-svc-schkc [551.904826ms]
Nov 13 09:09:36.264: INFO: Created: latency-svc-7zfnv
Nov 13 09:09:36.288: INFO: Created: latency-svc-fn8bn
Nov 13 09:09:36.322: INFO: Got endpoints: latency-svc-5wqg4 [564.449955ms]
Nov 13 09:09:36.324: INFO: Created: latency-svc-bgkht
Nov 13 09:09:36.342: INFO: Created: latency-svc-w4lgg
Nov 13 09:09:36.342: INFO: Got endpoints: latency-svc-7zfnv [578.036993ms]
Nov 13 09:09:36.369: INFO: Created: latency-svc-lvtdh
Nov 13 09:09:36.404: INFO: Created: latency-svc-kqzjn
Nov 13 09:09:36.404: INFO: Got endpoints: latency-svc-fn8bn [613.528256ms]
Nov 13 09:09:36.467: INFO: Got endpoints: latency-svc-bgkht [653.336862ms]
Nov 13 09:09:36.467: INFO: Created: latency-svc-tgv9r
Nov 13 09:09:36.508: INFO: Created: latency-svc-nxhj5
Nov 13 09:09:36.508: INFO: Got endpoints: latency-svc-w4lgg [668.168113ms]
Nov 13 09:09:36.533: INFO: Created: latency-svc-2p4kh
Nov 13 09:09:36.546: INFO: Got endpoints: latency-svc-lvtdh [647.347301ms]
Nov 13 09:09:36.593: INFO: Created: latency-svc-2nqtn
Nov 13 09:09:36.602: INFO: Got endpoints: latency-svc-kqzjn [690.013437ms]
Nov 13 09:09:36.620: INFO: Created: latency-svc-dqhtb
Nov 13 09:09:36.644: INFO: Got endpoints: latency-svc-tgv9r [707.125412ms]
Nov 13 09:09:36.692: INFO: Got endpoints: latency-svc-nxhj5 [699.157831ms]
Nov 13 09:09:36.693: INFO: Created: latency-svc-bghj2
Nov 13 09:09:36.745: INFO: Created: latency-svc-2j6wj
Nov 13 09:09:36.745: INFO: Got endpoints: latency-svc-2p4kh [675.897194ms]
Nov 13 09:09:36.769: INFO: Created: latency-svc-wdnrm
Nov 13 09:09:36.795: INFO: Got endpoints: latency-svc-2nqtn [695.848998ms]
Nov 13 09:09:36.795: INFO: Created: latency-svc-9nzxz
Nov 13 09:09:36.820: INFO: Created: latency-svc-bhbjh
Nov 13 09:09:36.856: INFO: Got endpoints: latency-svc-dqhtb [731.330659ms]
Nov 13 09:09:36.856: INFO: Created: latency-svc-f5wtr
Nov 13 09:09:36.871: INFO: Created: latency-svc-hv8ct
Nov 13 09:09:36.896: INFO: Created: latency-svc-bjc6w
Nov 13 09:09:36.897: INFO: Got endpoints: latency-svc-bghj2 [738.439332ms]
Nov 13 09:09:36.923: INFO: Created: latency-svc-jwc99
Nov 13 09:09:36.948: INFO: Created: latency-svc-v8248
Nov 13 09:09:36.948: INFO: Got endpoints: latency-svc-2j6wj [749.714947ms]
Nov 13 09:09:36.985: INFO: Created: latency-svc-wsx2m
Nov 13 09:09:37.002: INFO: Created: latency-svc-75h85
Nov 13 09:09:37.002: INFO: Got endpoints: latency-svc-wdnrm [750.936359ms]
Nov 13 09:09:37.025: INFO: Created: latency-svc-5flpt
Nov 13 09:09:37.049: INFO: Created: latency-svc-kbxpx
Nov 13 09:09:37.143: INFO: Got endpoints: latency-svc-9nzxz [820.516471ms]
Nov 13 09:09:37.144: INFO: Created: latency-svc-xd6fh
Nov 13 09:09:37.150: INFO: Got endpoints: latency-svc-f5wtr [746.060711ms]
Nov 13 09:09:37.150: INFO: Got endpoints: latency-svc-bhbjh [807.72814ms]
Nov 13 09:09:37.197: INFO: Got endpoints: latency-svc-hv8ct [729.867347ms]
Nov 13 09:09:37.197: INFO: Created: latency-svc-gj45m
Nov 13 09:09:37.260: INFO: Created: latency-svc-xt954
Nov 13 09:09:37.260: INFO: Got endpoints: latency-svc-bjc6w [751.234665ms]
Nov 13 09:09:37.277: INFO: Created: latency-svc-xwgqg
Nov 13 09:09:37.302: INFO: Got endpoints: latency-svc-jwc99 [755.415008ms]
Nov 13 09:09:37.302: INFO: Created: latency-svc-dshlr
Nov 13 09:09:37.326: INFO: Created: latency-svc-lcr5z
Nov 13 09:09:37.352: INFO: Got endpoints: latency-svc-v8248 [749.590349ms]
Nov 13 09:09:37.352: INFO: Created: latency-svc-fzfq7
Nov 13 09:09:37.388: INFO: Created: latency-svc-5ptvm
Nov 13 09:09:37.393: INFO: Got endpoints: latency-svc-wsx2m [748.922443ms]
Nov 13 09:09:37.405: INFO: Created: latency-svc-9qtsx
Nov 13 09:09:37.445: INFO: Created: latency-svc-9t2zf
Nov 13 09:09:37.445: INFO: Got endpoints: latency-svc-75h85 [753.035685ms]
Nov 13 09:09:37.523: INFO: Got endpoints: latency-svc-5flpt [773.495495ms]
Nov 13 09:09:37.524: INFO: Created: latency-svc-7qn9x
Nov 13 09:09:37.539: INFO: Created: latency-svc-frpv8
Nov 13 09:09:37.558: INFO: Got endpoints: latency-svc-kbxpx [762.947788ms]
Nov 13 09:09:37.579: INFO: Created: latency-svc-ccbkk
Nov 13 09:09:37.590: INFO: Got endpoints: latency-svc-xd6fh [734.468297ms]
Nov 13 09:09:37.603: INFO: Created: latency-svc-x7w4j
Nov 13 09:09:37.667: INFO: Got endpoints: latency-svc-gj45m [770.036361ms]
Nov 13 09:09:37.667: INFO: Created: latency-svc-htmbh
Nov 13 09:09:37.685: INFO: Created: latency-svc-9t94s
Nov 13 09:09:37.700: INFO: Got endpoints: latency-svc-xt954 [752.776086ms]
Nov 13 09:09:37.715: INFO: Created: latency-svc-kswgp
Nov 13 09:09:37.744: INFO: Got endpoints: latency-svc-xwgqg [741.862574ms]
Nov 13 09:09:37.745: INFO: Created: latency-svc-7j2tk
Nov 13 09:09:37.827: INFO: Created: latency-svc-hqrzg
Nov 13 09:09:37.828: INFO: Got endpoints: latency-svc-dshlr [684.494089ms]
Nov 13 09:09:37.876: INFO: Got endpoints: latency-svc-lcr5z [726.640219ms]
Nov 13 09:09:37.876: INFO: Created: latency-svc-x49x4
Nov 13 09:09:37.890: INFO: Got endpoints: latency-svc-fzfq7 [739.743653ms]
Nov 13 09:09:37.912: INFO: Created: latency-svc-kf8wx
Nov 13 09:09:37.951: INFO: Created: latency-svc-qnqr2
Nov 13 09:09:37.952: INFO: Got endpoints: latency-svc-5ptvm [754.385803ms]
Nov 13 09:09:37.974: INFO: Created: latency-svc-76blw
Nov 13 09:09:37.990: INFO: Got endpoints: latency-svc-9qtsx [730.173455ms]
Nov 13 09:09:38.021: INFO: Created: latency-svc-7qt24
Nov 13 09:09:38.040: INFO: Got endpoints: latency-svc-9t2zf [738.694843ms]
Nov 13 09:09:38.110: INFO: Got endpoints: latency-svc-7qn9x [758.169742ms]
Nov 13 09:09:38.150: INFO: Got endpoints: latency-svc-frpv8 [757.117332ms]
Nov 13 09:09:38.150: INFO: Created: latency-svc-9fnmw
Nov 13 09:09:38.189: INFO: Created: latency-svc-c924h
Nov 13 09:09:38.201: INFO: Got endpoints: latency-svc-ccbkk [751.241372ms]
Nov 13 09:09:38.278: INFO: Got endpoints: latency-svc-x7w4j [755.041312ms]
Nov 13 09:09:38.279: INFO: Created: latency-svc-s92pr
Nov 13 09:09:38.293: INFO: Created: latency-svc-nq9c7
Nov 13 09:09:38.293: INFO: Got endpoints: latency-svc-htmbh [735.097508ms]
Nov 13 09:09:38.317: INFO: Created: latency-svc-skcrs
Nov 13 09:09:38.341: INFO: Got endpoints: latency-svc-9t94s [750.816169ms]
Nov 13 09:09:38.341: INFO: Created: latency-svc-cfjwt
Nov 13 09:09:38.368: INFO: Created: latency-svc-w9fv5
Nov 13 09:09:38.404: INFO: Got endpoints: latency-svc-kswgp [737.283732ms]
Nov 13 09:09:38.440: INFO: Created: latency-svc-c62dv
Nov 13 09:09:38.440: INFO: Got endpoints: latency-svc-7j2tk [739.855459ms]
Nov 13 09:09:38.468: INFO: Created: latency-svc-mlvnf
Nov 13 09:09:38.490: INFO: Got endpoints: latency-svc-hqrzg [745.619217ms]
Nov 13 09:09:38.578: INFO: Created: latency-svc-xflwk
Nov 13 09:09:38.579: INFO: Got endpoints: latency-svc-x49x4 [750.925273ms]
Nov 13 09:09:38.596: INFO: Got endpoints: latency-svc-kf8wx [719.139048ms]
Nov 13 09:09:38.662: INFO: Got endpoints: latency-svc-qnqr2 [771.974088ms]
Nov 13 09:09:38.666: INFO: Created: latency-svc-7zxnt
Nov 13 09:09:38.730: INFO: Got endpoints: latency-svc-76blw [778.542656ms]
Nov 13 09:09:38.734: INFO: Created: latency-svc-hztjh
Nov 13 09:09:38.748: INFO: Got endpoints: latency-svc-7qt24 [757.624843ms]
Nov 13 09:09:38.748: INFO: Created: latency-svc-8hxlv
Nov 13 09:09:38.785: INFO: Created: latency-svc-ssbt7
Nov 13 09:09:38.799: INFO: Got endpoints: latency-svc-9fnmw [758.637353ms]
Nov 13 09:09:38.815: INFO: Created: latency-svc-cz8hx
Nov 13 09:09:38.860: INFO: Got endpoints: latency-svc-c924h [749.556661ms]
Nov 13 09:09:38.890: INFO: Got endpoints: latency-svc-s92pr [739.570159ms]
Nov 13 09:09:38.940: INFO: Got endpoints: latency-svc-nq9c7 [738.76615ms]
Nov 13 09:09:38.990: INFO: Got endpoints: latency-svc-skcrs [712.001877ms]
Nov 13 09:09:39.040: INFO: Got endpoints: latency-svc-cfjwt [746.809432ms]
Nov 13 09:09:39.090: INFO: Got endpoints: latency-svc-w9fv5 [748.791053ms]
Nov 13 09:09:39.140: INFO: Got endpoints: latency-svc-c62dv [735.629119ms]
Nov 13 09:09:39.191: INFO: Got endpoints: latency-svc-mlvnf [750.751273ms]
Nov 13 09:09:39.240: INFO: Got endpoints: latency-svc-xflwk [750.109267ms]
Nov 13 09:09:39.290: INFO: Got endpoints: latency-svc-7zxnt [711.219269ms]
Nov 13 09:09:39.340: INFO: Got endpoints: latency-svc-hztjh [744.56211ms]
Nov 13 09:09:39.390: INFO: Got endpoints: latency-svc-8hxlv [724.087402ms]
Nov 13 09:09:39.440: INFO: Got endpoints: latency-svc-ssbt7 [709.801156ms]
Nov 13 09:09:39.490: INFO: Got endpoints: latency-svc-cz8hx [742.183687ms]
Nov 13 09:09:39.491: INFO: Latencies: [57.053461ms 60.735497ms 84.049726ms 121.135691ms 199.35306ms 256.762325ms 295.196503ms 369.799837ms 381.39685ms 415.89789ms 432.410607ms 449.030415ms 467.350992ms 468.892407ms 475.130471ms 475.756648ms 483.906031ms 493.355151ms 494.01656ms 498.644407ms 499.789892ms 499.790218ms 500.590227ms 502.685623ms 503.150254ms 503.873635ms 505.362774ms 506.006076ms 506.589086ms 508.98641ms 509.137812ms 515.448474ms 515.85828ms 516.289861ms 518.382782ms 520.662505ms 522.98593ms 523.642537ms 523.662637ms 524.476566ms 527.379076ms 533.593093ms 536.715989ms 536.983573ms 540.176415ms 540.688964ms 543.752635ms 547.20288ms 551.904826ms 553.02073ms 555.001955ms 558.608392ms 559.024503ms 561.225117ms 562.748085ms 564.449955ms 565.46134ms 566.277465ms 566.76107ms 567.844685ms 571.217418ms 571.926527ms 573.822175ms 574.29132ms 576.912499ms 577.187282ms 577.567737ms 578.036993ms 582.284532ms 582.284826ms 585.979166ms 586.078249ms 586.748249ms 589.79951ms 590.026312ms 590.252211ms 590.456811ms 590.658816ms 591.505528ms 592.051427ms 592.552232ms 593.686773ms 594.390714ms 595.387341ms 595.858104ms 595.945352ms 596.524373ms 596.619207ms 598.012887ms 599.308191ms 602.397524ms 604.13415ms 605.562867ms 607.131371ms 608.06059ms 608.614995ms 608.816411ms 612.833528ms 613.331632ms 613.506918ms 613.528256ms 613.968101ms 615.530434ms 615.684971ms 621.918217ms 622.234024ms 623.536453ms 623.992137ms 625.23182ms 626.664635ms 627.674074ms 627.784175ms 630.268181ms 631.070306ms 632.939945ms 635.774573ms 638.648887ms 639.852659ms 645.007153ms 646.251757ms 646.607766ms 647.347301ms 653.336862ms 653.76876ms 655.301449ms 658.544483ms 668.168113ms 669.563207ms 675.897194ms 681.42343ms 684.352937ms 684.494089ms 686.482052ms 690.013437ms 691.778409ms 693.886831ms 695.848998ms 699.157831ms 701.0168ms 707.125412ms 709.801156ms 711.219269ms 712.001877ms 717.583161ms 719.139048ms 723.420317ms 723.710517ms 724.087402ms 726.640219ms 728.50867ms 729.867347ms 730.173455ms 731.330659ms 734.468297ms 735.097508ms 735.629119ms 737.283732ms 738.439332ms 738.694843ms 738.76615ms 739.273978ms 739.570159ms 739.743653ms 739.855459ms 741.862574ms 742.183687ms 744.56211ms 745.619217ms 746.060711ms 746.809432ms 748.791053ms 748.922443ms 749.556661ms 749.590349ms 749.714947ms 750.109267ms 750.751273ms 750.816169ms 750.925273ms 750.936359ms 751.234665ms 751.241372ms 752.776086ms 753.035685ms 754.385803ms 755.041312ms 755.415008ms 757.117332ms 757.624843ms 758.169742ms 758.637353ms 761.067092ms 762.947788ms 763.653414ms 770.036361ms 771.974088ms 773.495495ms 778.542656ms 807.72814ms 820.516471ms]
Nov 13 09:09:39.491: INFO: 50 %ile: 613.528256ms
Nov 13 09:09:39.491: INFO: 90 %ile: 751.234665ms
Nov 13 09:09:39.491: INFO: 99 %ile: 807.72814ms
Nov 13 09:09:39.491: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:09:39.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-tb59k" for this suite.
Nov 13 09:10:01.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:10:01.688: INFO: namespace: e2e-tests-svc-latency-tb59k, resource: bindings, ignored listing per whitelist
Nov 13 09:10:01.693: INFO: namespace e2e-tests-svc-latency-tb59k deletion completed in 22.189739071s

• [SLOW TEST:35.196 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:10:01.693: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ndcc4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Nov 13 09:10:01.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:02.245: INFO: stderr: ""
Nov 13 09:10:02.245: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 09:10:02.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:02.349: INFO: stderr: ""
Nov 13 09:10:02.349: INFO: stdout: "update-demo-nautilus-4h6nd update-demo-nautilus-kztzf "
Nov 13 09:10:02.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-4h6nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:02.431: INFO: stderr: ""
Nov 13 09:10:02.431: INFO: stdout: ""
Nov 13 09:10:02.431: INFO: update-demo-nautilus-4h6nd is created but not running
Nov 13 09:10:07.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:07.547: INFO: stderr: ""
Nov 13 09:10:07.547: INFO: stdout: "update-demo-nautilus-4h6nd update-demo-nautilus-kztzf "
Nov 13 09:10:07.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-4h6nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:07.640: INFO: stderr: ""
Nov 13 09:10:07.640: INFO: stdout: "true"
Nov 13 09:10:07.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-4h6nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:07.725: INFO: stderr: ""
Nov 13 09:10:07.725: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:10:07.725: INFO: validating pod update-demo-nautilus-4h6nd
Nov 13 09:10:07.815: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:10:07.815: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:10:07.815: INFO: update-demo-nautilus-4h6nd is verified up and running
Nov 13 09:10:07.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-kztzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:07.907: INFO: stderr: ""
Nov 13 09:10:07.907: INFO: stdout: "true"
Nov 13 09:10:07.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-kztzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:08.001: INFO: stderr: ""
Nov 13 09:10:08.001: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:10:08.001: INFO: validating pod update-demo-nautilus-kztzf
Nov 13 09:10:08.089: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:10:08.089: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:10:08.089: INFO: update-demo-nautilus-kztzf is verified up and running
STEP: scaling down the replication controller
Nov 13 09:10:08.090: INFO: scanned /root for discovery docs: <nil>
Nov 13 09:10:08.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:09.261: INFO: stderr: ""
Nov 13 09:10:09.261: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 09:10:09.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:09.402: INFO: stderr: ""
Nov 13 09:10:09.402: INFO: stdout: "update-demo-nautilus-4h6nd update-demo-nautilus-kztzf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 13 09:10:14.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:14.496: INFO: stderr: ""
Nov 13 09:10:14.496: INFO: stdout: "update-demo-nautilus-4h6nd update-demo-nautilus-kztzf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 13 09:10:19.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:19.681: INFO: stderr: ""
Nov 13 09:10:19.681: INFO: stdout: "update-demo-nautilus-4h6nd update-demo-nautilus-kztzf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 13 09:10:24.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:24.775: INFO: stderr: ""
Nov 13 09:10:24.775: INFO: stdout: "update-demo-nautilus-kztzf "
Nov 13 09:10:24.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-kztzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:24.866: INFO: stderr: ""
Nov 13 09:10:24.866: INFO: stdout: "true"
Nov 13 09:10:24.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-kztzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:24.958: INFO: stderr: ""
Nov 13 09:10:24.958: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:10:24.958: INFO: validating pod update-demo-nautilus-kztzf
Nov 13 09:10:24.964: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:10:24.964: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:10:24.964: INFO: update-demo-nautilus-kztzf is verified up and running
STEP: scaling up the replication controller
Nov 13 09:10:24.965: INFO: scanned /root for discovery docs: <nil>
Nov 13 09:10:24.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:26.097: INFO: stderr: ""
Nov 13 09:10:26.097: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 09:10:26.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:26.197: INFO: stderr: ""
Nov 13 09:10:26.197: INFO: stdout: "update-demo-nautilus-kztzf update-demo-nautilus-qgsbv "
Nov 13 09:10:26.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-kztzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:26.288: INFO: stderr: ""
Nov 13 09:10:26.288: INFO: stdout: "true"
Nov 13 09:10:26.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-kztzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:26.380: INFO: stderr: ""
Nov 13 09:10:26.380: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:10:26.380: INFO: validating pod update-demo-nautilus-kztzf
Nov 13 09:10:26.386: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:10:26.386: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:10:26.386: INFO: update-demo-nautilus-kztzf is verified up and running
Nov 13 09:10:26.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-qgsbv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:26.508: INFO: stderr: ""
Nov 13 09:10:26.508: INFO: stdout: ""
Nov 13 09:10:26.508: INFO: update-demo-nautilus-qgsbv is created but not running
Nov 13 09:10:31.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:31.605: INFO: stderr: ""
Nov 13 09:10:31.605: INFO: stdout: "update-demo-nautilus-kztzf update-demo-nautilus-qgsbv "
Nov 13 09:10:31.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-kztzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:31.699: INFO: stderr: ""
Nov 13 09:10:31.700: INFO: stdout: "true"
Nov 13 09:10:31.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-kztzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:31.850: INFO: stderr: ""
Nov 13 09:10:31.850: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:10:31.850: INFO: validating pod update-demo-nautilus-kztzf
Nov 13 09:10:31.856: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:10:31.856: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:10:31.856: INFO: update-demo-nautilus-kztzf is verified up and running
Nov 13 09:10:31.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-qgsbv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:31.960: INFO: stderr: ""
Nov 13 09:10:31.960: INFO: stdout: "true"
Nov 13 09:10:31.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-qgsbv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:32.046: INFO: stderr: ""
Nov 13 09:10:32.046: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:10:32.046: INFO: validating pod update-demo-nautilus-qgsbv
Nov 13 09:10:32.181: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:10:32.181: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:10:32.181: INFO: update-demo-nautilus-qgsbv is verified up and running
STEP: using delete to clean up resources
Nov 13 09:10:32.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:32.353: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:10:32.353: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 13 09:10:32.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-ndcc4'
Nov 13 09:10:32.493: INFO: stderr: "No resources found.\n"
Nov 13 09:10:32.493: INFO: stdout: ""
Nov 13 09:10:32.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -l name=update-demo --namespace=e2e-tests-kubectl-ndcc4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 13 09:10:32.588: INFO: stderr: ""
Nov 13 09:10:32.588: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:10:32.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ndcc4" for this suite.
Nov 13 09:10:54.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:10:54.659: INFO: namespace: e2e-tests-kubectl-ndcc4, resource: bindings, ignored listing per whitelist
Nov 13 09:10:54.802: INFO: namespace e2e-tests-kubectl-ndcc4 deletion completed in 22.210990046s

• [SLOW TEST:53.109 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:10:54.802: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-57xx4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Nov 13 09:10:55.015: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov 13 09:10:55.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:10:57.195: INFO: stderr: ""
Nov 13 09:10:57.195: INFO: stdout: "service/redis-slave created\n"
Nov 13 09:10:57.195: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov 13 09:10:57.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:10:58.204: INFO: stderr: ""
Nov 13 09:10:58.204: INFO: stdout: "service/redis-master created\n"
Nov 13 09:10:58.204: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 13 09:10:58.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:10:58.499: INFO: stderr: ""
Nov 13 09:10:58.499: INFO: stdout: "service/frontend created\n"
Nov 13 09:10:58.499: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov 13 09:10:58.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:10:58.862: INFO: stderr: ""
Nov 13 09:10:58.862: INFO: stdout: "deployment.extensions/frontend created\n"
Nov 13 09:10:58.863: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 13 09:10:58.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:10:59.282: INFO: stderr: ""
Nov 13 09:10:59.282: INFO: stdout: "deployment.extensions/redis-master created\n"
Nov 13 09:10:59.282: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov 13 09:10:59.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:11:00.312: INFO: stderr: ""
Nov 13 09:11:00.312: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Nov 13 09:11:00.312: INFO: Waiting for all frontend pods to be Running.
Nov 13 09:11:40.507: INFO: Waiting for frontend to serve content.
Nov 13 09:11:41.290: INFO: Trying to add a new entry to the guestbook.
Nov 13 09:11:41.343: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov 13 09:11:41.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:11:41.551: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:11:41.551: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 09:11:41.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:11:41.727: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:11:41.727: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 09:11:41.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:11:41.984: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:11:41.984: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 09:11:41.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:11:42.075: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:11:42.075: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 09:11:42.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:11:42.363: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:11:42.363: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 09:11:42.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57xx4'
Nov 13 09:11:42.462: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:11:42.463: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:11:42.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-57xx4" for this suite.
Nov 13 09:12:22.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:12:22.499: INFO: namespace: e2e-tests-kubectl-57xx4, resource: bindings, ignored listing per whitelist
Nov 13 09:12:22.622: INFO: namespace e2e-tests-kubectl-57xx4 deletion completed in 40.15276173s

• [SLOW TEST:87.820 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:12:22.622: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-l9zbf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov 13 09:12:27.447: INFO: Successfully updated pod "labelsupdate3aee8d90-e724-11e8-baa5-625675597e81"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:12:31.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l9zbf" for this suite.
Nov 13 09:12:53.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:12:53.792: INFO: namespace: e2e-tests-downward-api-l9zbf, resource: bindings, ignored listing per whitelist
Nov 13 09:12:53.842: INFO: namespace e2e-tests-downward-api-l9zbf deletion completed in 22.198734391s

• [SLOW TEST:31.220 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:12:53.842: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-tfjgm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-tfjgm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 13 09:12:54.055: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 13 09:13:24.427: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.1.31:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-tfjgm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:13:24.427: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:13:24.861: INFO: Found all expected endpoints: [netserver-0]
Nov 13 09:13:24.864: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.0.20:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-tfjgm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:13:24.865: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:13:25.397: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:13:25.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-tfjgm" for this suite.
Nov 13 09:13:47.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:13:47.546: INFO: namespace: e2e-tests-pod-network-test-tfjgm, resource: bindings, ignored listing per whitelist
Nov 13 09:13:47.668: INFO: namespace e2e-tests-pod-network-test-tfjgm deletion completed in 22.267000464s

• [SLOW TEST:53.826 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:13:47.668: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8l99t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Nov 13 09:13:47.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 cluster-info'
Nov 13 09:13:48.014: INFO: stderr: ""
Nov 13 09:13:48.014: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:13:48.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8l99t" for this suite.
Nov 13 09:13:54.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:13:54.049: INFO: namespace: e2e-tests-kubectl-8l99t, resource: bindings, ignored listing per whitelist
Nov 13 09:13:54.177: INFO: namespace e2e-tests-kubectl-8l99t deletion completed in 6.160131342s

• [SLOW TEST:6.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:13:54.178: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dp7qb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov 13 09:14:00.946: INFO: Successfully updated pod "annotationupdate7183d2cd-e724-11e8-baa5-625675597e81"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:14:02.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dp7qb" for this suite.
Nov 13 09:14:24.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:14:25.112: INFO: namespace: e2e-tests-projected-dp7qb, resource: bindings, ignored listing per whitelist
Nov 13 09:14:25.176: INFO: namespace e2e-tests-projected-dp7qb deletion completed in 22.194488668s

• [SLOW TEST:30.999 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:14:25.177: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-mprgn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 09:14:25.432: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 13 09:14:25.440: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 13 09:14:30.444: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 13 09:14:30.444: INFO: Creating deployment "test-rolling-update-deployment"
Nov 13 09:14:30.447: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 13 09:14:30.453: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 13 09:14:32.459: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 13 09:14:32.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677697270, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677697270, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677697270, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677697270, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 09:14:34.464: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677697270, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677697270, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677697270, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677697270, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 09:14:36.651: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 13 09:14:36.662: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-mprgn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mprgn/deployments/test-rolling-update-deployment,UID:86fd7da8-e724-11e8-90ec-1a79c3ab02d1,ResourceVersion:6602,Generation:1,CreationTimestamp:2018-11-13 09:14:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-13 09:14:30 +0000 UTC 2018-11-13 09:14:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-13 09:14:34 +0000 UTC 2018-11-13 09:14:30 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov 13 09:14:36.665: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-mprgn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mprgn/replicasets/test-rolling-update-deployment-65b7695dcf,UID:86ff69d9-e724-11e8-90ec-1a79c3ab02d1,ResourceVersion:6593,Generation:1,CreationTimestamp:2018-11-13 09:14:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 86fd7da8-e724-11e8-90ec-1a79c3ab02d1 0xc421d85237 0xc421d85238}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 13 09:14:36.665: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 13 09:14:36.665: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-mprgn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mprgn/replicasets/test-rolling-update-controller,UID:8400c902-e724-11e8-90ec-1a79c3ab02d1,ResourceVersion:6601,Generation:2,CreationTimestamp:2018-11-13 09:14:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 86fd7da8-e724-11e8-90ec-1a79c3ab02d1 0xc421d850e7 0xc421d850e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 13 09:14:36.668: INFO: Pod "test-rolling-update-deployment-65b7695dcf-kzljx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-kzljx,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-mprgn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mprgn/pods/test-rolling-update-deployment-65b7695dcf-kzljx,UID:8701a7a6-e724-11e8-90ec-1a79c3ab02d1,ResourceVersion:6592,Generation:0,CreationTimestamp:2018-11-13 09:14:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.35/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 86ff69d9-e724-11e8-90ec-1a79c3ab02d1 0xc422d95667 0xc422d95668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qm69n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qm69n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qm69n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422d956d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422d956f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:14:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:14:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:14:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:14:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.1.35,StartTime:2018-11-13 09:14:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-13 09:14:33 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://677e56fcfda2cb3684e567e21c23edd4f731fefff4d7862f22dd96d2c43f98d2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:14:36.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-mprgn" for this suite.
Nov 13 09:14:44.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:14:44.840: INFO: namespace: e2e-tests-deployment-mprgn, resource: bindings, ignored listing per whitelist
Nov 13 09:14:44.867: INFO: namespace e2e-tests-deployment-mprgn deletion completed in 8.188995612s

• [SLOW TEST:19.691 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:14:44.867: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-8g67w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-8fbe97e3-e724-11e8-baa5-625675597e81
Nov 13 09:14:45.143: INFO: Pod name my-hostname-basic-8fbe97e3-e724-11e8-baa5-625675597e81: Found 0 pods out of 1
Nov 13 09:14:50.146: INFO: Pod name my-hostname-basic-8fbe97e3-e724-11e8-baa5-625675597e81: Found 1 pods out of 1
Nov 13 09:14:50.146: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8fbe97e3-e724-11e8-baa5-625675597e81" are running
Nov 13 09:14:50.149: INFO: Pod "my-hostname-basic-8fbe97e3-e724-11e8-baa5-625675597e81-xg2fh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-13 09:14:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-13 09:14:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-13 09:14:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-13 09:14:45 +0000 UTC Reason: Message:}])
Nov 13 09:14:50.149: INFO: Trying to dial the pod
Nov 13 09:14:55.246: INFO: Controller my-hostname-basic-8fbe97e3-e724-11e8-baa5-625675597e81: Got expected result from replica 1 [my-hostname-basic-8fbe97e3-e724-11e8-baa5-625675597e81-xg2fh]: "my-hostname-basic-8fbe97e3-e724-11e8-baa5-625675597e81-xg2fh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:14:55.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8g67w" for this suite.
Nov 13 09:15:01.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:15:01.424: INFO: namespace: e2e-tests-replication-controller-8g67w, resource: bindings, ignored listing per whitelist
Nov 13 09:15:01.468: INFO: namespace e2e-tests-replication-controller-8g67w deletion completed in 6.219672331s

• [SLOW TEST:16.601 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:15:01.468: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7mqh9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 13 09:15:01.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7mqh9'
Nov 13 09:15:01.832: INFO: stderr: ""
Nov 13 09:15:01.832: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Nov 13 09:15:01.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7mqh9'
Nov 13 09:15:10.106: INFO: stderr: ""
Nov 13 09:15:10.106: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:15:10.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7mqh9" for this suite.
Nov 13 09:15:16.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:15:16.260: INFO: namespace: e2e-tests-kubectl-7mqh9, resource: bindings, ignored listing per whitelist
Nov 13 09:15:16.285: INFO: namespace e2e-tests-kubectl-7mqh9 deletion completed in 6.175133851s

• [SLOW TEST:14.817 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:15:16.285: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-mzlhs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 13 09:15:16.578: INFO: Number of nodes with available pods: 0
Nov 13 09:15:16.578: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:15:17.689: INFO: Number of nodes with available pods: 0
Nov 13 09:15:17.689: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:15:18.586: INFO: Number of nodes with available pods: 0
Nov 13 09:15:18.586: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:15:19.654: INFO: Number of nodes with available pods: 0
Nov 13 09:15:19.654: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:15:20.584: INFO: Number of nodes with available pods: 2
Nov 13 09:15:20.584: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov 13 09:15:20.613: INFO: Number of nodes with available pods: 1
Nov 13 09:15:20.613: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:15:21.647: INFO: Number of nodes with available pods: 1
Nov 13 09:15:21.647: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:15:22.619: INFO: Number of nodes with available pods: 1
Nov 13 09:15:22.619: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:15:23.619: INFO: Number of nodes with available pods: 1
Nov 13 09:15:23.619: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:15:24.646: INFO: Number of nodes with available pods: 1
Nov 13 09:15:24.646: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:15:25.619: INFO: Number of nodes with available pods: 2
Nov 13 09:15:25.619: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-mzlhs, will wait for the garbage collector to delete the pods
Nov 13 09:15:25.681: INFO: Deleting {extensions DaemonSet} daemon-set took: 4.991543ms
Nov 13 09:15:25.782: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.902654ms
Nov 13 09:16:10.185: INFO: Number of nodes with available pods: 0
Nov 13 09:16:10.185: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 09:16:10.188: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mzlhs/daemonsets","resourceVersion":"6882"},"items":null}

Nov 13 09:16:10.190: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mzlhs/pods","resourceVersion":"6882"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:16:10.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mzlhs" for this suite.
Nov 13 09:16:16.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:16:16.365: INFO: namespace: e2e-tests-daemonsets-mzlhs, resource: bindings, ignored listing per whitelist
Nov 13 09:16:16.399: INFO: namespace e2e-tests-daemonsets-mzlhs deletion completed in 6.185338999s

• [SLOW TEST:60.114 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:16:16.399: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rtswq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c64ea04c-e724-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 09:16:16.677: INFO: Waiting up to 5m0s for pod "pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-rtswq" to be "success or failure"
Nov 13 09:16:16.693: INFO: Pod "pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 15.693435ms
Nov 13 09:16:18.696: INFO: Pod "pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019120313s
Nov 13 09:16:20.700: INFO: Pod "pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022699934s
Nov 13 09:16:22.703: INFO: Pod "pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025596568s
STEP: Saw pod success
Nov 13 09:16:22.703: INFO: Pod "pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:16:22.705: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81 container secret-env-test: <nil>
STEP: delete the pod
Nov 13 09:16:22.725: INFO: Waiting for pod pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81 to disappear
Nov 13 09:16:22.729: INFO: Pod pod-secrets-c64f0d3f-e724-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:16:22.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rtswq" for this suite.
Nov 13 09:16:28.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:16:28.774: INFO: namespace: e2e-tests-secrets-rtswq, resource: bindings, ignored listing per whitelist
Nov 13 09:16:28.954: INFO: namespace e2e-tests-secrets-rtswq deletion completed in 6.213006135s

• [SLOW TEST:12.555 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:16:28.954: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-sw8pk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-sw8pk
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-sw8pk
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-sw8pk
Nov 13 09:16:29.244: INFO: Found 0 stateful pods, waiting for 1
Nov 13 09:16:39.248: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov 13 09:16:39.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 09:16:39.768: INFO: stderr: ""
Nov 13 09:16:39.768: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 09:16:39.768: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 09:16:39.772: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 13 09:16:49.776: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 09:16:49.776: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 09:16:49.789: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999998s
Nov 13 09:16:50.799: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994200563s
Nov 13 09:16:51.803: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984256278s
Nov 13 09:16:52.819: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.980422532s
Nov 13 09:16:53.823: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.964209467s
Nov 13 09:16:54.827: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960483497s
Nov 13 09:16:55.831: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.95648691s
Nov 13 09:16:56.834: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.952734514s
Nov 13 09:16:57.837: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.949436608s
Nov 13 09:16:58.840: INFO: Verifying statefulset ss doesn't scale past 1 for another 946.382492ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-sw8pk
Nov 13 09:16:59.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:17:00.293: INFO: stderr: ""
Nov 13 09:17:00.294: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 13 09:17:00.294: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 13 09:17:00.297: INFO: Found 1 stateful pods, waiting for 3
Nov 13 09:17:10.356: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:17:10.356: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:17:10.356: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 13 09:17:20.301: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:17:20.301: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 09:17:20.301: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov 13 09:17:20.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 09:17:20.817: INFO: stderr: ""
Nov 13 09:17:20.817: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 09:17:20.817: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 09:17:20.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 09:17:21.337: INFO: stderr: ""
Nov 13 09:17:21.337: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 09:17:21.337: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 09:17:21.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 09:17:21.839: INFO: stderr: ""
Nov 13 09:17:21.839: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 09:17:21.839: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 09:17:21.839: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 09:17:21.842: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov 13 09:17:31.860: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 09:17:31.860: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 09:17:31.860: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 09:17:31.873: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999998s
Nov 13 09:17:32.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99123919s
Nov 13 09:17:33.881: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987431106s
Nov 13 09:17:34.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983590609s
Nov 13 09:17:35.888: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.9799165s
Nov 13 09:17:36.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976428778s
Nov 13 09:17:37.896: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972718742s
Nov 13 09:17:38.947: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968902592s
Nov 13 09:17:39.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.917147833s
Nov 13 09:17:40.965: INFO: Verifying statefulset ss doesn't scale past 3 for another 902.861169ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-sw8pk
Nov 13 09:17:41.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:17:42.432: INFO: stderr: ""
Nov 13 09:17:42.432: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 13 09:17:42.432: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 13 09:17:42.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:17:42.939: INFO: stderr: ""
Nov 13 09:17:42.939: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 13 09:17:42.939: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 13 09:17:42.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:17:44.504: INFO: rc: 1
Nov 13 09:17:44.504: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: container not running (c7f3e294a1ecbb469c19847137450287d825bcbbf5a79af35ae486903ce625e1)
 [] <nil> 0xc422dbb590 exit status 1 <nil> <nil> true [0xc420dd6240 0xc420dd6258 0xc420dd6270] [0xc420dd6240 0xc420dd6258 0xc420dd6270] [0xc420dd6250 0xc420dd6268] [0x8fd520 0x8fd520] 0xc42155c180 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (c7f3e294a1ecbb469c19847137450287d825bcbbf5a79af35ae486903ce625e1)

error:
exit status 1

Nov 13 09:17:54.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:17:54.590: INFO: rc: 1
Nov 13 09:17:54.590: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbb950 exit status 1 <nil> <nil> true [0xc420dd6278 0xc420dd6290 0xc420dd62a8] [0xc420dd6278 0xc420dd6290 0xc420dd62a8] [0xc420dd6288 0xc420dd62a0] [0x8fd520 0x8fd520] 0xc42155c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:18:04.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:18:04.671: INFO: rc: 1
Nov 13 09:18:04.672: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff3fb0 exit status 1 <nil> <nil> true [0xc420090f78 0xc420091008 0xc420091090] [0xc420090f78 0xc420091008 0xc420091090] [0xc420091000 0xc420091060] [0x8fd520 0x8fd520] 0xc421246300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:18:14.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:18:14.763: INFO: rc: 1
Nov 13 09:18:14.763: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbbd70 exit status 1 <nil> <nil> true [0xc420dd62b0 0xc420dd62c8 0xc420dd62e0] [0xc420dd62b0 0xc420dd62c8 0xc420dd62e0] [0xc420dd62c0 0xc420dd62d8] [0x8fd520 0x8fd520] 0xc42155c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:18:24.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:18:24.850: INFO: rc: 1
Nov 13 09:18:24.850: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420bce420 exit status 1 <nil> <nil> true [0xc4200910a8 0xc4200910d8 0xc420091140] [0xc4200910a8 0xc4200910d8 0xc420091140] [0xc4200910d0 0xc420091110] [0x8fd520 0x8fd520] 0xc421246420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:18:34.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:18:34.939: INFO: rc: 1
Nov 13 09:18:34.940: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420bce810 exit status 1 <nil> <nil> true [0xc420091170 0xc420091230 0xc420091270] [0xc420091170 0xc420091230 0xc420091270] [0xc4200911f8 0xc420091258] [0x8fd520 0x8fd520] 0xc421246540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:18:44.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:18:45.150: INFO: rc: 1
Nov 13 09:18:45.150: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420bcebd0 exit status 1 <nil> <nil> true [0xc420091278 0xc4200912a8 0xc420091330] [0xc420091278 0xc4200912a8 0xc420091330] [0xc4200912a0 0xc420091308] [0x8fd520 0x8fd520] 0xc421246660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:18:55.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:18:55.237: INFO: rc: 1
Nov 13 09:18:55.237: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421a86180 exit status 1 <nil> <nil> true [0xc420dd62e8 0xc420dd6300 0xc420dd6318] [0xc420dd62e8 0xc420dd6300 0xc420dd6318] [0xc420dd62f8 0xc420dd6310] [0x8fd520 0x8fd520] 0xc42155c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:19:05.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:19:05.327: INFO: rc: 1
Nov 13 09:19:05.327: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421a86630 exit status 1 <nil> <nil> true [0xc420dd6328 0xc420dd6340 0xc420dd6358] [0xc420dd6328 0xc420dd6340 0xc420dd6358] [0xc420dd6338 0xc420dd6350] [0x8fd520 0x8fd520] 0xc42155c600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:19:15.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:19:15.408: INFO: rc: 1
Nov 13 09:19:15.408: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dba3c0 exit status 1 <nil> <nil> true [0xc420090010 0xc4200900a0 0xc420090160] [0xc420090010 0xc4200900a0 0xc420090160] [0xc420090068 0xc420090158] [0x8fd520 0x8fd520] 0xc4217fcde0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:19:25.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:19:25.508: INFO: rc: 1
Nov 13 09:19:25.508: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff2390 exit status 1 <nil> <nil> true [0xc420dd6000 0xc420dd6018 0xc420dd6030] [0xc420dd6000 0xc420dd6018 0xc420dd6030] [0xc420dd6010 0xc420dd6028] [0x8fd520 0x8fd520] 0xc4206b2060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:19:35.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:19:35.597: INFO: rc: 1
Nov 13 09:19:35.597: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dba7e0 exit status 1 <nil> <nil> true [0xc420090178 0xc4200902e8 0xc4200903c8] [0xc420090178 0xc4200902e8 0xc4200903c8] [0xc420090280 0xc420090360] [0x8fd520 0x8fd520] 0xc4217fcf00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:19:45.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:19:45.686: INFO: rc: 1
Nov 13 09:19:45.686: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbafc0 exit status 1 <nil> <nil> true [0xc420090400 0xc4200904c8 0xc420090568] [0xc420090400 0xc4200904c8 0xc420090568] [0xc4200904a0 0xc420090510] [0x8fd520 0x8fd520] 0xc4217fd080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:19:55.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:19:55.778: INFO: rc: 1
Nov 13 09:19:55.778: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff2780 exit status 1 <nil> <nil> true [0xc420dd6038 0xc420dd6050 0xc420dd6068] [0xc420dd6038 0xc420dd6050 0xc420dd6068] [0xc420dd6048 0xc420dd6060] [0x8fd520 0x8fd520] 0xc4206b2180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:20:05.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:20:05.895: INFO: rc: 1
Nov 13 09:20:05.895: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff2b70 exit status 1 <nil> <nil> true [0xc420dd6070 0xc420dd6088 0xc420dd60a0] [0xc420dd6070 0xc420dd6088 0xc420dd60a0] [0xc420dd6080 0xc420dd6098] [0x8fd520 0x8fd520] 0xc4206b2300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:20:15.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:20:15.980: INFO: rc: 1
Nov 13 09:20:15.980: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbb410 exit status 1 <nil> <nil> true [0xc420090578 0xc420090630 0xc420090840] [0xc420090578 0xc420090630 0xc420090840] [0xc420090618 0xc420090738] [0x8fd520 0x8fd520] 0xc4217fd1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:20:25.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:20:26.068: INFO: rc: 1
Nov 13 09:20:26.068: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff2f60 exit status 1 <nil> <nil> true [0xc420dd60a8 0xc420dd60c0 0xc420dd60d8] [0xc420dd60a8 0xc420dd60c0 0xc420dd60d8] [0xc420dd60b8 0xc420dd60d0] [0x8fd520 0x8fd520] 0xc4206b2420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:20:36.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:20:36.185: INFO: rc: 1
Nov 13 09:20:36.185: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbb860 exit status 1 <nil> <nil> true [0xc420090878 0xc420090900 0xc420090970] [0xc420090878 0xc420090900 0xc420090970] [0xc4200908f8 0xc420090940] [0x8fd520 0x8fd520] 0xc4217fd2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:20:46.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:20:46.276: INFO: rc: 1
Nov 13 09:20:46.276: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff3350 exit status 1 <nil> <nil> true [0xc420dd60e0 0xc420dd60f8 0xc420dd6110] [0xc420dd60e0 0xc420dd60f8 0xc420dd6110] [0xc420dd60f0 0xc420dd6108] [0x8fd520 0x8fd520] 0xc4206b2540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:20:56.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:20:56.357: INFO: rc: 1
Nov 13 09:20:56.357: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff3740 exit status 1 <nil> <nil> true [0xc420dd6118 0xc420dd6130 0xc420dd6148] [0xc420dd6118 0xc420dd6130 0xc420dd6148] [0xc420dd6128 0xc420dd6140] [0x8fd520 0x8fd520] 0xc4206b2660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:21:06.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:21:06.435: INFO: rc: 1
Nov 13 09:21:06.436: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dba3f0 exit status 1 <nil> <nil> true [0xc420090058 0xc420090100 0xc420090178] [0xc420090058 0xc420090100 0xc420090178] [0xc4200900a0 0xc420090160] [0x8fd520 0x8fd520] 0xc4217fcde0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:21:16.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:21:16.524: INFO: rc: 1
Nov 13 09:21:16.524: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dba7b0 exit status 1 <nil> <nil> true [0xc4200901f8 0xc420090318 0xc420090400] [0xc4200901f8 0xc420090318 0xc420090400] [0xc4200902e8 0xc4200903c8] [0x8fd520 0x8fd520] 0xc4217fcf00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:21:26.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:21:26.613: INFO: rc: 1
Nov 13 09:21:26.613: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff2420 exit status 1 <nil> <nil> true [0xc420dd6000 0xc420dd6018 0xc420dd6030] [0xc420dd6000 0xc420dd6018 0xc420dd6030] [0xc420dd6010 0xc420dd6028] [0x8fd520 0x8fd520] 0xc4206b2060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:21:36.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:21:36.704: INFO: rc: 1
Nov 13 09:21:36.704: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbaff0 exit status 1 <nil> <nil> true [0xc420090438 0xc4200904d8 0xc420090578] [0xc420090438 0xc4200904d8 0xc420090578] [0xc4200904c8 0xc420090568] [0x8fd520 0x8fd520] 0xc4217fd080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:21:46.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:21:46.806: INFO: rc: 1
Nov 13 09:21:46.806: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbb440 exit status 1 <nil> <nil> true [0xc4200905e8 0xc420090670 0xc420090878] [0xc4200905e8 0xc420090670 0xc420090878] [0xc420090630 0xc420090840] [0x8fd520 0x8fd520] 0xc4217fd1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:21:56.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:21:56.894: INFO: rc: 1
Nov 13 09:21:56.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbb890 exit status 1 <nil> <nil> true [0xc4200908e0 0xc420090908 0xc4200909a0] [0xc4200908e0 0xc420090908 0xc4200909a0] [0xc420090900 0xc420090970] [0x8fd520 0x8fd520] 0xc4217fd2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:22:06.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:22:06.977: INFO: rc: 1
Nov 13 09:22:06.977: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422dbbc50 exit status 1 <nil> <nil> true [0xc4200909a8 0xc420090a68 0xc420090b10] [0xc4200909a8 0xc420090a68 0xc420090b10] [0xc4200909e0 0xc420090a90] [0x8fd520 0x8fd520] 0xc4217fd3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:22:16.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:22:17.089: INFO: rc: 1
Nov 13 09:22:17.089: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422036060 exit status 1 <nil> <nil> true [0xc420090b40 0xc420090b80 0xc420090be0] [0xc420090b40 0xc420090b80 0xc420090be0] [0xc420090b58 0xc420090bc0] [0x8fd520 0x8fd520] 0xc4217fd500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:22:27.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:22:27.175: INFO: rc: 1
Nov 13 09:22:27.175: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422036690 exit status 1 <nil> <nil> true [0xc420090c68 0xc420090d90 0xc420090e48] [0xc420090c68 0xc420090d90 0xc420090e48] [0xc420090d80 0xc420090e10] [0x8fd520 0x8fd520] 0xc4217fd620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:22:37.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:22:37.256: INFO: rc: 1
Nov 13 09:22:37.256: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ff2870 exit status 1 <nil> <nil> true [0xc420dd6038 0xc420dd6050 0xc420dd6068] [0xc420dd6038 0xc420dd6050 0xc420dd6068] [0xc420dd6048 0xc420dd6060] [0x8fd520 0x8fd520] 0xc4206b2180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Nov 13 09:22:47.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-sw8pk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 09:22:47.340: INFO: rc: 1
Nov 13 09:22:47.340: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Nov 13 09:22:47.340: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 13 09:22:47.350: INFO: Deleting all statefulset in ns e2e-tests-statefulset-sw8pk
Nov 13 09:22:47.352: INFO: Scaling statefulset ss to 0
Nov 13 09:22:47.359: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 09:22:47.362: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:22:47.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-sw8pk" for this suite.
Nov 13 09:22:53.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:22:53.526: INFO: namespace: e2e-tests-statefulset-sw8pk, resource: bindings, ignored listing per whitelist
Nov 13 09:22:53.583: INFO: namespace e2e-tests-statefulset-sw8pk deletion completed in 6.208090988s

• [SLOW TEST:384.629 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:22:53.583: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vlv2z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Nov 13 09:22:53.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:22:57.039: INFO: stderr: ""
Nov 13 09:22:57.039: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 09:22:57.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:22:57.224: INFO: stderr: ""
Nov 13 09:22:57.224: INFO: stdout: "update-demo-nautilus-jh2ns update-demo-nautilus-vzcdw "
Nov 13 09:22:57.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-jh2ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:22:57.452: INFO: stderr: ""
Nov 13 09:22:57.452: INFO: stdout: ""
Nov 13 09:22:57.452: INFO: update-demo-nautilus-jh2ns is created but not running
Nov 13 09:23:02.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:23:02.544: INFO: stderr: ""
Nov 13 09:23:02.544: INFO: stdout: "update-demo-nautilus-jh2ns update-demo-nautilus-vzcdw "
Nov 13 09:23:02.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-jh2ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:23:02.634: INFO: stderr: ""
Nov 13 09:23:02.634: INFO: stdout: "true"
Nov 13 09:23:02.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-jh2ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:23:02.726: INFO: stderr: ""
Nov 13 09:23:02.726: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:23:02.726: INFO: validating pod update-demo-nautilus-jh2ns
Nov 13 09:23:02.850: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:23:02.850: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:23:02.850: INFO: update-demo-nautilus-jh2ns is verified up and running
Nov 13 09:23:02.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-vzcdw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:23:02.990: INFO: stderr: ""
Nov 13 09:23:02.990: INFO: stdout: "true"
Nov 13 09:23:02.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods update-demo-nautilus-vzcdw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:23:03.110: INFO: stderr: ""
Nov 13 09:23:03.110: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 09:23:03.111: INFO: validating pod update-demo-nautilus-vzcdw
Nov 13 09:23:03.199: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 09:23:03.199: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 09:23:03.199: INFO: update-demo-nautilus-vzcdw is verified up and running
STEP: using delete to clean up resources
Nov 13 09:23:03.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:23:03.297: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:23:03.297: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 13 09:23:03.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-vlv2z'
Nov 13 09:23:03.400: INFO: stderr: "No resources found.\n"
Nov 13 09:23:03.400: INFO: stdout: ""
Nov 13 09:23:03.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -l name=update-demo --namespace=e2e-tests-kubectl-vlv2z -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 13 09:23:03.492: INFO: stderr: ""
Nov 13 09:23:03.492: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:23:03.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vlv2z" for this suite.
Nov 13 09:23:25.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:23:25.530: INFO: namespace: e2e-tests-kubectl-vlv2z, resource: bindings, ignored listing per whitelist
Nov 13 09:23:25.686: INFO: namespace e2e-tests-kubectl-vlv2z deletion completed in 22.190927074s

• [SLOW TEST:32.103 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:23:25.687: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qml4t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 13 09:23:25.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-qml4t'
Nov 13 09:23:26.062: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov 13 09:23:26.062: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Nov 13 09:23:26.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-qml4t'
Nov 13 09:23:26.216: INFO: stderr: ""
Nov 13 09:23:26.216: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:23:26.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qml4t" for this suite.
Nov 13 09:23:32.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:23:32.352: INFO: namespace: e2e-tests-kubectl-qml4t, resource: bindings, ignored listing per whitelist
Nov 13 09:23:32.385: INFO: namespace e2e-tests-kubectl-qml4t deletion completed in 6.165922969s

• [SLOW TEST:6.698 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:23:32.385: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-tfvsc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Nov 13 09:23:32.680: INFO: Waiting up to 5m0s for pod "var-expansion-ca2ff150-e725-11e8-baa5-625675597e81" in namespace "e2e-tests-var-expansion-tfvsc" to be "success or failure"
Nov 13 09:23:32.726: INFO: Pod "var-expansion-ca2ff150-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 46.889549ms
Nov 13 09:23:34.730: INFO: Pod "var-expansion-ca2ff150-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050600574s
Nov 13 09:23:36.734: INFO: Pod "var-expansion-ca2ff150-e725-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05445396s
STEP: Saw pod success
Nov 13 09:23:36.734: INFO: Pod "var-expansion-ca2ff150-e725-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:23:36.736: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod var-expansion-ca2ff150-e725-11e8-baa5-625675597e81 container dapi-container: <nil>
STEP: delete the pod
Nov 13 09:23:36.772: INFO: Waiting for pod var-expansion-ca2ff150-e725-11e8-baa5-625675597e81 to disappear
Nov 13 09:23:36.790: INFO: Pod var-expansion-ca2ff150-e725-11e8-baa5-625675597e81 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:23:36.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tfvsc" for this suite.
Nov 13 09:23:42.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:23:43.052: INFO: namespace: e2e-tests-var-expansion-tfvsc, resource: bindings, ignored listing per whitelist
Nov 13 09:23:43.059: INFO: namespace e2e-tests-var-expansion-tfvsc deletion completed in 6.257527569s

• [SLOW TEST:10.674 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:23:43.060: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-x2hgl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 13 09:23:43.397: INFO: Waiting up to 5m0s for pod "pod-d09367d4-e725-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-x2hgl" to be "success or failure"
Nov 13 09:23:43.410: INFO: Pod "pod-d09367d4-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 12.551889ms
Nov 13 09:23:45.413: INFO: Pod "pod-d09367d4-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015851219s
Nov 13 09:23:47.417: INFO: Pod "pod-d09367d4-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019778277s
Nov 13 09:23:49.421: INFO: Pod "pod-d09367d4-e725-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023566273s
STEP: Saw pod success
Nov 13 09:23:49.421: INFO: Pod "pod-d09367d4-e725-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:23:49.423: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-d09367d4-e725-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 09:23:49.459: INFO: Waiting for pod pod-d09367d4-e725-11e8-baa5-625675597e81 to disappear
Nov 13 09:23:49.464: INFO: Pod pod-d09367d4-e725-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:23:49.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x2hgl" for this suite.
Nov 13 09:23:55.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:23:55.663: INFO: namespace: e2e-tests-emptydir-x2hgl, resource: bindings, ignored listing per whitelist
Nov 13 09:23:55.695: INFO: namespace e2e-tests-emptydir-x2hgl deletion completed in 6.228013177s

• [SLOW TEST:12.636 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:23:55.695: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-6hr6p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1113 09:24:36.058368      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 09:24:36.058: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:24:36.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6hr6p" for this suite.
Nov 13 09:24:42.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:24:42.186: INFO: namespace: e2e-tests-gc-6hr6p, resource: bindings, ignored listing per whitelist
Nov 13 09:24:42.261: INFO: namespace e2e-tests-gc-6hr6p deletion completed in 6.200241298s

• [SLOW TEST:46.565 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:24:42.261: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mnd94
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-f3d3a5a4-e725-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 09:24:42.543: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-mnd94" to be "success or failure"
Nov 13 09:24:42.548: INFO: Pod "pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.53444ms
Nov 13 09:24:44.552: INFO: Pod "pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009308156s
Nov 13 09:24:46.555: INFO: Pod "pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012742476s
Nov 13 09:24:48.559: INFO: Pod "pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016399325s
Nov 13 09:24:50.562: INFO: Pod "pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019875431s
Nov 13 09:24:52.566: INFO: Pod "pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.023734634s
STEP: Saw pod success
Nov 13 09:24:52.566: INFO: Pod "pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:24:52.569: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 09:24:52.590: INFO: Waiting for pod pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81 to disappear
Nov 13 09:24:52.600: INFO: Pod pod-projected-secrets-f3d41fd3-e725-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:24:52.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mnd94" for this suite.
Nov 13 09:24:58.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:24:58.720: INFO: namespace: e2e-tests-projected-mnd94, resource: bindings, ignored listing per whitelist
Nov 13 09:24:58.733: INFO: namespace e2e-tests-projected-mnd94 deletion completed in 6.129714803s

• [SLOW TEST:16.472 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:24:58.733: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-gzps5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fda08e43-e725-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 09:24:58.988: INFO: Waiting up to 5m0s for pod "pod-secrets-fda1676a-e725-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-gzps5" to be "success or failure"
Nov 13 09:24:59.000: INFO: Pod "pod-secrets-fda1676a-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 12.441196ms
Nov 13 09:25:01.004: INFO: Pod "pod-secrets-fda1676a-e725-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01607021s
Nov 13 09:25:03.008: INFO: Pod "pod-secrets-fda1676a-e725-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02007408s
STEP: Saw pod success
Nov 13 09:25:03.008: INFO: Pod "pod-secrets-fda1676a-e725-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:25:03.011: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-secrets-fda1676a-e725-11e8-baa5-625675597e81 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 09:25:03.044: INFO: Waiting for pod pod-secrets-fda1676a-e725-11e8-baa5-625675597e81 to disappear
Nov 13 09:25:03.050: INFO: Pod pod-secrets-fda1676a-e725-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:25:03.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gzps5" for this suite.
Nov 13 09:25:09.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:25:09.109: INFO: namespace: e2e-tests-secrets-gzps5, resource: bindings, ignored listing per whitelist
Nov 13 09:25:09.218: INFO: namespace e2e-tests-secrets-gzps5 deletion completed in 6.162917623s

• [SLOW TEST:10.485 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:25:09.218: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-cf7s2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 09:25:37.445: INFO: Container started at 2018-11-13 09:25:14 +0000 UTC, pod became ready at 2018-11-13 09:25:37 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:25:37.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cf7s2" for this suite.
Nov 13 09:25:59.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:25:59.597: INFO: namespace: e2e-tests-container-probe-cf7s2, resource: bindings, ignored listing per whitelist
Nov 13 09:25:59.597: INFO: namespace e2e-tests-container-probe-cf7s2 deletion completed in 22.148991974s

• [SLOW TEST:50.379 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:25:59.597: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-tbt2f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 09:25:59.915: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"21ead31d-e726-11e8-90ec-1a79c3ab02d1", Controller:(*bool)(0xc420a8de96), BlockOwnerDeletion:(*bool)(0xc420a8de97)}}
Nov 13 09:25:59.923: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"21e9bc9a-e726-11e8-90ec-1a79c3ab02d1", Controller:(*bool)(0xc420777e5a), BlockOwnerDeletion:(*bool)(0xc420777e5b)}}
Nov 13 09:25:59.934: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"21ea3c89-e726-11e8-90ec-1a79c3ab02d1", Controller:(*bool)(0xc4207db85a), BlockOwnerDeletion:(*bool)(0xc4207db85b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:26:04.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tbt2f" for this suite.
Nov 13 09:26:10.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:26:11.193: INFO: namespace: e2e-tests-gc-tbt2f, resource: bindings, ignored listing per whitelist
Nov 13 09:26:11.213: INFO: namespace e2e-tests-gc-tbt2f deletion completed in 6.253127417s

• [SLOW TEST:11.616 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:26:11.213: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-dcmj4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-dcmj4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 13 09:26:11.453: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 13 09:26:33.523: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.1.53 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dcmj4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:26:33.523: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:26:34.886: INFO: Found all expected endpoints: [netserver-0]
Nov 13 09:26:34.890: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.0.30 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dcmj4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:26:34.890: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:26:36.241: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:26:36.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-dcmj4" for this suite.
Nov 13 09:26:58.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:26:58.340: INFO: namespace: e2e-tests-pod-network-test-dcmj4, resource: bindings, ignored listing per whitelist
Nov 13 09:26:58.351: INFO: namespace e2e-tests-pod-network-test-dcmj4 deletion completed in 22.105239728s

• [SLOW TEST:47.138 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:26:58.352: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5v6tq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 09:26:58.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 version --client'
Nov 13 09:26:58.659: INFO: stderr: ""
Nov 13 09:26:58.659: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Nov 13 09:26:58.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-5v6tq'
Nov 13 09:26:58.982: INFO: stderr: ""
Nov 13 09:26:58.982: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov 13 09:26:58.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-5v6tq'
Nov 13 09:26:59.371: INFO: stderr: ""
Nov 13 09:26:59.371: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 13 09:27:00.386: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:27:00.386: INFO: Found 0 / 1
Nov 13 09:27:01.374: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:27:01.375: INFO: Found 0 / 1
Nov 13 09:27:02.377: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:27:02.377: INFO: Found 0 / 1
Nov 13 09:27:03.465: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:27:03.465: INFO: Found 1 / 1
Nov 13 09:27:03.465: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 13 09:27:03.468: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:27:03.468: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 13 09:27:03.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 describe pod redis-master-mmsbc --namespace=e2e-tests-kubectl-5v6tq'
Nov 13 09:27:03.571: INFO: stderr: ""
Nov 13 09:27:03.572: INFO: stdout: "Name:               redis-master-mmsbc\nNamespace:          e2e-tests-kubectl-5v6tq\nPriority:           0\nPriorityClassName:  <none>\nNode:               shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/10.250.0.5\nStart Time:         Tue, 13 Nov 2018 09:26:59 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 100.96.1.55/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 100.96.1.55\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://caaf322bfabb909382559203ebb627e425fe0b8cd32f20d0f2acca53cd0519e5\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 13 Nov 2018 09:27:01 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-wp54n (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-wp54n:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-wp54n\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                           Message\n  ----    ------     ----  ----                                                           -------\n  Normal  Scheduled  4s    default-scheduler                                              Successfully assigned e2e-tests-kubectl-5v6tq/redis-master-mmsbc to shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j\n  Normal  Pulled     3s    kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Created container\n  Normal  Started    2s    kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Started container\n"
Nov 13 09:27:03.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 describe rc redis-master --namespace=e2e-tests-kubectl-5v6tq'
Nov 13 09:27:03.686: INFO: stderr: ""
Nov 13 09:27:03.686: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-5v6tq\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-mmsbc\n"
Nov 13 09:27:03.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 describe service redis-master --namespace=e2e-tests-kubectl-5v6tq'
Nov 13 09:27:03.822: INFO: stderr: ""
Nov 13 09:27:03.822: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-5v6tq\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.67.114.207\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.55:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 13 09:27:03.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 describe node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j'
Nov 13 09:27:04.077: INFO: stderr: ""
Nov 13 09:27:04.077: INFO: stdout: "Name:               shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_DS2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westeurope\n                    failure-domain.beta.kubernetes.io/zone=1\n                    kubernetes.io/hostname=shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\n                    worker.garden.sapcloud.io/group=worker-wye0a\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.5/19\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 13 Nov 2018 08:45:15 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 13 Nov 2018 08:46:46 +0000   Tue, 13 Nov 2018 08:46:46 +0000   RouteCreated                 RouteController created a route\n  OutOfDisk            False   Tue, 13 Nov 2018 09:27:02 +0000   Tue, 13 Nov 2018 08:45:15 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Tue, 13 Nov 2018 09:27:02 +0000   Tue, 13 Nov 2018 08:45:15 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 13 Nov 2018 09:27:02 +0000   Tue, 13 Nov 2018 08:45:15 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 13 Nov 2018 09:27:02 +0000   Tue, 13 Nov 2018 08:45:15 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 13 Nov 2018 09:27:02 +0000   Tue, 13 Nov 2018 08:45:35 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.250.0.5\n  Hostname:    shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j\nCapacity:\n attachable-volumes-azure-disk:  8\n cpu:                            2\n ephemeral-storage:              48375392Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7115784Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  8\n cpu:                            2\n ephemeral-storage:              47059581301\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         5964808Ki\n pods:                           110\nSystem Info:\n Machine ID:                 cea80a4a6ea94b2e9f9ba1fe56155617\n System UUID:                7BD9E343-541F-AD44-B1E4-A59D09658B18\n Boot ID:                    12be6b12-ae79-4c04-8b4a-942804ec49e1\n Kernel Version:             4.14.67-coreos\n OS Image:                   Container Linux by CoreOS 1855.4.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.12.2\n Kube-Proxy Version:         v1.12.2\nPodCIDR:                     100.96.1.0/24\nProviderID:                  azure:///subscriptions/00d2caa5-cd29-46f7-845a-2f8ee0360ef5/resourceGroups/shoot--core--e2e-rw-az/providers/Microsoft.Compute/virtualMachines/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-5v6tq    redis-master-mmsbc                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-e2e-job-2ff76b52b92f4655                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-bc4jf    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-rncpj                                          250m (12%)    500m (25%)  100Mi (1%)       700Mi (12%)\n  kube-system                kube-proxy-nnlwg                                           50m (2%)      100m (5%)   64Mi (1%)        256Mi (4%)\n  kube-system                node-exporter-wspmd                                        10m (0%)      20m (1%)    10Mi (0%)        50Mi (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests    Limits\n  --------                       --------    ------\n  cpu                            310m (15%)  620m (31%)\n  memory                         174Mi (2%)  1006Mi (17%)\n  attachable-volumes-azure-disk  0           0\nEvents:\n  Type    Reason                   Age                From                                                              Message\n  ----    ------                   ----               ----                                                              -------\n  Normal  Starting                 42m                kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j     Starting kubelet.\n  Normal  NodeHasSufficientDisk    41m (x2 over 41m)  kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j     Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  41m (x2 over 41m)  kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j     Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    41m (x2 over 41m)  kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j     Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     41m (x2 over 41m)  kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j     Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  41m                kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j     Updated Node Allocatable limit across pods\n  Normal  Starting                 41m                kube-proxy, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Starting kube-proxy.\n  Normal  NodeReady                41m                kubelet, shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j     Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j status is now: NodeReady\n"
Nov 13 09:27:04.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 describe namespace e2e-tests-kubectl-5v6tq'
Nov 13 09:27:04.318: INFO: stderr: ""
Nov 13 09:27:04.318: INFO: stdout: "Name:         e2e-tests-kubectl-5v6tq\nLabels:       e2e-framework=kubectl\n              e2e-run=9818ee70-e722-11e8-baa5-625675597e81\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:27:04.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5v6tq" for this suite.
Nov 13 09:27:26.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:27:26.433: INFO: namespace: e2e-tests-kubectl-5v6tq, resource: bindings, ignored listing per whitelist
Nov 13 09:27:26.539: INFO: namespace e2e-tests-kubectl-5v6tq deletion completed in 22.217042976s

• [SLOW TEST:28.187 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:27:26.539: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-5cbx4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 13 09:27:38.932: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 09:27:39.085: INFO: Pod pod-with-poststart-http-hook still exists
Nov 13 09:27:41.202: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 09:27:41.205: INFO: Pod pod-with-poststart-http-hook still exists
Nov 13 09:27:43.086: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 09:27:43.089: INFO: Pod pod-with-poststart-http-hook still exists
Nov 13 09:27:45.103: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 09:27:45.123: INFO: Pod pod-with-poststart-http-hook still exists
Nov 13 09:27:47.086: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 09:27:47.089: INFO: Pod pod-with-poststart-http-hook still exists
Nov 13 09:27:49.086: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 09:27:49.089: INFO: Pod pod-with-poststart-http-hook still exists
Nov 13 09:27:51.086: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 09:27:51.089: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:27:51.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5cbx4" for this suite.
Nov 13 09:28:13.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:28:13.254: INFO: namespace: e2e-tests-container-lifecycle-hook-5cbx4, resource: bindings, ignored listing per whitelist
Nov 13 09:28:13.266: INFO: namespace e2e-tests-container-lifecycle-hook-5cbx4 deletion completed in 22.17393019s

• [SLOW TEST:46.727 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:28:13.267: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ts9v6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-719801c1-e726-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 09:28:13.547: INFO: Waiting up to 5m0s for pod "pod-configmaps-71987697-e726-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-ts9v6" to be "success or failure"
Nov 13 09:28:13.552: INFO: Pod "pod-configmaps-71987697-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.179119ms
Nov 13 09:28:15.555: INFO: Pod "pod-configmaps-71987697-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008408735s
Nov 13 09:28:17.594: INFO: Pod "pod-configmaps-71987697-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047172054s
Nov 13 09:28:19.598: INFO: Pod "pod-configmaps-71987697-e726-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050812018s
STEP: Saw pod success
Nov 13 09:28:19.598: INFO: Pod "pod-configmaps-71987697-e726-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:28:19.600: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-71987697-e726-11e8-baa5-625675597e81 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 09:28:19.687: INFO: Waiting for pod pod-configmaps-71987697-e726-11e8-baa5-625675597e81 to disappear
Nov 13 09:28:19.699: INFO: Pod pod-configmaps-71987697-e726-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:28:19.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ts9v6" for this suite.
Nov 13 09:28:25.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:28:25.892: INFO: namespace: e2e-tests-configmap-ts9v6, resource: bindings, ignored listing per whitelist
Nov 13 09:28:25.928: INFO: namespace e2e-tests-configmap-ts9v6 deletion completed in 6.226452193s

• [SLOW TEST:12.661 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:28:25.928: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-7dlgs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-dkhg
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 09:28:26.282: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dkhg" in namespace "e2e-tests-subpath-7dlgs" to be "success or failure"
Nov 13 09:28:26.286: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.360818ms
Nov 13 09:28:28.290: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00774182s
Nov 13 09:28:30.293: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01140777s
Nov 13 09:28:32.297: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014630593s
Nov 13 09:28:34.300: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018447166s
Nov 13 09:28:36.304: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02157745s
Nov 13 09:28:38.347: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 12.064775632s
Nov 13 09:28:40.350: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 14.067783486s
Nov 13 09:28:42.356: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 16.074042434s
Nov 13 09:28:44.443: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 18.160977685s
Nov 13 09:28:46.447: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 20.16489739s
Nov 13 09:28:48.450: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 22.168131571s
Nov 13 09:28:50.492: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 24.209882892s
Nov 13 09:28:52.495: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 26.212964135s
Nov 13 09:28:54.505: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Running", Reason="", readiness=false. Elapsed: 28.223116488s
Nov 13 09:28:56.547: INFO: Pod "pod-subpath-test-configmap-dkhg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.265078755s
STEP: Saw pod success
Nov 13 09:28:56.547: INFO: Pod "pod-subpath-test-configmap-dkhg" satisfied condition "success or failure"
Nov 13 09:28:56.550: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-subpath-test-configmap-dkhg container test-container-subpath-configmap-dkhg: <nil>
STEP: delete the pod
Nov 13 09:28:56.596: INFO: Waiting for pod pod-subpath-test-configmap-dkhg to disappear
Nov 13 09:28:56.610: INFO: Pod pod-subpath-test-configmap-dkhg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dkhg
Nov 13 09:28:56.610: INFO: Deleting pod "pod-subpath-test-configmap-dkhg" in namespace "e2e-tests-subpath-7dlgs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:28:56.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7dlgs" for this suite.
Nov 13 09:29:02.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:29:02.727: INFO: namespace: e2e-tests-subpath-7dlgs, resource: bindings, ignored listing per whitelist
Nov 13 09:29:02.759: INFO: namespace e2e-tests-subpath-7dlgs deletion completed in 6.143863075s

• [SLOW TEST:36.831 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:29:02.759: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-p5m8n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-p5m8n
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-p5m8n
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-p5m8n
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-p5m8n
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-p5m8n
Nov 13 09:29:09.072: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-p5m8n, name: ss-0, uid: 926143b8-e726-11e8-90ec-1a79c3ab02d1, status phase: Pending. Waiting for statefulset controller to delete.
Nov 13 09:29:09.453: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-p5m8n, name: ss-0, uid: 926143b8-e726-11e8-90ec-1a79c3ab02d1, status phase: Failed. Waiting for statefulset controller to delete.
Nov 13 09:29:09.457: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-p5m8n, name: ss-0, uid: 926143b8-e726-11e8-90ec-1a79c3ab02d1, status phase: Failed. Waiting for statefulset controller to delete.
Nov 13 09:29:09.471: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-p5m8n
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-p5m8n
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-p5m8n and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 13 09:29:17.529: INFO: Deleting all statefulset in ns e2e-tests-statefulset-p5m8n
Nov 13 09:29:17.532: INFO: Scaling statefulset ss to 0
Nov 13 09:29:27.565: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 09:29:27.568: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:29:27.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-p5m8n" for this suite.
Nov 13 09:29:33.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:29:33.659: INFO: namespace: e2e-tests-statefulset-p5m8n, resource: bindings, ignored listing per whitelist
Nov 13 09:29:33.916: INFO: namespace e2e-tests-statefulset-p5m8n deletion completed in 6.295580176s

• [SLOW TEST:31.157 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:29:33.916: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rvn98
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-a1c550cd-e726-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 09:29:34.406: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-rvn98" to be "success or failure"
Nov 13 09:29:34.416: INFO: Pod "pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 9.979245ms
Nov 13 09:29:36.420: INFO: Pod "pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013672854s
Nov 13 09:29:38.423: INFO: Pod "pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016807324s
Nov 13 09:29:40.426: INFO: Pod "pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020272541s
STEP: Saw pod success
Nov 13 09:29:40.426: INFO: Pod "pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:29:40.429: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 09:29:40.468: INFO: Waiting for pod pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81 to disappear
Nov 13 09:29:40.480: INFO: Pod pod-projected-secrets-a1c5bff7-e726-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:29:40.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rvn98" for this suite.
Nov 13 09:29:46.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:29:46.629: INFO: namespace: e2e-tests-projected-rvn98, resource: bindings, ignored listing per whitelist
Nov 13 09:29:46.636: INFO: namespace e2e-tests-projected-rvn98 deletion completed in 6.152496805s

• [SLOW TEST:12.720 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:29:46.637: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xdz7s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 13 09:29:46.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-xdz7s'
Nov 13 09:29:47.053: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov 13 09:29:47.053: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Nov 13 09:29:51.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-xdz7s'
Nov 13 09:29:51.251: INFO: stderr: ""
Nov 13 09:29:51.251: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:29:51.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xdz7s" for this suite.
Nov 13 09:31:55.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:31:55.395: INFO: namespace: e2e-tests-kubectl-xdz7s, resource: bindings, ignored listing per whitelist
Nov 13 09:31:55.397: INFO: namespace e2e-tests-kubectl-xdz7s deletion completed in 2m4.143368156s

• [SLOW TEST:128.760 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:31:55.398: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7t5z9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 09:31:55.675: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5fef26b-e726-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-7t5z9" to be "success or failure"
Nov 13 09:31:55.710: INFO: Pod "downwardapi-volume-f5fef26b-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 34.515277ms
Nov 13 09:31:57.713: INFO: Pod "downwardapi-volume-f5fef26b-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037888191s
Nov 13 09:31:59.717: INFO: Pod "downwardapi-volume-f5fef26b-e726-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041755602s
STEP: Saw pod success
Nov 13 09:31:59.717: INFO: Pod "downwardapi-volume-f5fef26b-e726-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:31:59.719: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-f5fef26b-e726-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 09:31:59.841: INFO: Waiting for pod downwardapi-volume-f5fef26b-e726-11e8-baa5-625675597e81 to disappear
Nov 13 09:31:59.849: INFO: Pod downwardapi-volume-f5fef26b-e726-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:31:59.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7t5z9" for this suite.
Nov 13 09:32:05.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:32:05.877: INFO: namespace: e2e-tests-projected-7t5z9, resource: bindings, ignored listing per whitelist
Nov 13 09:32:06.039: INFO: namespace e2e-tests-projected-7t5z9 deletion completed in 6.186682858s

• [SLOW TEST:10.642 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:32:06.040: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dtpr4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 09:32:06.346: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-dtpr4" to be "success or failure"
Nov 13 09:32:06.359: INFO: Pod "downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 12.53616ms
Nov 13 09:32:08.362: INFO: Pod "downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015960912s
Nov 13 09:32:10.366: INFO: Pod "downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019630592s
Nov 13 09:32:12.370: INFO: Pod "downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023429181s
Nov 13 09:32:14.446: INFO: Pod "downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.100232973s
STEP: Saw pod success
Nov 13 09:32:14.446: INFO: Pod "downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:32:14.451: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 09:32:14.478: INFO: Waiting for pod downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81 to disappear
Nov 13 09:32:14.481: INFO: Pod downwardapi-volume-fc5b1b79-e726-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:32:14.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dtpr4" for this suite.
Nov 13 09:32:20.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:32:20.536: INFO: namespace: e2e-tests-downward-api-dtpr4, resource: bindings, ignored listing per whitelist
Nov 13 09:32:20.635: INFO: namespace e2e-tests-downward-api-dtpr4 deletion completed in 6.142788653s

• [SLOW TEST:14.595 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:32:20.635: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-whfb5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Nov 13 09:32:20.907: INFO: Waiting up to 5m0s for pod "client-containers-0507eedc-e727-11e8-baa5-625675597e81" in namespace "e2e-tests-containers-whfb5" to be "success or failure"
Nov 13 09:32:20.917: INFO: Pod "client-containers-0507eedc-e727-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 9.790648ms
Nov 13 09:32:22.920: INFO: Pod "client-containers-0507eedc-e727-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012741705s
Nov 13 09:32:25.028: INFO: Pod "client-containers-0507eedc-e727-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12091828s
Nov 13 09:32:27.031: INFO: Pod "client-containers-0507eedc-e727-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.1243658s
Nov 13 09:32:29.035: INFO: Pod "client-containers-0507eedc-e727-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.127869453s
STEP: Saw pod success
Nov 13 09:32:29.035: INFO: Pod "client-containers-0507eedc-e727-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:32:29.038: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod client-containers-0507eedc-e727-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 09:32:29.061: INFO: Waiting for pod client-containers-0507eedc-e727-11e8-baa5-625675597e81 to disappear
Nov 13 09:32:29.064: INFO: Pod client-containers-0507eedc-e727-11e8-baa5-625675597e81 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:32:29.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-whfb5" for this suite.
Nov 13 09:32:35.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:32:35.102: INFO: namespace: e2e-tests-containers-whfb5, resource: bindings, ignored listing per whitelist
Nov 13 09:32:35.450: INFO: namespace e2e-tests-containers-whfb5 deletion completed in 6.379375191s

• [SLOW TEST:14.815 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:32:35.451: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-vhn9c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 13 09:32:45.862: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:32:45.870: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 09:32:47.870: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:32:47.874: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 09:32:50.139: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:32:50.143: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 09:32:51.870: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:32:51.877: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 09:32:53.870: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:32:53.874: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 09:32:55.870: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:32:55.874: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 09:32:57.870: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:32:57.874: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 09:32:59.870: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:32:59.876: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 09:33:01.870: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 09:33:01.874: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:33:01.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vhn9c" for this suite.
Nov 13 09:33:23.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:33:23.939: INFO: namespace: e2e-tests-container-lifecycle-hook-vhn9c, resource: bindings, ignored listing per whitelist
Nov 13 09:33:24.082: INFO: namespace e2e-tests-container-lifecycle-hook-vhn9c deletion completed in 22.169811505s

• [SLOW TEST:48.632 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:33:24.083: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fllhl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Nov 13 09:33:24.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-fllhl'
Nov 13 09:33:26.276: INFO: stderr: ""
Nov 13 09:33:26.276: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 13 09:33:27.280: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:33:27.280: INFO: Found 0 / 1
Nov 13 09:33:28.281: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:33:28.281: INFO: Found 0 / 1
Nov 13 09:33:29.280: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:33:29.280: INFO: Found 0 / 1
Nov 13 09:33:30.280: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:33:30.280: INFO: Found 0 / 1
Nov 13 09:33:31.280: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:33:31.280: INFO: Found 1 / 1
Nov 13 09:33:31.280: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov 13 09:33:31.346: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:33:31.346: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 13 09:33:31.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 patch pod redis-master-f526b --namespace=e2e-tests-kubectl-fllhl -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 13 09:33:31.460: INFO: stderr: ""
Nov 13 09:33:31.460: INFO: stdout: "pod/redis-master-f526b patched\n"
STEP: checking annotations
Nov 13 09:33:31.462: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:33:31.462: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:33:31.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fllhl" for this suite.
Nov 13 09:33:53.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:33:53.588: INFO: namespace: e2e-tests-kubectl-fllhl, resource: bindings, ignored listing per whitelist
Nov 13 09:33:53.684: INFO: namespace e2e-tests-kubectl-fllhl deletion completed in 22.218794886s

• [SLOW TEST:29.601 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:33:53.684: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-twvlw
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 09:33:53.957: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:33:55.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-twvlw" for this suite.
Nov 13 09:34:01.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:34:01.280: INFO: namespace: e2e-tests-custom-resource-definition-twvlw, resource: bindings, ignored listing per whitelist
Nov 13 09:34:01.334: INFO: namespace e2e-tests-custom-resource-definition-twvlw deletion completed in 6.265579131s

• [SLOW TEST:7.650 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:34:01.335: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6k48g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 13 09:34:01.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-6k48g'
Nov 13 09:34:01.734: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov 13 09:34:01.734: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Nov 13 09:34:01.747: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-5rndv]
Nov 13 09:34:01.747: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-5rndv" in namespace "e2e-tests-kubectl-6k48g" to be "running and ready"
Nov 13 09:34:01.749: INFO: Pod "e2e-test-nginx-rc-5rndv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.577412ms
Nov 13 09:34:03.753: INFO: Pod "e2e-test-nginx-rc-5rndv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005935918s
Nov 13 09:34:05.768: INFO: Pod "e2e-test-nginx-rc-5rndv": Phase="Running", Reason="", readiness=true. Elapsed: 4.020981474s
Nov 13 09:34:05.768: INFO: Pod "e2e-test-nginx-rc-5rndv" satisfied condition "running and ready"
Nov 13 09:34:05.768: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-5rndv]
Nov 13 09:34:05.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6k48g'
Nov 13 09:34:05.922: INFO: stderr: ""
Nov 13 09:34:05.922: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Nov 13 09:34:05.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6k48g'
Nov 13 09:34:06.019: INFO: stderr: ""
Nov 13 09:34:06.019: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:34:06.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6k48g" for this suite.
Nov 13 09:34:28.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:34:28.149: INFO: namespace: e2e-tests-kubectl-6k48g, resource: bindings, ignored listing per whitelist
Nov 13 09:34:28.257: INFO: namespace e2e-tests-kubectl-6k48g deletion completed in 22.235163076s

• [SLOW TEST:26.923 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:34:28.257: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-vd6sf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov 13 09:34:28.539: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 13 09:34:28.548: INFO: Waiting for terminating namespaces to be deleted...
Nov 13 09:34:28.550: INFO: 
Logging pods the kubelet thinks is on node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j before test
Nov 13 09:34:28.562: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-13 08:59:50 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.562: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 13 09:34:28.562: INFO: sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-bc4jf from heptio-sonobuoy started at 2018-11-13 08:59:55 +0000 UTC (2 container statuses recorded)
Nov 13 09:34:28.562: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov 13 09:34:28.562: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 09:34:28.562: INFO: kube-proxy-nnlwg from kube-system started at 2018-11-13 08:45:16 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.562: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 13 09:34:28.562: INFO: calico-node-rncpj from kube-system started at 2018-11-13 08:45:16 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.562: INFO: 	Container calico-node ready: true, restart count 0
Nov 13 09:34:28.562: INFO: node-exporter-wspmd from kube-system started at 2018-11-13 08:45:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.562: INFO: 	Container node-exporter ready: true, restart count 0
Nov 13 09:34:28.562: INFO: sonobuoy-e2e-job-2ff76b52b92f4655 from heptio-sonobuoy started at 2018-11-13 08:59:55 +0000 UTC (2 container statuses recorded)
Nov 13 09:34:28.562: INFO: 	Container e2e ready: true, restart count 0
Nov 13 09:34:28.562: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 09:34:28.562: INFO: 
Logging pods the kubelet thinks is on node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd before test
Nov 13 09:34:28.741: INFO: metrics-server-7b7c958998-5pqpk from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container metrics-server ready: true, restart count 0
Nov 13 09:34:28.741: INFO: addons-nginx-ingress-controller-5d8ff96544-4nqmh from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Nov 13 09:34:28.741: INFO: vpn-shoot-7598ff6d9d-zzfv2 from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container vpn-shoot ready: true, restart count 0
Nov 13 09:34:28.741: INFO: calico-node-szwdh from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container calico-node ready: true, restart count 0
Nov 13 09:34:28.741: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6584cc89bc-pfc2k from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Nov 13 09:34:28.741: INFO: node-exporter-rqx88 from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container node-exporter ready: true, restart count 0
Nov 13 09:34:28.741: INFO: coredns-996685c97-q726s from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container coredns ready: true, restart count 0
Nov 13 09:34:28.741: INFO: addons-kubernetes-dashboard-789b6fcb7f-ghcnb from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container main ready: true, restart count 0
Nov 13 09:34:28.741: INFO: kube-proxy-29h2s from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 13 09:34:28.741: INFO: sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-phpj5 from heptio-sonobuoy started at 2018-11-13 08:59:56 +0000 UTC (2 container statuses recorded)
Nov 13 09:34:28.741: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov 13 09:34:28.741: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-54d4b075-e727-11e8-baa5-625675597e81 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-54d4b075-e727-11e8-baa5-625675597e81 off the node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
STEP: verifying the node doesn't have the label kubernetes.io/e2e-54d4b075-e727-11e8-baa5-625675597e81
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:34:40.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-vd6sf" for this suite.
Nov 13 09:34:50.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:34:50.896: INFO: namespace: e2e-tests-sched-pred-vd6sf, resource: bindings, ignored listing per whitelist
Nov 13 09:34:51.083: INFO: namespace e2e-tests-sched-pred-vd6sf deletion completed in 10.22037658s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:22.826 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:34:51.084: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-dr9zd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 13 09:34:55.959: INFO: Successfully updated pod "pod-update-5eb8c4de-e727-11e8-baa5-625675597e81"
STEP: verifying the updated pod is in kubernetes
Nov 13 09:34:55.967: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:34:55.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dr9zd" for this suite.
Nov 13 09:35:17.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:35:18.124: INFO: namespace: e2e-tests-pods-dr9zd, resource: bindings, ignored listing per whitelist
Nov 13 09:35:18.127: INFO: namespace e2e-tests-pods-dr9zd deletion completed in 22.15619696s

• [SLOW TEST:27.043 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:35:18.127: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-829lb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:36:18.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-829lb" for this suite.
Nov 13 09:36:40.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:36:40.517: INFO: namespace: e2e-tests-container-probe-829lb, resource: bindings, ignored listing per whitelist
Nov 13 09:36:40.622: INFO: namespace e2e-tests-container-probe-829lb deletion completed in 22.215416652s

• [SLOW TEST:82.495 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:36:40.622: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vhgqf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Nov 13 09:36:40.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-vhgqf'
Nov 13 09:36:41.139: INFO: stderr: ""
Nov 13 09:36:41.139: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Nov 13 09:36:42.143: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:36:42.143: INFO: Found 0 / 1
Nov 13 09:36:43.143: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:36:43.143: INFO: Found 0 / 1
Nov 13 09:36:44.145: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:36:44.145: INFO: Found 0 / 1
Nov 13 09:36:45.143: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:36:45.143: INFO: Found 0 / 1
Nov 13 09:36:46.142: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:36:46.142: INFO: Found 1 / 1
Nov 13 09:36:46.142: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 13 09:36:46.145: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 09:36:46.145: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Nov 13 09:36:46.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 logs redis-master-6tmcw redis-master --namespace=e2e-tests-kubectl-vhgqf'
Nov 13 09:36:46.250: INFO: stderr: ""
Nov 13 09:36:46.250: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Nov 09:36:44.379 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Nov 09:36:44.379 # Server started, Redis version 3.2.12\n1:M 13 Nov 09:36:44.380 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Nov 09:36:44.380 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Nov 13 09:36:46.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 log redis-master-6tmcw redis-master --namespace=e2e-tests-kubectl-vhgqf --tail=1'
Nov 13 09:36:46.353: INFO: stderr: ""
Nov 13 09:36:46.353: INFO: stdout: "1:M 13 Nov 09:36:44.380 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Nov 13 09:36:46.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 log redis-master-6tmcw redis-master --namespace=e2e-tests-kubectl-vhgqf --limit-bytes=1'
Nov 13 09:36:46.464: INFO: stderr: ""
Nov 13 09:36:46.464: INFO: stdout: " "
STEP: exposing timestamps
Nov 13 09:36:46.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 log redis-master-6tmcw redis-master --namespace=e2e-tests-kubectl-vhgqf --tail=1 --timestamps'
Nov 13 09:36:46.579: INFO: stderr: ""
Nov 13 09:36:46.579: INFO: stdout: "2018-11-13T09:36:44.380224706Z 1:M 13 Nov 09:36:44.380 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Nov 13 09:36:49.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 log redis-master-6tmcw redis-master --namespace=e2e-tests-kubectl-vhgqf --since=1s'
Nov 13 09:36:49.230: INFO: stderr: ""
Nov 13 09:36:49.230: INFO: stdout: ""
Nov 13 09:36:49.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 log redis-master-6tmcw redis-master --namespace=e2e-tests-kubectl-vhgqf --since=24h'
Nov 13 09:36:49.345: INFO: stderr: ""
Nov 13 09:36:49.345: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Nov 09:36:44.379 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Nov 09:36:44.379 # Server started, Redis version 3.2.12\n1:M 13 Nov 09:36:44.380 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Nov 09:36:44.380 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Nov 13 09:36:49.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vhgqf'
Nov 13 09:36:49.434: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 09:36:49.434: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Nov 13 09:36:49.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-vhgqf'
Nov 13 09:36:49.570: INFO: stderr: "No resources found.\n"
Nov 13 09:36:49.570: INFO: stdout: ""
Nov 13 09:36:49.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -l name=nginx --namespace=e2e-tests-kubectl-vhgqf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 13 09:36:49.677: INFO: stderr: ""
Nov 13 09:36:49.677: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:36:49.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vhgqf" for this suite.
Nov 13 09:36:55.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:36:55.815: INFO: namespace: e2e-tests-kubectl-vhgqf, resource: bindings, ignored listing per whitelist
Nov 13 09:36:55.827: INFO: namespace e2e-tests-kubectl-vhgqf deletion completed in 6.146731997s

• [SLOW TEST:15.205 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:36:55.827: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-fpgh8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 09:36:56.103: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov 13 09:36:56.110: INFO: Number of nodes with available pods: 0
Nov 13 09:36:56.110: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov 13 09:36:56.147: INFO: Number of nodes with available pods: 0
Nov 13 09:36:56.147: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:36:57.150: INFO: Number of nodes with available pods: 0
Nov 13 09:36:57.150: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:36:58.150: INFO: Number of nodes with available pods: 0
Nov 13 09:36:58.150: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:36:59.151: INFO: Number of nodes with available pods: 0
Nov 13 09:36:59.151: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:00.151: INFO: Number of nodes with available pods: 0
Nov 13 09:37:00.151: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:01.151: INFO: Number of nodes with available pods: 1
Nov 13 09:37:01.151: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov 13 09:37:01.282: INFO: Number of nodes with available pods: 1
Nov 13 09:37:01.282: INFO: Number of running nodes: 0, number of available pods: 1
Nov 13 09:37:02.286: INFO: Number of nodes with available pods: 0
Nov 13 09:37:02.286: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov 13 09:37:02.293: INFO: Number of nodes with available pods: 0
Nov 13 09:37:02.293: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:03.310: INFO: Number of nodes with available pods: 0
Nov 13 09:37:03.310: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:04.346: INFO: Number of nodes with available pods: 0
Nov 13 09:37:04.346: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:05.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:05.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:06.355: INFO: Number of nodes with available pods: 0
Nov 13 09:37:06.355: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:07.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:07.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:08.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:08.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:09.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:09.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:10.321: INFO: Number of nodes with available pods: 0
Nov 13 09:37:10.321: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:11.297: INFO: Number of nodes with available pods: 0
Nov 13 09:37:11.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:12.448: INFO: Number of nodes with available pods: 0
Nov 13 09:37:12.448: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:13.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:13.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:14.344: INFO: Number of nodes with available pods: 0
Nov 13 09:37:14.344: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:15.297: INFO: Number of nodes with available pods: 0
Nov 13 09:37:15.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:16.297: INFO: Number of nodes with available pods: 0
Nov 13 09:37:16.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:17.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:17.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:18.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:18.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:19.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:19.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:20.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:20.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:21.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:21.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:22.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:22.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:23.346: INFO: Number of nodes with available pods: 0
Nov 13 09:37:23.346: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:24.297: INFO: Number of nodes with available pods: 0
Nov 13 09:37:24.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:25.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:25.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:26.345: INFO: Number of nodes with available pods: 0
Nov 13 09:37:26.345: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:27.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:27.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:28.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:28.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:29.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:29.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:30.297: INFO: Number of nodes with available pods: 0
Nov 13 09:37:30.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:31.297: INFO: Number of nodes with available pods: 0
Nov 13 09:37:31.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:32.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:32.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:33.314: INFO: Number of nodes with available pods: 0
Nov 13 09:37:33.314: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:34.297: INFO: Number of nodes with available pods: 0
Nov 13 09:37:34.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:35.297: INFO: Number of nodes with available pods: 0
Nov 13 09:37:35.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:36.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:36.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:37.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:37.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:38.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:38.297: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:39.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:39.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:40.296: INFO: Number of nodes with available pods: 0
Nov 13 09:37:40.296: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:41.298: INFO: Number of nodes with available pods: 0
Nov 13 09:37:41.298: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:37:42.297: INFO: Number of nodes with available pods: 1
Nov 13 09:37:42.297: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-fpgh8, will wait for the garbage collector to delete the pods
Nov 13 09:37:42.452: INFO: Deleting {extensions DaemonSet} daemon-set took: 97.381025ms
Nov 13 09:37:42.653: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.310479ms
Nov 13 09:38:16.955: INFO: Number of nodes with available pods: 0
Nov 13 09:38:16.955: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 09:38:16.957: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fpgh8/daemonsets","resourceVersion":"10440"},"items":null}

Nov 13 09:38:16.960: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fpgh8/pods","resourceVersion":"10440"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:38:16.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fpgh8" for this suite.
Nov 13 09:38:23.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:38:23.167: INFO: namespace: e2e-tests-daemonsets-fpgh8, resource: bindings, ignored listing per whitelist
Nov 13 09:38:23.188: INFO: namespace e2e-tests-daemonsets-fpgh8 deletion completed in 6.186649728s

• [SLOW TEST:87.361 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:38:23.188: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-srv92
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov 13 09:38:23.517: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-srv92,SelfLink:/api/v1/namespaces/e2e-tests-watch-srv92/configmaps/e2e-watch-test-resource-version,UID:dd26daf6-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10468,Generation:0,CreationTimestamp:2018-11-13 09:38:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 09:38:23.517: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-srv92,SelfLink:/api/v1/namespaces/e2e-tests-watch-srv92/configmaps/e2e-watch-test-resource-version,UID:dd26daf6-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10469,Generation:0,CreationTimestamp:2018-11-13 09:38:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:38:23.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-srv92" for this suite.
Nov 13 09:38:29.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:38:29.658: INFO: namespace: e2e-tests-watch-srv92, resource: bindings, ignored listing per whitelist
Nov 13 09:38:29.698: INFO: namespace e2e-tests-watch-srv92 deletion completed in 6.177566813s

• [SLOW TEST:6.510 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:38:29.699: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-pgw4b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 09:38:29.959: INFO: Creating deployment "test-recreate-deployment"
Nov 13 09:38:29.962: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 13 09:38:29.969: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Nov 13 09:38:31.977: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 13 09:38:32.046: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698709, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698709, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698710, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698709, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 09:38:34.049: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698709, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698709, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698710, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698709, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 09:38:36.052: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 13 09:38:36.145: INFO: Updating deployment test-recreate-deployment
Nov 13 09:38:36.145: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 13 09:38:36.370: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-pgw4b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pgw4b/deployments/test-recreate-deployment,UID:e10223cb-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10533,Generation:2,CreationTimestamp:2018-11-13 09:38:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-11-13 09:38:36 +0000 UTC 2018-11-13 09:38:36 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-11-13 09:38:36 +0000 UTC 2018-11-13 09:38:29 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Nov 13 09:38:36.390: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-pgw4b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pgw4b/replicasets/test-recreate-deployment-7cf749666b,UID:e4c8ae0d-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10531,Generation:1,CreationTimestamp:2018-11-13 09:38:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment e10223cb-e727-11e8-90ec-1a79c3ab02d1 0xc422edbdf7 0xc422edbdf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 13 09:38:36.390: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 13 09:38:36.390: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-pgw4b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pgw4b/replicasets/test-recreate-deployment-79f694ff59,UID:e1035932-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10525,Generation:2,CreationTimestamp:2018-11-13 09:38:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment e10223cb-e727-11e8-90ec-1a79c3ab02d1 0xc422edbd37 0xc422edbd38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 13 09:38:36.420: INFO: Pod "test-recreate-deployment-7cf749666b-tsbdw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-tsbdw,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-pgw4b,SelfLink:/api/v1/namespaces/e2e-tests-deployment-pgw4b/pods/test-recreate-deployment-7cf749666b-tsbdw,UID:e4c9669c-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10534,Generation:0,CreationTimestamp:2018-11-13 09:38:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b e4c8ae0d-e727-11e8-90ec-1a79c3ab02d1 0xc422e65ed7 0xc422e65ed8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-p5zn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p5zn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p5zn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e65f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e65f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:38:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:38:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:38:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:38:36 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2018-11-13 09:38:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:38:36.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-pgw4b" for this suite.
Nov 13 09:38:42.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:38:42.610: INFO: namespace: e2e-tests-deployment-pgw4b, resource: bindings, ignored listing per whitelist
Nov 13 09:38:42.612: INFO: namespace e2e-tests-deployment-pgw4b deletion completed in 6.165118164s

• [SLOW TEST:12.914 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:38:42.613: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-vbnv7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov 13 09:38:42.832: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-a,UID:e8adf17a-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10567,Generation:0,CreationTimestamp:2018-11-13 09:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 09:38:42.832: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-a,UID:e8adf17a-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10567,Generation:0,CreationTimestamp:2018-11-13 09:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov 13 09:38:52.846: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-a,UID:e8adf17a-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10587,Generation:0,CreationTimestamp:2018-11-13 09:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 13 09:38:52.846: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-a,UID:e8adf17a-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10587,Generation:0,CreationTimestamp:2018-11-13 09:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov 13 09:39:02.852: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-a,UID:e8adf17a-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10608,Generation:0,CreationTimestamp:2018-11-13 09:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 09:39:02.853: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-a,UID:e8adf17a-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10608,Generation:0,CreationTimestamp:2018-11-13 09:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov 13 09:39:12.859: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-a,UID:e8adf17a-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10628,Generation:0,CreationTimestamp:2018-11-13 09:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 09:39:12.859: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-a,UID:e8adf17a-e727-11e8-90ec-1a79c3ab02d1,ResourceVersion:10628,Generation:0,CreationTimestamp:2018-11-13 09:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov 13 09:39:22.891: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-b,UID:008ac204-e728-11e8-90ec-1a79c3ab02d1,ResourceVersion:10648,Generation:0,CreationTimestamp:2018-11-13 09:39:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 09:39:22.891: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-b,UID:008ac204-e728-11e8-90ec-1a79c3ab02d1,ResourceVersion:10648,Generation:0,CreationTimestamp:2018-11-13 09:39:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov 13 09:39:32.897: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-b,UID:008ac204-e728-11e8-90ec-1a79c3ab02d1,ResourceVersion:10668,Generation:0,CreationTimestamp:2018-11-13 09:39:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 09:39:32.897: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vbnv7,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbnv7/configmaps/e2e-watch-test-configmap-b,UID:008ac204-e728-11e8-90ec-1a79c3ab02d1,ResourceVersion:10668,Generation:0,CreationTimestamp:2018-11-13 09:39:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:39:42.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-vbnv7" for this suite.
Nov 13 09:39:48.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:39:49.154: INFO: namespace: e2e-tests-watch-vbnv7, resource: bindings, ignored listing per whitelist
Nov 13 09:39:49.278: INFO: namespace e2e-tests-watch-vbnv7 deletion completed in 6.377075591s

• [SLOW TEST:66.665 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:39:49.278: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8t8n9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 13 09:39:49.526: INFO: Waiting up to 5m0s for pod "pod-106ef9ca-e728-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-8t8n9" to be "success or failure"
Nov 13 09:39:49.530: INFO: Pod "pod-106ef9ca-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 3.085519ms
Nov 13 09:39:51.757: INFO: Pod "pod-106ef9ca-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.23082869s
Nov 13 09:39:53.761: INFO: Pod "pod-106ef9ca-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.234114453s
Nov 13 09:39:55.764: INFO: Pod "pod-106ef9ca-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.237496688s
Nov 13 09:39:57.767: INFO: Pod "pod-106ef9ca-e728-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.240806601s
STEP: Saw pod success
Nov 13 09:39:57.767: INFO: Pod "pod-106ef9ca-e728-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:39:57.769: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-106ef9ca-e728-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 09:39:57.905: INFO: Waiting for pod pod-106ef9ca-e728-11e8-baa5-625675597e81 to disappear
Nov 13 09:39:57.907: INFO: Pod pod-106ef9ca-e728-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:39:57.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8t8n9" for this suite.
Nov 13 09:40:03.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:40:04.062: INFO: namespace: e2e-tests-emptydir-8t8n9, resource: bindings, ignored listing per whitelist
Nov 13 09:40:04.092: INFO: namespace e2e-tests-emptydir-8t8n9 deletion completed in 6.181576123s

• [SLOW TEST:14.813 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:40:04.092: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-h5fqq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-h5fqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h5fqq to expose endpoints map[]
Nov 13 09:40:04.447: INFO: Get endpoints failed (2.609314ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov 13 09:40:05.450: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h5fqq exposes endpoints map[] (1.005992567s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-h5fqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h5fqq to expose endpoints map[pod1:[80]]
Nov 13 09:40:09.488: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.031656559s elapsed, will retry)
Nov 13 09:40:10.493: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h5fqq exposes endpoints map[pod1:[80]] (5.03731634s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-h5fqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h5fqq to expose endpoints map[pod1:[80] pod2:[80]]
Nov 13 09:40:14.544: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h5fqq exposes endpoints map[pod1:[80] pod2:[80]] (4.045480257s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-h5fqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h5fqq to expose endpoints map[pod2:[80]]
Nov 13 09:40:15.582: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h5fqq exposes endpoints map[pod2:[80]] (1.029390994s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-h5fqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h5fqq to expose endpoints map[]
Nov 13 09:40:16.592: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h5fqq exposes endpoints map[] (1.006096782s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:40:16.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-h5fqq" for this suite.
Nov 13 09:40:38.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:40:39.051: INFO: namespace: e2e-tests-services-h5fqq, resource: bindings, ignored listing per whitelist
Nov 13 09:40:39.059: INFO: namespace e2e-tests-services-h5fqq deletion completed in 22.429548835s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:34.967 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:40:39.060: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-8czkl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-8czkl
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-8czkl
STEP: Deleting pre-stop pod
Nov 13 09:40:58.740: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:40:58.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-8czkl" for this suite.
Nov 13 09:41:32.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:41:32.894: INFO: namespace: e2e-tests-prestop-8czkl, resource: bindings, ignored listing per whitelist
Nov 13 09:41:32.899: INFO: namespace e2e-tests-prestop-8czkl deletion completed in 34.14874532s

• [SLOW TEST:53.839 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:41:32.899: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-xl75b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov 13 09:41:33.196: INFO: PodSpec: initContainers in spec.initContainers
Nov 13 09:42:27.928: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-4e3a80e7-e728-11e8-baa5-625675597e81", GenerateName:"", Namespace:"e2e-tests-init-container-xl75b", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-xl75b/pods/pod-init-4e3a80e7-e728-11e8-baa5-625675597e81", UID:"4e3a4144-e728-11e8-90ec-1a79c3ab02d1", ResourceVersion:"11115", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63677698893, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"196520471"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.84/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kk5s8", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420952d80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kk5s8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kk5s8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kk5s8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420deb1c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421b57da0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420deb7b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420deb7d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc420deb7d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698893, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698893, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698893, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677698893, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.5", PodIP:"100.96.1.84", StartTime:(*v1.Time)(0xc420ed1820), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4209270a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420927110)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://9a98b348d5face933a9967f59719b79be648657dbf3de196216cb683c22d5c18"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420ed19a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420ed18e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:42:27.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xl75b" for this suite.
Nov 13 09:42:49.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:42:50.072: INFO: namespace: e2e-tests-init-container-xl75b, resource: bindings, ignored listing per whitelist
Nov 13 09:42:50.129: INFO: namespace e2e-tests-init-container-xl75b deletion completed in 22.183178085s

• [SLOW TEST:77.230 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:42:50.129: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-8z646
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 13 09:42:50.422: INFO: Number of nodes with available pods: 0
Nov 13 09:42:50.422: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:42:51.429: INFO: Number of nodes with available pods: 0
Nov 13 09:42:51.429: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:42:52.428: INFO: Number of nodes with available pods: 0
Nov 13 09:42:52.428: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:42:53.429: INFO: Number of nodes with available pods: 0
Nov 13 09:42:53.429: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:42:54.432: INFO: Number of nodes with available pods: 1
Nov 13 09:42:54.432: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j is running more than one daemon pod
Nov 13 09:42:55.445: INFO: Number of nodes with available pods: 2
Nov 13 09:42:55.445: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov 13 09:42:55.573: INFO: Number of nodes with available pods: 1
Nov 13 09:42:55.573: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:42:56.579: INFO: Number of nodes with available pods: 1
Nov 13 09:42:56.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:42:57.646: INFO: Number of nodes with available pods: 1
Nov 13 09:42:57.646: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:42:58.579: INFO: Number of nodes with available pods: 1
Nov 13 09:42:58.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:42:59.587: INFO: Number of nodes with available pods: 1
Nov 13 09:42:59.587: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:00.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:00.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:01.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:01.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:02.646: INFO: Number of nodes with available pods: 1
Nov 13 09:43:02.646: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:03.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:03.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:04.645: INFO: Number of nodes with available pods: 1
Nov 13 09:43:04.645: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:05.648: INFO: Number of nodes with available pods: 1
Nov 13 09:43:05.648: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:06.589: INFO: Number of nodes with available pods: 1
Nov 13 09:43:06.589: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:07.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:07.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:08.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:08.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:09.648: INFO: Number of nodes with available pods: 1
Nov 13 09:43:09.648: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:10.585: INFO: Number of nodes with available pods: 1
Nov 13 09:43:10.585: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:11.643: INFO: Number of nodes with available pods: 1
Nov 13 09:43:11.643: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:12.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:12.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:13.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:13.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:14.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:14.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:15.584: INFO: Number of nodes with available pods: 1
Nov 13 09:43:15.584: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:16.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:16.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:17.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:17.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:18.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:18.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:19.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:19.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:20.646: INFO: Number of nodes with available pods: 1
Nov 13 09:43:20.646: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:21.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:21.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:22.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:22.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:23.646: INFO: Number of nodes with available pods: 1
Nov 13 09:43:23.646: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:24.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:24.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:25.580: INFO: Number of nodes with available pods: 1
Nov 13 09:43:25.580: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:26.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:26.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:27.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:27.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:28.585: INFO: Number of nodes with available pods: 1
Nov 13 09:43:28.585: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:29.579: INFO: Number of nodes with available pods: 1
Nov 13 09:43:29.579: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:30.583: INFO: Number of nodes with available pods: 1
Nov 13 09:43:30.583: INFO: Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd is running more than one daemon pod
Nov 13 09:43:31.579: INFO: Number of nodes with available pods: 2
Nov 13 09:43:31.579: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8z646, will wait for the garbage collector to delete the pods
Nov 13 09:43:31.701: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.655933ms
Nov 13 09:43:31.802: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.315795ms
Nov 13 09:44:10.205: INFO: Number of nodes with available pods: 0
Nov 13 09:44:10.205: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 09:44:10.207: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8z646/daemonsets","resourceVersion":"11366"},"items":null}

Nov 13 09:44:10.209: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8z646/pods","resourceVersion":"11366"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:44:10.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8z646" for this suite.
Nov 13 09:44:16.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:44:16.371: INFO: namespace: e2e-tests-daemonsets-8z646, resource: bindings, ignored listing per whitelist
Nov 13 09:44:16.392: INFO: namespace e2e-tests-daemonsets-8z646 deletion completed in 6.171049915s

• [SLOW TEST:86.263 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:44:16.392: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-t8llw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov 13 09:44:16.614: INFO: Waiting up to 5m0s for pod "downward-api-afa161ab-e728-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-t8llw" to be "success or failure"
Nov 13 09:44:16.618: INFO: Pod "downward-api-afa161ab-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039123ms
Nov 13 09:44:18.622: INFO: Pod "downward-api-afa161ab-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007593714s
Nov 13 09:44:20.626: INFO: Pod "downward-api-afa161ab-e728-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011307079s
STEP: Saw pod success
Nov 13 09:44:20.626: INFO: Pod "downward-api-afa161ab-e728-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:44:20.628: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downward-api-afa161ab-e728-11e8-baa5-625675597e81 container dapi-container: <nil>
STEP: delete the pod
Nov 13 09:44:20.730: INFO: Waiting for pod downward-api-afa161ab-e728-11e8-baa5-625675597e81 to disappear
Nov 13 09:44:20.743: INFO: Pod downward-api-afa161ab-e728-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:44:20.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t8llw" for this suite.
Nov 13 09:44:26.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:44:26.852: INFO: namespace: e2e-tests-downward-api-t8llw, resource: bindings, ignored listing per whitelist
Nov 13 09:44:26.928: INFO: namespace e2e-tests-downward-api-t8llw deletion completed in 6.179800745s

• [SLOW TEST:10.536 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:44:26.929: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jrz62
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b5ef5ee2-e728-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 09:44:27.197: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-jrz62" to be "success or failure"
Nov 13 09:44:27.202: INFO: Pod "pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.600727ms
Nov 13 09:44:29.209: INFO: Pod "pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011645384s
Nov 13 09:44:31.213: INFO: Pod "pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015458242s
Nov 13 09:44:33.223: INFO: Pod "pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025483203s
STEP: Saw pod success
Nov 13 09:44:33.223: INFO: Pod "pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:44:33.225: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 09:44:33.254: INFO: Waiting for pod pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81 to disappear
Nov 13 09:44:33.264: INFO: Pod pod-projected-configmaps-b5efddd2-e728-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:44:33.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jrz62" for this suite.
Nov 13 09:44:39.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:44:39.407: INFO: namespace: e2e-tests-projected-jrz62, resource: bindings, ignored listing per whitelist
Nov 13 09:44:39.424: INFO: namespace e2e-tests-projected-jrz62 deletion completed in 6.156416118s

• [SLOW TEST:12.495 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:44:39.424: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qpg5s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bd621988-e728-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 09:44:39.692: INFO: Waiting up to 5m0s for pod "pod-secrets-bd62802c-e728-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-qpg5s" to be "success or failure"
Nov 13 09:44:39.696: INFO: Pod "pod-secrets-bd62802c-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110823ms
Nov 13 09:44:41.700: INFO: Pod "pod-secrets-bd62802c-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008238384s
Nov 13 09:44:43.704: INFO: Pod "pod-secrets-bd62802c-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012286502s
Nov 13 09:44:45.707: INFO: Pod "pod-secrets-bd62802c-e728-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015451038s
STEP: Saw pod success
Nov 13 09:44:45.707: INFO: Pod "pod-secrets-bd62802c-e728-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:44:45.715: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-secrets-bd62802c-e728-11e8-baa5-625675597e81 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 09:44:45.738: INFO: Waiting for pod pod-secrets-bd62802c-e728-11e8-baa5-625675597e81 to disappear
Nov 13 09:44:45.742: INFO: Pod pod-secrets-bd62802c-e728-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:44:45.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qpg5s" for this suite.
Nov 13 09:44:51.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:44:51.896: INFO: namespace: e2e-tests-secrets-qpg5s, resource: bindings, ignored listing per whitelist
Nov 13 09:44:51.932: INFO: namespace e2e-tests-secrets-qpg5s deletion completed in 6.173323194s

• [SLOW TEST:12.508 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:44:51.932: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cndx4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 09:44:52.236: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-cndx4" to be "success or failure"
Nov 13 09:44:52.239: INFO: Pod "downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 3.630122ms
Nov 13 09:44:54.244: INFO: Pod "downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008190697s
Nov 13 09:44:56.247: INFO: Pod "downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011795032s
Nov 13 09:44:58.251: INFO: Pod "downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015188887s
STEP: Saw pod success
Nov 13 09:44:58.251: INFO: Pod "downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:44:58.254: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 09:44:58.347: INFO: Waiting for pod downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81 to disappear
Nov 13 09:44:58.354: INFO: Pod downwardapi-volume-c4d9a9ba-e728-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:44:58.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cndx4" for this suite.
Nov 13 09:45:04.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:45:04.541: INFO: namespace: e2e-tests-projected-cndx4, resource: bindings, ignored listing per whitelist
Nov 13 09:45:04.553: INFO: namespace e2e-tests-projected-cndx4 deletion completed in 6.194906422s

• [SLOW TEST:12.621 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:45:04.554: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-v2ckt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov 13 09:45:08.838: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-cc5d35c3-e728-11e8-baa5-625675597e81,GenerateName:,Namespace:e2e-tests-events-v2ckt,SelfLink:/api/v1/namespaces/e2e-tests-events-v2ckt/pods/send-events-cc5d35c3-e728-11e8-baa5-625675597e81,UID:cc5cf365-e728-11e8-90ec-1a79c3ab02d1,ResourceVersion:11573,Generation:0,CreationTimestamp:2018-11-13 09:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 816894285,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.90/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-22b6r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-22b6r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-22b6r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f5d100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f5d130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:45:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:45:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:45:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 09:45:04 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.1.90,StartTime:2018-11-13 09:45:04 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-11-13 09:45:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://6db2790ed82bcf84baa6e8b692b7beb1e626cbe93758cb18bfd975f62991aad3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Nov 13 09:45:10.841: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov 13 09:45:12.845: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:45:12.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-v2ckt" for this suite.
Nov 13 09:45:50.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:45:51.021: INFO: namespace: e2e-tests-events-v2ckt, resource: bindings, ignored listing per whitelist
Nov 13 09:45:51.237: INFO: namespace e2e-tests-events-v2ckt deletion completed in 38.374888006s

• [SLOW TEST:46.683 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:45:51.237: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-q6l6w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 13 09:45:51.525: INFO: Waiting up to 5m0s for pod "pod-e83385c4-e728-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-q6l6w" to be "success or failure"
Nov 13 09:45:51.531: INFO: Pod "pod-e83385c4-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.142238ms
Nov 13 09:45:53.534: INFO: Pod "pod-e83385c4-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009497741s
Nov 13 09:45:55.541: INFO: Pod "pod-e83385c4-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016200525s
Nov 13 09:45:57.545: INFO: Pod "pod-e83385c4-e728-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020134132s
Nov 13 09:45:59.548: INFO: Pod "pod-e83385c4-e728-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023165204s
STEP: Saw pod success
Nov 13 09:45:59.548: INFO: Pod "pod-e83385c4-e728-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:45:59.550: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-e83385c4-e728-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 09:45:59.579: INFO: Waiting for pod pod-e83385c4-e728-11e8-baa5-625675597e81 to disappear
Nov 13 09:45:59.591: INFO: Pod pod-e83385c4-e728-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:45:59.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q6l6w" for this suite.
Nov 13 09:46:05.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:46:05.750: INFO: namespace: e2e-tests-emptydir-q6l6w, resource: bindings, ignored listing per whitelist
Nov 13 09:46:05.762: INFO: namespace e2e-tests-emptydir-q6l6w deletion completed in 6.16270572s

• [SLOW TEST:14.525 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:46:05.763: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ft6sb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-f0df6408-e728-11e8-baa5-625675597e81
STEP: Creating secret with name s-test-opt-upd-f0df6442-e728-11e8-baa5-625675597e81
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f0df6408-e728-11e8-baa5-625675597e81
STEP: Updating secret s-test-opt-upd-f0df6442-e728-11e8-baa5-625675597e81
STEP: Creating secret with name s-test-opt-create-f0df6459-e728-11e8-baa5-625675597e81
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:46:18.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ft6sb" for this suite.
Nov 13 09:46:40.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:46:40.642: INFO: namespace: e2e-tests-projected-ft6sb, resource: bindings, ignored listing per whitelist
Nov 13 09:46:40.665: INFO: namespace e2e-tests-projected-ft6sb deletion completed in 22.202958174s

• [SLOW TEST:34.902 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:46:40.665: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vxcmf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-05a091ad-e729-11e8-baa5-625675597e81
STEP: Creating configMap with name cm-test-opt-upd-05a091e7-e729-11e8-baa5-625675597e81
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-05a091ad-e729-11e8-baa5-625675597e81
STEP: Updating configmap cm-test-opt-upd-05a091e7-e729-11e8-baa5-625675597e81
STEP: Creating configMap with name cm-test-opt-create-05a091fe-e729-11e8-baa5-625675597e81
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:46:51.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vxcmf" for this suite.
Nov 13 09:47:13.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:47:13.311: INFO: namespace: e2e-tests-projected-vxcmf, resource: bindings, ignored listing per whitelist
Nov 13 09:47:13.432: INFO: namespace e2e-tests-projected-vxcmf deletion completed in 22.172744782s

• [SLOW TEST:32.768 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:47:13.433: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xg9jr
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-1932e151-e729-11e8-baa5-625675597e81
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:47:21.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xg9jr" for this suite.
Nov 13 09:47:43.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:47:43.855: INFO: namespace: e2e-tests-configmap-xg9jr, resource: bindings, ignored listing per whitelist
Nov 13 09:47:43.922: INFO: namespace e2e-tests-configmap-xg9jr deletion completed in 22.117318888s

• [SLOW TEST:30.490 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:47:43.923: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-j5jrt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 09:47:44.150: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-j5jrt" to be "success or failure"
Nov 13 09:47:44.155: INFO: Pod "downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.457135ms
Nov 13 09:47:46.158: INFO: Pod "downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008579152s
Nov 13 09:47:48.179: INFO: Pod "downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028753493s
Nov 13 09:47:50.184: INFO: Pod "downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033667813s
STEP: Saw pod success
Nov 13 09:47:50.184: INFO: Pod "downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:47:50.186: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 09:47:50.239: INFO: Waiting for pod downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81 to disappear
Nov 13 09:47:50.252: INFO: Pod downwardapi-volume-2b54bece-e729-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:47:50.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j5jrt" for this suite.
Nov 13 09:47:56.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:47:56.810: INFO: namespace: e2e-tests-downward-api-j5jrt, resource: bindings, ignored listing per whitelist
Nov 13 09:47:56.909: INFO: namespace e2e-tests-downward-api-j5jrt deletion completed in 6.653715452s

• [SLOW TEST:12.986 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:47:56.909: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-97ngs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 09:47:57.241: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-97ngs" to be "success or failure"
Nov 13 09:47:57.245: INFO: Pod "downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.670628ms
Nov 13 09:47:59.249: INFO: Pod "downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008010783s
Nov 13 09:48:01.252: INFO: Pod "downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011322804s
Nov 13 09:48:03.255: INFO: Pod "downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014532968s
STEP: Saw pod success
Nov 13 09:48:03.255: INFO: Pod "downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:48:03.258: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 09:48:03.293: INFO: Waiting for pod downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81 to disappear
Nov 13 09:48:03.309: INFO: Pod downwardapi-volume-33224bf7-e729-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:48:03.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-97ngs" for this suite.
Nov 13 09:48:09.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:48:09.434: INFO: namespace: e2e-tests-downward-api-97ngs, resource: bindings, ignored listing per whitelist
Nov 13 09:48:09.478: INFO: namespace e2e-tests-downward-api-97ngs deletion completed in 6.149509265s

• [SLOW TEST:12.569 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:48:09.479: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4nvjv
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov 13 09:48:09.744: INFO: Waiting up to 5m0s for pod "pod-3a962391-e729-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-4nvjv" to be "success or failure"
Nov 13 09:48:09.791: INFO: Pod "pod-3a962391-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 46.970271ms
Nov 13 09:48:11.795: INFO: Pod "pod-3a962391-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050385482s
Nov 13 09:48:13.798: INFO: Pod "pod-3a962391-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053473194s
Nov 13 09:48:15.801: INFO: Pod "pod-3a962391-e729-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056748733s
STEP: Saw pod success
Nov 13 09:48:15.801: INFO: Pod "pod-3a962391-e729-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:48:15.803: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-3a962391-e729-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 09:48:15.852: INFO: Waiting for pod pod-3a962391-e729-11e8-baa5-625675597e81 to disappear
Nov 13 09:48:15.861: INFO: Pod pod-3a962391-e729-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:48:15.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4nvjv" for this suite.
Nov 13 09:48:21.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:48:21.968: INFO: namespace: e2e-tests-emptydir-4nvjv, resource: bindings, ignored listing per whitelist
Nov 13 09:48:22.016: INFO: namespace e2e-tests-emptydir-4nvjv deletion completed in 6.151408487s

• [SLOW TEST:12.537 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:48:22.016: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6nd4z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Nov 13 09:48:22.242: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-071128755 proxy --unix-socket=/tmp/kubectl-proxy-unix536339062/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:48:22.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6nd4z" for this suite.
Nov 13 09:48:28.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:48:28.463: INFO: namespace: e2e-tests-kubectl-6nd4z, resource: bindings, ignored listing per whitelist
Nov 13 09:48:28.494: INFO: namespace e2e-tests-kubectl-6nd4z deletion completed in 6.183980345s

• [SLOW TEST:6.478 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:48:28.495: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6tvpx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 09:48:28.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-6tvpx" to be "success or failure"
Nov 13 09:48:28.840: INFO: Pod "downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 65.792886ms
Nov 13 09:48:30.844: INFO: Pod "downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069218889s
Nov 13 09:48:32.847: INFO: Pod "downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.07282412s
Nov 13 09:48:34.851: INFO: Pod "downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.076277539s
Nov 13 09:48:36.854: INFO: Pod "downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.079545947s
STEP: Saw pod success
Nov 13 09:48:36.854: INFO: Pod "downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:48:36.857: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 09:48:36.886: INFO: Waiting for pod downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81 to disappear
Nov 13 09:48:36.888: INFO: Pod downwardapi-volume-45ec2b74-e729-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:48:36.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6tvpx" for this suite.
Nov 13 09:48:42.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:48:42.984: INFO: namespace: e2e-tests-projected-6tvpx, resource: bindings, ignored listing per whitelist
Nov 13 09:48:43.264: INFO: namespace e2e-tests-projected-6tvpx deletion completed in 6.372583525s

• [SLOW TEST:14.769 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:48:43.264: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-xzkw9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-w7gd
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 09:48:43.736: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w7gd" in namespace "e2e-tests-subpath-xzkw9" to be "success or failure"
Nov 13 09:48:43.744: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.213739ms
Nov 13 09:48:45.751: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014690695s
Nov 13 09:48:47.754: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01790201s
Nov 13 09:48:49.758: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021107956s
Nov 13 09:48:51.761: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02457374s
Nov 13 09:48:53.796: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 10.059520877s
Nov 13 09:48:55.799: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 12.062842566s
Nov 13 09:48:57.803: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 14.066278507s
Nov 13 09:48:59.806: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 16.0696454s
Nov 13 09:49:01.810: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 18.073142546s
Nov 13 09:49:03.813: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 20.076632844s
Nov 13 09:49:05.816: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 22.079986492s
Nov 13 09:49:07.822: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 24.085160604s
Nov 13 09:49:09.825: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 26.088599055s
Nov 13 09:49:11.843: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Running", Reason="", readiness=false. Elapsed: 28.106302651s
Nov 13 09:49:13.866: INFO: Pod "pod-subpath-test-configmap-w7gd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.129475048s
STEP: Saw pod success
Nov 13 09:49:13.866: INFO: Pod "pod-subpath-test-configmap-w7gd" satisfied condition "success or failure"
Nov 13 09:49:13.869: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-subpath-test-configmap-w7gd container test-container-subpath-configmap-w7gd: <nil>
STEP: delete the pod
Nov 13 09:49:13.898: INFO: Waiting for pod pod-subpath-test-configmap-w7gd to disappear
Nov 13 09:49:13.908: INFO: Pod pod-subpath-test-configmap-w7gd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w7gd
Nov 13 09:49:13.908: INFO: Deleting pod "pod-subpath-test-configmap-w7gd" in namespace "e2e-tests-subpath-xzkw9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:49:13.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xzkw9" for this suite.
Nov 13 09:49:19.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:49:20.025: INFO: namespace: e2e-tests-subpath-xzkw9, resource: bindings, ignored listing per whitelist
Nov 13 09:49:20.097: INFO: namespace e2e-tests-subpath-xzkw9 deletion completed in 6.183738851s

• [SLOW TEST:36.833 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:49:20.100: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-5dps7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-5dps7/configmap-test-64b0fef4-e729-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 09:49:20.394: INFO: Waiting up to 5m0s for pod "pod-configmaps-64b26581-e729-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-5dps7" to be "success or failure"
Nov 13 09:49:20.411: INFO: Pod "pod-configmaps-64b26581-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 16.306407ms
Nov 13 09:49:22.414: INFO: Pod "pod-configmaps-64b26581-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019817796s
Nov 13 09:49:24.418: INFO: Pod "pod-configmaps-64b26581-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023518825s
Nov 13 09:49:26.421: INFO: Pod "pod-configmaps-64b26581-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026792231s
Nov 13 09:49:28.425: INFO: Pod "pod-configmaps-64b26581-e729-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030390557s
STEP: Saw pod success
Nov 13 09:49:28.425: INFO: Pod "pod-configmaps-64b26581-e729-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:49:28.445: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-64b26581-e729-11e8-baa5-625675597e81 container env-test: <nil>
STEP: delete the pod
Nov 13 09:49:28.465: INFO: Waiting for pod pod-configmaps-64b26581-e729-11e8-baa5-625675597e81 to disappear
Nov 13 09:49:28.474: INFO: Pod pod-configmaps-64b26581-e729-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:49:28.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5dps7" for this suite.
Nov 13 09:49:34.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:49:34.732: INFO: namespace: e2e-tests-configmap-5dps7, resource: bindings, ignored listing per whitelist
Nov 13 09:49:34.794: INFO: namespace e2e-tests-configmap-5dps7 deletion completed in 6.317104319s

• [SLOW TEST:14.694 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:49:34.794: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-nzckp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 13 09:49:41.610: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6d715343-e729-11e8-baa5-625675597e81"
Nov 13 09:49:41.612: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6d715343-e729-11e8-baa5-625675597e81" in namespace "e2e-tests-pods-nzckp" to be "terminated due to deadline exceeded"
Nov 13 09:49:41.617: INFO: Pod "pod-update-activedeadlineseconds-6d715343-e729-11e8-baa5-625675597e81": Phase="Running", Reason="", readiness=true. Elapsed: 4.825329ms
Nov 13 09:49:43.710: INFO: Pod "pod-update-activedeadlineseconds-6d715343-e729-11e8-baa5-625675597e81": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.097466466s
Nov 13 09:49:43.710: INFO: Pod "pod-update-activedeadlineseconds-6d715343-e729-11e8-baa5-625675597e81" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:49:43.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nzckp" for this suite.
Nov 13 09:49:49.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:49:49.811: INFO: namespace: e2e-tests-pods-nzckp, resource: bindings, ignored listing per whitelist
Nov 13 09:49:49.899: INFO: namespace e2e-tests-pods-nzckp deletion completed in 6.185670468s

• [SLOW TEST:15.106 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:49:49.899: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-xtvhm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xtvhm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 13 09:49:50.170: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 13 09:50:20.278: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.103:8080/dial?request=hostName&protocol=udp&host=100.96.0.34&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-xtvhm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:50:20.278: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:50:20.723: INFO: Waiting for endpoints: map[]
Nov 13 09:50:20.726: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.103:8080/dial?request=hostName&protocol=udp&host=100.96.1.102&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-xtvhm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:50:20.726: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:50:21.078: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:50:21.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xtvhm" for this suite.
Nov 13 09:50:43.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:50:43.161: INFO: namespace: e2e-tests-pod-network-test-xtvhm, resource: bindings, ignored listing per whitelist
Nov 13 09:50:43.476: INFO: namespace e2e-tests-pod-network-test-xtvhm deletion completed in 22.393509938s

• [SLOW TEST:53.577 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:50:43.477: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-95srt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 09:50:43.907: INFO: Waiting up to 5m0s for pod "downwardapi-volume-96796990-e729-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-95srt" to be "success or failure"
Nov 13 09:50:43.945: INFO: Pod "downwardapi-volume-96796990-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 38.830836ms
Nov 13 09:50:45.949: INFO: Pod "downwardapi-volume-96796990-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042292331s
Nov 13 09:50:47.952: INFO: Pod "downwardapi-volume-96796990-e729-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045563368s
Nov 13 09:50:49.956: INFO: Pod "downwardapi-volume-96796990-e729-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.049320636s
STEP: Saw pod success
Nov 13 09:50:49.956: INFO: Pod "downwardapi-volume-96796990-e729-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:50:49.959: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-96796990-e729-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 09:50:50.064: INFO: Waiting for pod downwardapi-volume-96796990-e729-11e8-baa5-625675597e81 to disappear
Nov 13 09:50:50.119: INFO: Pod downwardapi-volume-96796990-e729-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:50:50.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-95srt" for this suite.
Nov 13 09:50:56.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:50:56.363: INFO: namespace: e2e-tests-projected-95srt, resource: bindings, ignored listing per whitelist
Nov 13 09:50:56.406: INFO: namespace e2e-tests-projected-95srt deletion completed in 6.284246043s

• [SLOW TEST:12.930 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:50:56.407: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-nxkj2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-nxkj2
Nov 13 09:51:02.656: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-nxkj2
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 09:51:02.659: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:55:03.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nxkj2" for this suite.
Nov 13 09:55:09.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:55:09.770: INFO: namespace: e2e-tests-container-probe-nxkj2, resource: bindings, ignored listing per whitelist
Nov 13 09:55:09.827: INFO: namespace e2e-tests-container-probe-nxkj2 deletion completed in 6.267323916s

• [SLOW TEST:253.420 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:55:09.827: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qcfg7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3524373d-e72a-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 09:55:10.122: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-qcfg7" to be "success or failure"
Nov 13 09:55:10.127: INFO: Pod "pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.03363ms
Nov 13 09:55:12.143: INFO: Pod "pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02088734s
Nov 13 09:55:14.146: INFO: Pod "pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024185424s
Nov 13 09:55:16.149: INFO: Pod "pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027508519s
STEP: Saw pod success
Nov 13 09:55:16.149: INFO: Pod "pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:55:16.152: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 09:55:16.216: INFO: Waiting for pod pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81 to disappear
Nov 13 09:55:16.221: INFO: Pod pod-projected-secrets-3524e4ad-e72a-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:55:16.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qcfg7" for this suite.
Nov 13 09:55:22.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:55:22.316: INFO: namespace: e2e-tests-projected-qcfg7, resource: bindings, ignored listing per whitelist
Nov 13 09:55:22.373: INFO: namespace e2e-tests-projected-qcfg7 deletion completed in 6.143563358s

• [SLOW TEST:12.545 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:55:22.373: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-pccf2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1113 09:55:23.871896      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 09:55:23.871: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:55:23.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pccf2" for this suite.
Nov 13 09:55:29.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:55:30.064: INFO: namespace: e2e-tests-gc-pccf2, resource: bindings, ignored listing per whitelist
Nov 13 09:55:30.088: INFO: namespace e2e-tests-gc-pccf2 deletion completed in 6.213569804s

• [SLOW TEST:7.715 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:55:30.088: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-9klbf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-9klbf
Nov 13 09:55:36.459: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-9klbf
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 09:55:36.461: INFO: Initial restart count of pod liveness-exec is 0
Nov 13 09:56:26.705: INFO: Restart count of pod e2e-tests-container-probe-9klbf/liveness-exec is now 1 (50.243428967s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:56:26.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9klbf" for this suite.
Nov 13 09:56:32.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:56:32.908: INFO: namespace: e2e-tests-container-probe-9klbf, resource: bindings, ignored listing per whitelist
Nov 13 09:56:32.910: INFO: namespace e2e-tests-container-probe-9klbf deletion completed in 6.1765665s

• [SLOW TEST:62.822 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:56:32.911: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-wj7mb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-ls6h
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 09:56:33.169: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-ls6h" in namespace "e2e-tests-subpath-wj7mb" to be "success or failure"
Nov 13 09:56:33.213: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Pending", Reason="", readiness=false. Elapsed: 44.227591ms
Nov 13 09:56:35.218: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04904898s
Nov 13 09:56:37.222: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052814707s
Nov 13 09:56:39.225: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055965286s
Nov 13 09:56:41.245: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Pending", Reason="", readiness=false. Elapsed: 8.075652351s
Nov 13 09:56:43.248: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 10.078683858s
Nov 13 09:56:45.251: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 12.082292318s
Nov 13 09:56:47.255: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 14.085600125s
Nov 13 09:56:49.258: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 16.088782379s
Nov 13 09:56:51.261: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 18.091903882s
Nov 13 09:56:53.264: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 20.095536836s
Nov 13 09:56:55.269: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 22.099876742s
Nov 13 09:56:57.272: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 24.103523092s
Nov 13 09:56:59.276: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 26.106906987s
Nov 13 09:57:01.286: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Running", Reason="", readiness=false. Elapsed: 28.117492772s
Nov 13 09:57:03.290: INFO: Pod "pod-subpath-test-secret-ls6h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.121474829s
STEP: Saw pod success
Nov 13 09:57:03.290: INFO: Pod "pod-subpath-test-secret-ls6h" satisfied condition "success or failure"
Nov 13 09:57:03.293: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-subpath-test-secret-ls6h container test-container-subpath-secret-ls6h: <nil>
STEP: delete the pod
Nov 13 09:57:03.407: INFO: Waiting for pod pod-subpath-test-secret-ls6h to disappear
Nov 13 09:57:03.420: INFO: Pod pod-subpath-test-secret-ls6h no longer exists
STEP: Deleting pod pod-subpath-test-secret-ls6h
Nov 13 09:57:03.421: INFO: Deleting pod "pod-subpath-test-secret-ls6h" in namespace "e2e-tests-subpath-wj7mb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:57:03.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wj7mb" for this suite.
Nov 13 09:57:09.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:57:09.450: INFO: namespace: e2e-tests-subpath-wj7mb, resource: bindings, ignored listing per whitelist
Nov 13 09:57:09.598: INFO: namespace e2e-tests-subpath-wj7mb deletion completed in 6.167957665s

• [SLOW TEST:36.687 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:57:09.598: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-9j7zc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-vrthj
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-z4fck
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:57:16.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-9j7zc" for this suite.
Nov 13 09:57:22.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:57:22.470: INFO: namespace: e2e-tests-namespaces-9j7zc, resource: bindings, ignored listing per whitelist
Nov 13 09:57:22.536: INFO: namespace e2e-tests-namespaces-9j7zc deletion completed in 6.173002983s
STEP: Destroying namespace "e2e-tests-nsdeletetest-vrthj" for this suite.
Nov 13 09:57:22.539: INFO: Namespace e2e-tests-nsdeletetest-vrthj was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-z4fck" for this suite.
Nov 13 09:57:28.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:57:28.682: INFO: namespace: e2e-tests-nsdeletetest-z4fck, resource: bindings, ignored listing per whitelist
Nov 13 09:57:28.712: INFO: namespace e2e-tests-nsdeletetest-z4fck deletion completed in 6.172855433s

• [SLOW TEST:19.114 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:57:28.712: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-sq4rl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-87e904ff-e72a-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 09:57:28.975: INFO: Waiting up to 5m0s for pod "pod-secrets-87e9c953-e72a-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-sq4rl" to be "success or failure"
Nov 13 09:57:28.980: INFO: Pod "pod-secrets-87e9c953-e72a-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.593931ms
Nov 13 09:57:30.983: INFO: Pod "pod-secrets-87e9c953-e72a-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008379251s
Nov 13 09:57:32.987: INFO: Pod "pod-secrets-87e9c953-e72a-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011813271s
STEP: Saw pod success
Nov 13 09:57:32.987: INFO: Pod "pod-secrets-87e9c953-e72a-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:57:32.990: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-secrets-87e9c953-e72a-11e8-baa5-625675597e81 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 09:57:33.023: INFO: Waiting for pod pod-secrets-87e9c953-e72a-11e8-baa5-625675597e81 to disappear
Nov 13 09:57:33.037: INFO: Pod pod-secrets-87e9c953-e72a-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:57:33.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sq4rl" for this suite.
Nov 13 09:57:39.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:57:39.142: INFO: namespace: e2e-tests-secrets-sq4rl, resource: bindings, ignored listing per whitelist
Nov 13 09:57:39.149: INFO: namespace e2e-tests-secrets-sq4rl deletion completed in 6.107867995s

• [SLOW TEST:10.437 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:57:39.151: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-jjjkh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov 13 09:57:55.552: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:55.552: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:55.973: INFO: Exec stderr: ""
Nov 13 09:57:55.973: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:55.973: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:56.439: INFO: Exec stderr: ""
Nov 13 09:57:56.439: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:56.439: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:56.871: INFO: Exec stderr: ""
Nov 13 09:57:56.871: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:56.871: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:57.309: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov 13 09:57:57.309: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:57.309: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:57.721: INFO: Exec stderr: ""
Nov 13 09:57:57.721: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:57.721: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:58.140: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov 13 09:57:58.140: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:58.140: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:58.572: INFO: Exec stderr: ""
Nov 13 09:57:58.572: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:58.572: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:58.974: INFO: Exec stderr: ""
Nov 13 09:57:58.974: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:58.974: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:59.355: INFO: Exec stderr: ""
Nov 13 09:57:59.355: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jjjkh PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 09:57:59.355: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 09:57:59.832: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:57:59.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-jjjkh" for this suite.
Nov 13 09:58:41.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:58:42.053: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-jjjkh, resource: bindings, ignored listing per whitelist
Nov 13 09:58:42.138: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-jjjkh deletion completed in 42.301760763s

• [SLOW TEST:62.987 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:58:42.138: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-fmn5z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-fmn5z/configmap-test-b3b1e6d1-e72a-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 09:58:42.432: INFO: Waiting up to 5m0s for pod "pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-fmn5z" to be "success or failure"
Nov 13 09:58:42.440: INFO: Pod "pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 7.342147ms
Nov 13 09:58:44.444: INFO: Pod "pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012286048s
Nov 13 09:58:46.448: INFO: Pod "pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016148197s
Nov 13 09:58:48.452: INFO: Pod "pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019824359s
STEP: Saw pod success
Nov 13 09:58:48.452: INFO: Pod "pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 09:58:48.454: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81 container env-test: <nil>
STEP: delete the pod
Nov 13 09:58:48.586: INFO: Waiting for pod pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81 to disappear
Nov 13 09:58:48.593: INFO: Pod pod-configmaps-b3b251fc-e72a-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 09:58:48.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fmn5z" for this suite.
Nov 13 09:58:54.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 09:58:54.719: INFO: namespace: e2e-tests-configmap-fmn5z, resource: bindings, ignored listing per whitelist
Nov 13 09:58:54.757: INFO: namespace e2e-tests-configmap-fmn5z deletion completed in 6.15548397s

• [SLOW TEST:12.618 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 09:58:54.757: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6jsnf
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-bb3ace95-e72a-11e8-baa5-625675597e81
STEP: Creating configMap with name cm-test-opt-upd-bb3acecb-e72a-11e8-baa5-625675597e81
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-bb3ace95-e72a-11e8-baa5-625675597e81
STEP: Updating configmap cm-test-opt-upd-bb3acecb-e72a-11e8-baa5-625675597e81
STEP: Creating configMap with name cm-test-opt-create-bb3acef9-e72a-11e8-baa5-625675597e81
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:00:32.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6jsnf" for this suite.
Nov 13 10:00:54.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:00:54.861: INFO: namespace: e2e-tests-configmap-6jsnf, resource: bindings, ignored listing per whitelist
Nov 13 10:00:54.865: INFO: namespace e2e-tests-configmap-6jsnf deletion completed in 22.220082287s

• [SLOW TEST:120.108 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:00:54.865: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-4krxm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4krxm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 13 10:00:55.077: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 13 10:01:21.152: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.114:8080/dial?request=hostName&protocol=http&host=100.96.0.35&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4krxm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:01:21.152: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 10:01:21.517: INFO: Waiting for endpoints: map[]
Nov 13 10:01:21.522: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.114:8080/dial?request=hostName&protocol=http&host=100.96.1.113&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4krxm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:01:21.522: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
Nov 13 10:01:21.872: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:01:21.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4krxm" for this suite.
Nov 13 10:01:43.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:01:44.063: INFO: namespace: e2e-tests-pod-network-test-4krxm, resource: bindings, ignored listing per whitelist
Nov 13 10:01:44.132: INFO: namespace e2e-tests-pod-network-test-4krxm deletion completed in 22.25612513s

• [SLOW TEST:49.266 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:01:44.132: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wnjr2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov 13 10:01:49.156: INFO: Successfully updated pod "annotationupdate2029a95a-e72b-11e8-baa5-625675597e81"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:01:51.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wnjr2" for this suite.
Nov 13 10:02:13.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:02:13.302: INFO: namespace: e2e-tests-downward-api-wnjr2, resource: bindings, ignored listing per whitelist
Nov 13 10:02:13.381: INFO: namespace e2e-tests-downward-api-wnjr2 deletion completed in 22.135168053s

• [SLOW TEST:29.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:02:13.381: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-nj6sp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 13 10:02:13.728: INFO: Waiting up to 5m0s for pod "pod-31a38443-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-nj6sp" to be "success or failure"
Nov 13 10:02:13.732: INFO: Pod "pod-31a38443-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.463928ms
Nov 13 10:02:15.735: INFO: Pod "pod-31a38443-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007212994s
Nov 13 10:02:17.739: INFO: Pod "pod-31a38443-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010776317s
Nov 13 10:02:19.743: INFO: Pod "pod-31a38443-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0148947s
STEP: Saw pod success
Nov 13 10:02:19.743: INFO: Pod "pod-31a38443-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:02:19.745: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-31a38443-e72b-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:02:19.767: INFO: Waiting for pod pod-31a38443-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:02:19.803: INFO: Pod pod-31a38443-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:02:19.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nj6sp" for this suite.
Nov 13 10:02:25.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:02:25.849: INFO: namespace: e2e-tests-emptydir-nj6sp, resource: bindings, ignored listing per whitelist
Nov 13 10:02:25.964: INFO: namespace e2e-tests-emptydir-nj6sp deletion completed in 6.157488953s

• [SLOW TEST:12.582 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:02:25.964: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-bnhs2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:02:26.257: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Nov 13 10:02:26.262: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bnhs2/daemonsets","resourceVersion":"14236"},"items":null}

Nov 13 10:02:26.265: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bnhs2/pods","resourceVersion":"14236"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:02:26.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bnhs2" for this suite.
Nov 13 10:02:32.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:02:32.374: INFO: namespace: e2e-tests-daemonsets-bnhs2, resource: bindings, ignored listing per whitelist
Nov 13 10:02:32.391: INFO: namespace e2e-tests-daemonsets-bnhs2 deletion completed in 6.114044954s

S [SKIPPING] [6.428 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Nov 13 10:02:26.257: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:02:32.392: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-k8lq2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 13 10:02:32.670: INFO: Waiting up to 5m0s for pod "pod-3ceb7739-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-k8lq2" to be "success or failure"
Nov 13 10:02:32.680: INFO: Pod "pod-3ceb7739-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 9.762966ms
Nov 13 10:02:34.683: INFO: Pod "pod-3ceb7739-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012944927s
Nov 13 10:02:36.688: INFO: Pod "pod-3ceb7739-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017589825s
STEP: Saw pod success
Nov 13 10:02:36.688: INFO: Pod "pod-3ceb7739-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:02:36.690: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-3ceb7739-e72b-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:02:36.730: INFO: Waiting for pod pod-3ceb7739-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:02:36.736: INFO: Pod pod-3ceb7739-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:02:36.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k8lq2" for this suite.
Nov 13 10:02:42.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:02:42.839: INFO: namespace: e2e-tests-emptydir-k8lq2, resource: bindings, ignored listing per whitelist
Nov 13 10:02:42.893: INFO: namespace e2e-tests-emptydir-k8lq2 deletion completed in 6.149413157s

• [SLOW TEST:10.501 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:02:42.893: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vjhgx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-4330622a-e72b-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:02:43.174: INFO: Waiting up to 5m0s for pod "pod-configmaps-4330d39d-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-vjhgx" to be "success or failure"
Nov 13 10:02:43.180: INFO: Pod "pod-configmaps-4330d39d-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.377937ms
Nov 13 10:02:45.183: INFO: Pod "pod-configmaps-4330d39d-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008682571s
Nov 13 10:02:47.188: INFO: Pod "pod-configmaps-4330d39d-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01342613s
STEP: Saw pod success
Nov 13 10:02:47.188: INFO: Pod "pod-configmaps-4330d39d-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:02:47.190: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-4330d39d-e72b-11e8-baa5-625675597e81 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:02:47.249: INFO: Waiting for pod pod-configmaps-4330d39d-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:02:47.260: INFO: Pod pod-configmaps-4330d39d-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:02:47.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vjhgx" for this suite.
Nov 13 10:02:53.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:02:53.448: INFO: namespace: e2e-tests-configmap-vjhgx, resource: bindings, ignored listing per whitelist
Nov 13 10:02:53.510: INFO: namespace e2e-tests-configmap-vjhgx deletion completed in 6.246791205s

• [SLOW TEST:10.617 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:02:53.510: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4dqdf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-497c2610-e72b-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:02:53.736: INFO: Waiting up to 5m0s for pod "pod-configmaps-497c90eb-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-4dqdf" to be "success or failure"
Nov 13 10:02:53.741: INFO: Pod "pod-configmaps-497c90eb-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.121226ms
Nov 13 10:02:55.744: INFO: Pod "pod-configmaps-497c90eb-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007689315s
Nov 13 10:02:57.748: INFO: Pod "pod-configmaps-497c90eb-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010994822s
STEP: Saw pod success
Nov 13 10:02:57.748: INFO: Pod "pod-configmaps-497c90eb-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:02:57.750: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-497c90eb-e72b-11e8-baa5-625675597e81 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:02:57.837: INFO: Waiting for pod pod-configmaps-497c90eb-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:02:57.863: INFO: Pod pod-configmaps-497c90eb-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:02:57.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4dqdf" for this suite.
Nov 13 10:03:03.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:03:03.945: INFO: namespace: e2e-tests-configmap-4dqdf, resource: bindings, ignored listing per whitelist
Nov 13 10:03:04.090: INFO: namespace e2e-tests-configmap-4dqdf deletion completed in 6.219969438s

• [SLOW TEST:10.580 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:03:04.090: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ws7vd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4fd05c5d-e72b-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:03:04.355: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-ws7vd" to be "success or failure"
Nov 13 10:03:04.456: INFO: Pod "pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 100.343443ms
Nov 13 10:03:06.459: INFO: Pod "pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103604005s
Nov 13 10:03:08.462: INFO: Pod "pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.106782999s
Nov 13 10:03:10.466: INFO: Pod "pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.110565141s
Nov 13 10:03:12.469: INFO: Pod "pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.113933935s
STEP: Saw pod success
Nov 13 10:03:12.469: INFO: Pod "pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:03:12.471: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:03:12.595: INFO: Waiting for pod pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:03:12.599: INFO: Pod pod-projected-configmaps-4fd0c905-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:03:12.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ws7vd" for this suite.
Nov 13 10:03:18.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:03:19.041: INFO: namespace: e2e-tests-projected-ws7vd, resource: bindings, ignored listing per whitelist
Nov 13 10:03:19.050: INFO: namespace e2e-tests-projected-ws7vd deletion completed in 6.446885021s

• [SLOW TEST:14.959 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:03:19.050: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-b9l84
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 13 10:03:19.342: INFO: Waiting up to 5m0s for pod "pod-58bfca8b-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-b9l84" to be "success or failure"
Nov 13 10:03:19.352: INFO: Pod "pod-58bfca8b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.372431ms
Nov 13 10:03:21.355: INFO: Pod "pod-58bfca8b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009856457s
Nov 13 10:03:23.360: INFO: Pod "pod-58bfca8b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014702505s
Nov 13 10:03:25.364: INFO: Pod "pod-58bfca8b-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01835751s
STEP: Saw pod success
Nov 13 10:03:25.364: INFO: Pod "pod-58bfca8b-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:03:25.366: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-58bfca8b-e72b-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:03:25.399: INFO: Waiting for pod pod-58bfca8b-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:03:25.413: INFO: Pod pod-58bfca8b-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:03:25.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b9l84" for this suite.
Nov 13 10:03:31.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:03:31.530: INFO: namespace: e2e-tests-emptydir-b9l84, resource: bindings, ignored listing per whitelist
Nov 13 10:03:31.561: INFO: namespace e2e-tests-emptydir-b9l84 deletion completed in 6.145172135s

• [SLOW TEST:12.511 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:03:31.562: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-zpf52
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:03:31.783: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 13 10:03:36.800: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 13 10:03:36.800: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 13 10:03:36.828: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-zpf52,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zpf52/deployments/test-cleanup-deployment,UID:632a1d2a-e72b-11e8-90ec-1a79c3ab02d1,ResourceVersion:14491,Generation:1,CreationTimestamp:2018-11-13 10:03:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Nov 13 10:03:36.833: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Nov 13 10:03:36.833: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov 13 10:03:36.833: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-zpf52,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zpf52/replicasets/test-cleanup-controller,UID:60297996-e72b-11e8-90ec-1a79c3ab02d1,ResourceVersion:14492,Generation:1,CreationTimestamp:2018-11-13 10:03:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 632a1d2a-e72b-11e8-90ec-1a79c3ab02d1 0xc4214ed1c7 0xc4214ed1c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 13 10:03:36.837: INFO: Pod "test-cleanup-controller-nzh5r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-nzh5r,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-zpf52,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zpf52/pods/test-cleanup-controller-nzh5r,UID:602ad400-e72b-11e8-90ec-1a79c3ab02d1,ResourceVersion:14485,Generation:0,CreationTimestamp:2018-11-13 10:03:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.122/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 60297996-e72b-11e8-90ec-1a79c3ab02d1 0xc4217cea77 0xc4217cea78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bgqnn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bgqnn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bgqnn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217ceb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217cec10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:03:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:03:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:03:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:03:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.1.122,StartTime:2018-11-13 10:03:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:03:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://25df53d95645a47697fb171e8dc158e5458052c52f62d27a6d0610b6f7795146}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:03:36.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-zpf52" for this suite.
Nov 13 10:03:42.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:03:43.019: INFO: namespace: e2e-tests-deployment-zpf52, resource: bindings, ignored listing per whitelist
Nov 13 10:03:43.220: INFO: namespace e2e-tests-deployment-zpf52 deletion completed in 6.350640264s

• [SLOW TEST:11.658 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:03:43.221: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qvh64
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:03:43.490: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-qvh64" to be "success or failure"
Nov 13 10:03:43.493: INFO: Pod "downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 3.344022ms
Nov 13 10:03:45.496: INFO: Pod "downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006609999s
Nov 13 10:03:47.499: INFO: Pod "downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009741671s
Nov 13 10:03:49.505: INFO: Pod "downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014782182s
STEP: Saw pod success
Nov 13 10:03:49.505: INFO: Pod "downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:03:49.507: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:03:49.566: INFO: Waiting for pod downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:03:49.577: INFO: Pod downwardapi-volume-67245d61-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:03:49.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qvh64" for this suite.
Nov 13 10:03:55.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:03:55.707: INFO: namespace: e2e-tests-projected-qvh64, resource: bindings, ignored listing per whitelist
Nov 13 10:03:55.718: INFO: namespace e2e-tests-projected-qvh64 deletion completed in 6.138514873s

• [SLOW TEST:12.498 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:03:55.719: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-92jxb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 13 10:03:56.021: INFO: Waiting up to 5m0s for pod "pod-6e9aa311-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-92jxb" to be "success or failure"
Nov 13 10:03:56.038: INFO: Pod "pod-6e9aa311-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 17.374412ms
Nov 13 10:03:58.042: INFO: Pod "pod-6e9aa311-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020644098s
Nov 13 10:04:00.045: INFO: Pod "pod-6e9aa311-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024414256s
Nov 13 10:04:02.049: INFO: Pod "pod-6e9aa311-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027932454s
STEP: Saw pod success
Nov 13 10:04:02.049: INFO: Pod "pod-6e9aa311-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:04:02.051: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-6e9aa311-e72b-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:04:02.098: INFO: Waiting for pod pod-6e9aa311-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:04:02.107: INFO: Pod pod-6e9aa311-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:04:02.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-92jxb" for this suite.
Nov 13 10:04:08.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:04:08.178: INFO: namespace: e2e-tests-emptydir-92jxb, resource: bindings, ignored listing per whitelist
Nov 13 10:04:08.267: INFO: namespace e2e-tests-emptydir-92jxb deletion completed in 6.149026441s

• [SLOW TEST:12.549 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:04:08.267: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-nvktf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov 13 10:04:08.571: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nvktf,SelfLink:/api/v1/namespaces/e2e-tests-watch-nvktf/configmaps/e2e-watch-test-watch-closed,UID:761666d1-e72b-11e8-90ec-1a79c3ab02d1,ResourceVersion:14628,Generation:0,CreationTimestamp:2018-11-13 10:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 10:04:08.571: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nvktf,SelfLink:/api/v1/namespaces/e2e-tests-watch-nvktf/configmaps/e2e-watch-test-watch-closed,UID:761666d1-e72b-11e8-90ec-1a79c3ab02d1,ResourceVersion:14629,Generation:0,CreationTimestamp:2018-11-13 10:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov 13 10:04:08.591: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nvktf,SelfLink:/api/v1/namespaces/e2e-tests-watch-nvktf/configmaps/e2e-watch-test-watch-closed,UID:761666d1-e72b-11e8-90ec-1a79c3ab02d1,ResourceVersion:14630,Generation:0,CreationTimestamp:2018-11-13 10:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 10:04:08.592: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nvktf,SelfLink:/api/v1/namespaces/e2e-tests-watch-nvktf/configmaps/e2e-watch-test-watch-closed,UID:761666d1-e72b-11e8-90ec-1a79c3ab02d1,ResourceVersion:14631,Generation:0,CreationTimestamp:2018-11-13 10:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:04:08.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nvktf" for this suite.
Nov 13 10:04:14.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:04:14.666: INFO: namespace: e2e-tests-watch-nvktf, resource: bindings, ignored listing per whitelist
Nov 13 10:04:14.761: INFO: namespace e2e-tests-watch-nvktf deletion completed in 6.158729535s

• [SLOW TEST:6.494 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:04:14.762: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-7rb2k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Nov 13 10:04:15.018: INFO: Waiting up to 5m0s for pod "client-containers-79ef46a9-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-containers-7rb2k" to be "success or failure"
Nov 13 10:04:15.022: INFO: Pod "client-containers-79ef46a9-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.324229ms
Nov 13 10:04:17.026: INFO: Pod "client-containers-79ef46a9-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007837236s
Nov 13 10:04:19.033: INFO: Pod "client-containers-79ef46a9-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015251283s
Nov 13 10:04:21.036: INFO: Pod "client-containers-79ef46a9-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018342283s
STEP: Saw pod success
Nov 13 10:04:21.036: INFO: Pod "client-containers-79ef46a9-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:04:21.039: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod client-containers-79ef46a9-e72b-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:04:21.162: INFO: Waiting for pod client-containers-79ef46a9-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:04:21.179: INFO: Pod client-containers-79ef46a9-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:04:21.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7rb2k" for this suite.
Nov 13 10:04:27.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:04:27.305: INFO: namespace: e2e-tests-containers-7rb2k, resource: bindings, ignored listing per whitelist
Nov 13 10:04:27.422: INFO: namespace e2e-tests-containers-7rb2k deletion completed in 6.239669443s

• [SLOW TEST:12.660 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:04:27.422: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sf5fd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Nov 13 10:04:27.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 api-versions'
Nov 13 10:04:27.836: INFO: stderr: ""
Nov 13 10:04:27.836: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:04:27.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sf5fd" for this suite.
Nov 13 10:04:33.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:04:33.982: INFO: namespace: e2e-tests-kubectl-sf5fd, resource: bindings, ignored listing per whitelist
Nov 13 10:04:34.015: INFO: namespace e2e-tests-kubectl-sf5fd deletion completed in 6.174975308s

• [SLOW TEST:6.593 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:04:34.017: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b6dhl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Nov 13 10:04:34.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 --namespace=e2e-tests-kubectl-b6dhl run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov 13 10:04:42.199: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov 13 10:04:42.199: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:04:44.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b6dhl" for this suite.
Nov 13 10:04:50.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:04:50.428: INFO: namespace: e2e-tests-kubectl-b6dhl, resource: bindings, ignored listing per whitelist
Nov 13 10:04:50.433: INFO: namespace e2e-tests-kubectl-b6dhl deletion completed in 6.187541621s

• [SLOW TEST:16.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:04:50.434: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4s9db
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8f34b2b9-e72b-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:04:50.806: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-4s9db" to be "success or failure"
Nov 13 10:04:50.832: INFO: Pod "pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 25.470764ms
Nov 13 10:04:52.835: INFO: Pod "pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028988372s
Nov 13 10:04:54.839: INFO: Pod "pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03248102s
Nov 13 10:04:56.842: INFO: Pod "pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03612943s
Nov 13 10:04:58.846: INFO: Pod "pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.039462818s
STEP: Saw pod success
Nov 13 10:04:58.846: INFO: Pod "pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:04:58.858: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:04:58.879: INFO: Waiting for pod pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:04:58.892: INFO: Pod pod-configmaps-8f40782f-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:04:58.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4s9db" for this suite.
Nov 13 10:05:04.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:05:04.947: INFO: namespace: e2e-tests-configmap-4s9db, resource: bindings, ignored listing per whitelist
Nov 13 10:05:05.045: INFO: namespace e2e-tests-configmap-4s9db deletion completed in 6.148208188s

• [SLOW TEST:14.611 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:05:05.046: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jchfk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Nov 13 10:05:05.259: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-071128755 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:05:05.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jchfk" for this suite.
Nov 13 10:05:11.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:05:11.487: INFO: namespace: e2e-tests-kubectl-jchfk, resource: bindings, ignored listing per whitelist
Nov 13 10:05:11.517: INFO: namespace e2e-tests-kubectl-jchfk deletion completed in 6.176341653s

• [SLOW TEST:6.471 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:05:11.517: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-df9qt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 13 10:05:19.811: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:19.815: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:21.815: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:21.819: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:23.815: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:23.849: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:25.815: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:25.818: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:27.815: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:27.819: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:29.815: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:29.819: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:31.815: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:31.818: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:33.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:33.820: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:35.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:35.819: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:37.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:37.819: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:39.815: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:39.818: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:05:41.815: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:05:41.818: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:05:41.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-df9qt" for this suite.
Nov 13 10:06:03.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:06:04.076: INFO: namespace: e2e-tests-container-lifecycle-hook-df9qt, resource: bindings, ignored listing per whitelist
Nov 13 10:06:04.085: INFO: namespace e2e-tests-container-lifecycle-hook-df9qt deletion completed in 22.263559262s

• [SLOW TEST:52.567 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:06:04.085: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-bqlh9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-bb1c4a83-e72b-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:06:04.370: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb1cbb0b-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-bqlh9" to be "success or failure"
Nov 13 10:06:04.387: INFO: Pod "pod-configmaps-bb1cbb0b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 17.044211ms
Nov 13 10:06:06.390: INFO: Pod "pod-configmaps-bb1cbb0b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020327095s
Nov 13 10:06:08.393: INFO: Pod "pod-configmaps-bb1cbb0b-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023456724s
STEP: Saw pod success
Nov 13 10:06:08.393: INFO: Pod "pod-configmaps-bb1cbb0b-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:06:08.445: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-bb1cbb0b-e72b-11e8-baa5-625675597e81 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:06:08.519: INFO: Waiting for pod pod-configmaps-bb1cbb0b-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:06:08.531: INFO: Pod pod-configmaps-bb1cbb0b-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:06:08.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bqlh9" for this suite.
Nov 13 10:06:14.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:06:14.705: INFO: namespace: e2e-tests-configmap-bqlh9, resource: bindings, ignored listing per whitelist
Nov 13 10:06:14.716: INFO: namespace e2e-tests-configmap-bqlh9 deletion completed in 6.182329502s

• [SLOW TEST:10.630 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:06:14.716: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-sf7b5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Nov 13 10:06:21.034: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-c16eb923-e72b-11e8-baa5-625675597e81", GenerateName:"", Namespace:"e2e-tests-pods-sf7b5", SelfLink:"/api/v1/namespaces/e2e-tests-pods-sf7b5/pods/pod-submit-remove-c16eb923-e72b-11e8-baa5-625675597e81", UID:"c16f2116-e72b-11e8-90ec-1a79c3ab02d1", ResourceVersion:"15034", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63677700374, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"966925510"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.132/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-xhvw6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422a89cc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xhvw6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc423100708), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4231d1c20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc423100740)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc423100760)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc423100768), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677700375, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677700379, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677700379, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677700374, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.5", PodIP:"100.96.1.132", StartTime:(*v1.Time)(0xc422b4b8c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc422b4b8e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7", ContainerID:"docker://d48341b81de0f09de40795d559c3a3ddc7b8f90ae9b3ccd3a199cf4b17521c6c"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:06:30.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sf7b5" for this suite.
Nov 13 10:06:36.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:06:36.244: INFO: namespace: e2e-tests-pods-sf7b5, resource: bindings, ignored listing per whitelist
Nov 13 10:06:36.417: INFO: namespace e2e-tests-pods-sf7b5 deletion completed in 6.235242545s

• [SLOW TEST:21.701 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:06:36.417: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qrmjs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-ce5e0dc3-e72b-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 10:06:36.677: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-qrmjs" to be "success or failure"
Nov 13 10:06:36.683: INFO: Pod "pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.252441ms
Nov 13 10:06:38.687: INFO: Pod "pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009706329s
Nov 13 10:06:40.690: INFO: Pod "pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01312049s
Nov 13 10:06:42.694: INFO: Pod "pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016738184s
STEP: Saw pod success
Nov 13 10:06:42.694: INFO: Pod "pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:06:42.696: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:06:42.732: INFO: Waiting for pod pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:06:42.745: INFO: Pod pod-projected-secrets-ce5e76a8-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:06:42.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qrmjs" for this suite.
Nov 13 10:06:48.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:06:48.866: INFO: namespace: e2e-tests-projected-qrmjs, resource: bindings, ignored listing per whitelist
Nov 13 10:06:48.917: INFO: namespace e2e-tests-projected-qrmjs deletion completed in 6.163383908s

• [SLOW TEST:12.500 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:06:48.917: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rgjkj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 13 10:06:49.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rgjkj'
Nov 13 10:07:04.767: INFO: stderr: ""
Nov 13 10:07:04.767: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Nov 13 10:07:09.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rgjkj -o json'
Nov 13 10:07:09.927: INFO: stderr: ""
Nov 13 10:07:09.927: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.1.134/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2018-11-13T10:07:04Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-rgjkj\",\n        \"resourceVersion\": \"15170\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-rgjkj/pods/e2e-test-nginx-pod\",\n        \"uid\": \"df1a725a-e72b-11e8-90ec-1a79c3ab02d1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-vzm2q\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-vzm2q\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-vzm2q\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-13T10:07:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-13T10:07:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-13T10:07:08Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-13T10:07:04Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://040531713ee96b1fb1612cb919ecb078c020dee55b57efc4e4cec1a08448dfe8\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-11-13T10:07:07Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.134\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-11-13T10:07:04Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov 13 10:07:09.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 replace -f - --namespace=e2e-tests-kubectl-rgjkj'
Nov 13 10:07:10.411: INFO: stderr: ""
Nov 13 10:07:10.411: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Nov 13 10:07:10.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rgjkj'
Nov 13 10:07:20.163: INFO: stderr: ""
Nov 13 10:07:20.163: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:07:20.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rgjkj" for this suite.
Nov 13 10:07:26.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:07:26.282: INFO: namespace: e2e-tests-kubectl-rgjkj, resource: bindings, ignored listing per whitelist
Nov 13 10:07:26.357: INFO: namespace e2e-tests-kubectl-rgjkj deletion completed in 6.159841699s

• [SLOW TEST:37.440 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:07:26.357: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-9n48r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:07:26.670: INFO: (0) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.770847ms)
Nov 13 10:07:26.714: INFO: (1) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 43.807304ms)
Nov 13 10:07:26.726: INFO: (2) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.134284ms)
Nov 13 10:07:26.730: INFO: (3) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.22643ms)
Nov 13 10:07:26.734: INFO: (4) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.259929ms)
Nov 13 10:07:26.739: INFO: (5) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.679832ms)
Nov 13 10:07:26.743: INFO: (6) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.397131ms)
Nov 13 10:07:26.748: INFO: (7) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.31433ms)
Nov 13 10:07:26.752: INFO: (8) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.646232ms)
Nov 13 10:07:26.757: INFO: (9) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.38023ms)
Nov 13 10:07:26.761: INFO: (10) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.022728ms)
Nov 13 10:07:26.766: INFO: (11) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.959435ms)
Nov 13 10:07:26.771: INFO: (12) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.993734ms)
Nov 13 10:07:26.834: INFO: (13) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 63.233739ms)
Nov 13 10:07:26.839: INFO: (14) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.710333ms)
Nov 13 10:07:26.844: INFO: (15) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.538632ms)
Nov 13 10:07:26.849: INFO: (16) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.972234ms)
Nov 13 10:07:26.853: INFO: (17) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.435431ms)
Nov 13 10:07:26.858: INFO: (18) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.41903ms)
Nov 13 10:07:26.863: INFO: (19) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.294836ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:07:26.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9n48r" for this suite.
Nov 13 10:07:32.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:07:33.149: INFO: namespace: e2e-tests-proxy-9n48r, resource: bindings, ignored listing per whitelist
Nov 13 10:07:33.167: INFO: namespace e2e-tests-proxy-9n48r deletion completed in 6.301493015s

• [SLOW TEST:6.810 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:07:33.167: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qwhk6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f02bfd26-e72b-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 10:07:33.416: INFO: Waiting up to 5m0s for pod "pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-qwhk6" to be "success or failure"
Nov 13 10:07:33.421: INFO: Pod "pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.064336ms
Nov 13 10:07:35.425: INFO: Pod "pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008679187s
Nov 13 10:07:37.428: INFO: Pod "pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012190678s
Nov 13 10:07:39.432: INFO: Pod "pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015996638s
STEP: Saw pod success
Nov 13 10:07:39.432: INFO: Pod "pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:07:39.435: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:07:39.464: INFO: Waiting for pod pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:07:39.473: INFO: Pod pod-secrets-f03060ea-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:07:39.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qwhk6" for this suite.
Nov 13 10:07:45.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:07:45.675: INFO: namespace: e2e-tests-secrets-qwhk6, resource: bindings, ignored listing per whitelist
Nov 13 10:07:45.699: INFO: namespace e2e-tests-secrets-qwhk6 deletion completed in 6.222866702s

• [SLOW TEST:12.532 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:07:45.699: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-gg7p6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov 13 10:07:45.969: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 13 10:07:46.112: INFO: Waiting for terminating namespaces to be deleted...
Nov 13 10:07:46.115: INFO: 
Logging pods the kubelet thinks is on node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j before test
Nov 13 10:07:46.125: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-13 08:59:50 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.125: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 13 10:07:46.125: INFO: sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-bc4jf from heptio-sonobuoy started at 2018-11-13 08:59:55 +0000 UTC (2 container statuses recorded)
Nov 13 10:07:46.125: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Nov 13 10:07:46.125: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov 13 10:07:46.125: INFO: kube-proxy-nnlwg from kube-system started at 2018-11-13 08:45:16 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.125: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 13 10:07:46.125: INFO: calico-node-rncpj from kube-system started at 2018-11-13 08:45:16 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.125: INFO: 	Container calico-node ready: true, restart count 0
Nov 13 10:07:46.125: INFO: node-exporter-wspmd from kube-system started at 2018-11-13 08:45:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.125: INFO: 	Container node-exporter ready: true, restart count 0
Nov 13 10:07:46.125: INFO: sonobuoy-e2e-job-2ff76b52b92f4655 from heptio-sonobuoy started at 2018-11-13 08:59:55 +0000 UTC (2 container statuses recorded)
Nov 13 10:07:46.125: INFO: 	Container e2e ready: true, restart count 0
Nov 13 10:07:46.125: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:07:46.125: INFO: 
Logging pods the kubelet thinks is on node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd before test
Nov 13 10:07:46.145: INFO: vpn-shoot-7598ff6d9d-zzfv2 from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container vpn-shoot ready: true, restart count 0
Nov 13 10:07:46.145: INFO: calico-node-szwdh from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container calico-node ready: true, restart count 0
Nov 13 10:07:46.145: INFO: metrics-server-7b7c958998-5pqpk from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container metrics-server ready: true, restart count 0
Nov 13 10:07:46.145: INFO: addons-nginx-ingress-controller-5d8ff96544-4nqmh from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Nov 13 10:07:46.145: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6584cc89bc-pfc2k from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Nov 13 10:07:46.145: INFO: node-exporter-rqx88 from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container node-exporter ready: true, restart count 0
Nov 13 10:07:46.145: INFO: kube-proxy-29h2s from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 13 10:07:46.145: INFO: sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-phpj5 from heptio-sonobuoy started at 2018-11-13 08:59:56 +0000 UTC (2 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Nov 13 10:07:46.145: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov 13 10:07:46.145: INFO: coredns-996685c97-q726s from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:07:46.145: INFO: addons-kubernetes-dashboard-789b6fcb7f-ghcnb from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:07:46.145: INFO: 	Container main ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
STEP: verifying the node has the label node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.198: INFO: Pod sonobuoy requesting resource cpu=0m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
Nov 13 10:07:46.198: INFO: Pod sonobuoy-e2e-job-2ff76b52b92f4655 requesting resource cpu=0m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
Nov 13 10:07:46.198: INFO: Pod sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-bc4jf requesting resource cpu=0m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
Nov 13 10:07:46.198: INFO: Pod sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-phpj5 requesting resource cpu=0m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.198: INFO: Pod addons-kubernetes-dashboard-789b6fcb7f-ghcnb requesting resource cpu=50m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.198: INFO: Pod addons-nginx-ingress-controller-5d8ff96544-4nqmh requesting resource cpu=100m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.198: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-6584cc89bc-pfc2k requesting resource cpu=0m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.198: INFO: Pod calico-node-rncpj requesting resource cpu=250m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
Nov 13 10:07:46.198: INFO: Pod calico-node-szwdh requesting resource cpu=250m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.198: INFO: Pod coredns-996685c97-q726s requesting resource cpu=100m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.199: INFO: Pod kube-proxy-29h2s requesting resource cpu=50m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.199: INFO: Pod kube-proxy-nnlwg requesting resource cpu=50m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
Nov 13 10:07:46.199: INFO: Pod metrics-server-7b7c958998-5pqpk requesting resource cpu=0m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.199: INFO: Pod node-exporter-rqx88 requesting resource cpu=10m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
Nov 13 10:07:46.199: INFO: Pod node-exporter-wspmd requesting resource cpu=10m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
Nov 13 10:07:46.199: INFO: Pod vpn-shoot-7598ff6d9d-zzfv2 requesting resource cpu=100m on Node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7cfa809-e72b-11e8-baa5-625675597e81.1566a71d2f061d09], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-gg7p6/filler-pod-f7cfa809-e72b-11e8-baa5-625675597e81 to shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7cfa809-e72b-11e8-baa5-625675597e81.1566a71d84aa588f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7cfa809-e72b-11e8-baa5-625675597e81.1566a71dbbf55fc3], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7cfa809-e72b-11e8-baa5-625675597e81.1566a71dc57c7d4f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7d07275-e72b-11e8-baa5-625675597e81.1566a71d30a159fc], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-gg7p6/filler-pod-f7d07275-e72b-11e8-baa5-625675597e81 to shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7d07275-e72b-11e8-baa5-625675597e81.1566a71da43aa676], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7d07275-e72b-11e8-baa5-625675597e81.1566a71de45adf1f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7d07275-e72b-11e8-baa5-625675597e81.1566a71e053230f4], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1566a71e1ff9c8d7], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:07:51.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gg7p6" for this suite.
Nov 13 10:07:57.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:07:57.544: INFO: namespace: e2e-tests-sched-pred-gg7p6, resource: bindings, ignored listing per whitelist
Nov 13 10:07:57.601: INFO: namespace e2e-tests-sched-pred-gg7p6 deletion completed in 6.237797987s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.902 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:07:57.601: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qg7gg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:07:57.956: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-qg7gg" to be "success or failure"
Nov 13 10:07:57.961: INFO: Pod "downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.240633ms
Nov 13 10:07:59.964: INFO: Pod "downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008370698s
Nov 13 10:08:01.968: INFO: Pod "downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012040852s
Nov 13 10:08:04.646: INFO: Pod "downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.690419748s
Nov 13 10:08:06.650: INFO: Pod "downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 8.69399906s
Nov 13 10:08:08.654: INFO: Pod "downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.697781487s
STEP: Saw pod success
Nov 13 10:08:08.654: INFO: Pod "downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:08:08.656: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:08:08.769: INFO: Waiting for pod downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81 to disappear
Nov 13 10:08:08.780: INFO: Pod downwardapi-volume-fed0d32b-e72b-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:08:08.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qg7gg" for this suite.
Nov 13 10:08:14.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:08:14.936: INFO: namespace: e2e-tests-projected-qg7gg, resource: bindings, ignored listing per whitelist
Nov 13 10:08:15.102: INFO: namespace e2e-tests-projected-qg7gg deletion completed in 6.319459339s

• [SLOW TEST:17.501 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:08:15.102: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xpsn8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Nov 13 10:08:19.434: INFO: Pod pod-hostip-0936bbb6-e72c-11e8-baa5-625675597e81 has hostIP: 10.250.0.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:08:19.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xpsn8" for this suite.
Nov 13 10:08:41.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:08:41.551: INFO: namespace: e2e-tests-pods-xpsn8, resource: bindings, ignored listing per whitelist
Nov 13 10:08:41.589: INFO: namespace e2e-tests-pods-xpsn8 deletion completed in 22.151815008s

• [SLOW TEST:26.486 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:08:41.589: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8xmkk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-19043b52-e72c-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:08:41.970: INFO: Waiting up to 5m0s for pod "pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81" in namespace "e2e-tests-configmap-8xmkk" to be "success or failure"
Nov 13 10:08:42.004: INFO: Pod "pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 34.02362ms
Nov 13 10:08:44.007: INFO: Pod "pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037362329s
Nov 13 10:08:46.010: INFO: Pod "pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040703659s
Nov 13 10:08:48.014: INFO: Pod "pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044364864s
STEP: Saw pod success
Nov 13 10:08:48.014: INFO: Pod "pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:08:48.045: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:08:48.064: INFO: Waiting for pod pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81 to disappear
Nov 13 10:08:48.068: INFO: Pod pod-configmaps-19049bb3-e72c-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:08:48.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8xmkk" for this suite.
Nov 13 10:08:54.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:08:54.161: INFO: namespace: e2e-tests-configmap-8xmkk, resource: bindings, ignored listing per whitelist
Nov 13 10:08:54.221: INFO: namespace e2e-tests-configmap-8xmkk deletion completed in 6.149541569s

• [SLOW TEST:12.632 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:08:54.221: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-84pwl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-20809fbe-e72c-11e8-baa5-625675597e81
STEP: Creating secret with name secret-projected-all-test-volume-20809ec8-e72c-11e8-baa5-625675597e81
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov 13 10:08:54.585: INFO: Waiting up to 5m0s for pod "projected-volume-20809e8a-e72c-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-84pwl" to be "success or failure"
Nov 13 10:08:54.589: INFO: Pod "projected-volume-20809e8a-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075927ms
Nov 13 10:08:56.593: INFO: Pod "projected-volume-20809e8a-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007716653s
Nov 13 10:08:58.597: INFO: Pod "projected-volume-20809e8a-e72c-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011350044s
STEP: Saw pod success
Nov 13 10:08:58.597: INFO: Pod "projected-volume-20809e8a-e72c-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:08:58.599: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod projected-volume-20809e8a-e72c-11e8-baa5-625675597e81 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov 13 10:08:58.625: INFO: Waiting for pod projected-volume-20809e8a-e72c-11e8-baa5-625675597e81 to disappear
Nov 13 10:08:58.631: INFO: Pod projected-volume-20809e8a-e72c-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:08:58.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-84pwl" for this suite.
Nov 13 10:09:04.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:09:04.807: INFO: namespace: e2e-tests-projected-84pwl, resource: bindings, ignored listing per whitelist
Nov 13 10:09:04.820: INFO: namespace e2e-tests-projected-84pwl deletion completed in 6.171299491s

• [SLOW TEST:10.599 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:09:04.821: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-5xgct
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Nov 13 10:09:05.083: INFO: Waiting up to 5m0s for pod "client-containers-26d3c087-e72c-11e8-baa5-625675597e81" in namespace "e2e-tests-containers-5xgct" to be "success or failure"
Nov 13 10:09:05.087: INFO: Pod "client-containers-26d3c087-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 3.924625ms
Nov 13 10:09:07.090: INFO: Pod "client-containers-26d3c087-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007136842s
Nov 13 10:09:09.094: INFO: Pod "client-containers-26d3c087-e72c-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010419032s
STEP: Saw pod success
Nov 13 10:09:09.094: INFO: Pod "client-containers-26d3c087-e72c-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:09:09.096: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod client-containers-26d3c087-e72c-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:09:09.162: INFO: Waiting for pod client-containers-26d3c087-e72c-11e8-baa5-625675597e81 to disappear
Nov 13 10:09:09.168: INFO: Pod client-containers-26d3c087-e72c-11e8-baa5-625675597e81 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:09:09.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5xgct" for this suite.
Nov 13 10:09:15.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:09:15.305: INFO: namespace: e2e-tests-containers-5xgct, resource: bindings, ignored listing per whitelist
Nov 13 10:09:15.319: INFO: namespace e2e-tests-containers-5xgct deletion completed in 6.146600719s

• [SLOW TEST:10.498 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:09:15.319: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-vrjls
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-pnqrt in namespace e2e-tests-proxy-vrjls
I1113 10:09:15.607815      15 runners.go:180] Created replication controller with name: proxy-service-pnqrt, namespace: e2e-tests-proxy-vrjls, replica count: 1
I1113 10:09:16.658274      15 runners.go:180] proxy-service-pnqrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 10:09:17.658529      15 runners.go:180] proxy-service-pnqrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 10:09:18.658665      15 runners.go:180] proxy-service-pnqrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 10:09:19.658857      15 runners.go:180] proxy-service-pnqrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 10:09:20.661892      15 runners.go:180] proxy-service-pnqrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 10:09:21.662136      15 runners.go:180] proxy-service-pnqrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1113 10:09:22.662344      15 runners.go:180] proxy-service-pnqrt Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 13 10:09:22.678: INFO: setup took 7.101992256s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov 13 10:09:22.735: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 55.19086ms)
Nov 13 10:09:22.735: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 55.345461ms)
Nov 13 10:09:22.735: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 55.616262ms)
Nov 13 10:09:22.735: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 55.912664ms)
Nov 13 10:09:22.735: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 56.503268ms)
Nov 13 10:09:22.741: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 62.800008ms)
Nov 13 10:09:22.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 63.107111ms)
Nov 13 10:09:22.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 62.390207ms)
Nov 13 10:09:22.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 62.892409ms)
Nov 13 10:09:22.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 62.88371ms)
Nov 13 10:09:22.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 62.791809ms)
Nov 13 10:09:22.749: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 70.204057ms)
Nov 13 10:09:22.750: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 70.169857ms)
Nov 13 10:09:22.750: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 71.663666ms)
Nov 13 10:09:22.750: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 71.357664ms)
Nov 13 10:09:22.751: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 71.184563ms)
Nov 13 10:09:22.757: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.881938ms)
Nov 13 10:09:22.757: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.394742ms)
Nov 13 10:09:22.758: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 6.301741ms)
Nov 13 10:09:22.758: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 7.039246ms)
Nov 13 10:09:22.758: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 7.418648ms)
Nov 13 10:09:22.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.413035ms)
Nov 13 10:09:22.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 7.57195ms)
Nov 13 10:09:22.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.899738ms)
Nov 13 10:09:22.760: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 6.351342ms)
Nov 13 10:09:22.760: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.327441ms)
Nov 13 10:09:22.760: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 6.307541ms)
Nov 13 10:09:22.760: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 8.942758ms)
Nov 13 10:09:22.760: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.778944ms)
Nov 13 10:09:22.760: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 6.699043ms)
Nov 13 10:09:22.761: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 7.845851ms)
Nov 13 10:09:22.762: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 8.548755ms)
Nov 13 10:09:22.768: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 5.256434ms)
Nov 13 10:09:22.768: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.577636ms)
Nov 13 10:09:22.768: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 5.320634ms)
Nov 13 10:09:22.768: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.715538ms)
Nov 13 10:09:22.768: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.989439ms)
Nov 13 10:09:22.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.832738ms)
Nov 13 10:09:22.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 6.071839ms)
Nov 13 10:09:22.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 5.957239ms)
Nov 13 10:09:22.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 6.14004ms)
Nov 13 10:09:22.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 5.977139ms)
Nov 13 10:09:22.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.297541ms)
Nov 13 10:09:22.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 6.16804ms)
Nov 13 10:09:22.771: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 8.403255ms)
Nov 13 10:09:22.812: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 49.04242ms)
Nov 13 10:09:22.812: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 49.352522ms)
Nov 13 10:09:22.812: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 49.526522ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.568237ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.443536ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.525936ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.932838ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 5.486736ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 5.886738ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 6.22224ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 6.232141ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.230734ms)
Nov 13 10:09:22.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.435835ms)
Nov 13 10:09:22.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.988439ms)
Nov 13 10:09:22.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.444942ms)
Nov 13 10:09:22.861: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 47.385208ms)
Nov 13 10:09:22.861: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 47.193907ms)
Nov 13 10:09:22.861: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 47.64641ms)
Nov 13 10:09:22.861: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 47.998513ms)
Nov 13 10:09:22.867: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.968039ms)
Nov 13 10:09:22.867: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.909238ms)
Nov 13 10:09:22.867: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 6.244441ms)
Nov 13 10:09:22.868: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.470342ms)
Nov 13 10:09:22.868: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.413241ms)
Nov 13 10:09:22.869: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 7.047146ms)
Nov 13 10:09:22.869: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 7.237547ms)
Nov 13 10:09:22.869: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 7.271847ms)
Nov 13 10:09:22.869: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 7.67575ms)
Nov 13 10:09:22.869: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 7.383348ms)
Nov 13 10:09:22.870: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 8.983558ms)
Nov 13 10:09:22.870: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 8.848758ms)
Nov 13 10:09:22.870: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 8.770357ms)
Nov 13 10:09:22.870: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 9.039659ms)
Nov 13 10:09:22.870: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 8.785857ms)
Nov 13 10:09:22.871: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 9.541162ms)
Nov 13 10:09:22.876: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 4.676331ms)
Nov 13 10:09:22.876: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 4.61603ms)
Nov 13 10:09:22.876: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.374635ms)
Nov 13 10:09:22.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.359735ms)
Nov 13 10:09:22.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.291334ms)
Nov 13 10:09:22.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 4.789031ms)
Nov 13 10:09:22.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 4.855332ms)
Nov 13 10:09:22.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.869339ms)
Nov 13 10:09:22.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.248434ms)
Nov 13 10:09:22.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.261441ms)
Nov 13 10:09:22.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 5.018633ms)
Nov 13 10:09:22.878: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 6.701243ms)
Nov 13 10:09:22.879: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 8.250753ms)
Nov 13 10:09:22.879: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 7.869352ms)
Nov 13 10:09:22.879: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 7.217147ms)
Nov 13 10:09:22.879: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 8.031752ms)
Nov 13 10:09:22.885: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 4.676131ms)
Nov 13 10:09:22.885: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.479036ms)
Nov 13 10:09:22.885: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 4.942232ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.494536ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.020632ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 5.696137ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.638436ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.508736ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 6.369042ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 5.873439ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 6.10594ms)
Nov 13 10:09:22.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.10534ms)
Nov 13 10:09:22.887: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 7.274847ms)
Nov 13 10:09:22.929: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 49.286021ms)
Nov 13 10:09:22.929: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 48.735417ms)
Nov 13 10:09:22.929: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 48.230114ms)
Nov 13 10:09:22.935: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.863239ms)
Nov 13 10:09:22.935: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.885039ms)
Nov 13 10:09:22.935: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 6.12054ms)
Nov 13 10:09:22.935: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 6.333541ms)
Nov 13 10:09:22.935: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 6.305241ms)
Nov 13 10:09:22.935: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.19014ms)
Nov 13 10:09:22.935: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.21834ms)
Nov 13 10:09:22.936: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 6.544342ms)
Nov 13 10:09:22.936: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 6.673744ms)
Nov 13 10:09:22.936: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 7.025846ms)
Nov 13 10:09:22.936: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 6.687143ms)
Nov 13 10:09:22.936: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.718044ms)
Nov 13 10:09:22.938: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 8.928958ms)
Nov 13 10:09:22.939: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 10.212667ms)
Nov 13 10:09:22.939: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 10.154066ms)
Nov 13 10:09:22.939: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 10.128666ms)
Nov 13 10:09:22.945: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.555736ms)
Nov 13 10:09:22.945: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.208234ms)
Nov 13 10:09:22.945: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 5.573536ms)
Nov 13 10:09:22.945: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.623037ms)
Nov 13 10:09:22.945: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.998239ms)
Nov 13 10:09:22.945: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 5.572137ms)
Nov 13 10:09:22.945: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.756938ms)
Nov 13 10:09:22.946: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 5.963039ms)
Nov 13 10:09:22.946: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.839938ms)
Nov 13 10:09:22.946: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.263041ms)
Nov 13 10:09:22.946: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.953939ms)
Nov 13 10:09:22.946: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 6.272841ms)
Nov 13 10:09:22.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 48.933918ms)
Nov 13 10:09:22.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 48.876218ms)
Nov 13 10:09:22.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 49.031219ms)
Nov 13 10:09:22.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 49.17712ms)
Nov 13 10:09:22.995: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.630543ms)
Nov 13 10:09:22.996: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.619043ms)
Nov 13 10:09:22.996: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.775744ms)
Nov 13 10:09:22.996: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 6.552542ms)
Nov 13 10:09:22.996: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 6.679244ms)
Nov 13 10:09:22.996: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 6.583843ms)
Nov 13 10:09:22.996: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 6.563443ms)
Nov 13 10:09:22.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 9.795564ms)
Nov 13 10:09:22.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 9.979765ms)
Nov 13 10:09:22.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 10.356067ms)
Nov 13 10:09:22.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 10.089265ms)
Nov 13 10:09:22.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 10.051065ms)
Nov 13 10:09:22.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 10.295467ms)
Nov 13 10:09:22.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 10.110566ms)
Nov 13 10:09:22.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 10.388468ms)
Nov 13 10:09:23.001: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 11.387474ms)
Nov 13 10:09:23.005: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 4.468829ms)
Nov 13 10:09:23.007: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 4.52343ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 6.15294ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.601637ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.824838ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.921239ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.353242ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 7.250547ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 6.788644ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.743944ms)
Nov 13 10:09:23.008: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 6.565843ms)
Nov 13 10:09:23.009: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 7.71065ms)
Nov 13 10:09:23.009: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 7.913251ms)
Nov 13 10:09:23.011: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 9.22726ms)
Nov 13 10:09:23.012: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 10.65177ms)
Nov 13 10:09:23.012: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 10.191966ms)
Nov 13 10:09:23.018: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 4.836031ms)
Nov 13 10:09:23.018: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.354035ms)
Nov 13 10:09:23.018: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 4.984733ms)
Nov 13 10:09:23.018: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.012739ms)
Nov 13 10:09:23.018: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.693537ms)
Nov 13 10:09:23.019: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.511736ms)
Nov 13 10:09:23.019: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 6.414742ms)
Nov 13 10:09:23.019: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 6.230041ms)
Nov 13 10:09:23.019: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 6.765744ms)
Nov 13 10:09:23.019: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.22954ms)
Nov 13 10:09:23.019: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.549843ms)
Nov 13 10:09:23.019: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 6.691243ms)
Nov 13 10:09:23.060: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 46.879406ms)
Nov 13 10:09:23.060: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 47.424009ms)
Nov 13 10:09:23.060: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 47.136607ms)
Nov 13 10:09:23.060: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 47.056907ms)
Nov 13 10:09:23.065: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 4.781732ms)
Nov 13 10:09:23.065: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 4.67223ms)
Nov 13 10:09:23.065: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.313335ms)
Nov 13 10:09:23.066: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.142733ms)
Nov 13 10:09:23.066: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.518436ms)
Nov 13 10:09:23.067: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.364441ms)
Nov 13 10:09:23.067: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 6.310741ms)
Nov 13 10:09:23.067: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 6.458143ms)
Nov 13 10:09:23.067: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 6.365242ms)
Nov 13 10:09:23.068: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 7.144547ms)
Nov 13 10:09:23.068: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 8.152353ms)
Nov 13 10:09:23.068: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 8.012852ms)
Nov 13 10:09:23.068: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 8.146753ms)
Nov 13 10:09:23.069: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 8.298455ms)
Nov 13 10:09:23.069: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 8.226854ms)
Nov 13 10:09:23.069: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 8.713357ms)
Nov 13 10:09:23.074: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 4.454629ms)
Nov 13 10:09:23.075: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.234435ms)
Nov 13 10:09:23.075: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.201834ms)
Nov 13 10:09:23.075: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.526536ms)
Nov 13 10:09:23.075: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 5.308034ms)
Nov 13 10:09:23.076: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 6.636943ms)
Nov 13 10:09:23.076: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 6.21744ms)
Nov 13 10:09:23.076: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.028439ms)
Nov 13 10:09:23.076: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.939439ms)
Nov 13 10:09:23.077: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 6.13864ms)
Nov 13 10:09:23.077: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 7.255348ms)
Nov 13 10:09:23.077: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 6.896345ms)
Nov 13 10:09:23.077: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 6.22694ms)
Nov 13 10:09:23.118: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 46.959606ms)
Nov 13 10:09:23.118: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 47.802712ms)
Nov 13 10:09:23.118: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 47.310909ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.581736ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.724437ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.946439ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.885039ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 6.09874ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 5.614036ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 5.364635ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.551336ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 5.503736ms)
Nov 13 10:09:23.124: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 5.414535ms)
Nov 13 10:09:23.125: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 6.086439ms)
Nov 13 10:09:23.127: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 7.926152ms)
Nov 13 10:09:23.128: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 8.925758ms)
Nov 13 10:09:23.128: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 8.892558ms)
Nov 13 10:09:23.128: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 8.802458ms)
Nov 13 10:09:23.128: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 9.424062ms)
Nov 13 10:09:23.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.791838ms)
Nov 13 10:09:23.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 5.692138ms)
Nov 13 10:09:23.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.877239ms)
Nov 13 10:09:23.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.953639ms)
Nov 13 10:09:23.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.930739ms)
Nov 13 10:09:23.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 6.560643ms)
Nov 13 10:09:23.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 6.555342ms)
Nov 13 10:09:23.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.646443ms)
Nov 13 10:09:23.136: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 7.335648ms)
Nov 13 10:09:23.136: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 7.359848ms)
Nov 13 10:09:23.137: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 8.366954ms)
Nov 13 10:09:23.137: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 8.709856ms)
Nov 13 10:09:23.138: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 9.605262ms)
Nov 13 10:09:23.138: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 9.576262ms)
Nov 13 10:09:23.138: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 9.564462ms)
Nov 13 10:09:23.138: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 9.692763ms)
Nov 13 10:09:23.144: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.416836ms)
Nov 13 10:09:23.144: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.648237ms)
Nov 13 10:09:23.144: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.516336ms)
Nov 13 10:09:23.144: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.998139ms)
Nov 13 10:09:23.144: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 5.649836ms)
Nov 13 10:09:23.144: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.00374ms)
Nov 13 10:09:23.145: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 6.26234ms)
Nov 13 10:09:23.145: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 6.684044ms)
Nov 13 10:09:23.145: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 6.859144ms)
Nov 13 10:09:23.145: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 6.841945ms)
Nov 13 10:09:23.145: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 6.915345ms)
Nov 13 10:09:23.156: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 17.171512ms)
Nov 13 10:09:23.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 59.547688ms)
Nov 13 10:09:23.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 59.667189ms)
Nov 13 10:09:23.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 59.395787ms)
Nov 13 10:09:23.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 59.442088ms)
Nov 13 10:09:23.203: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 4.801032ms)
Nov 13 10:09:23.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 5.724637ms)
Nov 13 10:09:23.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 5.629037ms)
Nov 13 10:09:23.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 5.562736ms)
Nov 13 10:09:23.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 5.254834ms)
Nov 13 10:09:23.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 5.185934ms)
Nov 13 10:09:23.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 5.606936ms)
Nov 13 10:09:23.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.568836ms)
Nov 13 10:09:23.206: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 7.117446ms)
Nov 13 10:09:23.206: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 6.956945ms)
Nov 13 10:09:23.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 8.768157ms)
Nov 13 10:09:23.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 8.800858ms)
Nov 13 10:09:23.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 8.800557ms)
Nov 13 10:09:23.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 8.559356ms)
Nov 13 10:09:23.210: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 10.73617ms)
Nov 13 10:09:23.210: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 11.489774ms)
Nov 13 10:09:23.217: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 5.939439ms)
Nov 13 10:09:23.217: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 6.20924ms)
Nov 13 10:09:23.219: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 7.942552ms)
Nov 13 10:09:23.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 28.859488ms)
Nov 13 10:09:23.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 28.398185ms)
Nov 13 10:09:23.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 28.847388ms)
Nov 13 10:09:23.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 29.13509ms)
Nov 13 10:09:23.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 29.934095ms)
Nov 13 10:09:23.242: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 29.618393ms)
Nov 13 10:09:23.242: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 28.612487ms)
Nov 13 10:09:23.242: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 30.539999ms)
Nov 13 10:09:23.242: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 29.420592ms)
Nov 13 10:09:23.242: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 30.6936ms)
Nov 13 10:09:23.346: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 133.699872ms)
Nov 13 10:09:23.388: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 176.27235ms)
Nov 13 10:09:23.388: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 175.564545ms)
Nov 13 10:09:23.398: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname1/proxy/: foo (200; 8.809258ms)
Nov 13 10:09:23.399: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 9.896364ms)
Nov 13 10:09:23.399: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:160/proxy/: foo (200; 10.016965ms)
Nov 13 10:09:23.399: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:462/proxy/: tls qux (200; 10.338368ms)
Nov 13 10:09:23.400: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 10.277167ms)
Nov 13 10:09:23.400: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:1080/proxy/rewri... (200; 10.481569ms)
Nov 13 10:09:23.400: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg/proxy/rewriteme"... (200; 11.567276ms)
Nov 13 10:09:23.400: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/http:proxy-service-pnqrt-d6tcg:1080/proxy/... (200; 10.819771ms)
Nov 13 10:09:23.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname1/proxy/: foo (200; 52.415142ms)
Nov 13 10:09:23.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:443/proxy/... (200; 52.637843ms)
Nov 13 10:09:23.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/proxy-service-pnqrt-d6tcg:162/proxy/: bar (200; 52.793345ms)
Nov 13 10:09:23.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname2/proxy/: tls qux (200; 51.565937ms)
Nov 13 10:09:23.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/https:proxy-service-pnqrt:tlsportname1/proxy/: tls baz (200; 51.796538ms)
Nov 13 10:09:23.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/pods/https:proxy-service-pnqrt-d6tcg:460/proxy/: tls baz (200; 52.605143ms)
Nov 13 10:09:23.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/http:proxy-service-pnqrt:portname2/proxy/: bar (200; 53.207647ms)
Nov 13 10:09:23.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrjls/services/proxy-service-pnqrt:portname2/proxy/: bar (200; 52.470442ms)
STEP: deleting { ReplicationController} proxy-service-pnqrt in namespace e2e-tests-proxy-vrjls, will wait for the garbage collector to delete the pods
Nov 13 10:09:23.499: INFO: Deleting { ReplicationController} proxy-service-pnqrt took: 4.283528ms
Nov 13 10:09:23.599: INFO: Terminating { ReplicationController} proxy-service-pnqrt pods took: 100.145653ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:09:30.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-vrjls" for this suite.
Nov 13 10:09:36.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:09:36.282: INFO: namespace: e2e-tests-proxy-vrjls, resource: bindings, ignored listing per whitelist
Nov 13 10:09:36.385: INFO: namespace e2e-tests-proxy-vrjls deletion completed in 6.179615771s

• [SLOW TEST:21.066 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:09:36.385: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2ljcs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-39a92a14-e72c-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:09:36.692: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-2ljcs" to be "success or failure"
Nov 13 10:09:36.706: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 14.50419ms
Nov 13 10:09:38.709: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017459975s
Nov 13 10:09:40.713: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021099065s
Nov 13 10:09:42.716: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024708202s
Nov 13 10:09:44.720: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027954183s
Nov 13 10:09:46.752: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 10.06011099s
Nov 13 10:09:48.933: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 12.241121465s
Nov 13 10:09:50.937: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 14.244833494s
Nov 13 10:09:52.940: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 16.248709671s
Nov 13 10:09:54.944: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 18.252485292s
Nov 13 10:09:56.948: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 20.256092459s
Nov 13 10:09:58.951: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 22.25943347s
Nov 13 10:10:00.955: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 24.263107329s
Nov 13 10:10:02.958: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 26.266644332s
Nov 13 10:10:04.962: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 28.270031679s
Nov 13 10:10:06.966: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 30.274319677s
Nov 13 10:10:08.970: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 32.277796115s
Nov 13 10:10:10.973: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 34.281044496s
Nov 13 10:10:12.978: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 36.286093032s
Nov 13 10:10:14.981: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 38.289497703s
Nov 13 10:10:16.984: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 40.292523515s
Nov 13 10:10:18.988: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 42.295823473s
Nov 13 10:10:20.991: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 44.299019475s
Nov 13 10:10:22.994: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 46.302673622s
Nov 13 10:10:25.002: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 48.310166539s
Nov 13 10:10:27.005: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 50.313706973s
Nov 13 10:10:29.009: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 52.317644353s
Nov 13 10:10:31.013: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 54.320900072s
Nov 13 10:10:33.016: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 56.324055632s
Nov 13 10:10:35.019: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 58.327552837s
Nov 13 10:10:37.023: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.331031084s
Nov 13 10:10:39.161: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.469232583s
Nov 13 10:10:41.164: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.472519417s
Nov 13 10:10:43.168: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.475892892s
Nov 13 10:10:45.171: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.47924661s
Nov 13 10:10:47.180: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.488293208s
Nov 13 10:10:49.183: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.491534608s
Nov 13 10:10:51.187: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.495415853s
Nov 13 10:10:53.190: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.498593035s
Nov 13 10:10:55.194: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.502069759s
Nov 13 10:10:57.197: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.505163921s
Nov 13 10:10:59.245: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.552765734s
Nov 13 10:11:01.247: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.555679778s
Nov 13 10:11:03.250: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.558527661s
Nov 13 10:11:05.492: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.799801357s
Nov 13 10:11:07.494: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.802629325s
Nov 13 10:11:09.542: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.850667352s
Nov 13 10:11:11.545: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.853635102s
Nov 13 10:11:13.549: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.857020994s
Nov 13 10:11:15.552: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.860183424s
Nov 13 10:11:17.556: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.863843996s
Nov 13 10:11:19.560: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.867769809s
Nov 13 10:11:21.564: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.871764662s
Nov 13 10:11:23.569: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.877350265s
Nov 13 10:11:25.677: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.984834441s
Nov 13 10:11:27.680: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.988453509s
Nov 13 10:11:29.684: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.991947315s
Nov 13 10:11:31.689: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.996820769s
Nov 13 10:11:33.691: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.999667445s
Nov 13 10:11:35.744: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1m59.052611226s
Nov 13 10:11:37.747: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2m1.05562478s
Nov 13 10:11:39.755: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2m3.063545608s
E1113 10:11:40.445173      15 streamwatcher.go:109] Unable to decode an event from the watch stream: http2: server sent GOAWAY and closed the connection; LastStreamID=33883, ErrCode=NO_ERROR, debug=""
E1113 10:11:40.445262      15 streamwatcher.go:109] Unable to decode an event from the watch stream: http2: server sent GOAWAY and closed the connection; LastStreamID=33883, ErrCode=NO_ERROR, debug=""
E1113 10:11:40.445294      15 streamwatcher.go:109] Unable to decode an event from the watch stream: http2: server sent GOAWAY and closed the connection; LastStreamID=33883, ErrCode=NO_ERROR, debug=""
E1113 10:11:40.445306      15 streamwatcher.go:109] Unable to decode an event from the watch stream: http2: server sent GOAWAY and closed the connection; LastStreamID=33883, ErrCode=NO_ERROR, debug=""
E1113 10:11:40.445330      15 streamwatcher.go:109] Unable to decode an event from the watch stream: http2: server sent GOAWAY and closed the connection; LastStreamID=33883, ErrCode=NO_ERROR, debug=""
Nov 13 10:12:11.756: INFO: Get pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-2ljcs" failed, ignoring for 2s. Error: Get https://100.64.0.1:443/api/v1/namespaces/e2e-tests-projected-2ljcs/pods/pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81: dial tcp 100.64.0.1:443: i/o timeout
Nov 13 10:12:13.767: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.075402823s
Nov 13 10:12:15.770: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2m39.078279773s
STEP: Saw pod success
Nov 13 10:12:15.770: INFO: Pod "pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:12:15.778: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:12:15.895: INFO: Waiting for pod pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81 to disappear
Nov 13 10:12:15.908: INFO: Pod pod-projected-configmaps-39a99508-e72c-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:12:15.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2ljcs" for this suite.
Nov 13 10:13:03.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:13:04.047: INFO: namespace: e2e-tests-projected-2ljcs, resource: bindings, ignored listing per whitelist
Nov 13 10:13:04.082: INFO: namespace e2e-tests-projected-2ljcs deletion completed in 48.170331664s

• [SLOW TEST:207.697 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:13:04.083: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-4hwzw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4hwzw A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-4hwzw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4hwzw A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-4hwzw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4hwzw.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4hwzw.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4hwzw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4hwzw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-4hwzw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4hwzw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 131.164.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.164.131_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 131.164.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.164.131_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4hwzw A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-4hwzw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4hwzw A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-4hwzw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4hwzw.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4hwzw.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4hwzw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-4hwzw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4hwzw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-4hwzw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4hwzw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 131.164.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.164.131_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 131.164.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.164.131_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:13:36.613: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:36.697: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:36.740: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-4hwzw from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:36.746: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-4hwzw from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:36.753: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-4hwzw.svc from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:36.762: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-4hwzw.svc from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:36.836: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:36.841: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.231: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.236: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.241: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-4hwzw from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.245: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-4hwzw from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.250: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-4hwzw.svc from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.254: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-4hwzw.svc from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.259: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.264: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc from pod e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81: the server could not find the requested resource (get pods dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81)
Nov 13 10:13:37.615: INFO: Lookups using e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-4hwzw wheezy_tcp@dns-test-service.e2e-tests-dns-4hwzw wheezy_udp@dns-test-service.e2e-tests-dns-4hwzw.svc wheezy_tcp@dns-test-service.e2e-tests-dns-4hwzw.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-4hwzw jessie_tcp@dns-test-service.e2e-tests-dns-4hwzw jessie_udp@dns-test-service.e2e-tests-dns-4hwzw.svc jessie_tcp@dns-test-service.e2e-tests-dns-4hwzw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4hwzw.svc]

Nov 13 10:13:48.274: INFO: DNS probes using e2e-tests-dns-4hwzw/dns-test-b57ac3d8-e72c-11e8-baa5-625675597e81 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:13:48.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-4hwzw" for this suite.
Nov 13 10:13:54.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:13:54.559: INFO: namespace: e2e-tests-dns-4hwzw, resource: bindings, ignored listing per whitelist
Nov 13 10:13:54.631: INFO: namespace e2e-tests-dns-4hwzw deletion completed in 6.233714929s

• [SLOW TEST:50.548 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:13:54.631: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-rgxhf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:13:54.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rgxhf" for this suite.
Nov 13 10:14:00.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:14:01.020: INFO: namespace: e2e-tests-services-rgxhf, resource: bindings, ignored listing per whitelist
Nov 13 10:14:01.029: INFO: namespace e2e-tests-services-rgxhf deletion completed in 6.179174571s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.398 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:14:01.029: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wljt4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Nov 13 10:14:01.293: INFO: namespace e2e-tests-kubectl-wljt4
Nov 13 10:14:01.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 create -f - --namespace=e2e-tests-kubectl-wljt4'
Nov 13 10:14:01.580: INFO: stderr: ""
Nov 13 10:14:01.580: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 13 10:14:02.584: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 10:14:02.584: INFO: Found 0 / 1
Nov 13 10:14:03.586: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 10:14:03.586: INFO: Found 0 / 1
Nov 13 10:14:04.584: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 10:14:04.584: INFO: Found 0 / 1
Nov 13 10:14:05.583: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 10:14:05.583: INFO: Found 1 / 1
Nov 13 10:14:05.583: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 13 10:14:05.586: INFO: Selector matched 1 pods for map[app:redis]
Nov 13 10:14:05.586: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 13 10:14:05.586: INFO: wait on redis-master startup in e2e-tests-kubectl-wljt4 
Nov 13 10:14:05.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 logs redis-master-2d5hv redis-master --namespace=e2e-tests-kubectl-wljt4'
Nov 13 10:14:05.728: INFO: stderr: ""
Nov 13 10:14:05.728: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Nov 10:14:04.820 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Nov 10:14:04.820 # Server started, Redis version 3.2.12\n1:M 13 Nov 10:14:04.820 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Nov 10:14:04.820 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Nov 13 10:14:05.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-wljt4'
Nov 13 10:14:06.880: INFO: stderr: ""
Nov 13 10:14:06.880: INFO: stdout: "service/rm2 exposed\n"
Nov 13 10:14:06.898: INFO: Service rm2 in namespace e2e-tests-kubectl-wljt4 found.
STEP: exposing service
Nov 13 10:14:08.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-wljt4'
Nov 13 10:14:09.046: INFO: stderr: ""
Nov 13 10:14:09.046: INFO: stdout: "service/rm3 exposed\n"
Nov 13 10:14:09.055: INFO: Service rm3 in namespace e2e-tests-kubectl-wljt4 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:14:11.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wljt4" for this suite.
Nov 13 10:14:33.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:14:33.161: INFO: namespace: e2e-tests-kubectl-wljt4, resource: bindings, ignored listing per whitelist
Nov 13 10:14:33.253: INFO: namespace e2e-tests-kubectl-wljt4 deletion completed in 22.187579441s

• [SLOW TEST:32.223 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:14:33.255: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wxttd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov 13 10:14:33.516: INFO: Waiting up to 5m0s for pod "downward-api-ea967a96-e72c-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-wxttd" to be "success or failure"
Nov 13 10:14:33.582: INFO: Pod "downward-api-ea967a96-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 65.926396ms
Nov 13 10:14:35.586: INFO: Pod "downward-api-ea967a96-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069666348s
Nov 13 10:14:37.672: INFO: Pod "downward-api-ea967a96-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.156345263s
Nov 13 10:14:39.726: INFO: Pod "downward-api-ea967a96-e72c-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.210004054s
STEP: Saw pod success
Nov 13 10:14:39.726: INFO: Pod "downward-api-ea967a96-e72c-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:14:39.729: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downward-api-ea967a96-e72c-11e8-baa5-625675597e81 container dapi-container: <nil>
STEP: delete the pod
Nov 13 10:14:39.752: INFO: Waiting for pod downward-api-ea967a96-e72c-11e8-baa5-625675597e81 to disappear
Nov 13 10:14:39.756: INFO: Pod downward-api-ea967a96-e72c-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:14:39.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wxttd" for this suite.
Nov 13 10:14:45.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:14:45.925: INFO: namespace: e2e-tests-downward-api-wxttd, resource: bindings, ignored listing per whitelist
Nov 13 10:14:45.954: INFO: namespace e2e-tests-downward-api-wxttd deletion completed in 6.194719763s

• [SLOW TEST:12.699 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:14:45.954: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-g8qt7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 13 10:14:46.273: INFO: Waiting up to 5m0s for pod "pod-f22e4c45-e72c-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-g8qt7" to be "success or failure"
Nov 13 10:14:46.280: INFO: Pod "pod-f22e4c45-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.874942ms
Nov 13 10:14:48.287: INFO: Pod "pod-f22e4c45-e72c-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013720753s
Nov 13 10:14:50.306: INFO: Pod "pod-f22e4c45-e72c-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033169113s
STEP: Saw pod success
Nov 13 10:14:50.306: INFO: Pod "pod-f22e4c45-e72c-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:14:50.309: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-f22e4c45-e72c-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:14:50.326: INFO: Waiting for pod pod-f22e4c45-e72c-11e8-baa5-625675597e81 to disappear
Nov 13 10:14:50.336: INFO: Pod pod-f22e4c45-e72c-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:14:50.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g8qt7" for this suite.
Nov 13 10:14:56.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:14:56.563: INFO: namespace: e2e-tests-emptydir-g8qt7, resource: bindings, ignored listing per whitelist
Nov 13 10:14:56.566: INFO: namespace e2e-tests-emptydir-g8qt7 deletion completed in 6.225427394s

• [SLOW TEST:10.612 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:14:56.566: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-lfkrz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lfkrz
Nov 13 10:15:04.814: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lfkrz
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 10:15:04.816: INFO: Initial restart count of pod liveness-http is 0
Nov 13 10:15:24.868: INFO: Restart count of pod e2e-tests-container-probe-lfkrz/liveness-http is now 1 (20.051479984s elapsed)
Nov 13 10:15:44.904: INFO: Restart count of pod e2e-tests-container-probe-lfkrz/liveness-http is now 2 (40.087259603s elapsed)
Nov 13 10:16:04.940: INFO: Restart count of pod e2e-tests-container-probe-lfkrz/liveness-http is now 3 (1m0.123547085s elapsed)
Nov 13 10:16:24.980: INFO: Restart count of pod e2e-tests-container-probe-lfkrz/liveness-http is now 4 (1m20.163827936s elapsed)
Nov 13 10:17:25.200: INFO: Restart count of pod e2e-tests-container-probe-lfkrz/liveness-http is now 5 (2m20.383811419s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:17:25.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lfkrz" for this suite.
Nov 13 10:17:31.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:17:31.355: INFO: namespace: e2e-tests-container-probe-lfkrz, resource: bindings, ignored listing per whitelist
Nov 13 10:17:31.421: INFO: namespace e2e-tests-container-probe-lfkrz deletion completed in 6.155778946s

• [SLOW TEST:154.855 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:17:31.421: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-8st2q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:17:31.669: INFO: (0) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 7.747847ms)
Nov 13 10:17:31.713: INFO: (1) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 44.300871ms)
Nov 13 10:17:31.723: INFO: (2) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 10.187962ms)
Nov 13 10:17:31.728: INFO: (3) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.519328ms)
Nov 13 10:17:31.736: INFO: (4) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 8.13115ms)
Nov 13 10:17:31.740: INFO: (5) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.454327ms)
Nov 13 10:17:31.746: INFO: (6) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.085431ms)
Nov 13 10:17:31.751: INFO: (7) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.95833ms)
Nov 13 10:17:31.756: INFO: (8) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.694029ms)
Nov 13 10:17:31.761: INFO: (9) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.074531ms)
Nov 13 10:17:31.766: INFO: (10) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.624028ms)
Nov 13 10:17:31.770: INFO: (11) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.597128ms)
Nov 13 10:17:31.774: INFO: (12) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.034925ms)
Nov 13 10:17:31.779: INFO: (13) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.585528ms)
Nov 13 10:17:31.785: INFO: (14) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.182238ms)
Nov 13 10:17:31.790: INFO: (15) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.335027ms)
Nov 13 10:17:31.795: INFO: (16) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.122832ms)
Nov 13 10:17:31.800: INFO: (17) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.680729ms)
Nov 13 10:17:31.805: INFO: (18) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.132332ms)
Nov 13 10:17:31.810: INFO: (19) /api/v1/nodes/shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.671428ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:17:31.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8st2q" for this suite.
Nov 13 10:17:37.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:17:37.964: INFO: namespace: e2e-tests-proxy-8st2q, resource: bindings, ignored listing per whitelist
Nov 13 10:17:37.987: INFO: namespace e2e-tests-proxy-8st2q deletion completed in 6.173956513s

• [SLOW TEST:6.566 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:17:37.987: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-jbxjg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:17:38.345: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 13 10:17:43.348: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 13 10:17:43.348: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 13 10:17:45.352: INFO: Creating deployment "test-rollover-deployment"
Nov 13 10:17:45.445: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 13 10:17:47.465: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 13 10:17:47.472: INFO: Ensure that both replica sets have 1 created replica
Nov 13 10:17:47.477: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 13 10:17:47.486: INFO: Updating deployment test-rollover-deployment
Nov 13 10:17:47.486: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 13 10:17:49.515: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 13 10:17:49.520: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 13 10:17:49.525: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:17:49.525: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701067, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:17:51.533: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:17:51.533: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701067, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:17:53.532: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:17:53.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701072, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:17:55.532: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:17:55.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701072, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:17:57.532: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:17:57.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701072, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:17:59.531: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:17:59.531: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701072, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:18:01.532: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:18:01.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701072, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677701065, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:18:03.531: INFO: 
Nov 13 10:18:03.531: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 13 10:18:03.538: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-jbxjg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jbxjg/deployments/test-rollover-deployment,UID:5ceee89d-e72d-11e8-bc0f-0effc19a50ed,ResourceVersion:16761,Generation:2,CreationTimestamp:2018-11-13 10:17:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-13 10:17:45 +0000 UTC 2018-11-13 10:17:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-13 10:18:02 +0000 UTC 2018-11-13 10:17:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov 13 10:18:03.540: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-jbxjg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jbxjg/replicasets/test-rollover-deployment-5b76ff8c4,UID:5e34715e-e72d-11e8-bc0f-0effc19a50ed,ResourceVersion:16754,Generation:2,CreationTimestamp:2018-11-13 10:17:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5ceee89d-e72d-11e8-bc0f-0effc19a50ed 0xc421ee0f87 0xc421ee0f88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 13 10:18:03.541: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 13 10:18:03.541: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-jbxjg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jbxjg/replicasets/test-rollover-controller,UID:58b34fc8-e72d-11e8-bc0f-0effc19a50ed,ResourceVersion:16760,Generation:2,CreationTimestamp:2018-11-13 10:17:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5ceee89d-e72d-11e8-bc0f-0effc19a50ed 0xc421ee0dae 0xc421ee0daf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 13 10:18:03.541: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-jbxjg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jbxjg/replicasets/test-rollover-deployment-6975f4fb87,UID:5d001cf0-e72d-11e8-bc0f-0effc19a50ed,ResourceVersion:16717,Generation:2,CreationTimestamp:2018-11-13 10:17:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5ceee89d-e72d-11e8-bc0f-0effc19a50ed 0xc421ee1a97 0xc421ee1a98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 13 10:18:03.543: INFO: Pod "test-rollover-deployment-5b76ff8c4-qmss8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-qmss8,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-jbxjg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbxjg/pods/test-rollover-deployment-5b76ff8c4-qmss8,UID:5e3cd129-e72d-11e8-bc0f-0effc19a50ed,ResourceVersion:16733,Generation:0,CreationTimestamp:2018-11-13 10:17:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.151/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 5e34715e-e72d-11e8-bc0f-0effc19a50ed 0xc420dea220 0xc420dea221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mnmkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mnmkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-mnmkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420dea280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420dea2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:17:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:17:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:17:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:17:47 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.1.151,StartTime:2018-11-13 10:17:47 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-13 10:17:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://eed47fa2e3819f0fbdb61e536de0374a5036abe13953900c6accc11db42f8eb7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:18:03.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jbxjg" for this suite.
Nov 13 10:18:11.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:18:11.573: INFO: namespace: e2e-tests-deployment-jbxjg, resource: bindings, ignored listing per whitelist
Nov 13 10:18:11.811: INFO: namespace e2e-tests-deployment-jbxjg deletion completed in 8.264445298s

• [SLOW TEST:33.824 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:18:11.812: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-v6vb5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:18:12.303: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-v6vb5" to be "success or failure"
Nov 13 10:18:12.317: INFO: Pod "downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 14.07559ms
Nov 13 10:18:14.320: INFO: Pod "downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01743973s
Nov 13 10:18:16.324: INFO: Pod "downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020966341s
Nov 13 10:18:18.329: INFO: Pod "downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026000284s
STEP: Saw pod success
Nov 13 10:18:18.329: INFO: Pod "downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:18:18.332: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:18:18.353: INFO: Waiting for pod downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81 to disappear
Nov 13 10:18:18.362: INFO: Pod downwardapi-volume-6cfec0cb-e72d-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:18:18.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v6vb5" for this suite.
Nov 13 10:18:24.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:18:24.408: INFO: namespace: e2e-tests-projected-v6vb5, resource: bindings, ignored listing per whitelist
Nov 13 10:18:24.522: INFO: namespace e2e-tests-projected-v6vb5 deletion completed in 6.156261169s

• [SLOW TEST:12.710 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:18:24.523: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-fv4qj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-fv4qj
Nov 13 10:18:28.758: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-fv4qj
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 10:18:28.761: INFO: Initial restart count of pod liveness-http is 0
Nov 13 10:18:46.795: INFO: Restart count of pod e2e-tests-container-probe-fv4qj/liveness-http is now 1 (18.033849703s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:18:46.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fv4qj" for this suite.
Nov 13 10:18:52.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:18:53.183: INFO: namespace: e2e-tests-container-probe-fv4qj, resource: bindings, ignored listing per whitelist
Nov 13 10:18:53.196: INFO: namespace e2e-tests-container-probe-fv4qj deletion completed in 6.373308333s

• [SLOW TEST:28.674 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:18:53.197: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-gsk7s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-858e3117-e72d-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 10:18:53.512: INFO: Waiting up to 5m0s for pod "pod-secrets-858ea8c7-e72d-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-gsk7s" to be "success or failure"
Nov 13 10:18:53.517: INFO: Pod "pod-secrets-858ea8c7-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934529ms
Nov 13 10:18:55.520: INFO: Pod "pod-secrets-858ea8c7-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008418851s
Nov 13 10:18:57.571: INFO: Pod "pod-secrets-858ea8c7-e72d-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059707054s
STEP: Saw pod success
Nov 13 10:18:57.571: INFO: Pod "pod-secrets-858ea8c7-e72d-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:18:57.574: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-secrets-858ea8c7-e72d-11e8-baa5-625675597e81 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:18:57.600: INFO: Waiting for pod pod-secrets-858ea8c7-e72d-11e8-baa5-625675597e81 to disappear
Nov 13 10:18:57.610: INFO: Pod pod-secrets-858ea8c7-e72d-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:18:57.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gsk7s" for this suite.
Nov 13 10:19:03.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:19:03.768: INFO: namespace: e2e-tests-secrets-gsk7s, resource: bindings, ignored listing per whitelist
Nov 13 10:19:03.788: INFO: namespace e2e-tests-secrets-gsk7s deletion completed in 6.172125963s

• [SLOW TEST:10.591 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:19:03.789: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-52mxd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Nov 13 10:19:04.129: INFO: Waiting up to 5m0s for pod "client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81" in namespace "e2e-tests-containers-52mxd" to be "success or failure"
Nov 13 10:19:04.135: INFO: Pod "client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.444734ms
Nov 13 10:19:06.138: INFO: Pod "client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008878794s
Nov 13 10:19:08.211: INFO: Pod "client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.081623455s
Nov 13 10:19:10.214: INFO: Pod "client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.085011548s
STEP: Saw pod success
Nov 13 10:19:10.214: INFO: Pod "client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:19:10.217: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:19:10.248: INFO: Waiting for pod client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81 to disappear
Nov 13 10:19:10.252: INFO: Pod client-containers-8be2d7e9-e72d-11e8-baa5-625675597e81 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:19:10.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-52mxd" for this suite.
Nov 13 10:19:16.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:19:16.422: INFO: namespace: e2e-tests-containers-52mxd, resource: bindings, ignored listing per whitelist
Nov 13 10:19:16.429: INFO: namespace e2e-tests-containers-52mxd deletion completed in 6.163600378s

• [SLOW TEST:12.641 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:19:16.430: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-x5sv8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Nov 13 10:19:16.700: INFO: Waiting up to 5m0s for pod "var-expansion-9360f8d8-e72d-11e8-baa5-625675597e81" in namespace "e2e-tests-var-expansion-x5sv8" to be "success or failure"
Nov 13 10:19:16.704: INFO: Pod "var-expansion-9360f8d8-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011824ms
Nov 13 10:19:18.708: INFO: Pod "var-expansion-9360f8d8-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007619976s
Nov 13 10:19:20.712: INFO: Pod "var-expansion-9360f8d8-e72d-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012095393s
STEP: Saw pod success
Nov 13 10:19:20.712: INFO: Pod "var-expansion-9360f8d8-e72d-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:19:20.745: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod var-expansion-9360f8d8-e72d-11e8-baa5-625675597e81 container dapi-container: <nil>
STEP: delete the pod
Nov 13 10:19:20.774: INFO: Waiting for pod var-expansion-9360f8d8-e72d-11e8-baa5-625675597e81 to disappear
Nov 13 10:19:20.779: INFO: Pod var-expansion-9360f8d8-e72d-11e8-baa5-625675597e81 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:19:20.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-x5sv8" for this suite.
Nov 13 10:19:26.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:19:26.867: INFO: namespace: e2e-tests-var-expansion-x5sv8, resource: bindings, ignored listing per whitelist
Nov 13 10:19:26.905: INFO: namespace e2e-tests-var-expansion-x5sv8 deletion completed in 6.119828631s

• [SLOW TEST:10.475 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:19:26.905: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-5twf7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-5twf7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5twf7 to expose endpoints map[]
Nov 13 10:19:27.202: INFO: Get endpoints failed (19.650424ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov 13 10:19:28.205: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5twf7 exposes endpoints map[] (1.022615932s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-5twf7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5twf7 to expose endpoints map[pod1:[100]]
Nov 13 10:19:32.347: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.075128477s elapsed, will retry)
Nov 13 10:19:33.371: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5twf7 exposes endpoints map[pod1:[100]] (5.098447525s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-5twf7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5twf7 to expose endpoints map[pod1:[100] pod2:[101]]
Nov 13 10:19:37.546: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5twf7 exposes endpoints map[pod1:[100] pod2:[101]] (4.169986684s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-5twf7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5twf7 to expose endpoints map[pod2:[101]]
Nov 13 10:19:38.586: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5twf7 exposes endpoints map[pod2:[101]] (1.032234662s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-5twf7
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5twf7 to expose endpoints map[]
Nov 13 10:19:39.622: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5twf7 exposes endpoints map[] (1.032946788s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:19:39.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5twf7" for this suite.
Nov 13 10:20:01.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:20:01.764: INFO: namespace: e2e-tests-services-5twf7, resource: bindings, ignored listing per whitelist
Nov 13 10:20:01.876: INFO: namespace e2e-tests-services-5twf7 deletion completed in 22.14663694s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:34.971 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:20:01.876: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tzdms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:20:02.270: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-tzdms" to be "success or failure"
Nov 13 10:20:02.289: INFO: Pod "downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 18.278916ms
Nov 13 10:20:04.292: INFO: Pod "downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021861569s
Nov 13 10:20:06.296: INFO: Pod "downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02527742s
Nov 13 10:20:08.375: INFO: Pod "downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.104825648s
STEP: Saw pod success
Nov 13 10:20:08.375: INFO: Pod "downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:20:08.378: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:20:08.397: INFO: Waiting for pod downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81 to disappear
Nov 13 10:20:08.403: INFO: Pod downwardapi-volume-ae8a60cd-e72d-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:20:08.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tzdms" for this suite.
Nov 13 10:20:14.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:20:14.517: INFO: namespace: e2e-tests-projected-tzdms, resource: bindings, ignored listing per whitelist
Nov 13 10:20:14.583: INFO: namespace e2e-tests-projected-tzdms deletion completed in 6.176904952s

• [SLOW TEST:12.707 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:20:14.584: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-b7s6v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov 13 10:20:14.834: INFO: Waiting up to 5m0s for pod "downward-api-b6077943-e72d-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-b7s6v" to be "success or failure"
Nov 13 10:20:14.849: INFO: Pod "downward-api-b6077943-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 15.366695ms
Nov 13 10:20:16.852: INFO: Pod "downward-api-b6077943-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018105761s
Nov 13 10:20:18.857: INFO: Pod "downward-api-b6077943-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022767065s
Nov 13 10:20:20.860: INFO: Pod "downward-api-b6077943-e72d-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026277915s
STEP: Saw pod success
Nov 13 10:20:20.860: INFO: Pod "downward-api-b6077943-e72d-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:20:20.863: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downward-api-b6077943-e72d-11e8-baa5-625675597e81 container dapi-container: <nil>
STEP: delete the pod
Nov 13 10:20:20.951: INFO: Waiting for pod downward-api-b6077943-e72d-11e8-baa5-625675597e81 to disappear
Nov 13 10:20:20.955: INFO: Pod downward-api-b6077943-e72d-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:20:20.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b7s6v" for this suite.
Nov 13 10:20:27.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:20:27.104: INFO: namespace: e2e-tests-downward-api-b7s6v, resource: bindings, ignored listing per whitelist
Nov 13 10:20:27.149: INFO: namespace e2e-tests-downward-api-b7s6v deletion completed in 6.19008954s

• [SLOW TEST:12.566 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:20:27.150: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jzshd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:20:27.381: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd818e1c-e72d-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-jzshd" to be "success or failure"
Nov 13 10:20:27.397: INFO: Pod "downwardapi-volume-bd818e1c-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 16.053486ms
Nov 13 10:20:29.403: INFO: Pod "downwardapi-volume-bd818e1c-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022036167s
Nov 13 10:20:31.409: INFO: Pod "downwardapi-volume-bd818e1c-e72d-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028158425s
STEP: Saw pod success
Nov 13 10:20:31.409: INFO: Pod "downwardapi-volume-bd818e1c-e72d-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:20:31.416: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-bd818e1c-e72d-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:20:31.477: INFO: Waiting for pod downwardapi-volume-bd818e1c-e72d-11e8-baa5-625675597e81 to disappear
Nov 13 10:20:31.480: INFO: Pod downwardapi-volume-bd818e1c-e72d-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:20:31.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jzshd" for this suite.
Nov 13 10:20:37.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:20:37.608: INFO: namespace: e2e-tests-downward-api-jzshd, resource: bindings, ignored listing per whitelist
Nov 13 10:20:37.712: INFO: namespace e2e-tests-downward-api-jzshd deletion completed in 6.229145095s

• [SLOW TEST:10.563 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:20:37.712: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-56wqg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Nov 13 10:20:38.029: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-56wqg" to be "success or failure"
Nov 13 10:20:38.032: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.665321ms
Nov 13 10:20:40.036: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007375578s
Nov 13 10:20:42.040: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011532406s
Nov 13 10:20:44.046: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017580623s
STEP: Saw pod success
Nov 13 10:20:44.046: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov 13 10:20:44.048: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov 13 10:20:44.073: INFO: Waiting for pod pod-host-path-test to disappear
Nov 13 10:20:44.085: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:20:44.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-56wqg" for this suite.
Nov 13 10:20:50.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:20:50.184: INFO: namespace: e2e-tests-hostpath-56wqg, resource: bindings, ignored listing per whitelist
Nov 13 10:20:50.244: INFO: namespace e2e-tests-hostpath-56wqg deletion completed in 6.14522928s

• [SLOW TEST:12.532 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:20:50.245: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8kdx5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 13 10:20:50.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:20:52.271: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov 13 10:20:52.271: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Nov 13 10:20:52.276: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Nov 13 10:20:52.283: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov 13 10:20:52.299: INFO: scanned /root for discovery docs: <nil>
Nov 13 10:20:52.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:10.955: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 13 10:21:10.955: INFO: stdout: "Created e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57\nScaling up e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Nov 13 10:21:10.955: INFO: stdout: "Created e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57\nScaling up e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Nov 13 10:21:10.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:18.189: INFO: stderr: ""
Nov 13 10:21:18.189: INFO: stdout: "e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57-v7ndq e2e-test-nginx-rc-lqjwd "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Nov 13 10:21:23.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:23.288: INFO: stderr: ""
Nov 13 10:21:23.288: INFO: stdout: "e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57-v7ndq e2e-test-nginx-rc-lqjwd "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Nov 13 10:21:28.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:28.387: INFO: stderr: ""
Nov 13 10:21:28.387: INFO: stdout: "e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57-v7ndq e2e-test-nginx-rc-lqjwd "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Nov 13 10:21:33.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:33.495: INFO: stderr: ""
Nov 13 10:21:33.495: INFO: stdout: "e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57-v7ndq e2e-test-nginx-rc-lqjwd "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Nov 13 10:21:38.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:38.592: INFO: stderr: ""
Nov 13 10:21:38.592: INFO: stdout: "e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57-v7ndq "
Nov 13 10:21:38.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57-v7ndq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:38.677: INFO: stderr: ""
Nov 13 10:21:38.677: INFO: stdout: "true"
Nov 13 10:21:38.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 get pods e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57-v7ndq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:38.826: INFO: stderr: ""
Nov 13 10:21:38.826: INFO: stdout: "nginx:1.14-alpine"
Nov 13 10:21:38.826: INFO: e2e-test-nginx-rc-b8a618be6ee2b2b1a718fe37a5d98a57-v7ndq is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Nov 13 10:21:38.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8kdx5'
Nov 13 10:21:38.971: INFO: stderr: ""
Nov 13 10:21:38.971: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:21:38.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8kdx5" for this suite.
Nov 13 10:22:00.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:22:01.134: INFO: namespace: e2e-tests-kubectl-8kdx5, resource: bindings, ignored listing per whitelist
Nov 13 10:22:01.145: INFO: namespace e2e-tests-kubectl-8kdx5 deletion completed in 22.167777164s

• [SLOW TEST:70.900 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:22:01.145: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zstfm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:22:01.358: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-zstfm" to be "success or failure"
Nov 13 10:22:01.362: INFO: Pod "downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.407427ms
Nov 13 10:22:03.367: INFO: Pod "downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008908164s
Nov 13 10:22:05.371: INFO: Pod "downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01269045s
Nov 13 10:22:07.374: INFO: Pod "downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015899151s
STEP: Saw pod success
Nov 13 10:22:07.374: INFO: Pod "downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:22:07.376: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:22:07.583: INFO: Waiting for pod downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81 to disappear
Nov 13 10:22:07.607: INFO: Pod downwardapi-volume-f585b5db-e72d-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:22:07.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zstfm" for this suite.
Nov 13 10:22:13.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:22:13.688: INFO: namespace: e2e-tests-downward-api-zstfm, resource: bindings, ignored listing per whitelist
Nov 13 10:22:13.812: INFO: namespace e2e-tests-downward-api-zstfm deletion completed in 6.202606811s

• [SLOW TEST:12.667 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:22:13.812: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-kfxbc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:22:14.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kfxbc" for this suite.
Nov 13 10:22:36.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:22:36.251: INFO: namespace: e2e-tests-pods-kfxbc, resource: bindings, ignored listing per whitelist
Nov 13 10:22:36.325: INFO: namespace e2e-tests-pods-kfxbc deletion completed in 22.209564992s

• [SLOW TEST:22.512 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:22:36.325: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-q7kkn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov 13 10:22:36.543: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:22:43.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-q7kkn" for this suite.
Nov 13 10:23:03.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:23:03.784: INFO: namespace: e2e-tests-init-container-q7kkn, resource: bindings, ignored listing per whitelist
Nov 13 10:23:03.832: INFO: namespace e2e-tests-init-container-q7kkn deletion completed in 20.178446439s

• [SLOW TEST:27.507 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:23:03.832: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-g79zp
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-1ae42c33-e72e-11e8-baa5-625675597e81
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1ae42c33-e72e-11e8-baa5-625675597e81
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:23:10.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g79zp" for this suite.
Nov 13 10:23:32.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:23:32.419: INFO: namespace: e2e-tests-configmap-g79zp, resource: bindings, ignored listing per whitelist
Nov 13 10:23:32.568: INFO: namespace e2e-tests-configmap-g79zp deletion completed in 22.170104618s

• [SLOW TEST:28.736 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:23:32.569: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-f9bzc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov 13 10:23:32.905: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f9bzc,SelfLink:/api/v1/namespaces/e2e-tests-watch-f9bzc/configmaps/e2e-watch-test-label-changed,UID:2c11c4a7-e72e-11e8-bc0f-0effc19a50ed,ResourceVersion:17729,Generation:0,CreationTimestamp:2018-11-13 10:23:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 10:23:32.905: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f9bzc,SelfLink:/api/v1/namespaces/e2e-tests-watch-f9bzc/configmaps/e2e-watch-test-label-changed,UID:2c11c4a7-e72e-11e8-bc0f-0effc19a50ed,ResourceVersion:17730,Generation:0,CreationTimestamp:2018-11-13 10:23:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 13 10:23:32.905: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f9bzc,SelfLink:/api/v1/namespaces/e2e-tests-watch-f9bzc/configmaps/e2e-watch-test-label-changed,UID:2c11c4a7-e72e-11e8-bc0f-0effc19a50ed,ResourceVersion:17731,Generation:0,CreationTimestamp:2018-11-13 10:23:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov 13 10:23:42.982: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f9bzc,SelfLink:/api/v1/namespaces/e2e-tests-watch-f9bzc/configmaps/e2e-watch-test-label-changed,UID:2c11c4a7-e72e-11e8-bc0f-0effc19a50ed,ResourceVersion:17751,Generation:0,CreationTimestamp:2018-11-13 10:23:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 10:23:42.982: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f9bzc,SelfLink:/api/v1/namespaces/e2e-tests-watch-f9bzc/configmaps/e2e-watch-test-label-changed,UID:2c11c4a7-e72e-11e8-bc0f-0effc19a50ed,ResourceVersion:17752,Generation:0,CreationTimestamp:2018-11-13 10:23:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov 13 10:23:42.983: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f9bzc,SelfLink:/api/v1/namespaces/e2e-tests-watch-f9bzc/configmaps/e2e-watch-test-label-changed,UID:2c11c4a7-e72e-11e8-bc0f-0effc19a50ed,ResourceVersion:17753,Generation:0,CreationTimestamp:2018-11-13 10:23:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:23:42.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-f9bzc" for this suite.
Nov 13 10:23:49.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:23:49.035: INFO: namespace: e2e-tests-watch-f9bzc, resource: bindings, ignored listing per whitelist
Nov 13 10:23:49.148: INFO: namespace e2e-tests-watch-f9bzc deletion completed in 6.156098682s

• [SLOW TEST:16.579 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:23:49.148: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s2xbn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-35edd8ad-e72e-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:23:49.463: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-s2xbn" to be "success or failure"
Nov 13 10:23:49.470: INFO: Pod "pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.18064ms
Nov 13 10:23:51.473: INFO: Pod "pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009308304s
Nov 13 10:23:53.477: INFO: Pod "pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013052431s
Nov 13 10:23:55.480: INFO: Pod "pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016192999s
Nov 13 10:23:57.484: INFO: Pod "pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.019951816s
STEP: Saw pod success
Nov 13 10:23:57.484: INFO: Pod "pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:23:57.486: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:23:57.521: INFO: Waiting for pod pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81 to disappear
Nov 13 10:23:57.532: INFO: Pod pod-projected-configmaps-35f56113-e72e-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:23:57.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s2xbn" for this suite.
Nov 13 10:24:03.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:24:03.696: INFO: namespace: e2e-tests-projected-s2xbn, resource: bindings, ignored listing per whitelist
Nov 13 10:24:03.718: INFO: namespace e2e-tests-projected-s2xbn deletion completed in 6.181718425s

• [SLOW TEST:14.570 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:24:03.719: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ldvcv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:24:03.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3e9c082f-e72e-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-ldvcv" to be "success or failure"
Nov 13 10:24:03.981: INFO: Pod "downwardapi-volume-3e9c082f-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 3.546422ms
Nov 13 10:24:05.985: INFO: Pod "downwardapi-volume-3e9c082f-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007138391s
Nov 13 10:24:07.993: INFO: Pod "downwardapi-volume-3e9c082f-e72e-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015561472s
STEP: Saw pod success
Nov 13 10:24:07.993: INFO: Pod "downwardapi-volume-3e9c082f-e72e-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:24:07.996: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-3e9c082f-e72e-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:24:08.073: INFO: Waiting for pod downwardapi-volume-3e9c082f-e72e-11e8-baa5-625675597e81 to disappear
Nov 13 10:24:08.090: INFO: Pod downwardapi-volume-3e9c082f-e72e-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:24:08.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ldvcv" for this suite.
Nov 13 10:24:14.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:24:14.209: INFO: namespace: e2e-tests-downward-api-ldvcv, resource: bindings, ignored listing per whitelist
Nov 13 10:24:14.270: INFO: namespace e2e-tests-downward-api-ldvcv deletion completed in 6.17686642s

• [SLOW TEST:10.551 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:24:14.270: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-6vfkx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 13 10:24:14.544: INFO: Waiting up to 5m0s for pod "pod-44e82efd-e72e-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-6vfkx" to be "success or failure"
Nov 13 10:24:14.608: INFO: Pod "pod-44e82efd-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 64.831918ms
Nov 13 10:24:16.612: INFO: Pod "pod-44e82efd-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068319155s
Nov 13 10:24:18.748: INFO: Pod "pod-44e82efd-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.204470378s
Nov 13 10:24:20.754: INFO: Pod "pod-44e82efd-e72e-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.210815122s
STEP: Saw pod success
Nov 13 10:24:20.754: INFO: Pod "pod-44e82efd-e72e-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:24:20.757: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-44e82efd-e72e-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:24:20.795: INFO: Waiting for pod pod-44e82efd-e72e-11e8-baa5-625675597e81 to disappear
Nov 13 10:24:20.805: INFO: Pod pod-44e82efd-e72e-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:24:20.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6vfkx" for this suite.
Nov 13 10:24:26.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:24:26.925: INFO: namespace: e2e-tests-emptydir-6vfkx, resource: bindings, ignored listing per whitelist
Nov 13 10:24:26.952: INFO: namespace e2e-tests-emptydir-6vfkx deletion completed in 6.143493015s

• [SLOW TEST:12.682 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:24:26.953: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8v9rk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4c80b268-e72e-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:24:27.378: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-8v9rk" to be "success or failure"
Nov 13 10:24:27.383: INFO: Pod "pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.981431ms
Nov 13 10:24:29.386: INFO: Pod "pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00801391s
Nov 13 10:24:31.390: INFO: Pod "pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01134005s
Nov 13 10:24:33.476: INFO: Pod "pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.097522146s
STEP: Saw pod success
Nov 13 10:24:33.476: INFO: Pod "pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:24:33.479: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:24:33.636: INFO: Waiting for pod pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81 to disappear
Nov 13 10:24:33.684: INFO: Pod pod-projected-configmaps-4c8ea343-e72e-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:24:33.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8v9rk" for this suite.
Nov 13 10:24:39.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:24:39.942: INFO: namespace: e2e-tests-projected-8v9rk, resource: bindings, ignored listing per whitelist
Nov 13 10:24:39.970: INFO: namespace e2e-tests-projected-8v9rk deletion completed in 6.275378994s

• [SLOW TEST:13.017 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:24:39.970: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-r6h7f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 13 10:24:40.186: INFO: Waiting up to 5m0s for pod "pod-5430f582-e72e-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-r6h7f" to be "success or failure"
Nov 13 10:24:40.189: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.759318ms
Nov 13 10:24:42.193: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006438788s
Nov 13 10:24:44.196: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009811993s
Nov 13 10:24:46.199: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012974934s
Nov 13 10:24:48.202: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016309015s
Nov 13 10:24:50.206: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 10.019660334s
Nov 13 10:24:52.209: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 12.02301899s
Nov 13 10:24:54.213: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 14.026960488s
Nov 13 10:24:56.216: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 16.03036642s
Nov 13 10:24:58.220: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 18.033974757s
Nov 13 10:25:00.224: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 20.037589626s
Nov 13 10:25:02.227: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 22.040921991s
Nov 13 10:25:04.244: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057501559s
STEP: Saw pod success
Nov 13 10:25:04.244: INFO: Pod "pod-5430f582-e72e-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:25:04.260: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-5430f582-e72e-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:25:04.360: INFO: Waiting for pod pod-5430f582-e72e-11e8-baa5-625675597e81 to disappear
Nov 13 10:25:04.380: INFO: Pod pod-5430f582-e72e-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:25:04.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r6h7f" for this suite.
Nov 13 10:25:10.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:25:10.599: INFO: namespace: e2e-tests-emptydir-r6h7f, resource: bindings, ignored listing per whitelist
Nov 13 10:25:10.599: INFO: namespace e2e-tests-emptydir-r6h7f deletion completed in 6.213731734s

• [SLOW TEST:30.629 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:25:10.599: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-jrxmk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-jrxmk.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-jrxmk.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jrxmk.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-jrxmk.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-jrxmk.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jrxmk.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:25:30.318: INFO: DNS probes using e2e-tests-dns-jrxmk/dns-test-667d1a50-e72e-11e8-baa5-625675597e81 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:25:30.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-jrxmk" for this suite.
Nov 13 10:25:36.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:25:36.566: INFO: namespace: e2e-tests-dns-jrxmk, resource: bindings, ignored listing per whitelist
Nov 13 10:25:36.596: INFO: namespace e2e-tests-dns-jrxmk deletion completed in 6.229294043s

• [SLOW TEST:25.997 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:25:36.596: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9txlp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:25:36.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 version'
Nov 13 10:25:36.986: INFO: stderr: ""
Nov 13 10:25:36.986: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.2\", GitCommit:\"17c77c7898218073f14c8d573582e8d2313dc740\", GitTreeState:\"clean\", BuildDate:\"2018-10-24T06:43:59Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:25:36.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9txlp" for this suite.
Nov 13 10:25:43.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:25:43.195: INFO: namespace: e2e-tests-kubectl-9txlp, resource: bindings, ignored listing per whitelist
Nov 13 10:25:43.225: INFO: namespace e2e-tests-kubectl-9txlp deletion completed in 6.23535583s

• [SLOW TEST:6.629 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:25:43.226: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-fm47g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-5vfnw
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Nov 13 10:25:55.086: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-vqlbq
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:26:11.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-fm47g" for this suite.
Nov 13 10:26:18.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:26:18.151: INFO: namespace: e2e-tests-namespaces-fm47g, resource: bindings, ignored listing per whitelist
Nov 13 10:26:18.206: INFO: namespace e2e-tests-namespaces-fm47g deletion completed in 6.201860568s
STEP: Destroying namespace "e2e-tests-nsdeletetest-5vfnw" for this suite.
Nov 13 10:26:18.208: INFO: Namespace e2e-tests-nsdeletetest-5vfnw was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-vqlbq" for this suite.
Nov 13 10:26:24.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:26:24.317: INFO: namespace: e2e-tests-nsdeletetest-vqlbq, resource: bindings, ignored listing per whitelist
Nov 13 10:26:24.381: INFO: namespace e2e-tests-nsdeletetest-vqlbq deletion completed in 6.172790268s

• [SLOW TEST:41.155 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:26:24.382: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-bqmg5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1113 10:26:30.671342      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 10:26:30.671: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:26:30.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bqmg5" for this suite.
Nov 13 10:26:36.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:26:36.749: INFO: namespace: e2e-tests-gc-bqmg5, resource: bindings, ignored listing per whitelist
Nov 13 10:26:36.834: INFO: namespace e2e-tests-gc-bqmg5 deletion completed in 6.160305254s

• [SLOW TEST:12.452 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:26:36.834: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-t6l9f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov 13 10:26:37.072: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:26:45.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-t6l9f" for this suite.
Nov 13 10:26:51.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:26:51.572: INFO: namespace: e2e-tests-init-container-t6l9f, resource: bindings, ignored listing per whitelist
Nov 13 10:26:51.660: INFO: namespace e2e-tests-init-container-t6l9f deletion completed in 6.174246025s

• [SLOW TEST:14.826 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:26:51.661: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-fsl56
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov 13 10:26:51.967: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:27:03.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-fsl56" for this suite.
Nov 13 10:27:09.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:27:09.857: INFO: namespace: e2e-tests-init-container-fsl56, resource: bindings, ignored listing per whitelist
Nov 13 10:27:09.864: INFO: namespace e2e-tests-init-container-fsl56 deletion completed in 6.27318582s

• [SLOW TEST:18.204 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:27:09.865: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kgwpd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ad9b5487-e72e-11e8-baa5-625675597e81
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ad9b5487-e72e-11e8-baa5-625675597e81
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:28:29.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kgwpd" for this suite.
Nov 13 10:28:51.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:28:51.628: INFO: namespace: e2e-tests-projected-kgwpd, resource: bindings, ignored listing per whitelist
Nov 13 10:28:51.647: INFO: namespace e2e-tests-projected-kgwpd deletion completed in 22.243095615s

• [SLOW TEST:101.782 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:28:51.648: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-ff9gl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-hx6v
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 10:28:51.962: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-hx6v" in namespace "e2e-tests-subpath-ff9gl" to be "success or failure"
Nov 13 10:28:51.967: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Pending", Reason="", readiness=false. Elapsed: 4.593829ms
Nov 13 10:28:53.970: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008164942s
Nov 13 10:28:55.974: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011735407s
Nov 13 10:28:57.977: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015106006s
Nov 13 10:28:59.981: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018868841s
Nov 13 10:29:01.985: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 10.023021117s
Nov 13 10:29:03.989: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 12.026587327s
Nov 13 10:29:05.992: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 14.029997474s
Nov 13 10:29:07.998: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 16.036149077s
Nov 13 10:29:10.048: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 18.085367027s
Nov 13 10:29:12.052: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 20.08961678s
Nov 13 10:29:14.453: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 22.49081595s
Nov 13 10:29:16.456: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 24.49409838s
Nov 13 10:29:18.460: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Running", Reason="", readiness=false. Elapsed: 26.49765245s
Nov 13 10:29:20.463: INFO: Pod "pod-subpath-test-downwardapi-hx6v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.501141306s
STEP: Saw pod success
Nov 13 10:29:20.463: INFO: Pod "pod-subpath-test-downwardapi-hx6v" satisfied condition "success or failure"
Nov 13 10:29:20.466: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-subpath-test-downwardapi-hx6v container test-container-subpath-downwardapi-hx6v: <nil>
STEP: delete the pod
Nov 13 10:29:20.486: INFO: Waiting for pod pod-subpath-test-downwardapi-hx6v to disappear
Nov 13 10:29:20.488: INFO: Pod pod-subpath-test-downwardapi-hx6v no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-hx6v
Nov 13 10:29:20.492: INFO: Deleting pod "pod-subpath-test-downwardapi-hx6v" in namespace "e2e-tests-subpath-ff9gl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:29:20.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ff9gl" for this suite.
Nov 13 10:29:26.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:29:26.637: INFO: namespace: e2e-tests-subpath-ff9gl, resource: bindings, ignored listing per whitelist
Nov 13 10:29:26.639: INFO: namespace e2e-tests-subpath-ff9gl deletion completed in 6.141961491s

• [SLOW TEST:34.991 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:29:26.639: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nkmz6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 13 10:29:26.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nkmz6'
Nov 13 10:29:27.097: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov 13 10:29:27.097: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Nov 13 10:29:29.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-nkmz6'
Nov 13 10:29:29.225: INFO: stderr: ""
Nov 13 10:29:29.225: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:29:29.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nkmz6" for this suite.
Nov 13 10:29:35.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:29:35.357: INFO: namespace: e2e-tests-kubectl-nkmz6, resource: bindings, ignored listing per whitelist
Nov 13 10:29:35.419: INFO: namespace e2e-tests-kubectl-nkmz6 deletion completed in 6.190821777s

• [SLOW TEST:8.780 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:29:35.420: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-jbtlv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:29:35.687: INFO: Creating deployment "nginx-deployment"
Nov 13 10:29:35.715: INFO: Waiting for observed generation 1
Nov 13 10:29:37.721: INFO: Waiting for all required pods to come up
Nov 13 10:29:37.728: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov 13 10:29:49.744: INFO: Waiting for deployment "nginx-deployment" to complete
Nov 13 10:29:49.754: INFO: Updating deployment "nginx-deployment" with a non-existent image
Nov 13 10:29:49.761: INFO: Updating deployment nginx-deployment
Nov 13 10:29:49.761: INFO: Waiting for observed generation 2
Nov 13 10:29:51.769: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 13 10:29:51.776: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 13 10:29:51.780: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov 13 10:29:51.787: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 13 10:29:51.787: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 13 10:29:51.789: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov 13 10:29:51.794: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Nov 13 10:29:51.794: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Nov 13 10:29:51.799: INFO: Updating deployment nginx-deployment
Nov 13 10:29:51.799: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Nov 13 10:29:51.810: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 13 10:29:51.827: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 13 10:29:53.855: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jbtlv/deployments/nginx-deployment,UID:04537c98-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18979,Generation:3,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-11-13 10:29:51 +0000 UTC 2018-11-13 10:29:51 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-11-13 10:29:52 +0000 UTC 2018-11-13 10:29:35 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Nov 13 10:29:53.945: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jbtlv/replicasets/nginx-deployment-7dc8f79789,UID:0cb6e32d-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18978,Generation:3,CreationTimestamp:2018-11-13 10:29:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 04537c98-e72f-11e8-bc0f-0effc19a50ed 0xc4215aa417 0xc4215aa418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 13 10:29:53.945: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Nov 13 10:29:53.945: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jbtlv/replicasets/nginx-deployment-7f9675fb8b,UID:045797d8-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18967,Generation:3,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 04537c98-e72f-11e8-bc0f-0effc19a50ed 0xc4215aa557 0xc4215aa558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Nov 13 10:29:53.954: INFO: Pod "nginx-deployment-7dc8f79789-255h4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-255h4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-255h4,UID:0e0041eb-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18969,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4215ab9b7 0xc4215ab9b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215aba20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215aba40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.954: INFO: Pod "nginx-deployment-7dc8f79789-57scg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-57scg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-57scg,UID:0cb783e3-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18905,Generation:0,CreationTimestamp:2018-11-13 10:29:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4215abb30 0xc4215abb31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215abba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215abbd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2018-11-13 10:29:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.954: INFO: Pod "nginx-deployment-7dc8f79789-5wr7p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5wr7p,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-5wr7p,UID:0cb83aae-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18914,Generation:0,CreationTimestamp:2018-11-13 10:29:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4215abcd0 0xc4215abcd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215abda0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215abdc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2018-11-13 10:29:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.954: INFO: Pod "nginx-deployment-7dc8f79789-7hjn6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7hjn6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-7hjn6,UID:0df24bad-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18973,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4215abf10 0xc4215abf11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215abf90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215abfb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.954: INFO: Pod "nginx-deployment-7dc8f79789-92cwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-92cwg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-92cwg,UID:0df5eb32-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18960,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc422106080 0xc422106081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4221060f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.955: INFO: Pod "nginx-deployment-7dc8f79789-b9tbs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-b9tbs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-b9tbs,UID:0defad9b-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18965,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4221061f0 0xc4221061f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.955: INFO: Pod "nginx-deployment-7dc8f79789-bnc8t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bnc8t,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-bnc8t,UID:0df22953-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18940,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4221063b0 0xc4221063b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.955: INFO: Pod "nginx-deployment-7dc8f79789-j5hf6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-j5hf6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-j5hf6,UID:0cb83645-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18981,Generation:0,CreationTimestamp:2018-11-13 10:29:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.48/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4221064d0 0xc4221064d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221065a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.955: INFO: Pod "nginx-deployment-7dc8f79789-pz5rd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-pz5rd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-pz5rd,UID:0df5e75f-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18983,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc422106660 0xc422106661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4221066d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221066f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.955: INFO: Pod "nginx-deployment-7dc8f79789-s7msh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-s7msh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-s7msh,UID:0df5f67d-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18966,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4221067b0 0xc4221067b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.955: INFO: Pod "nginx-deployment-7dc8f79789-sc7tl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sc7tl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-sc7tl,UID:0cc837b6-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18980,Generation:0,CreationTimestamp:2018-11-13 10:29:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.47/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc4221068c0 0xc4221068c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.955: INFO: Pod "nginx-deployment-7dc8f79789-w5cb8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-w5cb8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-w5cb8,UID:0df5f337-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18985,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc422106a10 0xc422106a11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.955: INFO: Pod "nginx-deployment-7dc8f79789-wwzf9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wwzf9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7dc8f79789-wwzf9,UID:0cca25e5-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18919,Generation:0,CreationTimestamp:2018-11-13 10:29:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0cb6e32d-e72f-11e8-bc0f-0effc19a50ed 0xc422106b60 0xc422106b61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:49 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2018-11-13 10:29:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.956: INFO: Pod "nginx-deployment-7f9675fb8b-49v72" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-49v72,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-49v72,UID:045cc05c-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18859,Generation:0,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.44/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422106cd0 0xc422106cd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.0.44,StartTime:2018-11-13 10:29:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:29:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://3d747f17432d0c4f602f21f069798d3239bff28d4a5ff4e707f20e2a818b0a48}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.956: INFO: Pod "nginx-deployment-7f9675fb8b-4sh7d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4sh7d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-4sh7d,UID:0df5d8e4-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18976,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422106e10 0xc422106e11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.956: INFO: Pod "nginx-deployment-7f9675fb8b-7g8sx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7g8sx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-7g8sx,UID:0def9b4f-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18987,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422106f40 0xc422106f41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422106fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422106fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2018-11-13 10:29:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.956: INFO: Pod "nginx-deployment-7f9675fb8b-96lgs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-96lgs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-96lgs,UID:0df61037-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18989,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc4221070a0 0xc4221070a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.956: INFO: Pod "nginx-deployment-7f9675fb8b-bv752" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bv752,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-bv752,UID:045edd39-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18873,Generation:0,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.184/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc4221071e0 0xc4221071e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.1.184,StartTime:2018-11-13 10:29:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:29:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://91cf5164c20839ede82464a9a41f9cb116ce6106a6e0232d6a4a9902f9f08ea2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.956: INFO: Pod "nginx-deployment-7f9675fb8b-dxrzt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dxrzt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-dxrzt,UID:0df611fb-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18963,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107320 0xc422107321}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221073b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.956: INFO: Pod "nginx-deployment-7f9675fb8b-ft45h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ft45h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-ft45h,UID:045c2a13-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18870,Generation:0,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.185/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107440 0xc422107441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4221074a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221074c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.1.185,StartTime:2018-11-13 10:29:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:29:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://840172a2c3fd07e2a9face403168a20076a9db741302ab69d97e69a8b819d74c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.957: INFO: Pod "nginx-deployment-7f9675fb8b-j97n8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j97n8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-j97n8,UID:045c2d25-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18849,Generation:0,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.42/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107590 0xc422107591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4221075f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.0.42,StartTime:2018-11-13 10:29:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:29:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://3d99696076bffe5b3196814bbeb32d2ed16d44bab6e4ceb578fe61b4b324452e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.957: INFO: Pod "nginx-deployment-7f9675fb8b-jc9mm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jc9mm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-jc9mm,UID:045b8caa-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18863,Generation:0,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.183/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc4221076e0 0xc4221076e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.1.183,StartTime:2018-11-13 10:29:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:29:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://dc640c5a81cce226aea2e103f8fc7cafe9f41d590e2a8e0fb16374632895189a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.957: INFO: Pod "nginx-deployment-7f9675fb8b-k9wjn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k9wjn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-k9wjn,UID:0df24423-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18972,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107820 0xc422107821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221078b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.957: INFO: Pod "nginx-deployment-7f9675fb8b-nxhvl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nxhvl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-nxhvl,UID:0df23c15-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18974,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc4221079a0 0xc4221079a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107a20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.957: INFO: Pod "nginx-deployment-7f9675fb8b-pj6ww" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pj6ww,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-pj6ww,UID:0df61d3a-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18986,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107ad0 0xc422107ad1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2018-11-13 10:29:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.957: INFO: Pod "nginx-deployment-7f9675fb8b-qpspm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qpspm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-qpspm,UID:0df5fa29-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18962,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107c00 0xc422107c01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.957: INFO: Pod "nginx-deployment-7f9675fb8b-r4cb5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-r4cb5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-r4cb5,UID:045cba3c-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18856,Generation:0,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.46/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107d00 0xc422107d01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.0.46,StartTime:2018-11-13 10:29:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:29:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://5b9680791ee2c3533db67e3c50513544a7c30428f969547fddbd50b337f1e6a1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.957: INFO: Pod "nginx-deployment-7f9675fb8b-rtxrx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rtxrx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-rtxrx,UID:045ed9d7-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18852,Generation:0,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.45/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107e60 0xc422107e61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422107ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422107ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.0.45,StartTime:2018-11-13 10:29:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:29:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://99a0878ff0a5d913da64a538bd3bb55183f94ee8d669d5a0cef48dc00bf0a7b9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.958: INFO: Pod "nginx-deployment-7f9675fb8b-sbwb4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sbwb4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-sbwb4,UID:0def8915-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18984,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc422107fa0 0xc422107fa1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a32000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a32020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2018-11-13 10:29:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.958: INFO: Pod "nginx-deployment-7f9675fb8b-vfttr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vfttr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-vfttr,UID:0df22d3f-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18988,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc421a320d0 0xc421a320d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a32130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a32150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2018-11-13 10:29:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.958: INFO: Pod "nginx-deployment-7f9675fb8b-vjvkx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vjvkx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-vjvkx,UID:045edc0c-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18843,Generation:0,CreationTimestamp:2018-11-13 10:29:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.43/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc421a32220 0xc421a32221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a32280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a322a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.0.43,StartTime:2018-11-13 10:29:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-13 10:29:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://1aff637e09d9e6e87b7f0451c2f98886cc473ddb3afd4996993c53ff4a633173}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.958: INFO: Pod "nginx-deployment-7f9675fb8b-wdcpj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wdcpj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-wdcpj,UID:0deebe2a-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18977,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc421a32360 0xc421a32361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a323c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a323e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2018-11-13 10:29:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 13 10:29:53.958: INFO: Pod "nginx-deployment-7f9675fb8b-x96z5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-x96z5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-jbtlv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jbtlv/pods/nginx-deployment-7f9675fb8b-x96z5,UID:0df23687-e72f-11e8-bc0f-0effc19a50ed,ResourceVersion:18947,Generation:0,CreationTimestamp:2018-11-13 10:29:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 045797d8-e72f-11e8-bc0f-0effc19a50ed 0xc421a32490 0xc421a32491}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sd8rn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sd8rn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sd8rn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a324f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a32510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:29:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:29:53.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jbtlv" for this suite.
Nov 13 10:30:01.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:30:02.080: INFO: namespace: e2e-tests-deployment-jbtlv, resource: bindings, ignored listing per whitelist
Nov 13 10:30:02.156: INFO: namespace e2e-tests-deployment-jbtlv deletion completed in 8.194406867s

• [SLOW TEST:26.736 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:30:02.156: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-9nwl6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9nwl6
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-9nwl6
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-9nwl6
Nov 13 10:30:02.507: INFO: Found 0 stateful pods, waiting for 1
Nov 13 10:30:12.511: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Nov 13 10:30:22.510: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov 13 10:30:22.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 10:30:23.031: INFO: stderr: ""
Nov 13 10:30:23.031: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 10:30:23.031: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 10:30:23.034: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 13 10:30:33.051: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 10:30:33.051: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:30:33.151: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:30:33.151: INFO: ss-0  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:02 +0000 UTC  }]
Nov 13 10:30:33.151: INFO: 
Nov 13 10:30:33.151: INFO: StatefulSet ss has not reached scale 3, at 1
Nov 13 10:30:34.155: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992970059s
Nov 13 10:30:35.159: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989421834s
Nov 13 10:30:36.163: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985075821s
Nov 13 10:30:37.166: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981475511s
Nov 13 10:30:38.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977760342s
Nov 13 10:30:39.174: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.974170665s
Nov 13 10:30:40.177: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970470776s
Nov 13 10:30:41.181: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966793778s
Nov 13 10:30:42.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 962.859969ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-9nwl6
Nov 13 10:30:43.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:30:43.710: INFO: stderr: ""
Nov 13 10:30:43.710: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 13 10:30:43.710: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 13 10:30:43.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:30:44.298: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Nov 13 10:30:44.298: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 13 10:30:44.298: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 13 10:30:44.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:30:44.768: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Nov 13 10:30:44.768: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 13 10:30:44.768: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 13 10:30:44.771: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:30:44.771: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:30:44.771: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov 13 10:30:44.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 10:30:45.215: INFO: stderr: ""
Nov 13 10:30:45.215: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 10:30:45.215: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 10:30:45.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 10:30:46.436: INFO: stderr: ""
Nov 13 10:30:46.436: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 10:30:46.436: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 10:30:46.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 13 10:30:47.027: INFO: stderr: ""
Nov 13 10:30:47.027: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 13 10:30:47.027: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 13 10:30:47.027: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:30:47.030: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 13 10:30:57.037: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 10:30:57.037: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 10:30:57.037: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 10:30:57.047: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:30:57.047: INFO: ss-0  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:02 +0000 UTC  }]
Nov 13 10:30:57.047: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:30:57.047: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:30:57.047: INFO: 
Nov 13 10:30:57.047: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 10:30:58.050: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:30:58.050: INFO: ss-0  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:02 +0000 UTC  }]
Nov 13 10:30:58.050: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:30:58.050: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:30:58.050: INFO: 
Nov 13 10:30:58.050: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 10:30:59.054: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:30:59.054: INFO: ss-0  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:02 +0000 UTC  }]
Nov 13 10:30:59.054: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:30:59.054: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:30:59.054: INFO: 
Nov 13 10:30:59.054: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 10:31:00.114: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:31:00.114: INFO: ss-0  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:02 +0000 UTC  }]
Nov 13 10:31:00.114: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:00.114: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:00.114: INFO: 
Nov 13 10:31:00.114: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 10:31:01.118: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:31:01.118: INFO: ss-0  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:02 +0000 UTC  }]
Nov 13 10:31:01.118: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:01.118: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:01.118: INFO: 
Nov 13 10:31:01.118: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 10:31:02.122: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:31:02.122: INFO: ss-0  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:02 +0000 UTC  }]
Nov 13 10:31:02.122: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:02.122: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:02.122: INFO: 
Nov 13 10:31:02.122: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 10:31:03.126: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:31:03.126: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:03.126: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:03.126: INFO: 
Nov 13 10:31:03.126: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 13 10:31:04.130: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:31:04.130: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:04.130: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:04.130: INFO: 
Nov 13 10:31:04.130: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 13 10:31:05.136: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:31:05.136: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:05.136: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:05.136: INFO: 
Nov 13 10:31:05.136: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 13 10:31:06.140: INFO: POD   NODE                                                  PHASE    GRACE  CONDITIONS
Nov 13 10:31:06.140: INFO: ss-1  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:06.141: INFO: ss-2  shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-13 10:30:33 +0000 UTC  }]
Nov 13 10:31:06.141: INFO: 
Nov 13 10:31:06.141: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-9nwl6
Nov 13 10:31:07.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:31:07.351: INFO: rc: 1
Nov 13 10:31:07.351: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc422ec4ae0 exit status 1 <nil> <nil> true [0xc420090d90 0xc420090e48 0xc420090f10] [0xc420090d90 0xc420090e48 0xc420090f10] [0xc420090e10 0xc420090ed0] [0x8fd520 0x8fd520] 0xc422d5c780 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Nov 13 10:31:17.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:31:17.432: INFO: rc: 1
Nov 13 10:31:17.432: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423045b90 exit status 1 <nil> <nil> true [0xc42000fa80 0xc42000faa0 0xc42000fad8] [0xc42000fa80 0xc42000faa0 0xc42000fad8] [0xc42000fa98 0xc42000fac0] [0x8fd520 0x8fd520] 0xc42222b260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:31:27.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:31:27.585: INFO: rc: 1
Nov 13 10:31:27.585: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422ec4f00 exit status 1 <nil> <nil> true [0xc420090f18 0xc420090f50 0xc420091000] [0xc420090f18 0xc420090f50 0xc420091000] [0xc420090f48 0xc420090fd8] [0x8fd520 0x8fd520] 0xc422d5c8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:31:37.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:31:37.665: INFO: rc: 1
Nov 13 10:31:37.665: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423045f50 exit status 1 <nil> <nil> true [0xc42000fae8 0xc42000fb38 0xc42000fb78] [0xc42000fae8 0xc42000fb38 0xc42000fb78] [0xc42000fb08 0xc42000fb68] [0x8fd520 0x8fd520] 0xc42222b3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:31:47.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:31:47.753: INFO: rc: 1
Nov 13 10:31:47.753: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422ec52f0 exit status 1 <nil> <nil> true [0xc420091008 0xc420091090 0xc4200910d0] [0xc420091008 0xc420091090 0xc4200910d0] [0xc420091060 0xc4200910b8] [0x8fd520 0x8fd520] 0xc422d5c9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:31:57.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:31:57.857: INFO: rc: 1
Nov 13 10:31:57.860: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422ec5800 exit status 1 <nil> <nil> true [0xc4200910d8 0xc420091140 0xc4200911f8] [0xc4200910d8 0xc420091140 0xc4200911f8] [0xc420091110 0xc420091190] [0x8fd520 0x8fd520] 0xc422d5cae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:32:07.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:32:07.945: INFO: rc: 1
Nov 13 10:32:07.945: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421b26870 exit status 1 <nil> <nil> true [0xc42000fb90 0xc42000fbc0 0xc42000fc08] [0xc42000fb90 0xc42000fbc0 0xc42000fc08] [0xc42000fba8 0xc42000fbf0] [0x8fd520 0x8fd520] 0xc42222b500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:32:17.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:32:18.033: INFO: rc: 1
Nov 13 10:32:18.033: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421b26e10 exit status 1 <nil> <nil> true [0xc42000fc20 0xc42000fc68 0xc42000fca0] [0xc42000fc20 0xc42000fc68 0xc42000fca0] [0xc42000fc58 0xc42000fc98] [0x8fd520 0x8fd520] 0xc42222b620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:32:28.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:32:28.118: INFO: rc: 1
Nov 13 10:32:28.118: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421b27290 exit status 1 <nil> <nil> true [0xc42000fcb0 0xc42000fcf0 0xc42000fd18] [0xc42000fcb0 0xc42000fcf0 0xc42000fd18] [0xc42000fcd0 0xc42000fd10] [0x8fd520 0x8fd520] 0xc42222b7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:32:38.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:32:38.246: INFO: rc: 1
Nov 13 10:32:38.246: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422ec5c80 exit status 1 <nil> <nil> true [0xc420091230 0xc420091270 0xc4200912a0] [0xc420091230 0xc420091270 0xc4200912a0] [0xc420091258 0xc420091288] [0x8fd520 0x8fd520] 0xc422d5ccc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:32:48.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:32:48.396: INFO: rc: 1
Nov 13 10:32:48.396: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423044420 exit status 1 <nil> <nil> true [0xc4200ca158 0xc4200ca1e8 0xc4200ca2a8] [0xc4200ca158 0xc4200ca1e8 0xc4200ca2a8] [0xc4200ca1b8 0xc4200ca288] [0x8fd520 0x8fd520] 0xc422aa5140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:32:58.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:32:58.508: INFO: rc: 1
Nov 13 10:32:58.508: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4230447e0 exit status 1 <nil> <nil> true [0xc4200ca2b8 0xc4200ca308 0xc420090068] [0xc4200ca2b8 0xc4200ca308 0xc420090068] [0xc4200ca2e8 0xc420090058] [0x8fd520 0x8fd520] 0xc422aa5260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:33:08.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:33:08.631: INFO: rc: 1
Nov 13 10:33:08.631: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423044d80 exit status 1 <nil> <nil> true [0xc4200900a0 0xc420090160 0xc420090280] [0xc4200900a0 0xc420090160 0xc420090280] [0xc420090158 0xc4200901f8] [0x8fd520 0x8fd520] 0xc422aa5380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:33:18.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:33:18.752: INFO: rc: 1
Nov 13 10:33:18.753: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423045290 exit status 1 <nil> <nil> true [0xc4200902e8 0xc4200903c8 0xc4200904a0] [0xc4200902e8 0xc4200903c8 0xc4200904a0] [0xc420090360 0xc420090438] [0x8fd520 0x8fd520] 0xc422aa5500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:33:28.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:33:28.856: INFO: rc: 1
Nov 13 10:33:28.856: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4230456b0 exit status 1 <nil> <nil> true [0xc4200904c8 0xc420090568 0xc420090618] [0xc4200904c8 0xc420090568 0xc420090618] [0xc420090510 0xc4200905e8] [0x8fd520 0x8fd520] 0xc422aa5620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:33:38.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:33:38.942: INFO: rc: 1
Nov 13 10:33:38.942: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423045aa0 exit status 1 <nil> <nil> true [0xc420090630 0xc420090840 0xc4200908f8] [0xc420090630 0xc420090840 0xc4200908f8] [0xc420090738 0xc4200908e0] [0x8fd520 0x8fd520] 0xc422aa5740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:33:48.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:33:49.033: INFO: rc: 1
Nov 13 10:33:49.033: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423045e30 exit status 1 <nil> <nil> true [0xc42000e010 0xc420090908 0xc4200909a0] [0xc42000e010 0xc420090908 0xc4200909a0] [0xc420090900 0xc420090970] [0x8fd520 0x8fd520] 0xc422aa5800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:33:59.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:33:59.120: INFO: rc: 1
Nov 13 10:33:59.120: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422f9e2a0 exit status 1 <nil> <nil> true [0xc4200909a8 0xc420090a68 0xc420090b10] [0xc4200909a8 0xc420090a68 0xc420090b10] [0xc4200909e0 0xc420090a90] [0x8fd520 0x8fd520] 0xc422aa5920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:34:09.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:34:09.254: INFO: rc: 1
Nov 13 10:34:09.254: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422f9e6f0 exit status 1 <nil> <nil> true [0xc420090b40 0xc420090b80 0xc420090be0] [0xc420090b40 0xc420090b80 0xc420090be0] [0xc420090b58 0xc420090bc0] [0x8fd520 0x8fd520] 0xc422aa5a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:34:19.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:34:19.344: INFO: rc: 1
Nov 13 10:34:19.344: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422fea510 exit status 1 <nil> <nil> true [0xc42000e148 0xc42000e4e8 0xc42000e550] [0xc42000e148 0xc42000e4e8 0xc42000e550] [0xc42000e4e0 0xc42000e518] [0x8fd520 0x8fd520] 0xc422d5c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:34:29.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:34:29.425: INFO: rc: 1
Nov 13 10:34:29.425: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422f9eb10 exit status 1 <nil> <nil> true [0xc420090c68 0xc420090d90 0xc420090e48] [0xc420090c68 0xc420090d90 0xc420090e48] [0xc420090d80 0xc420090e10] [0x8fd520 0x8fd520] 0xc422aa5b60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:34:39.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:34:39.512: INFO: rc: 1
Nov 13 10:34:39.512: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422fea930 exit status 1 <nil> <nil> true [0xc42000e568 0xc42000e5a8 0xc42000e5d0] [0xc42000e568 0xc42000e5a8 0xc42000e5d0] [0xc42000e5a0 0xc42000e5c0] [0x8fd520 0x8fd520] 0xc422d5c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:34:49.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:34:49.606: INFO: rc: 1
Nov 13 10:34:49.606: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423044450 exit status 1 <nil> <nil> true [0xc4200ca158 0xc4200ca1e8 0xc4200ca2a8] [0xc4200ca158 0xc4200ca1e8 0xc4200ca2a8] [0xc4200ca1b8 0xc4200ca288] [0x8fd520 0x8fd520] 0xc422d5c240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:34:59.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:34:59.694: INFO: rc: 1
Nov 13 10:34:59.694: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422fea3f0 exit status 1 <nil> <nil> true [0xc42000e010 0xc42000e4c8 0xc42000e510] [0xc42000e010 0xc42000e4c8 0xc42000e510] [0xc42000e148 0xc42000e4e8] [0x8fd520 0x8fd520] 0xc422aa5140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:35:09.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:35:09.772: INFO: rc: 1
Nov 13 10:35:09.772: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423044870 exit status 1 <nil> <nil> true [0xc4200ca2b8 0xc4200ca308 0xc420090068] [0xc4200ca2b8 0xc4200ca308 0xc420090068] [0xc4200ca2e8 0xc420090058] [0x8fd520 0x8fd520] 0xc422d5c360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:35:19.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:35:19.855: INFO: rc: 1
Nov 13 10:35:19.855: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423044ea0 exit status 1 <nil> <nil> true [0xc4200900a0 0xc420090160 0xc420090280] [0xc4200900a0 0xc420090160 0xc420090280] [0xc420090158 0xc4200901f8] [0x8fd520 0x8fd520] 0xc422d5c480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:35:29.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:35:29.940: INFO: rc: 1
Nov 13 10:35:29.940: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422fea870 exit status 1 <nil> <nil> true [0xc42000e518 0xc42000e588 0xc42000e5b8] [0xc42000e518 0xc42000e588 0xc42000e5b8] [0xc42000e568 0xc42000e5a8] [0x8fd520 0x8fd520] 0xc422aa5260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:35:39.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:35:40.028: INFO: rc: 1
Nov 13 10:35:40.028: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc423045380 exit status 1 <nil> <nil> true [0xc4200902e8 0xc4200903c8 0xc4200904a0] [0xc4200902e8 0xc4200903c8 0xc4200904a0] [0xc420090360 0xc420090438] [0x8fd520 0x8fd520] 0xc422d5c5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:35:50.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:35:50.180: INFO: rc: 1
Nov 13 10:35:50.180: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422feac60 exit status 1 <nil> <nil> true [0xc42000e5c0 0xc42000e660 0xc42000e6e0] [0xc42000e5c0 0xc42000e660 0xc42000e6e0] [0xc42000e5e8 0xc42000e6d0] [0x8fd520 0x8fd520] 0xc422aa5380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:36:00.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:36:00.264: INFO: rc: 1
Nov 13 10:36:00.264: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4230457d0 exit status 1 <nil> <nil> true [0xc4200904c8 0xc420090568 0xc420090618] [0xc4200904c8 0xc420090568 0xc420090618] [0xc420090510 0xc4200905e8] [0x8fd520 0x8fd520] 0xc422d5c780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Nov 13 10:36:10.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-071128755 exec --namespace=e2e-tests-statefulset-9nwl6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 13 10:36:10.362: INFO: rc: 1
Nov 13 10:36:10.362: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Nov 13 10:36:10.362: INFO: Scaling statefulset ss to 0
Nov 13 10:36:10.370: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 13 10:36:10.373: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9nwl6
Nov 13 10:36:10.375: INFO: Scaling statefulset ss to 0
Nov 13 10:36:10.383: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:36:10.385: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:36:10.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9nwl6" for this suite.
Nov 13 10:36:16.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:36:16.584: INFO: namespace: e2e-tests-statefulset-9nwl6, resource: bindings, ignored listing per whitelist
Nov 13 10:36:16.592: INFO: namespace e2e-tests-statefulset-9nwl6 deletion completed in 6.18983014s

• [SLOW TEST:374.436 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:36:16.593: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-ljvq9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-p44t
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 10:36:16.908: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-p44t" in namespace "e2e-tests-subpath-ljvq9" to be "success or failure"
Nov 13 10:36:16.913: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Pending", Reason="", readiness=false. Elapsed: 4.54333ms
Nov 13 10:36:18.972: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063963729s
Nov 13 10:36:20.976: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Pending", Reason="", readiness=false. Elapsed: 4.06746741s
Nov 13 10:36:22.981: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Pending", Reason="", readiness=false. Elapsed: 6.073227448s
Nov 13 10:36:24.987: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Pending", Reason="", readiness=false. Elapsed: 8.079310072s
Nov 13 10:36:26.991: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Pending", Reason="", readiness=false. Elapsed: 10.083280731s
Nov 13 10:36:28.995: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Running", Reason="", readiness=false. Elapsed: 12.087004063s
Nov 13 10:36:30.999: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Running", Reason="", readiness=false. Elapsed: 14.090816334s
Nov 13 10:36:33.002: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Running", Reason="", readiness=false. Elapsed: 16.09440524s
Nov 13 10:36:35.006: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Running", Reason="", readiness=false. Elapsed: 18.097759782s
Nov 13 10:36:37.009: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Running", Reason="", readiness=false. Elapsed: 20.101380562s
Nov 13 10:36:39.013: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Running", Reason="", readiness=false. Elapsed: 22.104863778s
Nov 13 10:36:41.016: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Running", Reason="", readiness=false. Elapsed: 24.10832103s
Nov 13 10:36:43.020: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Running", Reason="", readiness=false. Elapsed: 26.112398421s
Nov 13 10:36:45.024: INFO: Pod "pod-subpath-test-projected-p44t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.115803144s
STEP: Saw pod success
Nov 13 10:36:45.024: INFO: Pod "pod-subpath-test-projected-p44t" satisfied condition "success or failure"
Nov 13 10:36:45.026: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-subpath-test-projected-p44t container test-container-subpath-projected-p44t: <nil>
STEP: delete the pod
Nov 13 10:36:45.102: INFO: Waiting for pod pod-subpath-test-projected-p44t to disappear
Nov 13 10:36:45.110: INFO: Pod pod-subpath-test-projected-p44t no longer exists
STEP: Deleting pod pod-subpath-test-projected-p44t
Nov 13 10:36:45.110: INFO: Deleting pod "pod-subpath-test-projected-p44t" in namespace "e2e-tests-subpath-ljvq9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:36:45.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ljvq9" for this suite.
Nov 13 10:36:51.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:36:51.330: INFO: namespace: e2e-tests-subpath-ljvq9, resource: bindings, ignored listing per whitelist
Nov 13 10:36:51.332: INFO: namespace e2e-tests-subpath-ljvq9 deletion completed in 6.202452131s

• [SLOW TEST:34.740 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:36:51.333: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-bv6fz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-bv6fz
Nov 13 10:36:55.624: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-bv6fz
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 10:36:55.626: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:40:57.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bv6fz" for this suite.
Nov 13 10:41:03.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:41:03.322: INFO: namespace: e2e-tests-container-probe-bv6fz, resource: bindings, ignored listing per whitelist
Nov 13 10:41:03.374: INFO: namespace e2e-tests-container-probe-bv6fz deletion completed in 6.200548022s

• [SLOW TEST:252.041 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:41:03.374: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-nx2v6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:41:07.683: INFO: Waiting up to 5m0s for pod "client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81" in namespace "e2e-tests-pods-nx2v6" to be "success or failure"
Nov 13 10:41:07.711: INFO: Pod "client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 28.69439ms
Nov 13 10:41:09.715: INFO: Pod "client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031917813s
Nov 13 10:41:11.720: INFO: Pod "client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037349125s
Nov 13 10:41:13.724: INFO: Pod "client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040924867s
STEP: Saw pod success
Nov 13 10:41:13.724: INFO: Pod "client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:41:13.726: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81 container env3cont: <nil>
STEP: delete the pod
Nov 13 10:41:13.796: INFO: Waiting for pod client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81 to disappear
Nov 13 10:41:13.801: INFO: Pod client-envvars-a0c92fd6-e730-11e8-baa5-625675597e81 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:41:13.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nx2v6" for this suite.
Nov 13 10:42:05.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:42:05.930: INFO: namespace: e2e-tests-pods-nx2v6, resource: bindings, ignored listing per whitelist
Nov 13 10:42:05.950: INFO: namespace e2e-tests-pods-nx2v6 deletion completed in 52.146184611s

• [SLOW TEST:62.577 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:42:05.951: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-9gr45
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov 13 10:42:06.164: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 13 10:42:06.170: INFO: Waiting for terminating namespaces to be deleted...
Nov 13 10:42:06.172: INFO: 
Logging pods the kubelet thinks is on node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j before test
Nov 13 10:42:06.188: INFO: node-exporter-wspmd from kube-system started at 2018-11-13 08:45:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.188: INFO: 	Container node-exporter ready: true, restart count 0
Nov 13 10:42:06.188: INFO: sonobuoy-e2e-job-2ff76b52b92f4655 from heptio-sonobuoy started at 2018-11-13 08:59:55 +0000 UTC (2 container statuses recorded)
Nov 13 10:42:06.188: INFO: 	Container e2e ready: true, restart count 0
Nov 13 10:42:06.188: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:42:06.188: INFO: calico-node-rncpj from kube-system started at 2018-11-13 08:45:16 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.188: INFO: 	Container calico-node ready: true, restart count 0
Nov 13 10:42:06.188: INFO: sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-bc4jf from heptio-sonobuoy started at 2018-11-13 08:59:55 +0000 UTC (2 container statuses recorded)
Nov 13 10:42:06.188: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Nov 13 10:42:06.188: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov 13 10:42:06.188: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-13 08:59:50 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.188: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 13 10:42:06.188: INFO: kube-proxy-nnlwg from kube-system started at 2018-11-13 08:45:16 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.189: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 13 10:42:06.189: INFO: 
Logging pods the kubelet thinks is on node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-tnrwd before test
Nov 13 10:42:06.330: INFO: metrics-server-7b7c958998-5pqpk from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container metrics-server ready: true, restart count 0
Nov 13 10:42:06.330: INFO: addons-nginx-ingress-controller-5d8ff96544-4nqmh from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Nov 13 10:42:06.330: INFO: vpn-shoot-7598ff6d9d-zzfv2 from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container vpn-shoot ready: true, restart count 0
Nov 13 10:42:06.330: INFO: calico-node-szwdh from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container calico-node ready: true, restart count 0
Nov 13 10:42:06.330: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6584cc89bc-pfc2k from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Nov 13 10:42:06.330: INFO: node-exporter-rqx88 from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container node-exporter ready: true, restart count 0
Nov 13 10:42:06.330: INFO: coredns-996685c97-q726s from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:42:06.330: INFO: addons-kubernetes-dashboard-789b6fcb7f-ghcnb from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container main ready: true, restart count 0
Nov 13 10:42:06.330: INFO: kube-proxy-29h2s from kube-system started at 2018-11-13 08:44:35 +0000 UTC (1 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 13 10:42:06.330: INFO: sonobuoy-systemd-logs-daemon-set-8fe3af13360c454e-phpj5 from heptio-sonobuoy started at 2018-11-13 08:59:56 +0000 UTC (2 container statuses recorded)
Nov 13 10:42:06.330: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Nov 13 10:42:06.330: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1566a8fcd8c8664e], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:42:07.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9gr45" for this suite.
Nov 13 10:42:13.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:42:13.456: INFO: namespace: e2e-tests-sched-pred-9gr45, resource: bindings, ignored listing per whitelist
Nov 13 10:42:13.538: INFO: namespace e2e-tests-sched-pred-9gr45 deletion completed in 6.185033368s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.588 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:42:13.539: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-l8c6w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:42:13.766: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-l8c6w" to be "success or failure"
Nov 13 10:42:13.782: INFO: Pod "downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 16.179403ms
Nov 13 10:42:15.785: INFO: Pod "downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019611609s
Nov 13 10:42:17.789: INFO: Pod "downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022964013s
Nov 13 10:42:19.792: INFO: Pod "downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026201876s
Nov 13 10:42:21.795: INFO: Pod "downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.029542576s
STEP: Saw pod success
Nov 13 10:42:21.795: INFO: Pod "downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:42:21.798: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:42:21.838: INFO: Waiting for pod downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81 to disappear
Nov 13 10:42:21.848: INFO: Pod downwardapi-volume-c82c73db-e730-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:42:21.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l8c6w" for this suite.
Nov 13 10:42:27.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:42:27.950: INFO: namespace: e2e-tests-downward-api-l8c6w, resource: bindings, ignored listing per whitelist
Nov 13 10:42:28.016: INFO: namespace e2e-tests-downward-api-l8c6w deletion completed in 6.163868389s

• [SLOW TEST:14.478 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:42:28.017: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tv692
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d0dc91d5-e730-11e8-baa5-625675597e81
STEP: Creating a pod to test consume configMaps
Nov 13 10:42:28.360: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-tv692" to be "success or failure"
Nov 13 10:42:28.372: INFO: Pod "pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 12.002677ms
Nov 13 10:42:30.375: INFO: Pod "pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015233653s
Nov 13 10:42:32.379: INFO: Pod "pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018918875s
Nov 13 10:42:34.453: INFO: Pod "pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.093096771s
STEP: Saw pod success
Nov 13 10:42:34.453: INFO: Pod "pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:42:34.456: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:42:34.499: INFO: Waiting for pod pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81 to disappear
Nov 13 10:42:34.502: INFO: Pod pod-projected-configmaps-d0df4271-e730-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:42:34.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tv692" for this suite.
Nov 13 10:42:40.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:42:40.580: INFO: namespace: e2e-tests-projected-tv692, resource: bindings, ignored listing per whitelist
Nov 13 10:42:40.659: INFO: namespace e2e-tests-projected-tv692 deletion completed in 6.152993358s

• [SLOW TEST:12.643 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:42:40.659: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-sbfwz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d85f5204-e730-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 10:42:40.946: INFO: Waiting up to 5m0s for pod "pod-secrets-d85fce35-e730-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-sbfwz" to be "success or failure"
Nov 13 10:42:40.953: INFO: Pod "pod-secrets-d85fce35-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 7.198847ms
Nov 13 10:42:42.957: INFO: Pod "pod-secrets-d85fce35-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010517967s
Nov 13 10:42:44.960: INFO: Pod "pod-secrets-d85fce35-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013919761s
Nov 13 10:42:46.964: INFO: Pod "pod-secrets-d85fce35-e730-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017803291s
STEP: Saw pod success
Nov 13 10:42:46.964: INFO: Pod "pod-secrets-d85fce35-e730-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:42:46.967: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-secrets-d85fce35-e730-11e8-baa5-625675597e81 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:42:47.258: INFO: Waiting for pod pod-secrets-d85fce35-e730-11e8-baa5-625675597e81 to disappear
Nov 13 10:42:47.261: INFO: Pod pod-secrets-d85fce35-e730-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:42:47.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sbfwz" for this suite.
Nov 13 10:42:53.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:42:53.506: INFO: namespace: e2e-tests-secrets-sbfwz, resource: bindings, ignored listing per whitelist
Nov 13 10:42:53.530: INFO: namespace e2e-tests-secrets-sbfwz deletion completed in 6.263444767s

• [SLOW TEST:12.871 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:42:53.530: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4ptnk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:42:53.748: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-4ptnk" to be "success or failure"
Nov 13 10:42:53.754: INFO: Pod "downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021337ms
Nov 13 10:42:55.757: INFO: Pod "downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009592268s
Nov 13 10:42:57.761: INFO: Pod "downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01295186s
Nov 13 10:42:59.765: INFO: Pod "downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016748608s
Nov 13 10:43:01.768: INFO: Pod "downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020491464s
STEP: Saw pod success
Nov 13 10:43:01.768: INFO: Pod "downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:43:01.771: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:43:01.797: INFO: Waiting for pod downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81 to disappear
Nov 13 10:43:01.809: INFO: Pod downwardapi-volume-e001330e-e730-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:43:01.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4ptnk" for this suite.
Nov 13 10:43:07.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:43:08.018: INFO: namespace: e2e-tests-downward-api-4ptnk, resource: bindings, ignored listing per whitelist
Nov 13 10:43:08.025: INFO: namespace e2e-tests-downward-api-4ptnk deletion completed in 6.211666689s

• [SLOW TEST:14.495 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:43:08.025: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vr957
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-e8ad5fc5-e730-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 10:43:08.302: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e8ae0020-e730-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-vr957" to be "success or failure"
Nov 13 10:43:08.344: INFO: Pod "pod-projected-secrets-e8ae0020-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 41.379169ms
Nov 13 10:43:10.348: INFO: Pod "pod-projected-secrets-e8ae0020-e730-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045382187s
Nov 13 10:43:12.351: INFO: Pod "pod-projected-secrets-e8ae0020-e730-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0490441s
STEP: Saw pod success
Nov 13 10:43:12.352: INFO: Pod "pod-projected-secrets-e8ae0020-e730-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:43:12.354: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-secrets-e8ae0020-e730-11e8-baa5-625675597e81 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:43:12.398: INFO: Waiting for pod pod-projected-secrets-e8ae0020-e730-11e8-baa5-625675597e81 to disappear
Nov 13 10:43:12.411: INFO: Pod pod-projected-secrets-e8ae0020-e730-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:43:12.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vr957" for this suite.
Nov 13 10:43:18.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:43:18.913: INFO: namespace: e2e-tests-projected-vr957, resource: bindings, ignored listing per whitelist
Nov 13 10:43:19.007: INFO: namespace e2e-tests-projected-vr957 deletion completed in 6.593696042s

• [SLOW TEST:10.982 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:43:19.009: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-qmjrs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qmjrs
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Nov 13 10:43:19.275: INFO: Found 0 stateful pods, waiting for 3
Nov 13 10:43:29.282: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:43:29.282: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:43:29.282: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 13 10:43:39.279: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:43:39.279: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:43:39.279: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov 13 10:43:39.308: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov 13 10:43:49.339: INFO: Updating stateful set ss2
Nov 13 10:43:49.345: INFO: Waiting for Pod e2e-tests-statefulset-qmjrs/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov 13 10:43:59.352: INFO: Waiting for Pod e2e-tests-statefulset-qmjrs/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Nov 13 10:44:09.472: INFO: Found 2 stateful pods, waiting for 3
Nov 13 10:44:19.595: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:44:19.595: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:44:19.595: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 13 10:44:29.476: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:44:29.476: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:44:29.476: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov 13 10:44:29.547: INFO: Updating stateful set ss2
Nov 13 10:44:29.590: INFO: Waiting for Pod e2e-tests-statefulset-qmjrs/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov 13 10:44:39.614: INFO: Updating stateful set ss2
Nov 13 10:44:39.621: INFO: Waiting for StatefulSet e2e-tests-statefulset-qmjrs/ss2 to complete update
Nov 13 10:44:39.621: INFO: Waiting for Pod e2e-tests-statefulset-qmjrs/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov 13 10:44:49.628: INFO: Waiting for StatefulSet e2e-tests-statefulset-qmjrs/ss2 to complete update
Nov 13 10:44:49.628: INFO: Waiting for Pod e2e-tests-statefulset-qmjrs/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 13 10:44:59.628: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qmjrs
Nov 13 10:44:59.631: INFO: Scaling statefulset ss2 to 0
Nov 13 10:45:39.653: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:45:39.655: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:45:39.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qmjrs" for this suite.
Nov 13 10:45:45.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:45:45.900: INFO: namespace: e2e-tests-statefulset-qmjrs, resource: bindings, ignored listing per whitelist
Nov 13 10:45:45.929: INFO: namespace e2e-tests-statefulset-qmjrs deletion completed in 6.169709391s

• [SLOW TEST:146.921 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:45:45.929: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-px9x2
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-46d01aa8-e731-11e8-baa5-625675597e81
STEP: Creating secret with name s-test-opt-upd-46d01ae2-e731-11e8-baa5-625675597e81
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-46d01aa8-e731-11e8-baa5-625675597e81
STEP: Updating secret s-test-opt-upd-46d01ae2-e731-11e8-baa5-625675597e81
STEP: Creating secret with name s-test-opt-create-46d01afa-e731-11e8-baa5-625675597e81
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:45:56.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-px9x2" for this suite.
Nov 13 10:46:19.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:46:19.809: INFO: namespace: e2e-tests-secrets-px9x2, resource: bindings, ignored listing per whitelist
Nov 13 10:46:19.881: INFO: namespace e2e-tests-secrets-px9x2 deletion completed in 23.236920166s

• [SLOW TEST:33.952 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:46:19.881: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-6svrb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Nov 13 10:46:20.686: INFO: Waiting up to 5m0s for pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn" in namespace "e2e-tests-svcaccounts-6svrb" to be "success or failure"
Nov 13 10:46:20.692: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn": Phase="Pending", Reason="", readiness=false. Elapsed: 5.340235ms
Nov 13 10:46:22.694: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008233937s
Nov 13 10:46:24.699: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012276112s
Nov 13 10:46:26.702: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015842821s
Nov 13 10:46:28.705: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.019083099s
STEP: Saw pod success
Nov 13 10:46:28.705: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn" satisfied condition "success or failure"
Nov 13 10:46:28.708: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn container token-test: <nil>
STEP: delete the pod
Nov 13 10:46:28.773: INFO: Waiting for pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn to disappear
Nov 13 10:46:28.791: INFO: Pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-2g4kn no longer exists
STEP: Creating a pod to test consume service account root CA
Nov 13 10:46:28.795: INFO: Waiting up to 5m0s for pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf" in namespace "e2e-tests-svcaccounts-6svrb" to be "success or failure"
Nov 13 10:46:28.800: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.81473ms
Nov 13 10:46:30.802: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007668747s
Nov 13 10:46:32.806: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011282228s
Nov 13 10:46:34.810: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014762954s
Nov 13 10:46:36.813: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.018659293s
STEP: Saw pod success
Nov 13 10:46:36.814: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf" satisfied condition "success or failure"
Nov 13 10:46:36.820: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf container root-ca-test: <nil>
STEP: delete the pod
Nov 13 10:46:36.853: INFO: Waiting for pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf to disappear
Nov 13 10:46:36.859: INFO: Pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-wqkpf no longer exists
STEP: Creating a pod to test consume service account namespace
Nov 13 10:46:36.863: INFO: Waiting up to 5m0s for pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8" in namespace "e2e-tests-svcaccounts-6svrb" to be "success or failure"
Nov 13 10:46:36.918: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8": Phase="Pending", Reason="", readiness=false. Elapsed: 55.007241ms
Nov 13 10:46:38.922: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058828117s
Nov 13 10:46:40.929: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.06571986s
Nov 13 10:46:42.932: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.069020472s
Nov 13 10:46:44.936: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.072661611s
Nov 13 10:46:46.939: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.075584979s
STEP: Saw pod success
Nov 13 10:46:46.939: INFO: Pod "pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8" satisfied condition "success or failure"
Nov 13 10:46:46.945: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8 container namespace-test: <nil>
STEP: delete the pod
Nov 13 10:46:47.003: INFO: Waiting for pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8 to disappear
Nov 13 10:46:47.020: INFO: Pod pod-service-account-5b59a48e-e731-11e8-baa5-625675597e81-tlgv8 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:46:47.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-6svrb" for this suite.
Nov 13 10:46:53.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:46:53.181: INFO: namespace: e2e-tests-svcaccounts-6svrb, resource: bindings, ignored listing per whitelist
Nov 13 10:46:53.197: INFO: namespace e2e-tests-svcaccounts-6svrb deletion completed in 6.173687437s

• [SLOW TEST:33.316 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:46:53.200: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cfqmf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-cfqmf/secret-test-6eed5921-e731-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 10:46:53.535: INFO: Waiting up to 5m0s for pod "pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-cfqmf" to be "success or failure"
Nov 13 10:46:53.541: INFO: Pod "pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 5.325633ms
Nov 13 10:46:55.544: INFO: Pod "pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008972414s
Nov 13 10:46:57.558: INFO: Pod "pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022672357s
Nov 13 10:46:59.561: INFO: Pod "pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025980687s
Nov 13 10:47:01.565: INFO: Pod "pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.02989337s
STEP: Saw pod success
Nov 13 10:47:01.565: INFO: Pod "pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:47:01.568: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81 container env-test: <nil>
STEP: delete the pod
Nov 13 10:47:01.591: INFO: Waiting for pod pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81 to disappear
Nov 13 10:47:01.593: INFO: Pod pod-configmaps-6eedd58d-e731-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:47:01.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cfqmf" for this suite.
Nov 13 10:47:07.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:47:07.804: INFO: namespace: e2e-tests-secrets-cfqmf, resource: bindings, ignored listing per whitelist
Nov 13 10:47:07.832: INFO: namespace e2e-tests-secrets-cfqmf deletion completed in 6.235043713s

• [SLOW TEST:14.632 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:47:07.832: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-zgqh2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Nov 13 10:47:08.644: INFO: created pod pod-service-account-defaultsa
Nov 13 10:47:08.645: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 13 10:47:08.659: INFO: created pod pod-service-account-mountsa
Nov 13 10:47:08.659: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 13 10:47:08.671: INFO: created pod pod-service-account-nomountsa
Nov 13 10:47:08.671: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 13 10:47:08.689: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 13 10:47:08.689: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 13 10:47:08.708: INFO: created pod pod-service-account-mountsa-mountspec
Nov 13 10:47:08.708: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 13 10:47:08.723: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 13 10:47:08.723: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 13 10:47:08.729: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 13 10:47:08.729: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 13 10:47:08.742: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 13 10:47:08.742: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 13 10:47:08.763: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 13 10:47:08.763: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:47:08.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-zgqh2" for this suite.
Nov 13 10:47:30.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:47:30.853: INFO: namespace: e2e-tests-svcaccounts-zgqh2, resource: bindings, ignored listing per whitelist
Nov 13 10:47:30.966: INFO: namespace e2e-tests-svcaccounts-zgqh2 deletion completed in 22.181112933s

• [SLOW TEST:23.133 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:47:30.966: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-7426w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1113 10:47:41.354796      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 10:47:41.354: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:47:41.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7426w" for this suite.
Nov 13 10:47:47.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:47:47.527: INFO: namespace: e2e-tests-gc-7426w, resource: bindings, ignored listing per whitelist
Nov 13 10:47:47.591: INFO: namespace e2e-tests-gc-7426w deletion completed in 6.233671627s

• [SLOW TEST:16.625 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:47:47.591: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-9tkv5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1113 10:47:57.947504      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 10:47:57.947: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:47:57.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9tkv5" for this suite.
Nov 13 10:48:03.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:48:04.055: INFO: namespace: e2e-tests-gc-9tkv5, resource: bindings, ignored listing per whitelist
Nov 13 10:48:04.109: INFO: namespace e2e-tests-gc-9tkv5 deletion completed in 6.159028378s

• [SLOW TEST:16.519 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:48:04.111: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lsv29
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:48:04.400: INFO: Waiting up to 5m0s for pod "downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81" in namespace "e2e-tests-downward-api-lsv29" to be "success or failure"
Nov 13 10:48:04.433: INFO: Pod "downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 32.811603ms
Nov 13 10:48:06.437: INFO: Pod "downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03634492s
Nov 13 10:48:08.440: INFO: Pod "downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040106431s
Nov 13 10:48:10.444: INFO: Pod "downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043485854s
Nov 13 10:48:12.448: INFO: Pod "downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.047245149s
STEP: Saw pod success
Nov 13 10:48:12.448: INFO: Pod "downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:48:12.450: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81 container client-container: <nil>
STEP: delete the pod
Nov 13 10:48:12.472: INFO: Waiting for pod downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81 to disappear
Nov 13 10:48:12.668: INFO: Pod downwardapi-volume-992b0a88-e731-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:48:12.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lsv29" for this suite.
Nov 13 10:48:18.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:48:18.755: INFO: namespace: e2e-tests-downward-api-lsv29, resource: bindings, ignored listing per whitelist
Nov 13 10:48:18.790: INFO: namespace e2e-tests-downward-api-lsv29 deletion completed in 6.114843918s

• [SLOW TEST:14.679 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:48:18.791: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-hjfq6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-q24k9
STEP: Creating secret with name secret-test-a1ece4a0-e731-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 10:48:19.262: INFO: Waiting up to 5m0s for pod "pod-secrets-a20688db-e731-11e8-baa5-625675597e81" in namespace "e2e-tests-secrets-hjfq6" to be "success or failure"
Nov 13 10:48:19.274: INFO: Pod "pod-secrets-a20688db-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 12.208377ms
Nov 13 10:48:21.289: INFO: Pod "pod-secrets-a20688db-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027330183s
Nov 13 10:48:23.292: INFO: Pod "pod-secrets-a20688db-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030713561s
Nov 13 10:48:25.316: INFO: Pod "pod-secrets-a20688db-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.054537067s
Nov 13 10:48:27.327: INFO: Pod "pod-secrets-a20688db-e731-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.065072206s
STEP: Saw pod success
Nov 13 10:48:27.327: INFO: Pod "pod-secrets-a20688db-e731-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:48:27.331: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-secrets-a20688db-e731-11e8-baa5-625675597e81 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:48:27.404: INFO: Waiting for pod pod-secrets-a20688db-e731-11e8-baa5-625675597e81 to disappear
Nov 13 10:48:27.407: INFO: Pod pod-secrets-a20688db-e731-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:48:27.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hjfq6" for this suite.
Nov 13 10:48:33.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:48:33.606: INFO: namespace: e2e-tests-secrets-hjfq6, resource: bindings, ignored listing per whitelist
Nov 13 10:48:33.676: INFO: namespace e2e-tests-secrets-hjfq6 deletion completed in 6.264815993s
STEP: Destroying namespace "e2e-tests-secret-namespace-q24k9" for this suite.
Nov 13 10:48:39.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:48:39.919: INFO: namespace: e2e-tests-secret-namespace-q24k9, resource: bindings, ignored listing per whitelist
Nov 13 10:48:39.935: INFO: namespace e2e-tests-secret-namespace-q24k9 deletion completed in 6.259364145s

• [SLOW TEST:21.145 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:48:39.936: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-schpn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov 13 10:48:44.762: INFO: Successfully updated pod "labelsupdateae819218-e731-11e8-baa5-625675597e81"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:48:46.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-schpn" for this suite.
Nov 13 10:49:08.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:49:08.904: INFO: namespace: e2e-tests-projected-schpn, resource: bindings, ignored listing per whitelist
Nov 13 10:49:08.998: INFO: namespace e2e-tests-projected-schpn deletion completed in 22.21233224s

• [SLOW TEST:29.062 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:49:08.998: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8pccm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-bfd24d3f-e731-11e8-baa5-625675597e81
STEP: Creating a pod to test consume secrets
Nov 13 10:49:09.253: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81" in namespace "e2e-tests-projected-8pccm" to be "success or failure"
Nov 13 10:49:09.258: INFO: Pod "pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.946931ms
Nov 13 10:49:11.261: INFO: Pod "pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00837335s
Nov 13 10:49:13.265: INFO: Pod "pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012098892s
Nov 13 10:49:15.269: INFO: Pod "pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015726925s
Nov 13 10:49:17.272: INFO: Pod "pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.019453163s
STEP: Saw pod success
Nov 13 10:49:17.272: INFO: Pod "pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:49:17.275: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:49:17.354: INFO: Waiting for pod pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81 to disappear
Nov 13 10:49:17.377: INFO: Pod pod-projected-secrets-bfd2bed3-e731-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:49:17.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8pccm" for this suite.
Nov 13 10:49:23.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:49:23.548: INFO: namespace: e2e-tests-projected-8pccm, resource: bindings, ignored listing per whitelist
Nov 13 10:49:23.575: INFO: namespace e2e-tests-projected-8pccm deletion completed in 6.19136865s

• [SLOW TEST:14.577 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:49:23.575: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-52fnp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov 13 10:49:23.832: INFO: Creating ReplicaSet my-hostname-basic-c8844c33-e731-11e8-baa5-625675597e81
Nov 13 10:49:23.848: INFO: Pod name my-hostname-basic-c8844c33-e731-11e8-baa5-625675597e81: Found 0 pods out of 1
Nov 13 10:49:28.852: INFO: Pod name my-hostname-basic-c8844c33-e731-11e8-baa5-625675597e81: Found 1 pods out of 1
Nov 13 10:49:28.852: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c8844c33-e731-11e8-baa5-625675597e81" is running
Nov 13 10:49:28.943: INFO: Pod "my-hostname-basic-c8844c33-e731-11e8-baa5-625675597e81-28d8k" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-13 10:49:24 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-13 10:49:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-13 10:49:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-13 10:49:23 +0000 UTC Reason: Message:}])
Nov 13 10:49:28.943: INFO: Trying to dial the pod
Nov 13 10:49:34.134: INFO: Controller my-hostname-basic-c8844c33-e731-11e8-baa5-625675597e81: Got expected result from replica 1 [my-hostname-basic-c8844c33-e731-11e8-baa5-625675597e81-28d8k]: "my-hostname-basic-c8844c33-e731-11e8-baa5-625675597e81-28d8k", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:49:34.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-52fnp" for this suite.
Nov 13 10:49:40.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:49:40.294: INFO: namespace: e2e-tests-replicaset-52fnp, resource: bindings, ignored listing per whitelist
Nov 13 10:49:40.299: INFO: namespace e2e-tests-replicaset-52fnp deletion completed in 6.162548715s

• [SLOW TEST:16.724 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:49:40.300: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-zvs8q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 13 10:49:40.598: INFO: Waiting up to 5m0s for pod "pod-d27d13af-e731-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-zvs8q" to be "success or failure"
Nov 13 10:49:40.602: INFO: Pod "pod-d27d13af-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.114226ms
Nov 13 10:49:42.606: INFO: Pod "pod-d27d13af-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007961277s
Nov 13 10:49:44.610: INFO: Pod "pod-d27d13af-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011662002s
Nov 13 10:49:46.613: INFO: Pod "pod-d27d13af-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015157526s
Nov 13 10:49:48.672: INFO: Pod "pod-d27d13af-e731-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.07327469s
STEP: Saw pod success
Nov 13 10:49:48.672: INFO: Pod "pod-d27d13af-e731-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:49:48.674: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-d27d13af-e731-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:49:48.694: INFO: Waiting for pod pod-d27d13af-e731-11e8-baa5-625675597e81 to disappear
Nov 13 10:49:48.700: INFO: Pod pod-d27d13af-e731-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:49:48.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zvs8q" for this suite.
Nov 13 10:49:54.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:49:54.840: INFO: namespace: e2e-tests-emptydir-zvs8q, resource: bindings, ignored listing per whitelist
Nov 13 10:49:54.887: INFO: namespace e2e-tests-emptydir-zvs8q deletion completed in 6.183814279s

• [SLOW TEST:14.587 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:49:54.887: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-8jx4v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Nov 13 10:49:55.107: INFO: Waiting up to 5m0s for pod "var-expansion-db27b479-e731-11e8-baa5-625675597e81" in namespace "e2e-tests-var-expansion-8jx4v" to be "success or failure"
Nov 13 10:49:55.119: INFO: Pod "var-expansion-db27b479-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 12.195077ms
Nov 13 10:49:57.126: INFO: Pod "var-expansion-db27b479-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018721796s
Nov 13 10:49:59.129: INFO: Pod "var-expansion-db27b479-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021891653s
Nov 13 10:50:01.133: INFO: Pod "var-expansion-db27b479-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025538612s
Nov 13 10:50:03.136: INFO: Pod "var-expansion-db27b479-e731-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.029203055s
STEP: Saw pod success
Nov 13 10:50:03.136: INFO: Pod "var-expansion-db27b479-e731-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:50:03.139: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod var-expansion-db27b479-e731-11e8-baa5-625675597e81 container dapi-container: <nil>
STEP: delete the pod
Nov 13 10:50:03.165: INFO: Waiting for pod var-expansion-db27b479-e731-11e8-baa5-625675597e81 to disappear
Nov 13 10:50:03.196: INFO: Pod var-expansion-db27b479-e731-11e8-baa5-625675597e81 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:50:03.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-8jx4v" for this suite.
Nov 13 10:50:09.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:50:09.279: INFO: namespace: e2e-tests-var-expansion-8jx4v, resource: bindings, ignored listing per whitelist
Nov 13 10:50:09.345: INFO: namespace e2e-tests-var-expansion-8jx4v deletion completed in 6.144016743s

• [SLOW TEST:14.458 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov 13 10:50:09.345: INFO: >>> kubeConfig: /tmp/kubeconfig-071128755
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hpkcb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 13 10:50:09.649: INFO: Waiting up to 5m0s for pod "pod-e3d29928-e731-11e8-baa5-625675597e81" in namespace "e2e-tests-emptydir-hpkcb" to be "success or failure"
Nov 13 10:50:09.680: INFO: Pod "pod-e3d29928-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 30.221511ms
Nov 13 10:50:11.683: INFO: Pod "pod-e3d29928-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034018044s
Nov 13 10:50:13.687: INFO: Pod "pod-e3d29928-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037721838s
Nov 13 10:50:15.690: INFO: Pod "pod-e3d29928-e731-11e8-baa5-625675597e81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040766519s
Nov 13 10:50:17.724: INFO: Pod "pod-e3d29928-e731-11e8-baa5-625675597e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.074835099s
STEP: Saw pod success
Nov 13 10:50:17.724: INFO: Pod "pod-e3d29928-e731-11e8-baa5-625675597e81" satisfied condition "success or failure"
Nov 13 10:50:17.727: INFO: Trying to get logs from node shoot--core--e2e-rw-az-worker-wye0a-7c974bf667-h9r4j pod pod-e3d29928-e731-11e8-baa5-625675597e81 container test-container: <nil>
STEP: delete the pod
Nov 13 10:50:17.783: INFO: Waiting for pod pod-e3d29928-e731-11e8-baa5-625675597e81 to disappear
Nov 13 10:50:17.791: INFO: Pod pod-e3d29928-e731-11e8-baa5-625675597e81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov 13 10:50:17.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hpkcb" for this suite.
Nov 13 10:50:23.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 13 10:50:23.841: INFO: namespace: e2e-tests-emptydir-hpkcb, resource: bindings, ignored listing per whitelist
Nov 13 10:50:23.949: INFO: namespace e2e-tests-emptydir-hpkcb deletion completed in 6.154695263s

• [SLOW TEST:14.604 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSNov 13 10:50:23.949: INFO: Running AfterSuite actions on all node
Nov 13 10:50:23.949: INFO: Running AfterSuite actions on node 1
Nov 13 10:50:23.949: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 6582.918 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h49m43.926280986s
Test Suite Passed
