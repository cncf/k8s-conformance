Dec  3 13:45:57.919: INFO: Overriding default scale value of zero to 1
Dec  3 13:45:57.920: INFO: Overriding default milliseconds value of zero to 5000
I1203 13:45:59.076090      18 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-442087039
I1203 13:45:59.077770      18 e2e.go:304] Starting e2e run "c334c54e-f701-11e8-a394-16db9a3896d3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1543844757 - Will randomize all specs
Will run 188 of 1814 specs

Dec  3 13:45:59.538: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 13:45:59.546: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  3 13:45:59.591: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  3 13:45:59.712: INFO: The status of Pod configure-calico-g59xb is Succeeded, skipping waiting
Dec  3 13:45:59.712: INFO: 18 / 19 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  3 13:45:59.712: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Dec  3 13:45:59.712: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  3 13:45:59.736: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  3 13:45:59.736: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-discovery' (0 seconds elapsed)
Dec  3 13:45:59.736: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  3 13:45:59.736: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kubectl' (0 seconds elapsed)
Dec  3 13:45:59.736: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'service-proxy' (0 seconds elapsed)
Dec  3 13:45:59.736: INFO: e2e test version: v1.12.1
Dec  3 13:45:59.739: INFO: kube-apiserver version: v1.12.0-2+a972eecbe602b2
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:45:59.739: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
Dec  3 13:45:59.990: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec  3 13:46:00.020: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jj9rh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 13:46:00.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4aaebbc-f701-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-jj9rh" to be "success or failure"
Dec  3 13:46:00.160: INFO: Pod "downwardapi-volume-c4aaebbc-f701-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.712616ms
Dec  3 13:46:02.165: INFO: Pod "downwardapi-volume-c4aaebbc-f701-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010567124s
Dec  3 13:46:04.173: INFO: Pod "downwardapi-volume-c4aaebbc-f701-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01876791s
STEP: Saw pod success
Dec  3 13:46:04.173: INFO: Pod "downwardapi-volume-c4aaebbc-f701-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:46:04.181: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-c4aaebbc-f701-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 13:46:04.270: INFO: Waiting for pod downwardapi-volume-c4aaebbc-f701-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:46:04.282: INFO: Pod downwardapi-volume-c4aaebbc-f701-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:46:04.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jj9rh" for this suite.
Dec  3 13:46:10.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:46:10.528: INFO: namespace: e2e-tests-downward-api-jj9rh, resource: bindings, ignored listing per whitelist
Dec  3 13:46:10.558: INFO: namespace e2e-tests-downward-api-jj9rh deletion completed in 6.266904592s

• [SLOW TEST:10.819 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:46:10.558: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-v8c4n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  3 13:46:10.824: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 13:46:10.842: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 13:46:10.849: INFO: 
Logging pods the kubelet thinks is on node k8s-master-3 before test
Dec  3 13:46:10.863: INFO: kubectl-cf7vk from kube-system started at 2018-12-03 04:10:12 +0000 UTC (1 container statuses recorded)
Dec  3 13:46:10.863: INFO: 	Container kubectl ready: true, restart count 0
Dec  3 13:46:10.863: INFO: kube-proxy-s9v52 from kube-system started at 2018-12-03 04:08:32 +0000 UTC (1 container statuses recorded)
Dec  3 13:46:10.863: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 13:46:10.863: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-03 13:45:48 +0000 UTC (1 container statuses recorded)
Dec  3 13:46:10.863: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 13:46:10.863: INFO: calico-node-6sjrk from kube-system started at 2018-12-03 06:28:28 +0000 UTC (2 container statuses recorded)
Dec  3 13:46:10.863: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 13:46:10.863: INFO: 	Container install-cni ready: true, restart count 0
Dec  3 13:46:10.863: INFO: sonobuoy-e2e-job-f27511e7d13f414e from heptio-sonobuoy started at 2018-12-03 13:45:52 +0000 UTC (2 container statuses recorded)
Dec  3 13:46:10.863: INFO: 	Container e2e ready: true, restart count 0
Dec  3 13:46:10.863: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 13:46:10.863: INFO: 
Logging pods the kubelet thinks is on node k8s-node-2 before test
Dec  3 13:46:10.883: INFO: calico-node-lps99 from kube-system started at 2018-12-03 06:28:28 +0000 UTC (2 container statuses recorded)
Dec  3 13:46:10.883: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 13:46:10.883: INFO: 	Container install-cni ready: true, restart count 0
Dec  3 13:46:10.883: INFO: kube-proxy-54j8t from kube-system started at 2018-12-03 04:10:52 +0000 UTC (1 container statuses recorded)
Dec  3 13:46:10.883: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 13:46:10.883: INFO: kubectl-prk85 from kube-system started at 2018-12-03 04:12:22 +0000 UTC (1 container statuses recorded)
Dec  3 13:46:10.883: INFO: 	Container kubectl ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s-master-3
STEP: verifying the node has the label node k8s-node-2
Dec  3 13:46:10.969: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-master-3
Dec  3 13:46:10.969: INFO: Pod sonobuoy-e2e-job-f27511e7d13f414e requesting resource cpu=0m on Node k8s-master-3
Dec  3 13:46:10.969: INFO: Pod calico-node-6sjrk requesting resource cpu=110m on Node k8s-master-3
Dec  3 13:46:10.969: INFO: Pod calico-node-lps99 requesting resource cpu=110m on Node k8s-node-2
Dec  3 13:46:10.969: INFO: Pod kube-proxy-54j8t requesting resource cpu=0m on Node k8s-node-2
Dec  3 13:46:10.969: INFO: Pod kube-proxy-s9v52 requesting resource cpu=0m on Node k8s-master-3
Dec  3 13:46:10.969: INFO: Pod kubectl-cf7vk requesting resource cpu=10m on Node k8s-master-3
Dec  3 13:46:10.969: INFO: Pod kubectl-prk85 requesting resource cpu=10m on Node k8s-node-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb1fe1c7-f701-11e8-a394-16db9a3896d3.156cd6a07eaa9ad1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-v8c4n/filler-pod-cb1fe1c7-f701-11e8-a394-16db9a3896d3 to k8s-master-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb1fe1c7-f701-11e8-a394-16db9a3896d3.156cd6a427339ebc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb1fe1c7-f701-11e8-a394-16db9a3896d3.156cd6a44d901628], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb1fe1c7-f701-11e8-a394-16db9a3896d3.156cd6a46bc629b4], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb225791-f701-11e8-a394-16db9a3896d3.156cd6a07f5a293b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-v8c4n/filler-pod-cb225791-f701-11e8-a394-16db9a3896d3 to k8s-node-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb225791-f701-11e8-a394-16db9a3896d3.156cd6a40ea53368], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb225791-f701-11e8-a394-16db9a3896d3.156cd6a4221c3803], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb225791-f701-11e8-a394-16db9a3896d3.156cd6a42df2fe5d], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156cd6a16f46937b], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node k8s-master-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-node-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:46:16.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-v8c4n" for this suite.
Dec  3 13:46:22.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:46:22.235: INFO: namespace: e2e-tests-sched-pred-v8c4n, resource: bindings, ignored listing per whitelist
Dec  3 13:46:22.299: INFO: namespace e2e-tests-sched-pred-v8c4n deletion completed in 6.192525574s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.741 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:46:22.299: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-fh45q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-fh45q
Dec  3 13:46:26.564: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-fh45q
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 13:46:26.570: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:50:27.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fh45q" for this suite.
Dec  3 13:50:33.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:50:33.961: INFO: namespace: e2e-tests-container-probe-fh45q, resource: bindings, ignored listing per whitelist
Dec  3 13:50:34.259: INFO: namespace e2e-tests-container-probe-fh45q deletion completed in 6.354941766s

• [SLOW TEST:251.960 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:50:34.259: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-q2px7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-q2px7
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-q2px7
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-q2px7
Dec  3 13:50:34.558: INFO: Found 0 stateful pods, waiting for 1
Dec  3 13:50:44.564: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  3 13:50:44.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-q2px7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 13:50:45.109: INFO: stderr: ""
Dec  3 13:50:45.109: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 13:50:45.109: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 13:50:45.119: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 13:50:55.125: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 13:50:55.125: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:50:55.148: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  3 13:50:55.148: INFO: ss-0  k8s-master-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:20 +0000 UTC  }]
Dec  3 13:50:55.148: INFO: 
Dec  3 13:50:55.148: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  3 13:50:56.160: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995011542s
Dec  3 13:50:57.171: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983428413s
Dec  3 13:50:58.177: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.972118s
Dec  3 13:50:59.185: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965651012s
Dec  3 13:51:00.191: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.958654426s
Dec  3 13:51:01.198: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.95194159s
Dec  3 13:51:02.204: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.944676904s
Dec  3 13:51:03.214: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.939215308s
Dec  3 13:51:04.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 929.045798ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-q2px7
Dec  3 13:51:05.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-q2px7 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 13:51:05.850: INFO: stderr: ""
Dec  3 13:51:05.850: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 13:51:05.850: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 13:51:05.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-q2px7 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 13:51:06.346: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  3 13:51:06.346: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 13:51:06.346: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 13:51:06.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-q2px7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 13:51:06.753: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  3 13:51:06.753: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 13:51:06.753: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 13:51:06.761: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:51:06.761: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:51:06.761: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  3 13:51:06.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-q2px7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 13:51:07.242: INFO: stderr: ""
Dec  3 13:51:07.242: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 13:51:07.243: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 13:51:07.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-q2px7 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 13:51:07.759: INFO: stderr: ""
Dec  3 13:51:07.759: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 13:51:07.759: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 13:51:07.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-q2px7 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 13:51:08.330: INFO: stderr: ""
Dec  3 13:51:08.330: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 13:51:08.330: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 13:51:08.330: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:51:08.337: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 13:51:18.355: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 13:51:18.355: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 13:51:18.355: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 13:51:18.389: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  3 13:51:18.389: INFO: ss-0  k8s-master-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:20 +0000 UTC  }]
Dec  3 13:51:18.389: INFO: ss-1  k8s-node-2    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:41 +0000 UTC  }]
Dec  3 13:51:18.389: INFO: ss-2  k8s-master-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:41 +0000 UTC  }]
Dec  3 13:51:18.389: INFO: 
Dec  3 13:51:18.389: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 13:51:19.396: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  3 13:51:19.396: INFO: ss-0  k8s-master-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:20 +0000 UTC  }]
Dec  3 13:51:19.396: INFO: ss-1  k8s-node-2    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:41 +0000 UTC  }]
Dec  3 13:51:19.396: INFO: ss-2  k8s-master-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:41 +0000 UTC  }]
Dec  3 13:51:19.397: INFO: 
Dec  3 13:51:19.397: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 13:51:20.402: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  3 13:51:20.402: INFO: ss-0  k8s-master-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:20 +0000 UTC  }]
Dec  3 13:51:20.402: INFO: ss-2  k8s-master-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:41 +0000 UTC  }]
Dec  3 13:51:20.402: INFO: 
Dec  3 13:51:20.402: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 13:51:21.411: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  3 13:51:21.411: INFO: ss-0  k8s-master-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:20 +0000 UTC  }]
Dec  3 13:51:21.411: INFO: ss-2  k8s-master-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:41 +0000 UTC  }]
Dec  3 13:51:21.411: INFO: 
Dec  3 13:51:21.411: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 13:51:22.418: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  3 13:51:22.418: INFO: ss-0  k8s-master-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:20 +0000 UTC  }]
Dec  3 13:51:22.418: INFO: ss-2  k8s-master-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:50:41 +0000 UTC  }]
Dec  3 13:51:22.418: INFO: 
Dec  3 13:51:22.418: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 13:51:23.427: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.959240625s
Dec  3 13:51:24.434: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.949707869s
Dec  3 13:51:25.440: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.942910841s
Dec  3 13:51:26.447: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.937088581s
Dec  3 13:51:27.453: INFO: Verifying statefulset ss doesn't scale past 0 for another 929.667985ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-q2px7
Dec  3 13:51:28.460: INFO: Scaling statefulset ss to 0
Dec  3 13:51:28.485: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 13:51:28.496: INFO: Deleting all statefulset in ns e2e-tests-statefulset-q2px7
Dec  3 13:51:28.500: INFO: Scaling statefulset ss to 0
Dec  3 13:51:28.521: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:51:28.530: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:51:28.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-q2px7" for this suite.
Dec  3 13:51:34.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:51:34.634: INFO: namespace: e2e-tests-statefulset-q2px7, resource: bindings, ignored listing per whitelist
Dec  3 13:51:34.787: INFO: namespace e2e-tests-statefulset-q2px7 deletion completed in 6.213862142s

• [SLOW TEST:60.528 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:51:34.788: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-msqtq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-8c4a1caa-f702-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 13:51:35.064: INFO: Waiting up to 5m0s for pod "pod-secrets-8c4b1943-f702-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-msqtq" to be "success or failure"
Dec  3 13:51:35.069: INFO: Pod "pod-secrets-8c4b1943-f702-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.958704ms
Dec  3 13:51:37.076: INFO: Pod "pod-secrets-8c4b1943-f702-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011765384s
Dec  3 13:51:39.090: INFO: Pod "pod-secrets-8c4b1943-f702-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026242326s
STEP: Saw pod success
Dec  3 13:51:39.090: INFO: Pod "pod-secrets-8c4b1943-f702-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:51:39.098: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-8c4b1943-f702-11e8-a394-16db9a3896d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 13:51:39.170: INFO: Waiting for pod pod-secrets-8c4b1943-f702-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:51:39.185: INFO: Pod pod-secrets-8c4b1943-f702-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:51:39.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-msqtq" for this suite.
Dec  3 13:51:45.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:51:45.259: INFO: namespace: e2e-tests-secrets-msqtq, resource: bindings, ignored listing per whitelist
Dec  3 13:51:45.473: INFO: namespace e2e-tests-secrets-msqtq deletion completed in 6.267931096s

• [SLOW TEST:10.686 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:51:45.474: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4xqnh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 13:51:45.755: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92a96cb5-f702-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-4xqnh" to be "success or failure"
Dec  3 13:51:45.768: INFO: Pod "downwardapi-volume-92a96cb5-f702-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.312598ms
Dec  3 13:51:47.783: INFO: Pod "downwardapi-volume-92a96cb5-f702-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027523784s
STEP: Saw pod success
Dec  3 13:51:47.783: INFO: Pod "downwardapi-volume-92a96cb5-f702-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:51:47.792: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-92a96cb5-f702-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 13:51:47.878: INFO: Waiting for pod downwardapi-volume-92a96cb5-f702-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:51:47.891: INFO: Pod downwardapi-volume-92a96cb5-f702-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:51:47.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4xqnh" for this suite.
Dec  3 13:51:53.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:51:54.127: INFO: namespace: e2e-tests-projected-4xqnh, resource: bindings, ignored listing per whitelist
Dec  3 13:51:54.264: INFO: namespace e2e-tests-projected-4xqnh deletion completed in 6.363813912s

• [SLOW TEST:8.789 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:51:54.264: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xrk2r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 13:51:54.764: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98069a0f-f702-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-xrk2r" to be "success or failure"
Dec  3 13:51:54.780: INFO: Pod "downwardapi-volume-98069a0f-f702-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.509724ms
Dec  3 13:51:56.796: INFO: Pod "downwardapi-volume-98069a0f-f702-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032127522s
Dec  3 13:51:58.803: INFO: Pod "downwardapi-volume-98069a0f-f702-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039384988s
STEP: Saw pod success
Dec  3 13:51:58.803: INFO: Pod "downwardapi-volume-98069a0f-f702-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:51:58.812: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-98069a0f-f702-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 13:51:58.848: INFO: Waiting for pod downwardapi-volume-98069a0f-f702-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:51:58.853: INFO: Pod downwardapi-volume-98069a0f-f702-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:51:58.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xrk2r" for this suite.
Dec  3 13:52:04.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:52:04.929: INFO: namespace: e2e-tests-downward-api-xrk2r, resource: bindings, ignored listing per whitelist
Dec  3 13:52:05.217: INFO: namespace e2e-tests-downward-api-xrk2r deletion completed in 6.355506374s

• [SLOW TEST:10.953 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:52:05.217: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-bvzqr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 13:52:05.606: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  3 13:52:10.616: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 13:52:10.616: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  3 13:52:12.626: INFO: Creating deployment "test-rollover-deployment"
Dec  3 13:52:12.659: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  3 13:52:14.681: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  3 13:52:14.716: INFO: Ensure that both replica sets have 1 created replica
Dec  3 13:52:14.757: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  3 13:52:14.789: INFO: Updating deployment test-rollover-deployment
Dec  3 13:52:14.789: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  3 13:52:16.845: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  3 13:52:16.861: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  3 13:52:16.881: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:16.882: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441921, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:18.902: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:18.902: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:20.905: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:20.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:22.905: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:22.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:24.896: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:24.896: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:26.916: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:26.916: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:28.900: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:28.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:30.895: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:30.895: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:32.900: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:32.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:34.908: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:34.908: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:36.893: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:36.893: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:38.896: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:38.896: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:40.893: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:40.893: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:42.901: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:42.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:44.900: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:44.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:46.907: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 13:52:46.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441923, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679441918, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 13:52:48.900: INFO: 
Dec  3 13:52:48.900: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 13:52:48.926: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-bvzqr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bvzqr/deployments/test-rollover-deployment,UID:9a6671a9-f702-11e8-849a-005056852a45,ResourceVersion:86334,Generation:2,CreationTimestamp:2018-12-03 13:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-03 13:51:58 +0000 UTC 2018-12-03 13:51:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-03 13:52:33 +0000 UTC 2018-12-03 13:51:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 13:52:48.932: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-bvzqr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bvzqr/replicasets/test-rollover-deployment-5b76ff8c4,UID:9bb12288-f702-11e8-849a-005056852a45,ResourceVersion:86325,Generation:2,CreationTimestamp:2018-12-03 13:52:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9a6671a9-f702-11e8-849a-005056852a45 0xc420efdfa7 0xc420efdfa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 13:52:48.932: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  3 13:52:48.932: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-bvzqr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bvzqr/replicasets/test-rollover-controller,UID:9633e040-f702-11e8-849a-005056852a45,ResourceVersion:86333,Generation:2,CreationTimestamp:2018-12-03 13:51:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9a6671a9-f702-11e8-849a-005056852a45 0xc420efdede 0xc420efdedf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 13:52:48.932: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-bvzqr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bvzqr/replicasets/test-rollover-deployment-6975f4fb87,UID:9a7123f5-f702-11e8-849a-005056852a45,ResourceVersion:86259,Generation:2,CreationTimestamp:2018-12-03 13:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9a6671a9-f702-11e8-849a-005056852a45 0xc4217940d7 0xc4217940d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 13:52:48.943: INFO: Pod "test-rollover-deployment-5b76ff8c4-j6p2j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-j6p2j,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-bvzqr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bvzqr/pods/test-rollover-deployment-5b76ff8c4-j6p2j,UID:9bc17491-f702-11e8-849a-005056852a45,ResourceVersion:86280,Generation:0,CreationTimestamp:2018-12-03 13:52:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 9bb12288-f702-11e8-849a-005056852a45 0xc421795540 0xc421795541}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qkn59 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qkn59,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qkn59 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217955b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217955d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:52:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:52:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:52:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 13:52:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:172.31.168.46,StartTime:2018-12-03 13:52:14 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-03 13:52:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f docker://ab065a460da1e07a65918eb02b2f761e38e2d2513fb34057c8c48db9c652c837}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:52:48.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bvzqr" for this suite.
Dec  3 13:52:56.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:52:57.030: INFO: namespace: e2e-tests-deployment-bvzqr, resource: bindings, ignored listing per whitelist
Dec  3 13:52:57.265: INFO: namespace e2e-tests-deployment-bvzqr deletion completed in 8.30974635s

• [SLOW TEST:52.048 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:52:57.266: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-fh766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fh766
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  3 13:52:57.618: INFO: Found 0 stateful pods, waiting for 3
Dec  3 13:53:07.639: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:53:07.639: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:53:07.639: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:53:07.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-fh766 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 13:53:08.138: INFO: stderr: ""
Dec  3 13:53:08.138: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 13:53:08.138: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  3 13:53:18.221: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  3 13:53:28.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-fh766 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 13:53:28.642: INFO: stderr: ""
Dec  3 13:53:28.642: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 13:53:28.642: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Dec  3 13:53:48.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-fh766 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 13:53:49.182: INFO: stderr: ""
Dec  3 13:53:49.182: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 13:53:49.182: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 13:53:59.234: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  3 13:54:09.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-fh766 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 13:54:09.628: INFO: stderr: ""
Dec  3 13:54:09.628: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 13:54:09.628: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 13:54:19.679: INFO: Waiting for StatefulSet e2e-tests-statefulset-fh766/ss2 to complete update
Dec  3 13:54:19.679: INFO: Waiting for Pod e2e-tests-statefulset-fh766/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  3 13:54:19.679: INFO: Waiting for Pod e2e-tests-statefulset-fh766/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  3 13:54:19.679: INFO: Waiting for Pod e2e-tests-statefulset-fh766/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  3 13:54:29.699: INFO: Waiting for StatefulSet e2e-tests-statefulset-fh766/ss2 to complete update
Dec  3 13:54:29.699: INFO: Waiting for Pod e2e-tests-statefulset-fh766/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 13:54:39.691: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fh766
Dec  3 13:54:39.697: INFO: Scaling statefulset ss2 to 0
Dec  3 13:54:59.725: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:54:59.730: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:54:59.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fh766" for this suite.
Dec  3 13:55:07.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:55:07.806: INFO: namespace: e2e-tests-statefulset-fh766, resource: bindings, ignored listing per whitelist
Dec  3 13:55:08.015: INFO: namespace e2e-tests-statefulset-fh766 deletion completed in 8.254898978s

• [SLOW TEST:130.749 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:55:08.015: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-wdfbb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0b79e138-f703-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 13:55:08.472: INFO: Waiting up to 5m0s for pod "pod-secrets-0b7ba603-f703-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-wdfbb" to be "success or failure"
Dec  3 13:55:08.478: INFO: Pod "pod-secrets-0b7ba603-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.69665ms
Dec  3 13:55:10.485: INFO: Pod "pod-secrets-0b7ba603-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013300578s
Dec  3 13:55:12.492: INFO: Pod "pod-secrets-0b7ba603-f703-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020090372s
STEP: Saw pod success
Dec  3 13:55:12.492: INFO: Pod "pod-secrets-0b7ba603-f703-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:55:12.497: INFO: Trying to get logs from node k8s-master-3 pod pod-secrets-0b7ba603-f703-11e8-a394-16db9a3896d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 13:55:12.536: INFO: Waiting for pod pod-secrets-0b7ba603-f703-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:55:12.542: INFO: Pod pod-secrets-0b7ba603-f703-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:55:12.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wdfbb" for this suite.
Dec  3 13:55:18.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:55:18.736: INFO: namespace: e2e-tests-secrets-wdfbb, resource: bindings, ignored listing per whitelist
Dec  3 13:55:18.850: INFO: namespace e2e-tests-secrets-wdfbb deletion completed in 6.295404084s

• [SLOW TEST:10.834 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:55:18.850: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bwpcz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-11dc3a03-f703-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 13:55:19.181: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-11de0aa2-f703-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-bwpcz" to be "success or failure"
Dec  3 13:55:19.193: INFO: Pod "pod-projected-configmaps-11de0aa2-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.376408ms
Dec  3 13:55:21.202: INFO: Pod "pod-projected-configmaps-11de0aa2-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0202896s
Dec  3 13:55:23.214: INFO: Pod "pod-projected-configmaps-11de0aa2-f703-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032244956s
STEP: Saw pod success
Dec  3 13:55:23.214: INFO: Pod "pod-projected-configmaps-11de0aa2-f703-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:55:23.218: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-configmaps-11de0aa2-f703-11e8-a394-16db9a3896d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 13:55:23.250: INFO: Waiting for pod pod-projected-configmaps-11de0aa2-f703-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:55:23.256: INFO: Pod pod-projected-configmaps-11de0aa2-f703-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:55:23.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bwpcz" for this suite.
Dec  3 13:55:29.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:55:29.320: INFO: namespace: e2e-tests-projected-bwpcz, resource: bindings, ignored listing per whitelist
Dec  3 13:55:29.453: INFO: namespace e2e-tests-projected-bwpcz deletion completed in 6.187457216s

• [SLOW TEST:10.603 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:55:29.456: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-m7h9g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 13:55:29.708: INFO: Waiting up to 5m0s for pod "pod-1826f766-f703-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-m7h9g" to be "success or failure"
Dec  3 13:55:29.714: INFO: Pod "pod-1826f766-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.51209ms
Dec  3 13:55:31.721: INFO: Pod "pod-1826f766-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012614708s
Dec  3 13:55:33.729: INFO: Pod "pod-1826f766-f703-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020655406s
STEP: Saw pod success
Dec  3 13:55:33.729: INFO: Pod "pod-1826f766-f703-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:55:33.744: INFO: Trying to get logs from node k8s-master-3 pod pod-1826f766-f703-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 13:55:33.812: INFO: Waiting for pod pod-1826f766-f703-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:55:33.824: INFO: Pod pod-1826f766-f703-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:55:33.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m7h9g" for this suite.
Dec  3 13:55:39.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:55:39.992: INFO: namespace: e2e-tests-emptydir-m7h9g, resource: bindings, ignored listing per whitelist
Dec  3 13:55:40.066: INFO: namespace e2e-tests-emptydir-m7h9g deletion completed in 6.231779414s

• [SLOW TEST:10.613 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:55:40.067: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-gbqwt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  3 13:55:44.380: INFO: Pod pod-hostip-1e7f5ea7-f703-11e8-a394-16db9a3896d3 has hostIP: 192.168.1.233
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:55:44.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-gbqwt" for this suite.
Dec  3 13:56:06.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:56:06.556: INFO: namespace: e2e-tests-pods-gbqwt, resource: bindings, ignored listing per whitelist
Dec  3 13:56:06.690: INFO: namespace e2e-tests-pods-gbqwt deletion completed in 22.295052714s

• [SLOW TEST:26.623 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:56:06.691: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tq76k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2e675d14-f703-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 13:56:07.059: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e68c76a-f703-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-tq76k" to be "success or failure"
Dec  3 13:56:07.074: INFO: Pod "pod-configmaps-2e68c76a-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.739128ms
Dec  3 13:56:09.083: INFO: Pod "pod-configmaps-2e68c76a-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024208036s
Dec  3 13:56:11.092: INFO: Pod "pod-configmaps-2e68c76a-f703-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0324177s
STEP: Saw pod success
Dec  3 13:56:11.092: INFO: Pod "pod-configmaps-2e68c76a-f703-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:56:11.102: INFO: Trying to get logs from node k8s-master-3 pod pod-configmaps-2e68c76a-f703-11e8-a394-16db9a3896d3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 13:56:11.144: INFO: Waiting for pod pod-configmaps-2e68c76a-f703-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:56:11.152: INFO: Pod pod-configmaps-2e68c76a-f703-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:56:11.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tq76k" for this suite.
Dec  3 13:56:17.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:56:17.381: INFO: namespace: e2e-tests-configmap-tq76k, resource: bindings, ignored listing per whitelist
Dec  3 13:56:17.463: INFO: namespace e2e-tests-configmap-tq76k deletion completed in 6.298081801s

• [SLOW TEST:10.772 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:56:17.463: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gfbtk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-34cc498a-f703-11e8-a394-16db9a3896d3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-34cc498a-f703-11e8-a394-16db9a3896d3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:57:41.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gfbtk" for this suite.
Dec  3 13:58:05.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:58:05.284: INFO: namespace: e2e-tests-projected-gfbtk, resource: bindings, ignored listing per whitelist
Dec  3 13:58:05.341: INFO: namespace e2e-tests-projected-gfbtk deletion completed in 24.258285916s

• [SLOW TEST:107.878 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:58:05.342: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cmfhh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Dec  3 13:58:05.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-cmfhh'
Dec  3 13:58:06.558: INFO: stderr: ""
Dec  3 13:58:06.559: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  3 13:58:07.576: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 13:58:07.576: INFO: Found 0 / 1
Dec  3 13:58:08.567: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 13:58:08.567: INFO: Found 0 / 1
Dec  3 13:58:09.566: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 13:58:09.566: INFO: Found 1 / 1
Dec  3 13:58:09.566: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 13:58:09.573: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 13:58:09.573: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  3 13:58:09.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 logs redis-master-vr9gl redis-master --namespace=e2e-tests-kubectl-cmfhh'
Dec  3 13:58:09.959: INFO: stderr: ""
Dec  3 13:58:09.959: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 13:58:08.660 # Server started, Redis version 3.2.12\n1:M 03 Dec 13:58:08.660 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 13:58:08.660 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  3 13:58:09.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 log redis-master-vr9gl redis-master --namespace=e2e-tests-kubectl-cmfhh --tail=1'
Dec  3 13:58:10.228: INFO: stderr: ""
Dec  3 13:58:10.228: INFO: stdout: "1:M 03 Dec 13:58:08.660 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  3 13:58:10.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 log redis-master-vr9gl redis-master --namespace=e2e-tests-kubectl-cmfhh --limit-bytes=1'
Dec  3 13:58:10.511: INFO: stderr: ""
Dec  3 13:58:10.511: INFO: stdout: " "
STEP: exposing timestamps
Dec  3 13:58:10.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 log redis-master-vr9gl redis-master --namespace=e2e-tests-kubectl-cmfhh --tail=1 --timestamps'
Dec  3 13:58:10.762: INFO: stderr: ""
Dec  3 13:58:10.762: INFO: stdout: "2018-12-03T13:58:08.661258823Z 1:M 03 Dec 13:58:08.660 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  3 13:58:13.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 log redis-master-vr9gl redis-master --namespace=e2e-tests-kubectl-cmfhh --since=1s'
Dec  3 13:58:13.558: INFO: stderr: ""
Dec  3 13:58:13.558: INFO: stdout: ""
Dec  3 13:58:13.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 log redis-master-vr9gl redis-master --namespace=e2e-tests-kubectl-cmfhh --since=24h'
Dec  3 13:58:13.820: INFO: stderr: ""
Dec  3 13:58:13.820: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 13:58:08.660 # Server started, Redis version 3.2.12\n1:M 03 Dec 13:58:08.660 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 13:58:08.660 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Dec  3 13:58:13.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cmfhh'
Dec  3 13:58:14.007: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 13:58:14.007: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  3 13:58:14.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-cmfhh'
Dec  3 13:58:14.216: INFO: stderr: "No resources found.\n"
Dec  3 13:58:14.216: INFO: stdout: ""
Dec  3 13:58:14.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -l name=nginx --namespace=e2e-tests-kubectl-cmfhh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 13:58:14.468: INFO: stderr: ""
Dec  3 13:58:14.468: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:58:14.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cmfhh" for this suite.
Dec  3 13:58:36.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:58:36.596: INFO: namespace: e2e-tests-kubectl-cmfhh, resource: bindings, ignored listing per whitelist
Dec  3 13:58:36.811: INFO: namespace e2e-tests-kubectl-cmfhh deletion completed in 22.318545356s

• [SLOW TEST:31.469 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:58:36.812: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qdbkk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  3 13:58:37.123: INFO: namespace e2e-tests-kubectl-qdbkk
Dec  3 13:58:37.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-qdbkk'
Dec  3 13:58:37.509: INFO: stderr: ""
Dec  3 13:58:37.509: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 13:58:38.516: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 13:58:38.516: INFO: Found 0 / 1
Dec  3 13:58:39.515: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 13:58:39.515: INFO: Found 0 / 1
Dec  3 13:58:40.518: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 13:58:40.518: INFO: Found 1 / 1
Dec  3 13:58:40.518: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 13:58:40.524: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 13:58:40.524: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 13:58:40.524: INFO: wait on redis-master startup in e2e-tests-kubectl-qdbkk 
Dec  3 13:58:40.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 logs redis-master-gxkcm redis-master --namespace=e2e-tests-kubectl-qdbkk'
Dec  3 13:58:40.790: INFO: stderr: ""
Dec  3 13:58:40.790: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 13:58:39.601 # Server started, Redis version 3.2.12\n1:M 03 Dec 13:58:39.601 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 13:58:39.601 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  3 13:58:40.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-qdbkk'
Dec  3 13:58:41.053: INFO: stderr: ""
Dec  3 13:58:41.053: INFO: stdout: "service/rm2 exposed\n"
Dec  3 13:58:41.068: INFO: Service rm2 in namespace e2e-tests-kubectl-qdbkk found.
STEP: exposing service
Dec  3 13:58:43.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-qdbkk'
Dec  3 13:58:43.366: INFO: stderr: ""
Dec  3 13:58:43.366: INFO: stdout: "service/rm3 exposed\n"
Dec  3 13:58:43.378: INFO: Service rm3 in namespace e2e-tests-kubectl-qdbkk found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:58:45.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qdbkk" for this suite.
Dec  3 13:59:09.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:59:09.668: INFO: namespace: e2e-tests-kubectl-qdbkk, resource: bindings, ignored listing per whitelist
Dec  3 13:59:09.737: INFO: namespace e2e-tests-kubectl-qdbkk deletion completed in 24.332717365s

• [SLOW TEST:32.925 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:59:09.738: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-njc7b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-9b7f74a0-f703-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 13:59:10.083: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9b8078ec-f703-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-njc7b" to be "success or failure"
Dec  3 13:59:10.099: INFO: Pod "pod-projected-configmaps-9b8078ec-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.431193ms
Dec  3 13:59:12.104: INFO: Pod "pod-projected-configmaps-9b8078ec-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020933825s
Dec  3 13:59:14.112: INFO: Pod "pod-projected-configmaps-9b8078ec-f703-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0287702s
STEP: Saw pod success
Dec  3 13:59:14.112: INFO: Pod "pod-projected-configmaps-9b8078ec-f703-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:59:14.120: INFO: Trying to get logs from node k8s-master-3 pod pod-projected-configmaps-9b8078ec-f703-11e8-a394-16db9a3896d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 13:59:14.173: INFO: Waiting for pod pod-projected-configmaps-9b8078ec-f703-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:59:14.196: INFO: Pod pod-projected-configmaps-9b8078ec-f703-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:59:14.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-njc7b" for this suite.
Dec  3 13:59:20.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:59:20.309: INFO: namespace: e2e-tests-projected-njc7b, resource: bindings, ignored listing per whitelist
Dec  3 13:59:20.469: INFO: namespace e2e-tests-projected-njc7b deletion completed in 6.258592492s

• [SLOW TEST:10.732 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:59:20.470: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dt5tq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 13:59:20.828: INFO: Waiting up to 5m0s for pod "pod-a1e7d349-f703-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-dt5tq" to be "success or failure"
Dec  3 13:59:20.837: INFO: Pod "pod-a1e7d349-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05111ms
Dec  3 13:59:22.846: INFO: Pod "pod-a1e7d349-f703-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018213082s
STEP: Saw pod success
Dec  3 13:59:22.846: INFO: Pod "pod-a1e7d349-f703-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 13:59:22.859: INFO: Trying to get logs from node k8s-node-2 pod pod-a1e7d349-f703-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 13:59:22.967: INFO: Waiting for pod pod-a1e7d349-f703-11e8-a394-16db9a3896d3 to disappear
Dec  3 13:59:22.975: INFO: Pod pod-a1e7d349-f703-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:59:22.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dt5tq" for this suite.
Dec  3 13:59:29.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:59:29.099: INFO: namespace: e2e-tests-emptydir-dt5tq, resource: bindings, ignored listing per whitelist
Dec  3 13:59:29.243: INFO: namespace e2e-tests-emptydir-dt5tq deletion completed in 6.245623522s

• [SLOW TEST:8.772 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:59:29.243: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g5gkt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 13:59:29.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-g5gkt'
Dec  3 13:59:29.842: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 13:59:29.842: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Dec  3 13:59:29.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-g5gkt'
Dec  3 13:59:30.103: INFO: stderr: ""
Dec  3 13:59:30.103: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:59:30.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g5gkt" for this suite.
Dec  3 13:59:36.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:59:36.237: INFO: namespace: e2e-tests-kubectl-g5gkt, resource: bindings, ignored listing per whitelist
Dec  3 13:59:36.417: INFO: namespace e2e-tests-kubectl-g5gkt deletion completed in 6.305430944s

• [SLOW TEST:7.174 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:59:36.418: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-r45x4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  3 13:59:36.800: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-r45x4" to be "success or failure"
Dec  3 13:59:36.810: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.28154ms
Dec  3 13:59:38.828: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02838342s
Dec  3 13:59:40.844: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043930662s
STEP: Saw pod success
Dec  3 13:59:40.844: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  3 13:59:40.861: INFO: Trying to get logs from node k8s-master-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  3 13:59:40.934: INFO: Waiting for pod pod-host-path-test to disappear
Dec  3 13:59:40.944: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 13:59:40.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-r45x4" for this suite.
Dec  3 13:59:47.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 13:59:47.156: INFO: namespace: e2e-tests-hostpath-r45x4, resource: bindings, ignored listing per whitelist
Dec  3 13:59:47.238: INFO: namespace e2e-tests-hostpath-r45x4 deletion completed in 6.280218352s

• [SLOW TEST:10.821 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 13:59:47.239: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-7s47t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-jvnb
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 13:59:47.531: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jvnb" in namespace "e2e-tests-subpath-7s47t" to be "success or failure"
Dec  3 13:59:47.549: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Pending", Reason="", readiness=false. Elapsed: 17.755832ms
Dec  3 13:59:49.554: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02293209s
Dec  3 13:59:51.561: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029914882s
Dec  3 13:59:53.569: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 6.0382406s
Dec  3 13:59:55.575: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 8.044081712s
Dec  3 13:59:57.584: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 10.053322252s
Dec  3 13:59:59.592: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 12.061023096s
Dec  3 14:00:01.599: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 14.067800662s
Dec  3 14:00:03.605: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 16.073754794s
Dec  3 14:00:05.613: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 18.082147346s
Dec  3 14:00:07.620: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 20.08877716s
Dec  3 14:00:09.628: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 22.097208984s
Dec  3 14:00:11.641: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Running", Reason="", readiness=false. Elapsed: 24.110156692s
Dec  3 14:00:13.682: INFO: Pod "pod-subpath-test-secret-jvnb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.151130917s
STEP: Saw pod success
Dec  3 14:00:13.682: INFO: Pod "pod-subpath-test-secret-jvnb" satisfied condition "success or failure"
Dec  3 14:00:13.696: INFO: Trying to get logs from node k8s-master-3 pod pod-subpath-test-secret-jvnb container test-container-subpath-secret-jvnb: <nil>
STEP: delete the pod
Dec  3 14:00:13.795: INFO: Waiting for pod pod-subpath-test-secret-jvnb to disappear
Dec  3 14:00:13.804: INFO: Pod pod-subpath-test-secret-jvnb no longer exists
STEP: Deleting pod pod-subpath-test-secret-jvnb
Dec  3 14:00:13.804: INFO: Deleting pod "pod-subpath-test-secret-jvnb" in namespace "e2e-tests-subpath-7s47t"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:00:13.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7s47t" for this suite.
Dec  3 14:00:19.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:00:19.868: INFO: namespace: e2e-tests-subpath-7s47t, resource: bindings, ignored listing per whitelist
Dec  3 14:00:20.023: INFO: namespace e2e-tests-subpath-7s47t deletion completed in 6.204806632s

• [SLOW TEST:32.785 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:00:20.024: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-x2dsx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  3 14:00:24.327: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-c5554fbe-f703-11e8-a394-16db9a3896d3", GenerateName:"", Namespace:"e2e-tests-pods-x2dsx", SelfLink:"/api/v1/namespaces/e2e-tests-pods-x2dsx/pods/pod-submit-remove-c5554fbe-f703-11e8-a394-16db9a3896d3", UID:"bd093134-f703-11e8-849a-005056852a45", ResourceVersion:"88052", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679442406, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"246531204"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-c5mwm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421d99780), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c5mwm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42217a9c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421e54060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42217aa10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42217aa30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc42217aa38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679442420, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679442422, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679442422, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679442406, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.233", PodIP:"172.31.140.89", StartTime:(*v1.Time)(0xc4214b8c20), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4214b8c40), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd", ContainerID:"docker://5938e3ad8b0060105bfa4a2203e0306adb38ac8c5c5ea576132ee9083466874a"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  3 14:00:29.354: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:00:29.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-x2dsx" for this suite.
Dec  3 14:00:35.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:00:35.471: INFO: namespace: e2e-tests-pods-x2dsx, resource: bindings, ignored listing per whitelist
Dec  3 14:00:35.599: INFO: namespace e2e-tests-pods-x2dsx deletion completed in 6.229819348s

• [SLOW TEST:15.576 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:00:35.600: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-b8l5p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:00:35.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cea63611-f703-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-b8l5p" to be "success or failure"
Dec  3 14:00:35.899: INFO: Pod "downwardapi-volume-cea63611-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.135425ms
Dec  3 14:00:37.915: INFO: Pod "downwardapi-volume-cea63611-f703-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023240794s
Dec  3 14:00:39.928: INFO: Pod "downwardapi-volume-cea63611-f703-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036262269s
STEP: Saw pod success
Dec  3 14:00:39.928: INFO: Pod "downwardapi-volume-cea63611-f703-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:00:39.939: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-cea63611-f703-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:00:40.071: INFO: Waiting for pod downwardapi-volume-cea63611-f703-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:00:40.081: INFO: Pod downwardapi-volume-cea63611-f703-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:00:40.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b8l5p" for this suite.
Dec  3 14:00:46.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:00:46.189: INFO: namespace: e2e-tests-projected-b8l5p, resource: bindings, ignored listing per whitelist
Dec  3 14:00:46.356: INFO: namespace e2e-tests-projected-b8l5p deletion completed in 6.264454045s

• [SLOW TEST:10.756 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:00:46.356: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wk8xd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:00:46.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 version'
Dec  3 14:00:47.016: INFO: stderr: ""
Dec  3 14:00:47.016: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.0-2+a972eecbe602b2\", GitCommit:\"a972eecbe602b24ed160cb0299969dec4218f5a0\", GitTreeState:\"clean\", BuildDate:\"2018-11-29T11:00:58Z\", GoVersion:\"go1.11\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:00:47.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wk8xd" for this suite.
Dec  3 14:00:53.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:00:53.135: INFO: namespace: e2e-tests-kubectl-wk8xd, resource: bindings, ignored listing per whitelist
Dec  3 14:00:53.484: INFO: namespace e2e-tests-kubectl-wk8xd deletion completed in 6.456746137s

• [SLOW TEST:7.128 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:00:53.485: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tpx5q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d960e4fc-f703-11e8-a394-16db9a3896d3
STEP: Creating configMap with name cm-test-opt-upd-d960e75e-f703-11e8-a394-16db9a3896d3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d960e4fc-f703-11e8-a394-16db9a3896d3
STEP: Updating configmap cm-test-opt-upd-d960e75e-f703-11e8-a394-16db9a3896d3
STEP: Creating configMap with name cm-test-opt-create-d960e7c4-f703-11e8-a394-16db9a3896d3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:01:02.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tpx5q" for this suite.
Dec  3 14:01:26.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:01:26.245: INFO: namespace: e2e-tests-projected-tpx5q, resource: bindings, ignored listing per whitelist
Dec  3 14:01:26.477: INFO: namespace e2e-tests-projected-tpx5q deletion completed in 24.29815591s

• [SLOW TEST:32.992 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:01:26.477: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fh9c7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1203 14:02:06.916393      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 14:02:06.916: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:02:06.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fh9c7" for this suite.
Dec  3 14:02:15.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:02:15.588: INFO: namespace: e2e-tests-gc-fh9c7, resource: bindings, ignored listing per whitelist
Dec  3 14:02:15.588: INFO: namespace e2e-tests-gc-fh9c7 deletion completed in 8.651754143s

• [SLOW TEST:49.111 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:02:15.588: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-b6fj9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1203 14:02:26.044458      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 14:02:26.044: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:02:26.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b6fj9" for this suite.
Dec  3 14:02:32.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:02:32.198: INFO: namespace: e2e-tests-gc-b6fj9, resource: bindings, ignored listing per whitelist
Dec  3 14:02:32.343: INFO: namespace e2e-tests-gc-b6fj9 deletion completed in 6.262676508s

• [SLOW TEST:16.755 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:02:32.343: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gg4cw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 14:02:32.658: INFO: Waiting up to 5m0s for pod "pod-143da214-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-gg4cw" to be "success or failure"
Dec  3 14:02:32.676: INFO: Pod "pod-143da214-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 18.631543ms
Dec  3 14:02:34.692: INFO: Pod "pod-143da214-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034302628s
Dec  3 14:02:36.705: INFO: Pod "pod-143da214-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047512992s
STEP: Saw pod success
Dec  3 14:02:36.705: INFO: Pod "pod-143da214-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:02:36.715: INFO: Trying to get logs from node k8s-master-3 pod pod-143da214-f704-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:02:36.774: INFO: Waiting for pod pod-143da214-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:02:36.779: INFO: Pod pod-143da214-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:02:36.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gg4cw" for this suite.
Dec  3 14:02:42.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:02:43.037: INFO: namespace: e2e-tests-emptydir-gg4cw, resource: bindings, ignored listing per whitelist
Dec  3 14:02:43.105: INFO: namespace e2e-tests-emptydir-gg4cw deletion completed in 6.31927598s

• [SLOW TEST:10.762 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:02:43.105: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-fr7wz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1aab08b8-f704-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 14:02:43.451: INFO: Waiting up to 5m0s for pod "pod-configmaps-1aad1ae4-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-fr7wz" to be "success or failure"
Dec  3 14:02:43.458: INFO: Pod "pod-configmaps-1aad1ae4-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.550324ms
Dec  3 14:02:45.501: INFO: Pod "pod-configmaps-1aad1ae4-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050334123s
Dec  3 14:02:47.511: INFO: Pod "pod-configmaps-1aad1ae4-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05965192s
STEP: Saw pod success
Dec  3 14:02:47.511: INFO: Pod "pod-configmaps-1aad1ae4-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:02:47.522: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-1aad1ae4-f704-11e8-a394-16db9a3896d3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:02:47.707: INFO: Waiting for pod pod-configmaps-1aad1ae4-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:02:47.715: INFO: Pod pod-configmaps-1aad1ae4-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:02:47.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fr7wz" for this suite.
Dec  3 14:02:53.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:02:53.934: INFO: namespace: e2e-tests-configmap-fr7wz, resource: bindings, ignored listing per whitelist
Dec  3 14:02:54.107: INFO: namespace e2e-tests-configmap-fr7wz deletion completed in 6.385785936s

• [SLOW TEST:11.002 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:02:54.108: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-js5k6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-cmjc
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:02:54.534: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-cmjc" in namespace "e2e-tests-subpath-js5k6" to be "success or failure"
Dec  3 14:02:54.542: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.905824ms
Dec  3 14:02:56.548: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013831303s
Dec  3 14:02:58.554: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020712093s
Dec  3 14:03:00.568: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 6.034233428s
Dec  3 14:03:02.575: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 8.041154489s
Dec  3 14:03:04.582: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 10.047879981s
Dec  3 14:03:06.589: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 12.055126561s
Dec  3 14:03:08.596: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 14.062157396s
Dec  3 14:03:10.611: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 16.076842348s
Dec  3 14:03:12.616: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 18.082773492s
Dec  3 14:03:14.623: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 20.089330932s
Dec  3 14:03:16.631: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 22.097747594s
Dec  3 14:03:18.639: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Running", Reason="", readiness=false. Elapsed: 24.104885946s
Dec  3 14:03:20.644: INFO: Pod "pod-subpath-test-projected-cmjc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.110597934s
STEP: Saw pod success
Dec  3 14:03:20.644: INFO: Pod "pod-subpath-test-projected-cmjc" satisfied condition "success or failure"
Dec  3 14:03:20.650: INFO: Trying to get logs from node k8s-master-3 pod pod-subpath-test-projected-cmjc container test-container-subpath-projected-cmjc: <nil>
STEP: delete the pod
Dec  3 14:03:20.688: INFO: Waiting for pod pod-subpath-test-projected-cmjc to disappear
Dec  3 14:03:20.693: INFO: Pod pod-subpath-test-projected-cmjc no longer exists
STEP: Deleting pod pod-subpath-test-projected-cmjc
Dec  3 14:03:20.693: INFO: Deleting pod "pod-subpath-test-projected-cmjc" in namespace "e2e-tests-subpath-js5k6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:03:20.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-js5k6" for this suite.
Dec  3 14:03:26.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:03:26.884: INFO: namespace: e2e-tests-subpath-js5k6, resource: bindings, ignored listing per whitelist
Dec  3 14:03:26.918: INFO: namespace e2e-tests-subpath-js5k6 deletion completed in 6.215842476s

• [SLOW TEST:32.810 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:03:26.918: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-f7sdn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 14:03:31.750: INFO: Successfully updated pod "pod-update-activedeadlineseconds-34be5b34-f704-11e8-a394-16db9a3896d3"
Dec  3 14:03:31.757: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-34be5b34-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-pods-f7sdn" to be "terminated due to deadline exceeded"
Dec  3 14:03:31.763: INFO: Pod "pod-update-activedeadlineseconds-34be5b34-f704-11e8-a394-16db9a3896d3": Phase="Running", Reason="", readiness=true. Elapsed: 5.956788ms
Dec  3 14:03:33.769: INFO: Pod "pod-update-activedeadlineseconds-34be5b34-f704-11e8-a394-16db9a3896d3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.012232606s
Dec  3 14:03:33.769: INFO: Pod "pod-update-activedeadlineseconds-34be5b34-f704-11e8-a394-16db9a3896d3" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:03:33.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f7sdn" for this suite.
Dec  3 14:03:39.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:03:39.904: INFO: namespace: e2e-tests-pods-f7sdn, resource: bindings, ignored listing per whitelist
Dec  3 14:03:39.976: INFO: namespace e2e-tests-pods-f7sdn deletion completed in 6.195788144s

• [SLOW TEST:13.058 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:03:39.976: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-mzw2b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-3c84dc7b-f704-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:03:40.256: INFO: Waiting up to 5m0s for pod "pod-secrets-3c8725a9-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-mzw2b" to be "success or failure"
Dec  3 14:03:40.263: INFO: Pod "pod-secrets-3c8725a9-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.493508ms
Dec  3 14:03:42.316: INFO: Pod "pod-secrets-3c8725a9-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059534646s
Dec  3 14:03:44.324: INFO: Pod "pod-secrets-3c8725a9-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067596772s
STEP: Saw pod success
Dec  3 14:03:44.324: INFO: Pod "pod-secrets-3c8725a9-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:03:44.352: INFO: Trying to get logs from node k8s-master-3 pod pod-secrets-3c8725a9-f704-11e8-a394-16db9a3896d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:03:44.389: INFO: Waiting for pod pod-secrets-3c8725a9-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:03:44.395: INFO: Pod pod-secrets-3c8725a9-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:03:44.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mzw2b" for this suite.
Dec  3 14:03:50.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:03:50.766: INFO: namespace: e2e-tests-secrets-mzw2b, resource: bindings, ignored listing per whitelist
Dec  3 14:03:50.780: INFO: namespace e2e-tests-secrets-mzw2b deletion completed in 6.376927558s

• [SLOW TEST:10.804 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:03:50.781: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xh4g4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 14:03:51.214: INFO: Waiting up to 5m0s for pod "downward-api-4310d29a-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-xh4g4" to be "success or failure"
Dec  3 14:03:51.242: INFO: Pod "downward-api-4310d29a-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 28.036054ms
Dec  3 14:03:53.253: INFO: Pod "downward-api-4310d29a-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039196518s
Dec  3 14:03:55.273: INFO: Pod "downward-api-4310d29a-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058799712s
STEP: Saw pod success
Dec  3 14:03:55.273: INFO: Pod "downward-api-4310d29a-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:03:55.291: INFO: Trying to get logs from node k8s-master-3 pod downward-api-4310d29a-f704-11e8-a394-16db9a3896d3 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:03:55.714: INFO: Waiting for pod downward-api-4310d29a-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:03:55.750: INFO: Pod downward-api-4310d29a-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:03:55.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xh4g4" for this suite.
Dec  3 14:04:01.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:04:01.933: INFO: namespace: e2e-tests-downward-api-xh4g4, resource: bindings, ignored listing per whitelist
Dec  3 14:04:02.006: INFO: namespace e2e-tests-downward-api-xh4g4 deletion completed in 6.235139251s

• [SLOW TEST:11.225 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:04:02.007: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-fnfk2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  3 14:04:02.281: INFO: Waiting up to 5m0s for pod "client-containers-49aacf4a-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-containers-fnfk2" to be "success or failure"
Dec  3 14:04:02.289: INFO: Pod "client-containers-49aacf4a-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.785645ms
Dec  3 14:04:04.296: INFO: Pod "client-containers-49aacf4a-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015180277s
Dec  3 14:04:06.301: INFO: Pod "client-containers-49aacf4a-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020569293s
STEP: Saw pod success
Dec  3 14:04:06.301: INFO: Pod "client-containers-49aacf4a-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:04:06.308: INFO: Trying to get logs from node k8s-master-3 pod client-containers-49aacf4a-f704-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:04:06.377: INFO: Waiting for pod client-containers-49aacf4a-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:04:06.386: INFO: Pod client-containers-49aacf4a-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:04:06.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fnfk2" for this suite.
Dec  3 14:04:12.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:04:12.545: INFO: namespace: e2e-tests-containers-fnfk2, resource: bindings, ignored listing per whitelist
Dec  3 14:04:12.614: INFO: namespace e2e-tests-containers-fnfk2 deletion completed in 6.22188586s

• [SLOW TEST:10.608 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:04:12.614: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-d8xcp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4fff66fa-f704-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:04:12.922: INFO: Waiting up to 5m0s for pod "pod-secrets-50009163-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-d8xcp" to be "success or failure"
Dec  3 14:04:12.933: INFO: Pod "pod-secrets-50009163-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.492084ms
Dec  3 14:04:14.941: INFO: Pod "pod-secrets-50009163-f704-11e8-a394-16db9a3896d3": Phase="Running", Reason="", readiness=true. Elapsed: 2.019300836s
Dec  3 14:04:16.950: INFO: Pod "pod-secrets-50009163-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028178503s
STEP: Saw pod success
Dec  3 14:04:16.950: INFO: Pod "pod-secrets-50009163-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:04:16.963: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-50009163-f704-11e8-a394-16db9a3896d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:04:17.072: INFO: Waiting for pod pod-secrets-50009163-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:04:17.086: INFO: Pod pod-secrets-50009163-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:04:17.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-d8xcp" for this suite.
Dec  3 14:04:23.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:04:23.406: INFO: namespace: e2e-tests-secrets-d8xcp, resource: bindings, ignored listing per whitelist
Dec  3 14:04:23.434: INFO: namespace e2e-tests-secrets-d8xcp deletion completed in 6.32998045s

• [SLOW TEST:10.819 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:04:23.434: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-rnfzd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-56772887-f704-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 14:04:23.768: INFO: Waiting up to 5m0s for pod "pod-configmaps-5678863f-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-rnfzd" to be "success or failure"
Dec  3 14:04:23.789: INFO: Pod "pod-configmaps-5678863f-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.307456ms
Dec  3 14:04:25.801: INFO: Pod "pod-configmaps-5678863f-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032690422s
Dec  3 14:04:27.806: INFO: Pod "pod-configmaps-5678863f-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037711218s
STEP: Saw pod success
Dec  3 14:04:27.806: INFO: Pod "pod-configmaps-5678863f-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:04:27.813: INFO: Trying to get logs from node k8s-master-3 pod pod-configmaps-5678863f-f704-11e8-a394-16db9a3896d3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:04:27.866: INFO: Waiting for pod pod-configmaps-5678863f-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:04:27.874: INFO: Pod pod-configmaps-5678863f-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:04:27.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rnfzd" for this suite.
Dec  3 14:04:33.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:04:34.078: INFO: namespace: e2e-tests-configmap-rnfzd, resource: bindings, ignored listing per whitelist
Dec  3 14:04:34.119: INFO: namespace e2e-tests-configmap-rnfzd deletion completed in 6.23793863s

• [SLOW TEST:10.686 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:04:34.120: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-fkj4g
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-5ce9cd1c-f704-11e8-a394-16db9a3896d3
STEP: Creating configMap with name cm-test-opt-upd-5ce9cdba-f704-11e8-a394-16db9a3896d3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5ce9cd1c-f704-11e8-a394-16db9a3896d3
STEP: Updating configmap cm-test-opt-upd-5ce9cdba-f704-11e8-a394-16db9a3896d3
STEP: Creating configMap with name cm-test-opt-create-5ce9ce02-f704-11e8-a394-16db9a3896d3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:04:42.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fkj4g" for this suite.
Dec  3 14:05:07.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:05:07.117: INFO: namespace: e2e-tests-configmap-fkj4g, resource: bindings, ignored listing per whitelist
Dec  3 14:05:07.233: INFO: namespace e2e-tests-configmap-fkj4g deletion completed in 24.260562196s

• [SLOW TEST:33.113 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:05:07.233: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-t8mw4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  3 14:05:07.526: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-t8mw4,SelfLink:/api/v1/namespaces/e2e-tests-watch-t8mw4/configmaps/e2e-watch-test-label-changed,UID:683c2ab5-f704-11e8-849a-005056852a45,ResourceVersion:89367,Generation:0,CreationTimestamp:2018-12-03 14:04:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 14:05:07.527: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-t8mw4,SelfLink:/api/v1/namespaces/e2e-tests-watch-t8mw4/configmaps/e2e-watch-test-label-changed,UID:683c2ab5-f704-11e8-849a-005056852a45,ResourceVersion:89368,Generation:0,CreationTimestamp:2018-12-03 14:04:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 14:05:07.527: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-t8mw4,SelfLink:/api/v1/namespaces/e2e-tests-watch-t8mw4/configmaps/e2e-watch-test-label-changed,UID:683c2ab5-f704-11e8-849a-005056852a45,ResourceVersion:89369,Generation:0,CreationTimestamp:2018-12-03 14:04:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  3 14:05:17.592: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-t8mw4,SelfLink:/api/v1/namespaces/e2e-tests-watch-t8mw4/configmaps/e2e-watch-test-label-changed,UID:683c2ab5-f704-11e8-849a-005056852a45,ResourceVersion:89385,Generation:0,CreationTimestamp:2018-12-03 14:04:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 14:05:17.593: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-t8mw4,SelfLink:/api/v1/namespaces/e2e-tests-watch-t8mw4/configmaps/e2e-watch-test-label-changed,UID:683c2ab5-f704-11e8-849a-005056852a45,ResourceVersion:89386,Generation:0,CreationTimestamp:2018-12-03 14:04:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  3 14:05:17.593: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-t8mw4,SelfLink:/api/v1/namespaces/e2e-tests-watch-t8mw4/configmaps/e2e-watch-test-label-changed,UID:683c2ab5-f704-11e8-849a-005056852a45,ResourceVersion:89387,Generation:0,CreationTimestamp:2018-12-03 14:04:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:05:17.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-t8mw4" for this suite.
Dec  3 14:05:23.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:05:23.844: INFO: namespace: e2e-tests-watch-t8mw4, resource: bindings, ignored listing per whitelist
Dec  3 14:05:23.912: INFO: namespace e2e-tests-watch-t8mw4 deletion completed in 6.306740531s

• [SLOW TEST:16.679 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:05:23.913: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bncxp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-7a850ef6-f704-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:05:24.270: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7a878971-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-bncxp" to be "success or failure"
Dec  3 14:05:24.290: INFO: Pod "pod-projected-secrets-7a878971-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.065142ms
Dec  3 14:05:26.309: INFO: Pod "pod-projected-secrets-7a878971-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039184465s
Dec  3 14:05:28.317: INFO: Pod "pod-projected-secrets-7a878971-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046735591s
STEP: Saw pod success
Dec  3 14:05:28.317: INFO: Pod "pod-projected-secrets-7a878971-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:05:28.322: INFO: Trying to get logs from node k8s-master-3 pod pod-projected-secrets-7a878971-f704-11e8-a394-16db9a3896d3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:05:28.527: INFO: Waiting for pod pod-projected-secrets-7a878971-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:05:28.531: INFO: Pod pod-projected-secrets-7a878971-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:05:28.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bncxp" for this suite.
Dec  3 14:05:34.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:05:34.851: INFO: namespace: e2e-tests-projected-bncxp, resource: bindings, ignored listing per whitelist
Dec  3 14:05:34.899: INFO: namespace e2e-tests-projected-bncxp deletion completed in 6.360200568s

• [SLOW TEST:10.986 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:05:34.900: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-cvfzj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  3 14:05:35.177: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:05:39.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cvfzj" for this suite.
Dec  3 14:05:45.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:05:45.339: INFO: namespace: e2e-tests-init-container-cvfzj, resource: bindings, ignored listing per whitelist
Dec  3 14:05:45.549: INFO: namespace e2e-tests-init-container-cvfzj deletion completed in 6.293795971s

• [SLOW TEST:10.649 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:05:45.549: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-95498
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:05:45.895: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 14:05:45.929: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:45.945: INFO: Number of nodes with available pods: 0
Dec  3 14:05:45.945: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:05:46.991: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:46.998: INFO: Number of nodes with available pods: 0
Dec  3 14:05:46.998: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:05:47.954: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:47.962: INFO: Number of nodes with available pods: 0
Dec  3 14:05:47.962: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:05:48.956: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:48.965: INFO: Number of nodes with available pods: 1
Dec  3 14:05:48.965: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:05:49.955: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:49.964: INFO: Number of nodes with available pods: 2
Dec  3 14:05:49.964: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  3 14:05:50.039: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:50.039: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:50.053: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:51.061: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:51.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:51.078: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:52.060: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:52.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:52.076: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:53.064: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:53.064: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:53.074: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:54.061: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:54.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:54.068: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:55.066: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:55.066: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:55.098: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:56.061: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:56.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:56.070: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:57.063: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:57.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:57.070: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:58.072: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:58.072: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:58.078: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:05:59.062: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:59.062: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:05:59.074: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:00.062: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:00.062: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:00.072: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:01.060: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:01.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:01.067: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:02.060: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:02.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:02.067: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:03.064: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:03.064: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:03.078: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:04.078: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:04.078: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:04.091: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:05.068: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:05.068: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:05.082: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:06.059: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:06.059: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:06.065: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:07.060: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:07.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:07.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:08.061: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:08.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:08.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:09.062: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:09.062: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:09.074: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:10.063: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:10.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:10.070: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:11.063: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:11.064: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:11.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:12.066: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:12.066: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:12.085: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:13.063: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:13.064: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:13.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:14.063: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:14.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:14.073: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:15.063: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:15.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:15.072: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:16.063: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:16.064: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:16.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:17.063: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:17.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:17.076: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:18.061: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:18.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:18.068: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:19.078: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:19.078: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:19.114: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:20.061: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:20.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:20.069: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:21.061: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:21.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:21.077: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:22.061: INFO: Wrong image for pod: daemon-set-7lcqr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:22.061: INFO: Pod daemon-set-7lcqr is not available
Dec  3 14:06:22.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:22.066: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:23.075: INFO: Pod daemon-set-bpnmz is not available
Dec  3 14:06:23.075: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:23.084: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:24.061: INFO: Pod daemon-set-bpnmz is not available
Dec  3 14:06:24.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:24.068: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:25.067: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:25.083: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:26.064: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:26.074: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:27.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:27.067: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:28.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:28.070: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:29.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:29.067: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:30.059: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:30.067: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:31.059: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:31.065: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:32.062: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:32.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:33.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:33.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:34.062: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:34.069: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:35.064: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:35.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:36.059: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:36.064: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:37.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:37.074: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:38.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:38.068: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:39.062: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:39.074: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:40.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:40.070: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:41.059: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:41.065: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:42.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:42.067: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:43.064: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:43.074: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:44.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:44.076: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:45.070: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:45.103: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:46.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:46.065: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:47.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:47.072: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:48.066: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:48.077: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:49.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:49.068: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:50.074: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:50.084: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:51.059: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:51.066: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:52.066: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:52.073: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:53.073: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:53.084: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:54.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:54.067: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:55.065: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:55.072: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:56.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:56.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:57.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:57.061: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:06:57.068: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:58.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:58.060: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:06:58.071: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:06:59.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:06:59.060: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:06:59.073: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:00.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:07:00.060: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:07:00.075: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:01.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:07:01.060: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:07:01.070: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:02.060: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:07:02.060: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:07:02.066: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:03.063: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:07:03.063: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:07:03.072: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:04.061: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:07:04.062: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:07:04.069: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:05.092: INFO: Wrong image for pod: daemon-set-rlrnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 14:07:05.092: INFO: Pod daemon-set-rlrnz is not available
Dec  3 14:07:05.105: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:06.063: INFO: Pod daemon-set-fk9d4 is not available
Dec  3 14:07:06.076: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  3 14:07:06.088: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:06.095: INFO: Number of nodes with available pods: 1
Dec  3 14:07:06.095: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:07:07.112: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:07.123: INFO: Number of nodes with available pods: 1
Dec  3 14:07:07.123: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:07:08.113: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:07:08.137: INFO: Number of nodes with available pods: 2
Dec  3 14:07:08.137: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-95498, will wait for the garbage collector to delete the pods
Dec  3 14:07:08.272: INFO: Deleting {extensions DaemonSet} daemon-set took: 23.827578ms
Dec  3 14:07:08.373: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.488862ms
Dec  3 14:07:12.078: INFO: Number of nodes with available pods: 0
Dec  3 14:07:12.078: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:07:12.084: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-95498/daemonsets","resourceVersion":"89760"},"items":null}

Dec  3 14:07:12.092: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-95498/pods","resourceVersion":"89760"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:07:12.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-95498" for this suite.
Dec  3 14:07:18.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:07:18.297: INFO: namespace: e2e-tests-daemonsets-95498, resource: bindings, ignored listing per whitelist
Dec  3 14:07:18.424: INFO: namespace e2e-tests-daemonsets-95498 deletion completed in 6.297792991s

• [SLOW TEST:92.875 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:07:18.425: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-bknxc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-mvd2c in namespace e2e-tests-proxy-bknxc
I1203 14:07:18.746436      18 runners.go:180] Created replication controller with name: proxy-service-mvd2c, namespace: e2e-tests-proxy-bknxc, replica count: 1
I1203 14:07:19.802381      18 runners.go:180] proxy-service-mvd2c Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:07:20.802917      18 runners.go:180] proxy-service-mvd2c Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:07:21.803627      18 runners.go:180] proxy-service-mvd2c Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:07:22.804087      18 runners.go:180] proxy-service-mvd2c Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:07:23.804373      18 runners.go:180] proxy-service-mvd2c Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:07:24.806181      18 runners.go:180] proxy-service-mvd2c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 14:07:25.806734      18 runners.go:180] proxy-service-mvd2c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 14:07:26.807292      18 runners.go:180] proxy-service-mvd2c Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 14:07:26.813: INFO: setup took 8.122282513s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  3 14:07:26.823: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 8.946577ms)
Dec  3 14:07:26.840: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 25.949228ms)
Dec  3 14:07:26.852: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 38.628865ms)
Dec  3 14:07:26.855: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 40.520169ms)
Dec  3 14:07:26.855: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 40.431944ms)
Dec  3 14:07:26.855: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 40.905782ms)
Dec  3 14:07:26.856: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 41.349344ms)
Dec  3 14:07:26.857: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 42.9316ms)
Dec  3 14:07:26.858: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 44.402693ms)
Dec  3 14:07:26.859: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 44.615045ms)
Dec  3 14:07:26.859: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 44.68288ms)
Dec  3 14:07:26.860: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 46.151422ms)
Dec  3 14:07:26.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 55.462872ms)
Dec  3 14:07:26.882: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 67.658362ms)
Dec  3 14:07:26.882: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 67.870379ms)
Dec  3 14:07:26.882: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 68.073428ms)
Dec  3 14:07:26.896: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 13.399504ms)
Dec  3 14:07:26.900: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 16.321548ms)
Dec  3 14:07:26.903: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 19.26859ms)
Dec  3 14:07:26.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 23.791761ms)
Dec  3 14:07:26.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 26.428576ms)
Dec  3 14:07:26.926: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 42.797566ms)
Dec  3 14:07:26.927: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 43.351705ms)
Dec  3 14:07:26.927: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 43.888682ms)
Dec  3 14:07:26.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 46.596561ms)
Dec  3 14:07:26.931: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 47.328042ms)
Dec  3 14:07:26.931: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 47.918856ms)
Dec  3 14:07:26.931: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 48.288795ms)
Dec  3 14:07:26.932: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 47.841717ms)
Dec  3 14:07:26.932: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 48.602533ms)
Dec  3 14:07:26.934: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 50.282613ms)
Dec  3 14:07:26.942: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 59.261092ms)
Dec  3 14:07:26.968: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 26.33853ms)
Dec  3 14:07:26.969: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 26.863713ms)
Dec  3 14:07:26.969: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 26.884196ms)
Dec  3 14:07:26.970: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 28.153775ms)
Dec  3 14:07:26.970: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 27.908982ms)
Dec  3 14:07:26.970: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 28.178983ms)
Dec  3 14:07:26.970: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 28.320192ms)
Dec  3 14:07:26.970: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 28.299546ms)
Dec  3 14:07:26.972: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 30.052253ms)
Dec  3 14:07:26.972: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 30.66129ms)
Dec  3 14:07:26.982: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 39.670098ms)
Dec  3 14:07:26.982: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 40.061071ms)
Dec  3 14:07:26.982: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 39.960276ms)
Dec  3 14:07:26.983: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 40.849472ms)
Dec  3 14:07:26.983: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 41.736698ms)
Dec  3 14:07:26.984: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 42.067651ms)
Dec  3 14:07:27.000: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 14.319478ms)
Dec  3 14:07:27.000: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 15.30611ms)
Dec  3 14:07:27.000: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 15.942515ms)
Dec  3 14:07:27.002: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 15.663164ms)
Dec  3 14:07:27.002: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 16.625853ms)
Dec  3 14:07:27.006: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 20.84724ms)
Dec  3 14:07:27.007: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 21.543723ms)
Dec  3 14:07:27.008: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 22.641397ms)
Dec  3 14:07:27.008: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 21.810856ms)
Dec  3 14:07:27.008: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 21.845011ms)
Dec  3 14:07:27.008: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 23.444029ms)
Dec  3 14:07:27.021: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 36.240946ms)
Dec  3 14:07:27.021: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 34.565385ms)
Dec  3 14:07:27.021: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 34.15144ms)
Dec  3 14:07:27.021: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 34.480577ms)
Dec  3 14:07:27.021: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 36.023091ms)
Dec  3 14:07:27.039: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 17.805849ms)
Dec  3 14:07:27.040: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 18.801792ms)
Dec  3 14:07:27.053: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 31.508593ms)
Dec  3 14:07:27.053: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 31.606695ms)
Dec  3 14:07:27.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 33.486769ms)
Dec  3 14:07:27.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 33.492071ms)
Dec  3 14:07:27.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 33.300913ms)
Dec  3 14:07:27.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 33.558421ms)
Dec  3 14:07:27.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 33.863737ms)
Dec  3 14:07:27.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 33.825821ms)
Dec  3 14:07:27.061: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 39.468543ms)
Dec  3 14:07:27.061: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 39.998317ms)
Dec  3 14:07:27.061: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 39.78113ms)
Dec  3 14:07:27.064: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 42.244475ms)
Dec  3 14:07:27.064: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 42.469895ms)
Dec  3 14:07:27.064: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 42.894339ms)
Dec  3 14:07:27.083: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 18.939117ms)
Dec  3 14:07:27.084: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 19.379213ms)
Dec  3 14:07:27.084: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 20.089205ms)
Dec  3 14:07:27.085: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 20.30282ms)
Dec  3 14:07:27.085: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 20.513021ms)
Dec  3 14:07:27.086: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 21.415322ms)
Dec  3 14:07:27.092: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 27.802185ms)
Dec  3 14:07:27.092: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 28.080206ms)
Dec  3 14:07:27.092: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 28.352651ms)
Dec  3 14:07:27.092: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 28.027676ms)
Dec  3 14:07:27.093: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 28.020458ms)
Dec  3 14:07:27.093: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 28.975086ms)
Dec  3 14:07:27.094: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 29.165279ms)
Dec  3 14:07:27.094: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 28.91151ms)
Dec  3 14:07:27.094: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 29.328018ms)
Dec  3 14:07:27.095: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 30.9469ms)
Dec  3 14:07:27.117: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 21.029761ms)
Dec  3 14:07:27.117: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 21.987018ms)
Dec  3 14:07:27.123: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 26.922547ms)
Dec  3 14:07:27.123: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 26.889836ms)
Dec  3 14:07:27.123: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 27.907188ms)
Dec  3 14:07:27.124: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 27.9054ms)
Dec  3 14:07:27.124: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 27.870767ms)
Dec  3 14:07:27.124: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 28.566042ms)
Dec  3 14:07:27.125: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 28.551549ms)
Dec  3 14:07:27.125: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 28.550511ms)
Dec  3 14:07:27.125: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 29.57544ms)
Dec  3 14:07:27.126: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 29.275643ms)
Dec  3 14:07:27.126: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 29.774789ms)
Dec  3 14:07:27.127: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 31.262218ms)
Dec  3 14:07:27.127: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 30.952755ms)
Dec  3 14:07:27.128: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 32.109292ms)
Dec  3 14:07:27.145: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 16.256847ms)
Dec  3 14:07:27.145: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 16.627055ms)
Dec  3 14:07:27.145: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 15.76087ms)
Dec  3 14:07:27.145: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 16.628357ms)
Dec  3 14:07:27.145: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 15.733389ms)
Dec  3 14:07:27.145: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 15.840773ms)
Dec  3 14:07:27.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 19.031645ms)
Dec  3 14:07:27.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 19.245785ms)
Dec  3 14:07:27.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 18.722904ms)
Dec  3 14:07:27.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 19.276638ms)
Dec  3 14:07:27.149: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 20.465163ms)
Dec  3 14:07:27.154: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 25.131062ms)
Dec  3 14:07:27.155: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 26.386563ms)
Dec  3 14:07:27.157: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 27.921614ms)
Dec  3 14:07:27.161: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 32.559358ms)
Dec  3 14:07:27.161: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 31.953729ms)
Dec  3 14:07:27.196: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 32.236726ms)
Dec  3 14:07:27.196: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 30.575835ms)
Dec  3 14:07:27.196: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 34.219501ms)
Dec  3 14:07:27.196: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 34.229655ms)
Dec  3 14:07:27.196: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 31.246395ms)
Dec  3 14:07:27.197: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 31.391512ms)
Dec  3 14:07:27.201: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 35.438553ms)
Dec  3 14:07:27.201: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 38.118055ms)
Dec  3 14:07:27.201: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 38.429181ms)
Dec  3 14:07:27.201: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 36.60357ms)
Dec  3 14:07:27.204: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 40.196148ms)
Dec  3 14:07:27.204: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 41.766466ms)
Dec  3 14:07:27.204: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 39.309085ms)
Dec  3 14:07:27.204: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 42.950583ms)
Dec  3 14:07:27.204: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 39.163512ms)
Dec  3 14:07:27.205: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 40.003845ms)
Dec  3 14:07:27.217: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 12.338339ms)
Dec  3 14:07:27.229: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 23.730927ms)
Dec  3 14:07:27.232: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 26.04133ms)
Dec  3 14:07:27.232: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 26.306986ms)
Dec  3 14:07:27.232: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 25.968281ms)
Dec  3 14:07:27.234: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 28.299457ms)
Dec  3 14:07:27.234: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 28.608523ms)
Dec  3 14:07:27.238: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 31.936106ms)
Dec  3 14:07:27.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 36.41845ms)
Dec  3 14:07:27.243: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 37.027801ms)
Dec  3 14:07:27.243: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 38.229802ms)
Dec  3 14:07:27.243: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 37.844305ms)
Dec  3 14:07:27.243: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 37.646362ms)
Dec  3 14:07:27.247: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 41.036766ms)
Dec  3 14:07:27.248: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 41.780211ms)
Dec  3 14:07:27.248: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 41.891989ms)
Dec  3 14:07:27.266: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 18.289273ms)
Dec  3 14:07:27.267: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 19.229295ms)
Dec  3 14:07:27.268: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 19.88701ms)
Dec  3 14:07:27.271: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 22.31179ms)
Dec  3 14:07:27.271: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 22.212899ms)
Dec  3 14:07:27.272: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 23.116242ms)
Dec  3 14:07:27.273: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 24.278477ms)
Dec  3 14:07:27.287: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 38.591238ms)
Dec  3 14:07:27.287: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 38.889769ms)
Dec  3 14:07:27.291: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 43.671096ms)
Dec  3 14:07:27.293: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 44.541375ms)
Dec  3 14:07:27.293: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 44.510163ms)
Dec  3 14:07:27.293: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 43.886839ms)
Dec  3 14:07:27.293: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 43.963081ms)
Dec  3 14:07:27.293: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 44.863356ms)
Dec  3 14:07:27.293: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 44.263667ms)
Dec  3 14:07:27.317: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 23.52358ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 25.980047ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 25.321641ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 25.346223ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 25.93274ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 25.497649ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 25.401939ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 25.734798ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 25.487262ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 25.87617ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 25.954706ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 25.808696ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 25.790096ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 26.070039ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 25.74034ms)
Dec  3 14:07:27.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 25.78683ms)
Dec  3 14:07:27.341: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 21.957263ms)
Dec  3 14:07:27.341: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 20.307688ms)
Dec  3 14:07:27.342: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 20.317385ms)
Dec  3 14:07:27.342: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 22.140981ms)
Dec  3 14:07:27.343: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 22.262733ms)
Dec  3 14:07:27.344: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 24.381755ms)
Dec  3 14:07:27.344: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 22.857306ms)
Dec  3 14:07:27.344: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 22.604078ms)
Dec  3 14:07:27.344: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 23.316569ms)
Dec  3 14:07:27.344: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 23.145729ms)
Dec  3 14:07:27.344: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 22.866986ms)
Dec  3 14:07:27.348: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 26.824214ms)
Dec  3 14:07:27.348: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 28.380879ms)
Dec  3 14:07:27.348: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 26.81538ms)
Dec  3 14:07:27.348: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 28.319896ms)
Dec  3 14:07:27.348: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 28.250906ms)
Dec  3 14:07:27.360: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 11.399618ms)
Dec  3 14:07:27.360: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 10.943832ms)
Dec  3 14:07:27.361: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 12.24807ms)
Dec  3 14:07:27.366: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 15.936955ms)
Dec  3 14:07:27.366: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 16.183735ms)
Dec  3 14:07:27.367: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 17.712465ms)
Dec  3 14:07:27.368: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 18.151136ms)
Dec  3 14:07:27.370: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 20.13676ms)
Dec  3 14:07:27.370: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 20.779761ms)
Dec  3 14:07:27.370: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 20.711396ms)
Dec  3 14:07:27.370: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 20.016873ms)
Dec  3 14:07:27.370: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 21.001644ms)
Dec  3 14:07:27.372: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 22.535951ms)
Dec  3 14:07:27.372: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 22.263731ms)
Dec  3 14:07:27.373: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 22.865926ms)
Dec  3 14:07:27.374: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 24.610628ms)
Dec  3 14:07:27.382: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 7.925243ms)
Dec  3 14:07:27.396: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 21.811585ms)
Dec  3 14:07:27.396: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 21.424206ms)
Dec  3 14:07:27.396: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 21.759778ms)
Dec  3 14:07:27.397: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 21.887117ms)
Dec  3 14:07:27.398: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 23.610173ms)
Dec  3 14:07:27.398: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 23.704268ms)
Dec  3 14:07:27.398: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 23.30903ms)
Dec  3 14:07:27.398: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 23.18903ms)
Dec  3 14:07:27.399: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 24.310442ms)
Dec  3 14:07:27.410: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 35.622225ms)
Dec  3 14:07:27.410: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 36.181164ms)
Dec  3 14:07:27.410: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 36.52792ms)
Dec  3 14:07:27.411: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 36.180643ms)
Dec  3 14:07:27.411: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 36.527033ms)
Dec  3 14:07:27.412: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 37.804246ms)
Dec  3 14:07:27.441: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 27.966799ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 35.747776ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 36.203131ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 36.136825ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 36.760857ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 36.701694ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 35.795311ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 36.364405ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 36.258015ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 36.695673ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 36.102956ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 36.658042ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 36.75344ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 36.370803ms)
Dec  3 14:07:27.449: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 36.24882ms)
Dec  3 14:07:27.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 36.468694ms)
Dec  3 14:07:27.463: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 13.737579ms)
Dec  3 14:07:27.465: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 14.889969ms)
Dec  3 14:07:27.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 28.435826ms)
Dec  3 14:07:27.481: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 30.898969ms)
Dec  3 14:07:27.482: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 30.916252ms)
Dec  3 14:07:27.482: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 31.051464ms)
Dec  3 14:07:27.482: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 31.109441ms)
Dec  3 14:07:27.482: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 32.468392ms)
Dec  3 14:07:27.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 34.86272ms)
Dec  3 14:07:27.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 34.495379ms)
Dec  3 14:07:27.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 34.999751ms)
Dec  3 14:07:27.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 34.89357ms)
Dec  3 14:07:27.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 34.686237ms)
Dec  3 14:07:27.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 34.737084ms)
Dec  3 14:07:27.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 35.028296ms)
Dec  3 14:07:27.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 34.587231ms)
Dec  3 14:07:27.509: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 22.652545ms)
Dec  3 14:07:27.509: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 22.806246ms)
Dec  3 14:07:27.509: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 23.240892ms)
Dec  3 14:07:27.510: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 24.554313ms)
Dec  3 14:07:27.519: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 32.790164ms)
Dec  3 14:07:27.520: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 34.674231ms)
Dec  3 14:07:27.520: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 33.988008ms)
Dec  3 14:07:27.520: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 34.184668ms)
Dec  3 14:07:27.520: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 34.650276ms)
Dec  3 14:07:27.520: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 34.974394ms)
Dec  3 14:07:27.522: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 35.79138ms)
Dec  3 14:07:27.522: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 35.981795ms)
Dec  3 14:07:27.524: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 37.470311ms)
Dec  3 14:07:27.524: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 38.444654ms)
Dec  3 14:07:27.526: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 39.83476ms)
Dec  3 14:07:27.527: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 41.132742ms)
Dec  3 14:07:27.564: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 36.955769ms)
Dec  3 14:07:27.579: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 50.835273ms)
Dec  3 14:07:27.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 51.4978ms)
Dec  3 14:07:27.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 52.508554ms)
Dec  3 14:07:27.583: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 55.031041ms)
Dec  3 14:07:27.584: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 56.684834ms)
Dec  3 14:07:27.584: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 55.734984ms)
Dec  3 14:07:27.590: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 61.794118ms)
Dec  3 14:07:27.590: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 62.930259ms)
Dec  3 14:07:27.590: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 62.481352ms)
Dec  3 14:07:27.590: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 62.094228ms)
Dec  3 14:07:27.590: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 62.318379ms)
Dec  3 14:07:27.590: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 63.358008ms)
Dec  3 14:07:27.590: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 61.792274ms)
Dec  3 14:07:27.590: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 62.967732ms)
Dec  3 14:07:27.591: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 63.283053ms)
Dec  3 14:07:27.738: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh/proxy/rewriteme"... (200; 145.62346ms)
Dec  3 14:07:27.738: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 145.560981ms)
Dec  3 14:07:27.738: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:1080/proxy/... (200; 146.872344ms)
Dec  3 14:07:27.746: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:462/proxy/: tls qux (200; 155.036673ms)
Dec  3 14:07:27.746: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname2/proxy/: tls qux (200; 153.210692ms)
Dec  3 14:07:27.746: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname1/proxy/: foo (200; 154.286532ms)
Dec  3 14:07:27.746: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:1080/proxy/rewri... (200; 152.466398ms)
Dec  3 14:07:27.746: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:443/proxy/... (200; 152.484206ms)
Dec  3 14:07:27.747: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/http:proxy-service-mvd2c:portname2/proxy/: bar (200; 155.353745ms)
Dec  3 14:07:27.748: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:160/proxy/: foo (200; 155.240984ms)
Dec  3 14:07:27.748: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname2/proxy/: bar (200; 156.422068ms)
Dec  3 14:07:27.748: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/proxy-service-mvd2c:portname1/proxy/: foo (200; 155.160554ms)
Dec  3 14:07:27.748: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/http:proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 155.043378ms)
Dec  3 14:07:27.750: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/https:proxy-service-mvd2c-wwkqh:460/proxy/: tls baz (200; 157.563984ms)
Dec  3 14:07:27.752: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/services/https:proxy-service-mvd2c:tlsportname1/proxy/: tls baz (200; 159.668333ms)
Dec  3 14:07:27.752: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bknxc/pods/proxy-service-mvd2c-wwkqh:162/proxy/: bar (200; 160.310205ms)
STEP: deleting { ReplicationController} proxy-service-mvd2c in namespace e2e-tests-proxy-bknxc, will wait for the garbage collector to delete the pods
Dec  3 14:07:27.869: INFO: Deleting { ReplicationController} proxy-service-mvd2c took: 44.440861ms
Dec  3 14:07:27.970: INFO: Terminating { ReplicationController} proxy-service-mvd2c pods took: 100.678828ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:07:30.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bknxc" for this suite.
Dec  3 14:07:36.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:07:36.639: INFO: namespace: e2e-tests-proxy-bknxc, resource: bindings, ignored listing per whitelist
Dec  3 14:07:36.799: INFO: namespace e2e-tests-proxy-bknxc deletion completed in 6.218920529s

• [SLOW TEST:18.375 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:07:36.800: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-6kr5t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:07:37.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6kr5t" for this suite.
Dec  3 14:07:59.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:07:59.432: INFO: namespace: e2e-tests-pods-6kr5t, resource: bindings, ignored listing per whitelist
Dec  3 14:07:59.540: INFO: namespace e2e-tests-pods-6kr5t deletion completed in 22.312192374s

• [SLOW TEST:22.741 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:07:59.541: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sfn4x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 14:07:59.829: INFO: Waiting up to 5m0s for pod "pod-d741938f-f704-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-sfn4x" to be "success or failure"
Dec  3 14:07:59.838: INFO: Pod "pod-d741938f-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.650078ms
Dec  3 14:08:01.844: INFO: Pod "pod-d741938f-f704-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014895805s
Dec  3 14:08:03.851: INFO: Pod "pod-d741938f-f704-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021911999s
STEP: Saw pod success
Dec  3 14:08:03.851: INFO: Pod "pod-d741938f-f704-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:08:03.857: INFO: Trying to get logs from node k8s-master-3 pod pod-d741938f-f704-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:08:03.903: INFO: Waiting for pod pod-d741938f-f704-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:08:03.910: INFO: Pod pod-d741938f-f704-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:08:03.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sfn4x" for this suite.
Dec  3 14:08:09.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:08:10.094: INFO: namespace: e2e-tests-emptydir-sfn4x, resource: bindings, ignored listing per whitelist
Dec  3 14:08:10.193: INFO: namespace e2e-tests-emptydir-sfn4x deletion completed in 6.265119312s

• [SLOW TEST:10.652 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:08:10.193: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-cwwp6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-cwwp6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cwwp6 to expose endpoints map[]
Dec  3 14:08:10.465: INFO: Get endpoints failed (7.867764ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  3 14:08:11.472: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cwwp6 exposes endpoints map[] (1.014585933s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-cwwp6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cwwp6 to expose endpoints map[pod1:[80]]
Dec  3 14:08:15.562: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cwwp6 exposes endpoints map[pod1:[80]] (4.075819256s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-cwwp6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cwwp6 to expose endpoints map[pod2:[80] pod1:[80]]
Dec  3 14:08:18.649: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cwwp6 exposes endpoints map[pod1:[80] pod2:[80]] (3.080106024s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-cwwp6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cwwp6 to expose endpoints map[pod2:[80]]
Dec  3 14:08:19.695: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cwwp6 exposes endpoints map[pod2:[80]] (1.037558108s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-cwwp6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cwwp6 to expose endpoints map[]
Dec  3 14:08:20.718: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cwwp6 exposes endpoints map[] (1.012128986s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:08:20.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-cwwp6" for this suite.
Dec  3 14:08:26.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:08:26.894: INFO: namespace: e2e-tests-services-cwwp6, resource: bindings, ignored listing per whitelist
Dec  3 14:08:27.000: INFO: namespace e2e-tests-services-cwwp6 deletion completed in 6.238557534s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:16.807 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:08:27.000: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-jvlw8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-jvlw8
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-jvlw8
STEP: Deleting pre-stop pod
Dec  3 14:08:40.387: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:08:40.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-jvlw8" for this suite.
Dec  3 14:09:20.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:09:20.508: INFO: namespace: e2e-tests-prestop-jvlw8, resource: bindings, ignored listing per whitelist
Dec  3 14:09:20.627: INFO: namespace e2e-tests-prestop-jvlw8 deletion completed in 40.205171052s

• [SLOW TEST:53.627 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:09:20.627: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-xfs8d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1203 14:09:21.943551      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 14:09:21.944: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:09:21.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xfs8d" for this suite.
Dec  3 14:09:27.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:09:28.025: INFO: namespace: e2e-tests-gc-xfs8d, resource: bindings, ignored listing per whitelist
Dec  3 14:09:28.211: INFO: namespace e2e-tests-gc-xfs8d deletion completed in 6.257517222s

• [SLOW TEST:7.584 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:09:28.211: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wl6pl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0c18abd3-f705-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 14:09:28.486: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c19d45b-f705-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-wl6pl" to be "success or failure"
Dec  3 14:09:28.492: INFO: Pod "pod-configmaps-0c19d45b-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.917996ms
Dec  3 14:09:30.502: INFO: Pod "pod-configmaps-0c19d45b-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016115056s
Dec  3 14:09:32.508: INFO: Pod "pod-configmaps-0c19d45b-f705-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022458872s
STEP: Saw pod success
Dec  3 14:09:32.508: INFO: Pod "pod-configmaps-0c19d45b-f705-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:09:32.514: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-0c19d45b-f705-11e8-a394-16db9a3896d3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:09:32.600: INFO: Waiting for pod pod-configmaps-0c19d45b-f705-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:09:32.607: INFO: Pod pod-configmaps-0c19d45b-f705-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:09:32.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wl6pl" for this suite.
Dec  3 14:09:38.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:09:38.857: INFO: namespace: e2e-tests-configmap-wl6pl, resource: bindings, ignored listing per whitelist
Dec  3 14:09:38.914: INFO: namespace e2e-tests-configmap-wl6pl deletion completed in 6.294363572s

• [SLOW TEST:10.703 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:09:38.915: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ls925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 14:09:39.194: INFO: Waiting up to 5m0s for pod "downward-api-127bd8e7-f705-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-ls925" to be "success or failure"
Dec  3 14:09:39.200: INFO: Pod "downward-api-127bd8e7-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.917732ms
Dec  3 14:09:41.207: INFO: Pod "downward-api-127bd8e7-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012875052s
Dec  3 14:09:43.215: INFO: Pod "downward-api-127bd8e7-f705-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021492072s
STEP: Saw pod success
Dec  3 14:09:43.215: INFO: Pod "downward-api-127bd8e7-f705-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:09:43.221: INFO: Trying to get logs from node k8s-master-3 pod downward-api-127bd8e7-f705-11e8-a394-16db9a3896d3 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:09:43.257: INFO: Waiting for pod downward-api-127bd8e7-f705-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:09:43.262: INFO: Pod downward-api-127bd8e7-f705-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:09:43.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ls925" for this suite.
Dec  3 14:09:49.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:09:49.452: INFO: namespace: e2e-tests-downward-api-ls925, resource: bindings, ignored listing per whitelist
Dec  3 14:09:49.824: INFO: namespace e2e-tests-downward-api-ls925 deletion completed in 6.553932632s

• [SLOW TEST:10.909 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:09:49.831: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xn658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-19102cfa-f705-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:09:50.269: INFO: Waiting up to 5m0s for pod "pod-secrets-1913f3d2-f705-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-xn658" to be "success or failure"
Dec  3 14:09:50.278: INFO: Pod "pod-secrets-1913f3d2-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.598188ms
Dec  3 14:09:52.301: INFO: Pod "pod-secrets-1913f3d2-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032112182s
Dec  3 14:09:54.306: INFO: Pod "pod-secrets-1913f3d2-f705-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036823309s
STEP: Saw pod success
Dec  3 14:09:54.306: INFO: Pod "pod-secrets-1913f3d2-f705-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:09:54.309: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-1913f3d2-f705-11e8-a394-16db9a3896d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:09:54.337: INFO: Waiting for pod pod-secrets-1913f3d2-f705-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:09:54.343: INFO: Pod pod-secrets-1913f3d2-f705-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:09:54.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xn658" for this suite.
Dec  3 14:10:00.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:10:00.390: INFO: namespace: e2e-tests-secrets-xn658, resource: bindings, ignored listing per whitelist
Dec  3 14:10:00.575: INFO: namespace e2e-tests-secrets-xn658 deletion completed in 6.222493629s

• [SLOW TEST:10.744 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:10:00.575: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-x98t5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:10:00.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x98t5'
Dec  3 14:10:02.038: INFO: stderr: ""
Dec  3 14:10:02.038: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  3 14:10:07.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x98t5 -o json'
Dec  3 14:10:07.498: INFO: stderr: ""
Dec  3 14:10:07.498: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2018-12-03T14:09:48Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-x98t5\",\n        \"resourceVersion\": \"90511\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-x98t5/pods/e2e-test-nginx-pod\",\n        \"uid\": \"17c729b7-f705-11e8-849a-005056852a45\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gh262\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"k8s-master-3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gh262\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gh262\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-03T14:10:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-03T14:10:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-03T14:10:04Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-03T14:09:48Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7fb9ee4d1833a832e72f72241a5b513f374f8487aadddc74f0dcaad23397b306\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-03T14:10:04Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.237\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.31.168.33\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-03T14:10:02Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  3 14:10:07.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 replace -f - --namespace=e2e-tests-kubectl-x98t5'
Dec  3 14:10:07.992: INFO: stderr: ""
Dec  3 14:10:07.992: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Dec  3 14:10:07.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x98t5'
Dec  3 14:10:10.754: INFO: stderr: ""
Dec  3 14:10:10.754: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:10:10.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x98t5" for this suite.
Dec  3 14:10:16.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:10:16.857: INFO: namespace: e2e-tests-kubectl-x98t5, resource: bindings, ignored listing per whitelist
Dec  3 14:10:17.012: INFO: namespace e2e-tests-kubectl-x98t5 deletion completed in 6.245012756s

• [SLOW TEST:16.436 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:10:17.012: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-5vm5f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:10:17.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5vm5f" for this suite.
Dec  3 14:10:23.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:10:23.364: INFO: namespace: e2e-tests-services-5vm5f, resource: bindings, ignored listing per whitelist
Dec  3 14:10:23.803: INFO: namespace e2e-tests-services-5vm5f deletion completed in 6.486188346s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.791 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:10:23.803: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pmxkj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  3 14:10:24.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:24.603: INFO: stderr: ""
Dec  3 14:10:24.603: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:10:24.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:24.880: INFO: stderr: ""
Dec  3 14:10:24.881: INFO: stdout: "update-demo-nautilus-cnlpn update-demo-nautilus-jhnxp "
Dec  3 14:10:24.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-cnlpn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:25.150: INFO: stderr: ""
Dec  3 14:10:25.150: INFO: stdout: ""
Dec  3 14:10:25.150: INFO: update-demo-nautilus-cnlpn is created but not running
Dec  3 14:10:30.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:30.349: INFO: stderr: ""
Dec  3 14:10:30.349: INFO: stdout: "update-demo-nautilus-cnlpn update-demo-nautilus-jhnxp "
Dec  3 14:10:30.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-cnlpn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:30.532: INFO: stderr: ""
Dec  3 14:10:30.532: INFO: stdout: "true"
Dec  3 14:10:30.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-cnlpn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:30.735: INFO: stderr: ""
Dec  3 14:10:30.735: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:10:30.735: INFO: validating pod update-demo-nautilus-cnlpn
Dec  3 14:10:30.745: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:10:30.745: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:10:30.745: INFO: update-demo-nautilus-cnlpn is verified up and running
Dec  3 14:10:30.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-jhnxp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:30.958: INFO: stderr: ""
Dec  3 14:10:30.958: INFO: stdout: "true"
Dec  3 14:10:30.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-jhnxp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:31.132: INFO: stderr: ""
Dec  3 14:10:31.132: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:10:31.132: INFO: validating pod update-demo-nautilus-jhnxp
Dec  3 14:10:31.140: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:10:31.140: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:10:31.141: INFO: update-demo-nautilus-jhnxp is verified up and running
STEP: rolling-update to new replication controller
Dec  3 14:10:31.142: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:10:31.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:54.065: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 14:10:54.065: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:10:54.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:54.296: INFO: stderr: ""
Dec  3 14:10:54.296: INFO: stdout: "update-demo-kitten-ds8gs update-demo-kitten-xrkb5 update-demo-nautilus-jhnxp "
STEP: Replicas for name=update-demo: expected=2 actual=3
Dec  3 14:10:59.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:59.475: INFO: stderr: ""
Dec  3 14:10:59.475: INFO: stdout: "update-demo-kitten-ds8gs update-demo-kitten-xrkb5 "
Dec  3 14:10:59.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-kitten-ds8gs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:59.670: INFO: stderr: ""
Dec  3 14:10:59.670: INFO: stdout: "true"
Dec  3 14:10:59.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-kitten-ds8gs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:10:59.832: INFO: stderr: ""
Dec  3 14:10:59.832: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 14:10:59.832: INFO: validating pod update-demo-kitten-ds8gs
Dec  3 14:10:59.841: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 14:10:59.841: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 14:10:59.841: INFO: update-demo-kitten-ds8gs is verified up and running
Dec  3 14:10:59.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-kitten-xrkb5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:11:00.012: INFO: stderr: ""
Dec  3 14:11:00.012: INFO: stdout: "true"
Dec  3 14:11:00.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-kitten-xrkb5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pmxkj'
Dec  3 14:11:00.208: INFO: stderr: ""
Dec  3 14:11:00.208: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 14:11:00.208: INFO: validating pod update-demo-kitten-xrkb5
Dec  3 14:11:00.220: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 14:11:00.220: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 14:11:00.220: INFO: update-demo-kitten-xrkb5 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:11:00.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pmxkj" for this suite.
Dec  3 14:11:24.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:11:24.321: INFO: namespace: e2e-tests-kubectl-pmxkj, resource: bindings, ignored listing per whitelist
Dec  3 14:11:24.461: INFO: namespace e2e-tests-kubectl-pmxkj deletion completed in 24.23506998s

• [SLOW TEST:60.658 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:11:24.462: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xtbbb
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-516e0fff-f705-11e8-a394-16db9a3896d3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-516e0fff-f705-11e8-a394-16db9a3896d3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:12:31.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xtbbb" for this suite.
Dec  3 14:12:55.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:12:55.839: INFO: namespace: e2e-tests-configmap-xtbbb, resource: bindings, ignored listing per whitelist
Dec  3 14:12:55.952: INFO: namespace e2e-tests-configmap-xtbbb deletion completed in 24.378480388s

• [SLOW TEST:91.491 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:12:55.953: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-2pq28
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2pq28
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 14:12:56.291: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 14:13:20.465: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.31.168.38:8080/dial?request=hostName&protocol=http&host=172.31.140.109&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-2pq28 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:13:20.465: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:13:20.665: INFO: Waiting for endpoints: map[]
Dec  3 14:13:20.672: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.31.168.38:8080/dial?request=hostName&protocol=http&host=172.31.168.34&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-2pq28 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:13:20.672: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:13:20.842: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:13:20.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2pq28" for this suite.
Dec  3 14:13:44.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:13:45.033: INFO: namespace: e2e-tests-pod-network-test-2pq28, resource: bindings, ignored listing per whitelist
Dec  3 14:13:45.195: INFO: namespace e2e-tests-pod-network-test-2pq28 deletion completed in 24.331888619s

• [SLOW TEST:49.242 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:13:45.196: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-trmxf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:13:45.516: INFO: Creating deployment "test-recreate-deployment"
Dec  3 14:13:45.526: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  3 14:13:45.542: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec  3 14:13:47.556: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  3 14:13:47.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679443211, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679443211, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679443211, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679443211, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:13:49.571: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  3 14:13:49.587: INFO: Updating deployment test-recreate-deployment
Dec  3 14:13:49.588: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 14:13:49.829: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-trmxf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-trmxf/deployments/test-recreate-deployment,UID:9cfd2650-f705-11e8-849a-005056852a45,ResourceVersion:91245,Generation:2,CreationTimestamp:2018-12-03 14:13:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-03 14:13:35 +0000 UTC 2018-12-03 14:13:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-03 14:13:35 +0000 UTC 2018-12-03 14:13:31 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 14:13:49.867: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-trmxf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-trmxf/replicasets/test-recreate-deployment-7cf749666b,UID:9f79a501-f705-11e8-849a-005056852a45,ResourceVersion:91243,Generation:1,CreationTimestamp:2018-12-03 14:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9cfd2650-f705-11e8-849a-005056852a45 0xc421fbd197 0xc421fbd198}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 14:13:49.867: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  3 14:13:49.868: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-trmxf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-trmxf/replicasets/test-recreate-deployment-79f694ff59,UID:9d00fca5-f705-11e8-849a-005056852a45,ResourceVersion:91234,Generation:2,CreationTimestamp:2018-12-03 14:13:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9cfd2650-f705-11e8-849a-005056852a45 0xc421fbd0d7 0xc421fbd0d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 14:13:49.881: INFO: Pod "test-recreate-deployment-7cf749666b-pcrcf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-pcrcf,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-trmxf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-trmxf/pods/test-recreate-deployment-7cf749666b-pcrcf,UID:9f7d2776-f705-11e8-849a-005056852a45,ResourceVersion:91247,Generation:0,CreationTimestamp:2018-12-03 14:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 9f79a501-f705-11e8-849a-005056852a45 0xc421fbdab7 0xc421fbdab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8972l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8972l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8972l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fbdb30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fbdb50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:13:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:13:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:13:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:13:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 14:13:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:13:49.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-trmxf" for this suite.
Dec  3 14:13:55.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:13:56.140: INFO: namespace: e2e-tests-deployment-trmxf, resource: bindings, ignored listing per whitelist
Dec  3 14:13:56.333: INFO: namespace e2e-tests-deployment-trmxf deletion completed in 6.43843228s

• [SLOW TEST:11.137 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:13:56.333: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xd4pp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-abeca140-f705-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:13:56.639: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-abee207c-f705-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-xd4pp" to be "success or failure"
Dec  3 14:13:56.645: INFO: Pod "pod-projected-secrets-abee207c-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015742ms
Dec  3 14:13:58.656: INFO: Pod "pod-projected-secrets-abee207c-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017482503s
Dec  3 14:14:00.667: INFO: Pod "pod-projected-secrets-abee207c-f705-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028654824s
STEP: Saw pod success
Dec  3 14:14:00.667: INFO: Pod "pod-projected-secrets-abee207c-f705-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:14:00.678: INFO: Trying to get logs from node k8s-master-3 pod pod-projected-secrets-abee207c-f705-11e8-a394-16db9a3896d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:14:00.781: INFO: Waiting for pod pod-projected-secrets-abee207c-f705-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:14:00.788: INFO: Pod pod-projected-secrets-abee207c-f705-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:14:00.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xd4pp" for this suite.
Dec  3 14:14:06.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:14:06.886: INFO: namespace: e2e-tests-projected-xd4pp, resource: bindings, ignored listing per whitelist
Dec  3 14:14:07.079: INFO: namespace e2e-tests-projected-xd4pp deletion completed in 6.27987766s

• [SLOW TEST:10.747 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:14:07.081: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lvk72
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b2596e50-f705-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 14:14:07.413: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b25a8c90-f705-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-lvk72" to be "success or failure"
Dec  3 14:14:07.422: INFO: Pod "pod-projected-configmaps-b25a8c90-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.335746ms
Dec  3 14:14:09.432: INFO: Pod "pod-projected-configmaps-b25a8c90-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019411353s
Dec  3 14:14:11.441: INFO: Pod "pod-projected-configmaps-b25a8c90-f705-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02806208s
STEP: Saw pod success
Dec  3 14:14:11.441: INFO: Pod "pod-projected-configmaps-b25a8c90-f705-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:14:11.448: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-configmaps-b25a8c90-f705-11e8-a394-16db9a3896d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:14:11.487: INFO: Waiting for pod pod-projected-configmaps-b25a8c90-f705-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:14:11.493: INFO: Pod pod-projected-configmaps-b25a8c90-f705-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:14:11.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lvk72" for this suite.
Dec  3 14:14:17.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:14:17.594: INFO: namespace: e2e-tests-projected-lvk72, resource: bindings, ignored listing per whitelist
Dec  3 14:14:17.827: INFO: namespace e2e-tests-projected-lvk72 deletion completed in 6.326936893s

• [SLOW TEST:10.746 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:14:17.827: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h25sh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b8c54a29-f705-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:14:18.186: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b8c6d1e6-f705-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-h25sh" to be "success or failure"
Dec  3 14:14:18.191: INFO: Pod "pod-projected-secrets-b8c6d1e6-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.487669ms
Dec  3 14:14:20.199: INFO: Pod "pod-projected-secrets-b8c6d1e6-f705-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013446503s
Dec  3 14:14:22.207: INFO: Pod "pod-projected-secrets-b8c6d1e6-f705-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02164734s
STEP: Saw pod success
Dec  3 14:14:22.207: INFO: Pod "pod-projected-secrets-b8c6d1e6-f705-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:14:22.213: INFO: Trying to get logs from node k8s-master-3 pod pod-projected-secrets-b8c6d1e6-f705-11e8-a394-16db9a3896d3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:14:22.249: INFO: Waiting for pod pod-projected-secrets-b8c6d1e6-f705-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:14:22.253: INFO: Pod pod-projected-secrets-b8c6d1e6-f705-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:14:22.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h25sh" for this suite.
Dec  3 14:14:28.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:14:28.527: INFO: namespace: e2e-tests-projected-h25sh, resource: bindings, ignored listing per whitelist
Dec  3 14:14:28.528: INFO: namespace e2e-tests-projected-h25sh deletion completed in 6.26745467s

• [SLOW TEST:10.700 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:14:28.528: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dwfd6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  3 14:14:28.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 --namespace=e2e-tests-kubectl-dwfd6 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  3 14:14:31.315: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  3 14:14:31.315: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:14:33.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dwfd6" for this suite.
Dec  3 14:14:39.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:14:39.411: INFO: namespace: e2e-tests-kubectl-dwfd6, resource: bindings, ignored listing per whitelist
Dec  3 14:14:39.658: INFO: namespace e2e-tests-kubectl-dwfd6 deletion completed in 6.32101666s

• [SLOW TEST:11.131 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:14:39.659: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-r9z45
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 14:14:40.069: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:14:40.075: INFO: Number of nodes with available pods: 0
Dec  3 14:14:40.075: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:14:41.081: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:14:41.086: INFO: Number of nodes with available pods: 0
Dec  3 14:14:41.086: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:14:42.084: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:14:42.090: INFO: Number of nodes with available pods: 0
Dec  3 14:14:42.090: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:14:43.083: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:14:43.091: INFO: Number of nodes with available pods: 2
Dec  3 14:14:43.091: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  3 14:14:43.128: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:14:43.134: INFO: Number of nodes with available pods: 1
Dec  3 14:14:43.134: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:14:44.141: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:14:44.150: INFO: Number of nodes with available pods: 1
Dec  3 14:14:44.150: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:14:45.144: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:14:45.151: INFO: Number of nodes with available pods: 1
Dec  3 14:14:45.151: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:14:46.143: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:14:46.148: INFO: Number of nodes with available pods: 2
Dec  3 14:14:46.149: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-r9z45, will wait for the garbage collector to delete the pods
Dec  3 14:14:46.223: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.988844ms
Dec  3 14:14:46.324: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.524446ms
Dec  3 14:15:20.629: INFO: Number of nodes with available pods: 0
Dec  3 14:15:20.629: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:15:20.633: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r9z45/daemonsets","resourceVersion":"91646"},"items":null}

Dec  3 14:15:20.638: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r9z45/pods","resourceVersion":"91646"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:15:20.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r9z45" for this suite.
Dec  3 14:15:26.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:15:26.749: INFO: namespace: e2e-tests-daemonsets-r9z45, resource: bindings, ignored listing per whitelist
Dec  3 14:15:26.898: INFO: namespace e2e-tests-daemonsets-r9z45 deletion completed in 6.237760246s

• [SLOW TEST:47.239 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:15:26.898: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zknzc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  3 14:15:27.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 api-versions'
Dec  3 14:15:27.421: INFO: stderr: ""
Dec  3 14:15:27.421: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:15:27.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zknzc" for this suite.
Dec  3 14:15:33.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:15:33.731: INFO: namespace: e2e-tests-kubectl-zknzc, resource: bindings, ignored listing per whitelist
Dec  3 14:15:33.839: INFO: namespace e2e-tests-kubectl-zknzc deletion completed in 6.407186116s

• [SLOW TEST:6.941 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:15:33.840: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4tgwm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4tgwm
Dec  3 14:15:38.386: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4tgwm
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:15:38.395: INFO: Initial restart count of pod liveness-http is 0
Dec  3 14:16:02.526: INFO: Restart count of pod e2e-tests-container-probe-4tgwm/liveness-http is now 1 (24.130767381s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:16:02.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4tgwm" for this suite.
Dec  3 14:16:08.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:16:08.664: INFO: namespace: e2e-tests-container-probe-4tgwm, resource: bindings, ignored listing per whitelist
Dec  3 14:16:08.914: INFO: namespace e2e-tests-container-probe-4tgwm deletion completed in 6.347083426s

• [SLOW TEST:35.074 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:16:08.914: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jxnrc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:16:09.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jxnrc'
Dec  3 14:16:09.412: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 14:16:09.412: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Dec  3 14:16:11.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jxnrc'
Dec  3 14:16:11.670: INFO: stderr: ""
Dec  3 14:16:11.671: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:16:11.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jxnrc" for this suite.
Dec  3 14:16:33.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:16:33.869: INFO: namespace: e2e-tests-kubectl-jxnrc, resource: bindings, ignored listing per whitelist
Dec  3 14:16:33.963: INFO: namespace e2e-tests-kubectl-jxnrc deletion completed in 22.286001216s

• [SLOW TEST:25.049 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:16:33.963: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-mxhff
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-09e1e810-f706-11e8-a394-16db9a3896d3
STEP: Creating secret with name s-test-opt-upd-09e1e8aa-f706-11e8-a394-16db9a3896d3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-09e1e810-f706-11e8-a394-16db9a3896d3
STEP: Updating secret s-test-opt-upd-09e1e8aa-f706-11e8-a394-16db9a3896d3
STEP: Creating secret with name s-test-opt-create-09e1e8e2-f706-11e8-a394-16db9a3896d3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:17:51.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mxhff" for this suite.
Dec  3 14:18:13.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:18:13.403: INFO: namespace: e2e-tests-secrets-mxhff, resource: bindings, ignored listing per whitelist
Dec  3 14:18:13.653: INFO: namespace e2e-tests-secrets-mxhff deletion completed in 22.284818148s

• [SLOW TEST:99.690 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:18:13.654: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rzj95
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:18:39.960: INFO: Container started at 2018-12-03 14:18:15 +0000 UTC, pod became ready at 2018-12-03 14:18:38 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:18:39.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rzj95" for this suite.
Dec  3 14:19:04.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:19:04.145: INFO: namespace: e2e-tests-container-probe-rzj95, resource: bindings, ignored listing per whitelist
Dec  3 14:19:04.214: INFO: namespace e2e-tests-container-probe-rzj95 deletion completed in 24.22434034s

• [SLOW TEST:50.561 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:19:04.215: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-t6phk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  3 14:19:04.428: INFO: Waiting up to 5m0s for pod "client-containers-6363e2ba-f706-11e8-a394-16db9a3896d3" in namespace "e2e-tests-containers-t6phk" to be "success or failure"
Dec  3 14:19:04.441: INFO: Pod "client-containers-6363e2ba-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.378791ms
Dec  3 14:19:06.447: INFO: Pod "client-containers-6363e2ba-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018819172s
Dec  3 14:19:08.456: INFO: Pod "client-containers-6363e2ba-f706-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028266914s
STEP: Saw pod success
Dec  3 14:19:08.456: INFO: Pod "client-containers-6363e2ba-f706-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:19:08.465: INFO: Trying to get logs from node k8s-master-3 pod client-containers-6363e2ba-f706-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:19:08.563: INFO: Waiting for pod client-containers-6363e2ba-f706-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:19:08.570: INFO: Pod client-containers-6363e2ba-f706-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:19:08.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-t6phk" for this suite.
Dec  3 14:19:14.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:19:14.641: INFO: namespace: e2e-tests-containers-t6phk, resource: bindings, ignored listing per whitelist
Dec  3 14:19:14.964: INFO: namespace e2e-tests-containers-t6phk deletion completed in 6.379225195s

• [SLOW TEST:10.749 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:19:14.965: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gcmxd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 14:19:15.384: INFO: Waiting up to 5m0s for pod "pod-69eaeffa-f706-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-gcmxd" to be "success or failure"
Dec  3 14:19:15.401: INFO: Pod "pod-69eaeffa-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 17.640502ms
Dec  3 14:19:17.411: INFO: Pod "pod-69eaeffa-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026773864s
Dec  3 14:19:19.423: INFO: Pod "pod-69eaeffa-f706-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039486111s
STEP: Saw pod success
Dec  3 14:19:19.423: INFO: Pod "pod-69eaeffa-f706-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:19:19.429: INFO: Trying to get logs from node k8s-node-2 pod pod-69eaeffa-f706-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:19:19.480: INFO: Waiting for pod pod-69eaeffa-f706-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:19:19.487: INFO: Pod pod-69eaeffa-f706-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:19:19.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gcmxd" for this suite.
Dec  3 14:19:25.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:19:25.699: INFO: namespace: e2e-tests-emptydir-gcmxd, resource: bindings, ignored listing per whitelist
Dec  3 14:19:25.917: INFO: namespace e2e-tests-emptydir-gcmxd deletion completed in 6.412775384s

• [SLOW TEST:10.953 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:19:25.917: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-5l7g2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-5l7g2
I1203 14:19:26.263442      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-5l7g2, replica count: 1
I1203 14:19:27.314314      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:19:28.316337      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:19:29.317082      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 14:19:29.439: INFO: Created: latency-svc-kvxvm
Dec  3 14:19:29.478: INFO: Got endpoints: latency-svc-kvxvm [60.390524ms]
Dec  3 14:19:29.510: INFO: Created: latency-svc-jlz8b
Dec  3 14:19:29.527: INFO: Got endpoints: latency-svc-jlz8b [49.052594ms]
Dec  3 14:19:29.541: INFO: Created: latency-svc-wndfk
Dec  3 14:19:29.568: INFO: Got endpoints: latency-svc-wndfk [88.586292ms]
Dec  3 14:19:29.587: INFO: Created: latency-svc-7pncr
Dec  3 14:19:29.610: INFO: Got endpoints: latency-svc-7pncr [82.63557ms]
Dec  3 14:19:29.625: INFO: Created: latency-svc-kh9xx
Dec  3 14:19:29.644: INFO: Got endpoints: latency-svc-kh9xx [165.542496ms]
Dec  3 14:19:29.663: INFO: Created: latency-svc-mg7qp
Dec  3 14:19:29.672: INFO: Got endpoints: latency-svc-mg7qp [193.023672ms]
Dec  3 14:19:29.717: INFO: Created: latency-svc-vwhlh
Dec  3 14:19:29.732: INFO: Got endpoints: latency-svc-vwhlh [252.649854ms]
Dec  3 14:19:29.773: INFO: Created: latency-svc-tc9dj
Dec  3 14:19:29.793: INFO: Got endpoints: latency-svc-tc9dj [314.124902ms]
Dec  3 14:19:29.823: INFO: Created: latency-svc-8zwlj
Dec  3 14:19:29.860: INFO: Got endpoints: latency-svc-8zwlj [380.413228ms]
Dec  3 14:19:29.937: INFO: Created: latency-svc-rg69z
Dec  3 14:19:29.937: INFO: Got endpoints: latency-svc-rg69z [457.893798ms]
Dec  3 14:19:30.000: INFO: Created: latency-svc-q52zw
Dec  3 14:19:30.001: INFO: Got endpoints: latency-svc-q52zw [522.164457ms]
Dec  3 14:19:30.075: INFO: Created: latency-svc-9bfwh
Dec  3 14:19:30.077: INFO: Got endpoints: latency-svc-9bfwh [596.588475ms]
Dec  3 14:19:30.118: INFO: Created: latency-svc-xwdjp
Dec  3 14:19:30.132: INFO: Got endpoints: latency-svc-xwdjp [652.799816ms]
Dec  3 14:19:30.190: INFO: Created: latency-svc-bltfq
Dec  3 14:19:30.231: INFO: Got endpoints: latency-svc-bltfq [751.254446ms]
Dec  3 14:19:30.243: INFO: Created: latency-svc-g2tgw
Dec  3 14:19:30.253: INFO: Got endpoints: latency-svc-g2tgw [772.253131ms]
Dec  3 14:19:30.267: INFO: Created: latency-svc-t5f89
Dec  3 14:19:30.276: INFO: Got endpoints: latency-svc-t5f89 [797.15416ms]
Dec  3 14:19:30.291: INFO: Created: latency-svc-qpj6b
Dec  3 14:19:30.299: INFO: Got endpoints: latency-svc-qpj6b [818.09256ms]
Dec  3 14:19:30.318: INFO: Created: latency-svc-kgxf2
Dec  3 14:19:30.318: INFO: Got endpoints: latency-svc-kgxf2 [750.512949ms]
Dec  3 14:19:30.342: INFO: Created: latency-svc-n8k5q
Dec  3 14:19:30.352: INFO: Got endpoints: latency-svc-n8k5q [742.524468ms]
Dec  3 14:19:30.360: INFO: Created: latency-svc-j7bk6
Dec  3 14:19:30.369: INFO: Got endpoints: latency-svc-j7bk6 [725.155509ms]
Dec  3 14:19:30.382: INFO: Created: latency-svc-drpd4
Dec  3 14:19:30.392: INFO: Got endpoints: latency-svc-drpd4 [719.788193ms]
Dec  3 14:19:30.400: INFO: Created: latency-svc-znbps
Dec  3 14:19:30.404: INFO: Got endpoints: latency-svc-znbps [671.946906ms]
Dec  3 14:19:30.419: INFO: Created: latency-svc-slhw5
Dec  3 14:19:30.425: INFO: Got endpoints: latency-svc-slhw5 [631.773738ms]
Dec  3 14:19:30.455: INFO: Created: latency-svc-bb9mv
Dec  3 14:19:30.459: INFO: Got endpoints: latency-svc-bb9mv [598.937208ms]
Dec  3 14:19:30.476: INFO: Created: latency-svc-k85st
Dec  3 14:19:30.483: INFO: Got endpoints: latency-svc-k85st [545.28261ms]
Dec  3 14:19:30.497: INFO: Created: latency-svc-655gm
Dec  3 14:19:30.506: INFO: Got endpoints: latency-svc-655gm [504.06665ms]
Dec  3 14:19:30.524: INFO: Created: latency-svc-9qsht
Dec  3 14:19:30.527: INFO: Got endpoints: latency-svc-9qsht [450.039141ms]
Dec  3 14:19:30.546: INFO: Created: latency-svc-tpzvk
Dec  3 14:19:30.566: INFO: Got endpoints: latency-svc-tpzvk [433.527721ms]
Dec  3 14:19:30.578: INFO: Created: latency-svc-vcvp4
Dec  3 14:19:30.588: INFO: Got endpoints: latency-svc-vcvp4 [356.402058ms]
Dec  3 14:19:30.607: INFO: Created: latency-svc-25mxf
Dec  3 14:19:30.616: INFO: Got endpoints: latency-svc-25mxf [363.459348ms]
Dec  3 14:19:30.641: INFO: Created: latency-svc-zzk8m
Dec  3 14:19:30.661: INFO: Got endpoints: latency-svc-zzk8m [384.824771ms]
Dec  3 14:19:30.683: INFO: Created: latency-svc-h6bfk
Dec  3 14:19:30.708: INFO: Got endpoints: latency-svc-h6bfk [409.254377ms]
Dec  3 14:19:30.711: INFO: Created: latency-svc-449bk
Dec  3 14:19:30.721: INFO: Got endpoints: latency-svc-449bk [403.079646ms]
Dec  3 14:19:30.738: INFO: Created: latency-svc-kdks2
Dec  3 14:19:30.744: INFO: Got endpoints: latency-svc-kdks2 [391.687113ms]
Dec  3 14:19:30.764: INFO: Created: latency-svc-4p67c
Dec  3 14:19:30.769: INFO: Got endpoints: latency-svc-4p67c [399.259581ms]
Dec  3 14:19:30.788: INFO: Created: latency-svc-rpvvt
Dec  3 14:19:30.799: INFO: Got endpoints: latency-svc-rpvvt [406.813451ms]
Dec  3 14:19:30.815: INFO: Created: latency-svc-zxzvm
Dec  3 14:19:30.823: INFO: Got endpoints: latency-svc-zxzvm [419.474707ms]
Dec  3 14:19:30.866: INFO: Created: latency-svc-b8qn2
Dec  3 14:19:30.867: INFO: Got endpoints: latency-svc-b8qn2 [441.638191ms]
Dec  3 14:19:30.904: INFO: Created: latency-svc-84f54
Dec  3 14:19:30.912: INFO: Got endpoints: latency-svc-84f54 [452.861646ms]
Dec  3 14:19:30.923: INFO: Created: latency-svc-qsjmq
Dec  3 14:19:30.932: INFO: Got endpoints: latency-svc-qsjmq [449.361888ms]
Dec  3 14:19:30.946: INFO: Created: latency-svc-p8w9w
Dec  3 14:19:30.955: INFO: Got endpoints: latency-svc-p8w9w [449.222334ms]
Dec  3 14:19:30.967: INFO: Created: latency-svc-dkxrc
Dec  3 14:19:30.981: INFO: Got endpoints: latency-svc-dkxrc [454.088784ms]
Dec  3 14:19:30.998: INFO: Created: latency-svc-css94
Dec  3 14:19:31.011: INFO: Got endpoints: latency-svc-css94 [444.794174ms]
Dec  3 14:19:31.023: INFO: Created: latency-svc-glqk7
Dec  3 14:19:31.025: INFO: Got endpoints: latency-svc-glqk7 [437.566282ms]
Dec  3 14:19:31.048: INFO: Created: latency-svc-cn54m
Dec  3 14:19:31.064: INFO: Got endpoints: latency-svc-cn54m [447.880212ms]
Dec  3 14:19:31.080: INFO: Created: latency-svc-xtk6r
Dec  3 14:19:31.096: INFO: Got endpoints: latency-svc-xtk6r [434.861418ms]
Dec  3 14:19:31.108: INFO: Created: latency-svc-4knzh
Dec  3 14:19:31.135: INFO: Got endpoints: latency-svc-4knzh [426.925614ms]
Dec  3 14:19:31.148: INFO: Created: latency-svc-668kw
Dec  3 14:19:31.161: INFO: Got endpoints: latency-svc-668kw [439.326868ms]
Dec  3 14:19:31.177: INFO: Created: latency-svc-h4rxl
Dec  3 14:19:31.191: INFO: Got endpoints: latency-svc-h4rxl [446.868014ms]
Dec  3 14:19:31.218: INFO: Created: latency-svc-nvfkd
Dec  3 14:19:31.223: INFO: Got endpoints: latency-svc-nvfkd [454.41994ms]
Dec  3 14:19:31.241: INFO: Created: latency-svc-fc6sn
Dec  3 14:19:31.269: INFO: Got endpoints: latency-svc-fc6sn [470.538224ms]
Dec  3 14:19:31.332: INFO: Created: latency-svc-rjnfr
Dec  3 14:19:31.353: INFO: Got endpoints: latency-svc-rjnfr [529.08726ms]
Dec  3 14:19:31.406: INFO: Created: latency-svc-8xrct
Dec  3 14:19:31.415: INFO: Got endpoints: latency-svc-8xrct [547.658136ms]
Dec  3 14:19:31.439: INFO: Created: latency-svc-z9zsr
Dec  3 14:19:31.453: INFO: Got endpoints: latency-svc-z9zsr [541.532816ms]
Dec  3 14:19:31.474: INFO: Created: latency-svc-w6wqc
Dec  3 14:19:31.491: INFO: Got endpoints: latency-svc-w6wqc [559.159182ms]
Dec  3 14:19:31.519: INFO: Created: latency-svc-bshrf
Dec  3 14:19:31.529: INFO: Got endpoints: latency-svc-bshrf [573.545452ms]
Dec  3 14:19:31.583: INFO: Created: latency-svc-6sfhm
Dec  3 14:19:31.583: INFO: Got endpoints: latency-svc-6sfhm [601.995998ms]
Dec  3 14:19:31.612: INFO: Created: latency-svc-vvcrr
Dec  3 14:19:31.618: INFO: Got endpoints: latency-svc-vvcrr [606.734146ms]
Dec  3 14:19:31.634: INFO: Created: latency-svc-r8rch
Dec  3 14:19:31.642: INFO: Got endpoints: latency-svc-r8rch [616.537232ms]
Dec  3 14:19:31.661: INFO: Created: latency-svc-7cdnb
Dec  3 14:19:31.666: INFO: Got endpoints: latency-svc-7cdnb [601.62299ms]
Dec  3 14:19:31.695: INFO: Created: latency-svc-qjrnq
Dec  3 14:19:31.706: INFO: Got endpoints: latency-svc-qjrnq [609.562364ms]
Dec  3 14:19:31.710: INFO: Created: latency-svc-g8j5p
Dec  3 14:19:31.716: INFO: Got endpoints: latency-svc-g8j5p [580.861272ms]
Dec  3 14:19:31.745: INFO: Created: latency-svc-7slgs
Dec  3 14:19:31.746: INFO: Got endpoints: latency-svc-7slgs [584.853028ms]
Dec  3 14:19:31.754: INFO: Created: latency-svc-d96kz
Dec  3 14:19:31.761: INFO: Got endpoints: latency-svc-d96kz [570.431146ms]
Dec  3 14:19:31.772: INFO: Created: latency-svc-wrmfq
Dec  3 14:19:31.777: INFO: Got endpoints: latency-svc-wrmfq [553.887116ms]
Dec  3 14:19:31.797: INFO: Created: latency-svc-qqw4j
Dec  3 14:19:31.806: INFO: Got endpoints: latency-svc-qqw4j [536.156262ms]
Dec  3 14:19:31.822: INFO: Created: latency-svc-ffqr5
Dec  3 14:19:31.826: INFO: Got endpoints: latency-svc-ffqr5 [473.143808ms]
Dec  3 14:19:31.848: INFO: Created: latency-svc-8cmtw
Dec  3 14:19:31.861: INFO: Got endpoints: latency-svc-8cmtw [446.44244ms]
Dec  3 14:19:31.877: INFO: Created: latency-svc-c7gvc
Dec  3 14:19:31.881: INFO: Got endpoints: latency-svc-c7gvc [427.265386ms]
Dec  3 14:19:31.924: INFO: Created: latency-svc-dwl4b
Dec  3 14:19:31.933: INFO: Got endpoints: latency-svc-dwl4b [441.387408ms]
Dec  3 14:19:31.958: INFO: Created: latency-svc-4dsm7
Dec  3 14:19:31.961: INFO: Got endpoints: latency-svc-4dsm7 [432.84754ms]
Dec  3 14:19:31.973: INFO: Created: latency-svc-4tssq
Dec  3 14:19:31.980: INFO: Got endpoints: latency-svc-4tssq [397.051542ms]
Dec  3 14:19:31.997: INFO: Created: latency-svc-r4rnj
Dec  3 14:19:32.003: INFO: Got endpoints: latency-svc-r4rnj [384.524208ms]
Dec  3 14:19:32.013: INFO: Created: latency-svc-7t484
Dec  3 14:19:32.020: INFO: Got endpoints: latency-svc-7t484 [378.443484ms]
Dec  3 14:19:32.051: INFO: Created: latency-svc-f78n9
Dec  3 14:19:32.053: INFO: Got endpoints: latency-svc-f78n9 [386.807ms]
Dec  3 14:19:32.075: INFO: Created: latency-svc-pf2wb
Dec  3 14:19:32.075: INFO: Got endpoints: latency-svc-pf2wb [369.388868ms]
Dec  3 14:19:32.085: INFO: Created: latency-svc-jsqxq
Dec  3 14:19:32.095: INFO: Got endpoints: latency-svc-jsqxq [378.486806ms]
Dec  3 14:19:32.111: INFO: Created: latency-svc-64r55
Dec  3 14:19:32.117: INFO: Got endpoints: latency-svc-64r55 [371.616538ms]
Dec  3 14:19:32.127: INFO: Created: latency-svc-5479d
Dec  3 14:19:32.135: INFO: Got endpoints: latency-svc-5479d [373.225238ms]
Dec  3 14:19:32.153: INFO: Created: latency-svc-gnrwv
Dec  3 14:19:32.159: INFO: Got endpoints: latency-svc-gnrwv [382.045618ms]
Dec  3 14:19:32.179: INFO: Created: latency-svc-rxmm4
Dec  3 14:19:32.187: INFO: Got endpoints: latency-svc-rxmm4 [381.332936ms]
Dec  3 14:19:32.202: INFO: Created: latency-svc-rxgn5
Dec  3 14:19:32.210: INFO: Got endpoints: latency-svc-rxgn5 [383.954296ms]
Dec  3 14:19:32.221: INFO: Created: latency-svc-6glm7
Dec  3 14:19:32.227: INFO: Got endpoints: latency-svc-6glm7 [366.018982ms]
Dec  3 14:19:32.241: INFO: Created: latency-svc-nlj6s
Dec  3 14:19:32.268: INFO: Got endpoints: latency-svc-nlj6s [387.16835ms]
Dec  3 14:19:32.288: INFO: Created: latency-svc-9v7t8
Dec  3 14:19:32.301: INFO: Got endpoints: latency-svc-9v7t8 [367.525686ms]
Dec  3 14:19:32.308: INFO: Created: latency-svc-jgwxt
Dec  3 14:19:32.338: INFO: Created: latency-svc-j788s
Dec  3 14:19:32.350: INFO: Got endpoints: latency-svc-jgwxt [388.402048ms]
Dec  3 14:19:32.356: INFO: Created: latency-svc-n9xvt
Dec  3 14:19:32.380: INFO: Created: latency-svc-lfkzl
Dec  3 14:19:32.394: INFO: Created: latency-svc-5vtgn
Dec  3 14:19:32.403: INFO: Got endpoints: latency-svc-j788s [422.844354ms]
Dec  3 14:19:32.419: INFO: Created: latency-svc-jrtjw
Dec  3 14:19:32.454: INFO: Got endpoints: latency-svc-n9xvt [451.292238ms]
Dec  3 14:19:32.455: INFO: Created: latency-svc-sxfck
Dec  3 14:19:32.501: INFO: Created: latency-svc-5nqdj
Dec  3 14:19:32.505: INFO: Got endpoints: latency-svc-lfkzl [484.984574ms]
Dec  3 14:19:32.524: INFO: Created: latency-svc-xn5xp
Dec  3 14:19:32.554: INFO: Created: latency-svc-67vl2
Dec  3 14:19:32.562: INFO: Got endpoints: latency-svc-5vtgn [509.282306ms]
Dec  3 14:19:32.581: INFO: Created: latency-svc-nctl4
Dec  3 14:19:32.641: INFO: Got endpoints: latency-svc-jrtjw [566.288914ms]
Dec  3 14:19:32.652: INFO: Got endpoints: latency-svc-sxfck [557.839356ms]
Dec  3 14:19:32.671: INFO: Created: latency-svc-w24hg
Dec  3 14:19:32.707: INFO: Created: latency-svc-7vns2
Dec  3 14:19:32.714: INFO: Got endpoints: latency-svc-5nqdj [596.738312ms]
Dec  3 14:19:32.735: INFO: Created: latency-svc-qxck4
Dec  3 14:19:32.752: INFO: Got endpoints: latency-svc-xn5xp [616.555422ms]
Dec  3 14:19:32.773: INFO: Created: latency-svc-m7t4j
Dec  3 14:19:32.789: INFO: Created: latency-svc-dhz92
Dec  3 14:19:32.801: INFO: Got endpoints: latency-svc-67vl2 [641.308548ms]
Dec  3 14:19:32.807: INFO: Created: latency-svc-nz228
Dec  3 14:19:32.829: INFO: Created: latency-svc-8pwt7
Dec  3 14:19:32.839: INFO: Created: latency-svc-wl59p
Dec  3 14:19:32.860: INFO: Got endpoints: latency-svc-nctl4 [672.606358ms]
Dec  3 14:19:32.871: INFO: Created: latency-svc-d825f
Dec  3 14:19:32.892: INFO: Created: latency-svc-7qn6r
Dec  3 14:19:32.901: INFO: Got endpoints: latency-svc-w24hg [691.185522ms]
Dec  3 14:19:32.918: INFO: Created: latency-svc-2cx7c
Dec  3 14:19:32.940: INFO: Created: latency-svc-sdg4l
Dec  3 14:19:32.955: INFO: Got endpoints: latency-svc-7vns2 [727.159826ms]
Dec  3 14:19:32.966: INFO: Created: latency-svc-rvn2n
Dec  3 14:19:32.982: INFO: Created: latency-svc-4fzs8
Dec  3 14:19:33.008: INFO: Got endpoints: latency-svc-qxck4 [739.500842ms]
Dec  3 14:19:33.016: INFO: Created: latency-svc-hbzvp
Dec  3 14:19:33.037: INFO: Created: latency-svc-77rt9
Dec  3 14:19:33.051: INFO: Got endpoints: latency-svc-m7t4j [750.293684ms]
Dec  3 14:19:33.072: INFO: Created: latency-svc-gfdgl
Dec  3 14:19:33.109: INFO: Got endpoints: latency-svc-dhz92 [758.799426ms]
Dec  3 14:19:33.126: INFO: Created: latency-svc-l48g9
Dec  3 14:19:33.163: INFO: Got endpoints: latency-svc-nz228 [759.50914ms]
Dec  3 14:19:33.163: INFO: Created: latency-svc-fjlm6
Dec  3 14:19:33.205: INFO: Created: latency-svc-7g9zf
Dec  3 14:19:33.207: INFO: Got endpoints: latency-svc-8pwt7 [753.374366ms]
Dec  3 14:19:33.232: INFO: Created: latency-svc-nmjwl
Dec  3 14:19:33.252: INFO: Created: latency-svc-9s5vg
Dec  3 14:19:33.252: INFO: Got endpoints: latency-svc-wl59p [746.312716ms]
Dec  3 14:19:33.277: INFO: Created: latency-svc-56j24
Dec  3 14:19:33.307: INFO: Got endpoints: latency-svc-d825f [744.10137ms]
Dec  3 14:19:33.334: INFO: Created: latency-svc-5xvjq
Dec  3 14:19:33.353: INFO: Got endpoints: latency-svc-7qn6r [711.512404ms]
Dec  3 14:19:33.385: INFO: Created: latency-svc-czdln
Dec  3 14:19:33.421: INFO: Got endpoints: latency-svc-2cx7c [768.530814ms]
Dec  3 14:19:33.453: INFO: Got endpoints: latency-svc-sdg4l [739.237374ms]
Dec  3 14:19:33.477: INFO: Created: latency-svc-6zrsh
Dec  3 14:19:33.504: INFO: Got endpoints: latency-svc-rvn2n [752.390496ms]
Dec  3 14:19:33.521: INFO: Created: latency-svc-55nc6
Dec  3 14:19:33.557: INFO: Got endpoints: latency-svc-4fzs8 [755.996688ms]
Dec  3 14:19:33.576: INFO: Created: latency-svc-99rsk
Dec  3 14:19:33.610: INFO: Created: latency-svc-vt5l4
Dec  3 14:19:33.610: INFO: Got endpoints: latency-svc-hbzvp [750.021604ms]
Dec  3 14:19:33.652: INFO: Created: latency-svc-t8c8w
Dec  3 14:19:33.654: INFO: Got endpoints: latency-svc-77rt9 [753.279336ms]
Dec  3 14:19:33.721: INFO: Got endpoints: latency-svc-gfdgl [765.963264ms]
Dec  3 14:19:33.739: INFO: Created: latency-svc-7xgb7
Dec  3 14:19:33.782: INFO: Got endpoints: latency-svc-l48g9 [774.095936ms]
Dec  3 14:19:33.812: INFO: Created: latency-svc-p62f4
Dec  3 14:19:33.833: INFO: Got endpoints: latency-svc-fjlm6 [782.386742ms]
Dec  3 14:19:33.858: INFO: Got endpoints: latency-svc-7g9zf [749.355902ms]
Dec  3 14:19:33.880: INFO: Created: latency-svc-x2f7h
Dec  3 14:19:33.927: INFO: Got endpoints: latency-svc-nmjwl [764.387644ms]
Dec  3 14:19:33.929: INFO: Created: latency-svc-8kgpz
Dec  3 14:19:33.954: INFO: Got endpoints: latency-svc-9s5vg [746.707264ms]
Dec  3 14:19:34.001: INFO: Created: latency-svc-8fwk4
Dec  3 14:19:34.004: INFO: Got endpoints: latency-svc-56j24 [751.851752ms]
Dec  3 14:19:34.053: INFO: Created: latency-svc-dswxc
Dec  3 14:19:34.055: INFO: Got endpoints: latency-svc-5xvjq [747.880396ms]
Dec  3 14:19:34.079: INFO: Created: latency-svc-ct89c
Dec  3 14:19:34.122: INFO: Got endpoints: latency-svc-czdln [769.124998ms]
Dec  3 14:19:34.124: INFO: Created: latency-svc-69f6k
Dec  3 14:19:34.158: INFO: Got endpoints: latency-svc-6zrsh [736.83643ms]
Dec  3 14:19:34.159: INFO: Created: latency-svc-5wgg5
Dec  3 14:19:34.229: INFO: Created: latency-svc-rk2br
Dec  3 14:19:34.356: INFO: Got endpoints: latency-svc-99rsk [850.906828ms]
Dec  3 14:19:34.357: INFO: Got endpoints: latency-svc-t8c8w [746.434558ms]
Dec  3 14:19:34.357: INFO: Got endpoints: latency-svc-55nc6 [903.28607ms]
Dec  3 14:19:34.358: INFO: Got endpoints: latency-svc-vt5l4 [800.402902ms]
Dec  3 14:19:34.402: INFO: Created: latency-svc-8cptz
Dec  3 14:19:34.414: INFO: Got endpoints: latency-svc-7xgb7 [759.685482ms]
Dec  3 14:19:34.431: INFO: Created: latency-svc-2pfj9
Dec  3 14:19:34.454: INFO: Got endpoints: latency-svc-p62f4 [733.0999ms]
Dec  3 14:19:34.473: INFO: Created: latency-svc-vvbf8
Dec  3 14:19:34.496: INFO: Created: latency-svc-w5prd
Dec  3 14:19:34.514: INFO: Got endpoints: latency-svc-x2f7h [732.229982ms]
Dec  3 14:19:34.533: INFO: Created: latency-svc-m48np
Dec  3 14:19:34.560: INFO: Got endpoints: latency-svc-8kgpz [701.772078ms]
Dec  3 14:19:34.564: INFO: Created: latency-svc-hvtr9
Dec  3 14:19:34.597: INFO: Created: latency-svc-fhdc6
Dec  3 14:19:34.611: INFO: Got endpoints: latency-svc-8fwk4 [777.654568ms]
Dec  3 14:19:34.629: INFO: Created: latency-svc-67gm5
Dec  3 14:19:34.658: INFO: Created: latency-svc-4bpl5
Dec  3 14:19:34.664: INFO: Got endpoints: latency-svc-dswxc [736.632082ms]
Dec  3 14:19:34.703: INFO: Created: latency-svc-s2hqz
Dec  3 14:19:34.709: INFO: Got endpoints: latency-svc-ct89c [754.864606ms]
Dec  3 14:19:34.735: INFO: Created: latency-svc-n9wc8
Dec  3 14:19:34.754: INFO: Got endpoints: latency-svc-69f6k [750.194406ms]
Dec  3 14:19:34.764: INFO: Created: latency-svc-8fg2n
Dec  3 14:19:34.809: INFO: Created: latency-svc-mgn7s
Dec  3 14:19:34.813: INFO: Got endpoints: latency-svc-5wgg5 [757.977104ms]
Dec  3 14:19:34.865: INFO: Got endpoints: latency-svc-rk2br [742.857384ms]
Dec  3 14:19:34.908: INFO: Created: latency-svc-5b7t4
Dec  3 14:19:34.917: INFO: Got endpoints: latency-svc-8cptz [758.796332ms]
Dec  3 14:19:34.944: INFO: Created: latency-svc-mzwfc
Dec  3 14:19:34.967: INFO: Got endpoints: latency-svc-2pfj9 [610.984816ms]
Dec  3 14:19:34.984: INFO: Created: latency-svc-h985h
Dec  3 14:19:35.032: INFO: Got endpoints: latency-svc-vvbf8 [674.91952ms]
Dec  3 14:19:35.035: INFO: Created: latency-svc-hfptr
Dec  3 14:19:35.051: INFO: Got endpoints: latency-svc-w5prd [694.025964ms]
Dec  3 14:19:35.071: INFO: Created: latency-svc-cmfkb
Dec  3 14:19:35.111: INFO: Got endpoints: latency-svc-m48np [753.831842ms]
Dec  3 14:19:35.115: INFO: Created: latency-svc-qqtbb
Dec  3 14:19:35.144: INFO: Created: latency-svc-2thkh
Dec  3 14:19:35.153: INFO: Got endpoints: latency-svc-hvtr9 [738.566256ms]
Dec  3 14:19:35.179: INFO: Created: latency-svc-8cj8b
Dec  3 14:19:35.203: INFO: Got endpoints: latency-svc-fhdc6 [749.081898ms]
Dec  3 14:19:35.236: INFO: Created: latency-svc-ssq7g
Dec  3 14:19:35.261: INFO: Got endpoints: latency-svc-67gm5 [746.708082ms]
Dec  3 14:19:35.324: INFO: Got endpoints: latency-svc-4bpl5 [762.994492ms]
Dec  3 14:19:35.325: INFO: Created: latency-svc-jqtw2
Dec  3 14:19:35.373: INFO: Got endpoints: latency-svc-s2hqz [762.309364ms]
Dec  3 14:19:35.377: INFO: Created: latency-svc-jc5zj
Dec  3 14:19:35.418: INFO: Got endpoints: latency-svc-n9wc8 [753.96681ms]
Dec  3 14:19:35.464: INFO: Got endpoints: latency-svc-8fg2n [755.003008ms]
Dec  3 14:19:35.485: INFO: Created: latency-svc-pnkvd
Dec  3 14:19:35.532: INFO: Got endpoints: latency-svc-mgn7s [777.816382ms]
Dec  3 14:19:35.597: INFO: Created: latency-svc-zj6sh
Dec  3 14:19:35.600: INFO: Got endpoints: latency-svc-5b7t4 [786.91429ms]
Dec  3 14:19:35.621: INFO: Got endpoints: latency-svc-mzwfc [756.274882ms]
Dec  3 14:19:35.627: INFO: Created: latency-svc-jq4zk
Dec  3 14:19:35.647: INFO: Created: latency-svc-tvz67
Dec  3 14:19:35.661: INFO: Got endpoints: latency-svc-h985h [743.991046ms]
Dec  3 14:19:35.696: INFO: Created: latency-svc-q8pmf
Dec  3 14:19:35.709: INFO: Got endpoints: latency-svc-hfptr [741.81025ms]
Dec  3 14:19:35.747: INFO: Created: latency-svc-b2xwq
Dec  3 14:19:35.757: INFO: Got endpoints: latency-svc-cmfkb [724.062092ms]
Dec  3 14:19:35.773: INFO: Created: latency-svc-jg88h
Dec  3 14:19:35.809: INFO: Got endpoints: latency-svc-qqtbb [757.63471ms]
Dec  3 14:19:35.816: INFO: Created: latency-svc-gfjng
Dec  3 14:19:35.838: INFO: Created: latency-svc-jfr7r
Dec  3 14:19:35.849: INFO: Got endpoints: latency-svc-2thkh [738.16753ms]
Dec  3 14:19:35.864: INFO: Created: latency-svc-g2f2n
Dec  3 14:19:35.879: INFO: Created: latency-svc-ww5xc
Dec  3 14:19:35.910: INFO: Got endpoints: latency-svc-8cj8b [756.635462ms]
Dec  3 14:19:35.939: INFO: Created: latency-svc-9qb6g
Dec  3 14:19:35.953: INFO: Got endpoints: latency-svc-ssq7g [749.986432ms]
Dec  3 14:19:35.977: INFO: Created: latency-svc-t46zm
Dec  3 14:19:36.004: INFO: Got endpoints: latency-svc-jqtw2 [742.894698ms]
Dec  3 14:19:36.033: INFO: Created: latency-svc-vj6f2
Dec  3 14:19:36.050: INFO: Got endpoints: latency-svc-jc5zj [725.378534ms]
Dec  3 14:19:36.075: INFO: Created: latency-svc-k4qhg
Dec  3 14:19:36.106: INFO: Got endpoints: latency-svc-pnkvd [732.117756ms]
Dec  3 14:19:36.130: INFO: Created: latency-svc-bs2rh
Dec  3 14:19:36.157: INFO: Got endpoints: latency-svc-zj6sh [738.54477ms]
Dec  3 14:19:36.189: INFO: Created: latency-svc-dtncv
Dec  3 14:19:36.203: INFO: Got endpoints: latency-svc-jq4zk [738.374492ms]
Dec  3 14:19:36.231: INFO: Created: latency-svc-h5pzj
Dec  3 14:19:36.251: INFO: Got endpoints: latency-svc-tvz67 [718.881448ms]
Dec  3 14:19:36.280: INFO: Created: latency-svc-ngmsg
Dec  3 14:19:36.304: INFO: Got endpoints: latency-svc-q8pmf [704.524242ms]
Dec  3 14:19:36.339: INFO: Created: latency-svc-h7r8k
Dec  3 14:19:36.350: INFO: Got endpoints: latency-svc-b2xwq [728.693302ms]
Dec  3 14:19:36.388: INFO: Created: latency-svc-pv4qw
Dec  3 14:19:36.402: INFO: Got endpoints: latency-svc-jg88h [740.464088ms]
Dec  3 14:19:36.419: INFO: Created: latency-svc-xwgvp
Dec  3 14:19:36.450: INFO: Got endpoints: latency-svc-gfjng [740.621362ms]
Dec  3 14:19:36.472: INFO: Created: latency-svc-jsld7
Dec  3 14:19:36.502: INFO: Got endpoints: latency-svc-jfr7r [745.468108ms]
Dec  3 14:19:36.522: INFO: Created: latency-svc-xxw6p
Dec  3 14:19:36.549: INFO: Got endpoints: latency-svc-g2f2n [739.418518ms]
Dec  3 14:19:36.568: INFO: Created: latency-svc-rw65x
Dec  3 14:19:36.619: INFO: Got endpoints: latency-svc-ww5xc [769.62835ms]
Dec  3 14:19:36.641: INFO: Created: latency-svc-hk4j9
Dec  3 14:19:36.650: INFO: Got endpoints: latency-svc-9qb6g [740.344974ms]
Dec  3 14:19:36.671: INFO: Created: latency-svc-8bpx9
Dec  3 14:19:36.700: INFO: Got endpoints: latency-svc-t46zm [745.963092ms]
Dec  3 14:19:36.738: INFO: Created: latency-svc-2qv4w
Dec  3 14:19:36.749: INFO: Got endpoints: latency-svc-vj6f2 [744.714854ms]
Dec  3 14:19:36.795: INFO: Created: latency-svc-btx77
Dec  3 14:19:36.804: INFO: Got endpoints: latency-svc-k4qhg [754.674786ms]
Dec  3 14:19:36.835: INFO: Created: latency-svc-x6vs6
Dec  3 14:19:36.853: INFO: Got endpoints: latency-svc-bs2rh [747.707842ms]
Dec  3 14:19:36.876: INFO: Created: latency-svc-4tkkt
Dec  3 14:19:36.901: INFO: Got endpoints: latency-svc-dtncv [743.406166ms]
Dec  3 14:19:36.925: INFO: Created: latency-svc-dz92g
Dec  3 14:19:36.950: INFO: Got endpoints: latency-svc-h5pzj [746.99526ms]
Dec  3 14:19:36.970: INFO: Created: latency-svc-b7bcj
Dec  3 14:19:37.001: INFO: Got endpoints: latency-svc-ngmsg [749.955642ms]
Dec  3 14:19:37.034: INFO: Created: latency-svc-w9d9z
Dec  3 14:19:37.052: INFO: Got endpoints: latency-svc-h7r8k [747.33452ms]
Dec  3 14:19:37.085: INFO: Created: latency-svc-m8cc7
Dec  3 14:19:37.108: INFO: Got endpoints: latency-svc-pv4qw [756.713322ms]
Dec  3 14:19:37.135: INFO: Created: latency-svc-gp4h5
Dec  3 14:19:37.154: INFO: Got endpoints: latency-svc-xwgvp [752.011218ms]
Dec  3 14:19:37.224: INFO: Got endpoints: latency-svc-jsld7 [774.59834ms]
Dec  3 14:19:37.236: INFO: Created: latency-svc-nlj4k
Dec  3 14:19:37.252: INFO: Got endpoints: latency-svc-xxw6p [750.051494ms]
Dec  3 14:19:37.278: INFO: Created: latency-svc-w4hqj
Dec  3 14:19:37.322: INFO: Got endpoints: latency-svc-rw65x [773.047358ms]
Dec  3 14:19:37.343: INFO: Created: latency-svc-rgj2m
Dec  3 14:19:37.357: INFO: Got endpoints: latency-svc-hk4j9 [738.064016ms]
Dec  3 14:19:37.378: INFO: Created: latency-svc-qwtx2
Dec  3 14:19:37.397: INFO: Created: latency-svc-jj7k4
Dec  3 14:19:37.403: INFO: Got endpoints: latency-svc-8bpx9 [752.775018ms]
Dec  3 14:19:37.450: INFO: Got endpoints: latency-svc-2qv4w [750.876892ms]
Dec  3 14:19:37.499: INFO: Got endpoints: latency-svc-btx77 [750.284706ms]
Dec  3 14:19:37.556: INFO: Got endpoints: latency-svc-x6vs6 [751.438156ms]
Dec  3 14:19:37.601: INFO: Got endpoints: latency-svc-4tkkt [747.317094ms]
Dec  3 14:19:37.649: INFO: Got endpoints: latency-svc-dz92g [748.30612ms]
Dec  3 14:19:37.701: INFO: Got endpoints: latency-svc-b7bcj [750.774522ms]
Dec  3 14:19:37.750: INFO: Got endpoints: latency-svc-w9d9z [749.03258ms]
Dec  3 14:19:37.821: INFO: Got endpoints: latency-svc-m8cc7 [768.830792ms]
Dec  3 14:19:37.852: INFO: Got endpoints: latency-svc-gp4h5 [744.736086ms]
Dec  3 14:19:37.913: INFO: Got endpoints: latency-svc-nlj4k [758.950248ms]
Dec  3 14:19:37.951: INFO: Got endpoints: latency-svc-w4hqj [726.150264ms]
Dec  3 14:19:38.012: INFO: Got endpoints: latency-svc-rgj2m [759.243706ms]
Dec  3 14:19:38.047: INFO: Got endpoints: latency-svc-qwtx2 [725.582548ms]
Dec  3 14:19:38.110: INFO: Got endpoints: latency-svc-jj7k4 [753.30125ms]
Dec  3 14:19:38.110: INFO: Latencies: [49.052594ms 82.63557ms 88.586292ms 165.542496ms 193.023672ms 252.649854ms 314.124902ms 356.402058ms 363.459348ms 366.018982ms 367.525686ms 369.388868ms 371.616538ms 373.225238ms 378.443484ms 378.486806ms 380.413228ms 381.332936ms 382.045618ms 383.954296ms 384.524208ms 384.824771ms 386.807ms 387.16835ms 388.402048ms 391.687113ms 397.051542ms 399.259581ms 403.079646ms 406.813451ms 409.254377ms 419.474707ms 422.844354ms 426.925614ms 427.265386ms 432.84754ms 433.527721ms 434.861418ms 437.566282ms 439.326868ms 441.387408ms 441.638191ms 444.794174ms 446.44244ms 446.868014ms 447.880212ms 449.222334ms 449.361888ms 450.039141ms 451.292238ms 452.861646ms 454.088784ms 454.41994ms 457.893798ms 470.538224ms 473.143808ms 484.984574ms 504.06665ms 509.282306ms 522.164457ms 529.08726ms 536.156262ms 541.532816ms 545.28261ms 547.658136ms 553.887116ms 557.839356ms 559.159182ms 566.288914ms 570.431146ms 573.545452ms 580.861272ms 584.853028ms 596.588475ms 596.738312ms 598.937208ms 601.62299ms 601.995998ms 606.734146ms 609.562364ms 610.984816ms 616.537232ms 616.555422ms 631.773738ms 641.308548ms 652.799816ms 671.946906ms 672.606358ms 674.91952ms 691.185522ms 694.025964ms 701.772078ms 704.524242ms 711.512404ms 718.881448ms 719.788193ms 724.062092ms 725.155509ms 725.378534ms 725.582548ms 726.150264ms 727.159826ms 728.693302ms 732.117756ms 732.229982ms 733.0999ms 736.632082ms 736.83643ms 738.064016ms 738.16753ms 738.374492ms 738.54477ms 738.566256ms 739.237374ms 739.418518ms 739.500842ms 740.344974ms 740.464088ms 740.621362ms 741.81025ms 742.524468ms 742.857384ms 742.894698ms 743.406166ms 743.991046ms 744.10137ms 744.714854ms 744.736086ms 745.468108ms 745.963092ms 746.312716ms 746.434558ms 746.707264ms 746.708082ms 746.99526ms 747.317094ms 747.33452ms 747.707842ms 747.880396ms 748.30612ms 749.03258ms 749.081898ms 749.355902ms 749.955642ms 749.986432ms 750.021604ms 750.051494ms 750.194406ms 750.284706ms 750.293684ms 750.512949ms 750.774522ms 750.876892ms 751.254446ms 751.438156ms 751.851752ms 752.011218ms 752.390496ms 752.775018ms 753.279336ms 753.30125ms 753.374366ms 753.831842ms 753.96681ms 754.674786ms 754.864606ms 755.003008ms 755.996688ms 756.274882ms 756.635462ms 756.713322ms 757.63471ms 757.977104ms 758.796332ms 758.799426ms 758.950248ms 759.243706ms 759.50914ms 759.685482ms 762.309364ms 762.994492ms 764.387644ms 765.963264ms 768.530814ms 768.830792ms 769.124998ms 769.62835ms 772.253131ms 773.047358ms 774.095936ms 774.59834ms 777.654568ms 777.816382ms 782.386742ms 786.91429ms 797.15416ms 800.402902ms 818.09256ms 850.906828ms 903.28607ms]
Dec  3 14:19:38.110: INFO: 50 %ile: 726.150264ms
Dec  3 14:19:38.110: INFO: 90 %ile: 762.994492ms
Dec  3 14:19:38.110: INFO: 99 %ile: 850.906828ms
Dec  3 14:19:38.110: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:19:38.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-5l7g2" for this suite.
Dec  3 14:20:02.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:20:02.307: INFO: namespace: e2e-tests-svc-latency-5l7g2, resource: bindings, ignored listing per whitelist
Dec  3 14:20:02.420: INFO: namespace e2e-tests-svc-latency-5l7g2 deletion completed in 24.302531861s

• [SLOW TEST:36.503 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:20:02.421: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-ssznx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:20:02.767: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  3 14:20:07.782: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 14:20:07.783: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 14:20:07.906: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-ssznx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ssznx/deployments/test-cleanup-deployment,UID:80d94e6b-f706-11e8-849a-005056852a45,ResourceVersion:93836,Generation:1,CreationTimestamp:2018-12-03 14:19:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 14:20:07.928: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec  3 14:20:07.928: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec  3 14:20:07.929: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-ssznx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ssznx/replicasets/test-cleanup-controller,UID:7dd2ce4a-f706-11e8-849a-005056852a45,ResourceVersion:93837,Generation:1,CreationTimestamp:2018-12-03 14:19:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 80d94e6b-f706-11e8-849a-005056852a45 0xc420942517 0xc420942518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 14:20:07.944: INFO: Pod "test-cleanup-controller-pn6nl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-pn6nl,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-ssznx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ssznx/pods/test-cleanup-controller-pn6nl,UID:7dd930a2-f706-11e8-849a-005056852a45,ResourceVersion:93831,Generation:0,CreationTimestamp:2018-12-03 14:19:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 7dd2ce4a-f706-11e8-849a-005056852a45 0xc421b4d1d7 0xc421b4d1d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cmn4s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cmn4s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cmn4s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b4d250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b4d270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:20:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:20:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:20:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:19:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:172.31.140.117,StartTime:2018-12-03 14:20:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 14:20:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://ee34243f66197402ae0123da052b59073359201d8645a7040d4c70d21c3f3e57}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:20:07.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ssznx" for this suite.
Dec  3 14:20:16.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:20:16.347: INFO: namespace: e2e-tests-deployment-ssznx, resource: bindings, ignored listing per whitelist
Dec  3 14:20:16.379: INFO: namespace e2e-tests-deployment-ssznx deletion completed in 8.323569192s

• [SLOW TEST:13.958 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:20:16.379: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vsjpl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-hnw4t
STEP: Creating secret with name secret-test-8e7c9695-f706-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:20:16.947: INFO: Waiting up to 5m0s for pod "pod-secrets-8e9ba460-f706-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-vsjpl" to be "success or failure"
Dec  3 14:20:16.959: INFO: Pod "pod-secrets-8e9ba460-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.275087ms
Dec  3 14:20:18.976: INFO: Pod "pod-secrets-8e9ba460-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0292118s
Dec  3 14:20:20.984: INFO: Pod "pod-secrets-8e9ba460-f706-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037756813s
STEP: Saw pod success
Dec  3 14:20:20.985: INFO: Pod "pod-secrets-8e9ba460-f706-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:20:20.994: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-8e9ba460-f706-11e8-a394-16db9a3896d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:20:21.040: INFO: Waiting for pod pod-secrets-8e9ba460-f706-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:20:21.049: INFO: Pod pod-secrets-8e9ba460-f706-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:20:21.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vsjpl" for this suite.
Dec  3 14:20:27.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:20:27.143: INFO: namespace: e2e-tests-secrets-vsjpl, resource: bindings, ignored listing per whitelist
Dec  3 14:20:27.389: INFO: namespace e2e-tests-secrets-vsjpl deletion completed in 6.327429251s
STEP: Destroying namespace "e2e-tests-secret-namespace-hnw4t" for this suite.
Dec  3 14:20:33.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:20:33.544: INFO: namespace: e2e-tests-secret-namespace-hnw4t, resource: bindings, ignored listing per whitelist
Dec  3 14:20:33.633: INFO: namespace e2e-tests-secret-namespace-hnw4t deletion completed in 6.244188026s

• [SLOW TEST:17.254 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:20:33.633: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-2gq4z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:20:33.932: INFO: (0) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.61649ms)
Dec  3 14:20:33.942: INFO: (1) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.592626ms)
Dec  3 14:20:33.950: INFO: (2) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.148556ms)
Dec  3 14:20:33.957: INFO: (3) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.41359ms)
Dec  3 14:20:33.966: INFO: (4) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.519878ms)
Dec  3 14:20:33.973: INFO: (5) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.440662ms)
Dec  3 14:20:33.991: INFO: (6) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 17.302604ms)
Dec  3 14:20:34.004: INFO: (7) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.747448ms)
Dec  3 14:20:34.012: INFO: (8) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.500702ms)
Dec  3 14:20:34.021: INFO: (9) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.361854ms)
Dec  3 14:20:34.029: INFO: (10) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.683882ms)
Dec  3 14:20:34.035: INFO: (11) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.229214ms)
Dec  3 14:20:34.042: INFO: (12) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.722578ms)
Dec  3 14:20:34.050: INFO: (13) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.577958ms)
Dec  3 14:20:34.059: INFO: (14) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.146222ms)
Dec  3 14:20:34.066: INFO: (15) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.627224ms)
Dec  3 14:20:34.074: INFO: (16) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.570308ms)
Dec  3 14:20:34.087: INFO: (17) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.009738ms)
Dec  3 14:20:34.097: INFO: (18) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.764492ms)
Dec  3 14:20:34.105: INFO: (19) /api/v1/nodes/k8s-master-3:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.61138ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:20:34.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2gq4z" for this suite.
Dec  3 14:20:40.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:20:40.172: INFO: namespace: e2e-tests-proxy-2gq4z, resource: bindings, ignored listing per whitelist
Dec  3 14:20:40.400: INFO: namespace e2e-tests-proxy-2gq4z deletion completed in 6.289392237s

• [SLOW TEST:6.767 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:20:40.401: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zhnvk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:20:40.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9cd21494-f706-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-zhnvk" to be "success or failure"
Dec  3 14:20:40.838: INFO: Pod "downwardapi-volume-9cd21494-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 22.949295ms
Dec  3 14:20:42.845: INFO: Pod "downwardapi-volume-9cd21494-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029852246s
Dec  3 14:20:44.852: INFO: Pod "downwardapi-volume-9cd21494-f706-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036746736s
STEP: Saw pod success
Dec  3 14:20:44.852: INFO: Pod "downwardapi-volume-9cd21494-f706-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:20:44.857: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-9cd21494-f706-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:20:44.910: INFO: Waiting for pod downwardapi-volume-9cd21494-f706-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:20:44.921: INFO: Pod downwardapi-volume-9cd21494-f706-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:20:44.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zhnvk" for this suite.
Dec  3 14:20:50.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:20:50.992: INFO: namespace: e2e-tests-downward-api-zhnvk, resource: bindings, ignored listing per whitelist
Dec  3 14:20:51.184: INFO: namespace e2e-tests-downward-api-zhnvk deletion completed in 6.252545848s

• [SLOW TEST:10.784 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:20:51.185: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tp92r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  3 14:20:51.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:52.197: INFO: stderr: ""
Dec  3 14:20:52.197: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:20:52.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:52.414: INFO: stderr: ""
Dec  3 14:20:52.414: INFO: stdout: "update-demo-nautilus-6gzcj update-demo-nautilus-6kbbl "
Dec  3 14:20:52.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-6gzcj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:52.645: INFO: stderr: ""
Dec  3 14:20:52.645: INFO: stdout: ""
Dec  3 14:20:52.645: INFO: update-demo-nautilus-6gzcj is created but not running
Dec  3 14:20:57.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:57.877: INFO: stderr: ""
Dec  3 14:20:57.878: INFO: stdout: "update-demo-nautilus-6gzcj update-demo-nautilus-6kbbl "
Dec  3 14:20:57.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-6gzcj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:58.055: INFO: stderr: ""
Dec  3 14:20:58.055: INFO: stdout: "true"
Dec  3 14:20:58.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-6gzcj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:58.268: INFO: stderr: ""
Dec  3 14:20:58.268: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:20:58.268: INFO: validating pod update-demo-nautilus-6gzcj
Dec  3 14:20:58.278: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:20:58.278: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:20:58.278: INFO: update-demo-nautilus-6gzcj is verified up and running
Dec  3 14:20:58.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-6kbbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:58.512: INFO: stderr: ""
Dec  3 14:20:58.512: INFO: stdout: "true"
Dec  3 14:20:58.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-6kbbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:58.750: INFO: stderr: ""
Dec  3 14:20:58.750: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:20:58.750: INFO: validating pod update-demo-nautilus-6kbbl
Dec  3 14:20:58.760: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:20:58.760: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:20:58.760: INFO: update-demo-nautilus-6kbbl is verified up and running
STEP: using delete to clean up resources
Dec  3 14:20:58.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:58.964: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:20:58.964: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 14:20:58.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-tp92r'
Dec  3 14:20:59.199: INFO: stderr: "No resources found.\n"
Dec  3 14:20:59.199: INFO: stdout: ""
Dec  3 14:20:59.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -l name=update-demo --namespace=e2e-tests-kubectl-tp92r -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 14:20:59.421: INFO: stderr: ""
Dec  3 14:20:59.422: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:20:59.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tp92r" for this suite.
Dec  3 14:21:23.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:21:23.482: INFO: namespace: e2e-tests-kubectl-tp92r, resource: bindings, ignored listing per whitelist
Dec  3 14:21:23.747: INFO: namespace e2e-tests-kubectl-tp92r deletion completed in 24.315855662s

• [SLOW TEST:32.562 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:21:23.747: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fbw82
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b69b1432-f706-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:21:24.049: INFO: Waiting up to 5m0s for pod "pod-secrets-b69c6785-f706-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-fbw82" to be "success or failure"
Dec  3 14:21:24.061: INFO: Pod "pod-secrets-b69c6785-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.574088ms
Dec  3 14:21:26.078: INFO: Pod "pod-secrets-b69c6785-f706-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02872953s
Dec  3 14:21:28.084: INFO: Pod "pod-secrets-b69c6785-f706-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034071092s
STEP: Saw pod success
Dec  3 14:21:28.084: INFO: Pod "pod-secrets-b69c6785-f706-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:21:28.088: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-b69c6785-f706-11e8-a394-16db9a3896d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:21:28.139: INFO: Waiting for pod pod-secrets-b69c6785-f706-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:21:28.149: INFO: Pod pod-secrets-b69c6785-f706-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:21:28.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fbw82" for this suite.
Dec  3 14:21:34.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:21:34.404: INFO: namespace: e2e-tests-secrets-fbw82, resource: bindings, ignored listing per whitelist
Dec  3 14:21:34.458: INFO: namespace e2e-tests-secrets-fbw82 deletion completed in 6.293591062s

• [SLOW TEST:10.711 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:21:34.459: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-d2pgj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:21:34.788: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b4ab2cd2-f706-11e8-849a-005056852a45", Controller:(*bool)(0xc4221c72be), BlockOwnerDeletion:(*bool)(0xc4221c72bf)}}
Dec  3 14:21:34.801: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b4a8866d-f706-11e8-849a-005056852a45", Controller:(*bool)(0xc420dcc1a6), BlockOwnerDeletion:(*bool)(0xc420dcc1a7)}}
Dec  3 14:21:34.815: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b4a9adbc-f706-11e8-849a-005056852a45", Controller:(*bool)(0xc420dcc3e6), BlockOwnerDeletion:(*bool)(0xc420dcc3e7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:21:39.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-d2pgj" for this suite.
Dec  3 14:21:45.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:21:45.932: INFO: namespace: e2e-tests-gc-d2pgj, resource: bindings, ignored listing per whitelist
Dec  3 14:21:45.996: INFO: namespace e2e-tests-gc-d2pgj deletion completed in 6.159885706s

• [SLOW TEST:11.537 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:21:45.996: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-xd7rx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-xd7rx.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-xd7rx.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xd7rx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-xd7rx.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-xd7rx.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xd7rx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 14:22:22.432: INFO: DNS probes using e2e-tests-dns-xd7rx/dns-test-c3d99a1e-f706-11e8-a394-16db9a3896d3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:22:22.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-xd7rx" for this suite.
Dec  3 14:22:28.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:22:28.516: INFO: namespace: e2e-tests-dns-xd7rx, resource: bindings, ignored listing per whitelist
Dec  3 14:22:28.698: INFO: namespace e2e-tests-dns-xd7rx deletion completed in 6.237450646s

• [SLOW TEST:42.702 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:22:28.698: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-lh8kf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:23:29.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lh8kf" for this suite.
Dec  3 14:23:51.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:23:51.069: INFO: namespace: e2e-tests-container-probe-lh8kf, resource: bindings, ignored listing per whitelist
Dec  3 14:23:51.228: INFO: namespace e2e-tests-container-probe-lh8kf deletion completed in 22.207985012s

• [SLOW TEST:82.530 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:23:51.228: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7c8qb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:23:51.522: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e82640a-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-7c8qb" to be "success or failure"
Dec  3 14:23:51.534: INFO: Pod "downwardapi-volume-0e82640a-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.414142ms
Dec  3 14:23:53.544: INFO: Pod "downwardapi-volume-0e82640a-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022402332s
Dec  3 14:23:55.555: INFO: Pod "downwardapi-volume-0e82640a-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03335806s
STEP: Saw pod success
Dec  3 14:23:55.555: INFO: Pod "downwardapi-volume-0e82640a-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:23:55.566: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-0e82640a-f707-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:23:55.621: INFO: Waiting for pod downwardapi-volume-0e82640a-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:23:55.630: INFO: Pod downwardapi-volume-0e82640a-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:23:55.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7c8qb" for this suite.
Dec  3 14:24:01.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:24:01.750: INFO: namespace: e2e-tests-downward-api-7c8qb, resource: bindings, ignored listing per whitelist
Dec  3 14:24:01.865: INFO: namespace e2e-tests-downward-api-7c8qb deletion completed in 6.22587237s

• [SLOW TEST:10.637 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:24:01.865: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bm7w5
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  3 14:24:02.121: INFO: Waiting up to 5m0s for pod "pod-14d405c3-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-bm7w5" to be "success or failure"
Dec  3 14:24:02.130: INFO: Pod "pod-14d405c3-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.635422ms
Dec  3 14:24:04.147: INFO: Pod "pod-14d405c3-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025888154s
Dec  3 14:24:06.154: INFO: Pod "pod-14d405c3-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033064568s
STEP: Saw pod success
Dec  3 14:24:06.154: INFO: Pod "pod-14d405c3-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:24:06.160: INFO: Trying to get logs from node k8s-master-3 pod pod-14d405c3-f707-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:24:06.241: INFO: Waiting for pod pod-14d405c3-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:24:06.248: INFO: Pod pod-14d405c3-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:24:06.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bm7w5" for this suite.
Dec  3 14:24:12.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:24:12.327: INFO: namespace: e2e-tests-emptydir-bm7w5, resource: bindings, ignored listing per whitelist
Dec  3 14:24:12.436: INFO: namespace e2e-tests-emptydir-bm7w5 deletion completed in 6.181098254s

• [SLOW TEST:10.570 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:24:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-8bdht
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  3 14:24:12.677: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:24:17.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8bdht" for this suite.
Dec  3 14:24:39.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:24:39.128: INFO: namespace: e2e-tests-init-container-8bdht, resource: bindings, ignored listing per whitelist
Dec  3 14:24:39.308: INFO: namespace e2e-tests-init-container-8bdht deletion completed in 22.282232496s

• [SLOW TEST:26.872 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:24:39.309: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-8smqz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8smqz
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-8smqz
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-8smqz
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-8smqz
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-8smqz
Dec  3 14:24:43.804: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8smqz, name: ss-0, uid: 2557fd42-f707-11e8-849a-005056852a45, status phase: Pending. Waiting for statefulset controller to delete.
Dec  3 14:24:44.364: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8smqz, name: ss-0, uid: 2557fd42-f707-11e8-849a-005056852a45, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 14:24:44.378: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8smqz, name: ss-0, uid: 2557fd42-f707-11e8-849a-005056852a45, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 14:24:44.384: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-8smqz
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-8smqz
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-8smqz and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 14:24:48.428: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8smqz
Dec  3 14:24:48.437: INFO: Scaling statefulset ss to 0
Dec  3 14:25:08.471: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 14:25:08.480: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:25:08.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8smqz" for this suite.
Dec  3 14:25:14.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:25:14.677: INFO: namespace: e2e-tests-statefulset-8smqz, resource: bindings, ignored listing per whitelist
Dec  3 14:25:14.757: INFO: namespace e2e-tests-statefulset-8smqz deletion completed in 6.231222504s

• [SLOW TEST:35.448 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:25:14.757: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wmr2x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 14:25:15.032: INFO: Waiting up to 5m0s for pod "pod-40496e09-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-wmr2x" to be "success or failure"
Dec  3 14:25:15.049: INFO: Pod "pod-40496e09-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.738414ms
Dec  3 14:25:17.057: INFO: Pod "pod-40496e09-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024234563s
Dec  3 14:25:19.064: INFO: Pod "pod-40496e09-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031362349s
STEP: Saw pod success
Dec  3 14:25:19.064: INFO: Pod "pod-40496e09-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:25:19.069: INFO: Trying to get logs from node k8s-master-3 pod pod-40496e09-f707-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:25:19.143: INFO: Waiting for pod pod-40496e09-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:25:19.156: INFO: Pod pod-40496e09-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:25:19.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wmr2x" for this suite.
Dec  3 14:25:25.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:25:25.327: INFO: namespace: e2e-tests-emptydir-wmr2x, resource: bindings, ignored listing per whitelist
Dec  3 14:25:25.459: INFO: namespace e2e-tests-emptydir-wmr2x deletion completed in 6.292533902s

• [SLOW TEST:10.702 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:25:25.460: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-tbjj2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  3 14:25:26.334: INFO: Waiting up to 5m0s for pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-25g7t" in namespace "e2e-tests-svcaccounts-tbjj2" to be "success or failure"
Dec  3 14:25:26.345: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-25g7t": Phase="Pending", Reason="", readiness=false. Elapsed: 10.477715ms
Dec  3 14:25:28.352: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-25g7t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01766293s
Dec  3 14:25:30.357: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-25g7t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02303408s
STEP: Saw pod success
Dec  3 14:25:30.357: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-25g7t" satisfied condition "success or failure"
Dec  3 14:25:30.363: INFO: Trying to get logs from node k8s-node-2 pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-25g7t container token-test: <nil>
STEP: delete the pod
Dec  3 14:25:30.418: INFO: Waiting for pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-25g7t to disappear
Dec  3 14:25:30.425: INFO: Pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-25g7t no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  3 14:25:30.433: INFO: Waiting up to 5m0s for pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-kbddb" in namespace "e2e-tests-svcaccounts-tbjj2" to be "success or failure"
Dec  3 14:25:30.440: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-kbddb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.119657ms
Dec  3 14:25:32.446: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-kbddb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013221595s
Dec  3 14:25:34.453: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-kbddb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019635154s
STEP: Saw pod success
Dec  3 14:25:34.453: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-kbddb" satisfied condition "success or failure"
Dec  3 14:25:34.465: INFO: Trying to get logs from node k8s-master-3 pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-kbddb container root-ca-test: <nil>
STEP: delete the pod
Dec  3 14:25:34.538: INFO: Waiting for pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-kbddb to disappear
Dec  3 14:25:34.550: INFO: Pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-kbddb no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  3 14:25:34.567: INFO: Waiting up to 5m0s for pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb" in namespace "e2e-tests-svcaccounts-tbjj2" to be "success or failure"
Dec  3 14:25:34.582: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 15.071402ms
Dec  3 14:25:36.590: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023116582s
Dec  3 14:25:38.604: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036595479s
Dec  3 14:25:40.612: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045042574s
STEP: Saw pod success
Dec  3 14:25:40.612: INFO: Pod "pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb" satisfied condition "success or failure"
Dec  3 14:25:40.618: INFO: Trying to get logs from node k8s-node-2 pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb container namespace-test: <nil>
STEP: delete the pod
Dec  3 14:25:40.681: INFO: Waiting for pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb to disappear
Dec  3 14:25:40.690: INFO: Pod pod-service-account-4705f048-f707-11e8-a394-16db9a3896d3-9zbdb no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:25:40.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-tbjj2" for this suite.
Dec  3 14:25:46.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:25:46.886: INFO: namespace: e2e-tests-svcaccounts-tbjj2, resource: bindings, ignored listing per whitelist
Dec  3 14:25:46.920: INFO: namespace e2e-tests-svcaccounts-tbjj2 deletion completed in 6.221747518s

• [SLOW TEST:21.461 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:25:46.921: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-fm55c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 14:25:47.224: INFO: Waiting up to 5m0s for pod "pod-53797a43-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-fm55c" to be "success or failure"
Dec  3 14:25:47.228: INFO: Pod "pod-53797a43-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.575586ms
Dec  3 14:25:49.234: INFO: Pod "pod-53797a43-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010513804s
Dec  3 14:25:51.241: INFO: Pod "pod-53797a43-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017237189s
STEP: Saw pod success
Dec  3 14:25:51.241: INFO: Pod "pod-53797a43-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:25:51.246: INFO: Trying to get logs from node k8s-node-2 pod pod-53797a43-f707-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:25:51.340: INFO: Waiting for pod pod-53797a43-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:25:51.346: INFO: Pod pod-53797a43-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:25:51.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fm55c" for this suite.
Dec  3 14:25:57.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:25:57.458: INFO: namespace: e2e-tests-emptydir-fm55c, resource: bindings, ignored listing per whitelist
Dec  3 14:25:57.602: INFO: namespace e2e-tests-emptydir-fm55c deletion completed in 6.249428581s

• [SLOW TEST:10.681 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:25:57.602: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cmjpl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 14:25:57.909: INFO: Waiting up to 5m0s for pod "pod-59d766cb-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-cmjpl" to be "success or failure"
Dec  3 14:25:57.916: INFO: Pod "pod-59d766cb-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.312132ms
Dec  3 14:25:59.928: INFO: Pod "pod-59d766cb-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019231498s
Dec  3 14:26:01.935: INFO: Pod "pod-59d766cb-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025757011s
STEP: Saw pod success
Dec  3 14:26:01.935: INFO: Pod "pod-59d766cb-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:26:01.941: INFO: Trying to get logs from node k8s-node-2 pod pod-59d766cb-f707-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:26:01.979: INFO: Waiting for pod pod-59d766cb-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:26:01.990: INFO: Pod pod-59d766cb-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:26:01.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cmjpl" for this suite.
Dec  3 14:26:08.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:26:08.118: INFO: namespace: e2e-tests-emptydir-cmjpl, resource: bindings, ignored listing per whitelist
Dec  3 14:26:08.275: INFO: namespace e2e-tests-emptydir-cmjpl deletion completed in 6.273189583s

• [SLOW TEST:10.673 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:26:08.275: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7z6wr
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  3 14:26:08.742: INFO: Waiting up to 5m0s for pod "pod-604a74e9-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-7z6wr" to be "success or failure"
Dec  3 14:26:08.753: INFO: Pod "pod-604a74e9-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.500586ms
Dec  3 14:26:10.765: INFO: Pod "pod-604a74e9-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022818252s
Dec  3 14:26:12.773: INFO: Pod "pod-604a74e9-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030386961s
STEP: Saw pod success
Dec  3 14:26:12.773: INFO: Pod "pod-604a74e9-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:26:12.781: INFO: Trying to get logs from node k8s-master-3 pod pod-604a74e9-f707-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:26:12.898: INFO: Waiting for pod pod-604a74e9-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:26:12.908: INFO: Pod pod-604a74e9-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:26:12.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7z6wr" for this suite.
Dec  3 14:26:18.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:26:19.179: INFO: namespace: e2e-tests-emptydir-7z6wr, resource: bindings, ignored listing per whitelist
Dec  3 14:26:19.249: INFO: namespace e2e-tests-emptydir-7z6wr deletion completed in 6.330188035s

• [SLOW TEST:10.974 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:26:19.250: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-c55mn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  3 14:26:24.216: INFO: Successfully updated pod "annotationupdate66c15a5e-f707-11e8-a394-16db9a3896d3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:26:26.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c55mn" for this suite.
Dec  3 14:26:48.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:26:48.492: INFO: namespace: e2e-tests-downward-api-c55mn, resource: bindings, ignored listing per whitelist
Dec  3 14:26:48.632: INFO: namespace e2e-tests-downward-api-c55mn deletion completed in 22.330735964s

• [SLOW TEST:29.382 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:26:48.633: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zq9fx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-78425a56-f707-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 14:26:48.962: INFO: Waiting up to 5m0s for pod "pod-configmaps-78441f21-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-zq9fx" to be "success or failure"
Dec  3 14:26:48.990: INFO: Pod "pod-configmaps-78441f21-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 27.608937ms
Dec  3 14:26:50.996: INFO: Pod "pod-configmaps-78441f21-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033168236s
Dec  3 14:26:53.009: INFO: Pod "pod-configmaps-78441f21-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046485992s
STEP: Saw pod success
Dec  3 14:26:53.009: INFO: Pod "pod-configmaps-78441f21-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:26:53.018: INFO: Trying to get logs from node k8s-master-3 pod pod-configmaps-78441f21-f707-11e8-a394-16db9a3896d3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:26:53.285: INFO: Waiting for pod pod-configmaps-78441f21-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:26:53.300: INFO: Pod pod-configmaps-78441f21-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:26:53.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zq9fx" for this suite.
Dec  3 14:26:59.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:26:59.450: INFO: namespace: e2e-tests-configmap-zq9fx, resource: bindings, ignored listing per whitelist
Dec  3 14:26:59.538: INFO: namespace e2e-tests-configmap-zq9fx deletion completed in 6.226755133s

• [SLOW TEST:10.905 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:26:59.539: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pxhqm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:26:59.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ecd3b8e-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-pxhqm" to be "success or failure"
Dec  3 14:26:59.931: INFO: Pod "downwardapi-volume-7ecd3b8e-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.392278ms
Dec  3 14:27:01.940: INFO: Pod "downwardapi-volume-7ecd3b8e-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022401071s
Dec  3 14:27:03.952: INFO: Pod "downwardapi-volume-7ecd3b8e-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034546607s
STEP: Saw pod success
Dec  3 14:27:03.952: INFO: Pod "downwardapi-volume-7ecd3b8e-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:27:03.957: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-7ecd3b8e-f707-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:27:04.026: INFO: Waiting for pod downwardapi-volume-7ecd3b8e-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:27:04.036: INFO: Pod downwardapi-volume-7ecd3b8e-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:27:04.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pxhqm" for this suite.
Dec  3 14:27:10.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:27:10.108: INFO: namespace: e2e-tests-projected-pxhqm, resource: bindings, ignored listing per whitelist
Dec  3 14:27:10.326: INFO: namespace e2e-tests-projected-pxhqm deletion completed in 6.276300752s

• [SLOW TEST:10.787 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:27:10.326: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dvmm2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:27:10.647: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8531b6b9-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-dvmm2" to be "success or failure"
Dec  3 14:27:10.653: INFO: Pod "downwardapi-volume-8531b6b9-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.995142ms
Dec  3 14:27:12.660: INFO: Pod "downwardapi-volume-8531b6b9-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012587524s
Dec  3 14:27:14.671: INFO: Pod "downwardapi-volume-8531b6b9-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02369517s
STEP: Saw pod success
Dec  3 14:27:14.671: INFO: Pod "downwardapi-volume-8531b6b9-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:27:14.699: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-8531b6b9-f707-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:27:14.964: INFO: Waiting for pod downwardapi-volume-8531b6b9-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:27:14.972: INFO: Pod downwardapi-volume-8531b6b9-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:27:14.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dvmm2" for this suite.
Dec  3 14:27:21.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:27:21.115: INFO: namespace: e2e-tests-projected-dvmm2, resource: bindings, ignored listing per whitelist
Dec  3 14:27:21.274: INFO: namespace e2e-tests-projected-dvmm2 deletion completed in 6.291313702s

• [SLOW TEST:10.947 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:27:21.274: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-ldnnm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 14:27:29.704: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:29.713: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:31.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:31.720: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:33.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:33.721: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:35.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:35.722: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:37.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:37.719: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:39.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:39.727: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:41.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:41.721: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:43.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:43.720: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:45.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:45.742: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:47.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:47.719: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:49.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:49.722: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:51.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:51.720: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:27:53.714: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:27:53.720: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:27:53.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ldnnm" for this suite.
Dec  3 14:28:17.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:28:17.951: INFO: namespace: e2e-tests-container-lifecycle-hook-ldnnm, resource: bindings, ignored listing per whitelist
Dec  3 14:28:18.006: INFO: namespace e2e-tests-container-lifecycle-hook-ldnnm deletion completed in 24.254592649s

• [SLOW TEST:56.732 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:28:18.006: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-rqp8z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  3 14:28:26.378: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:26.378: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:26.514: INFO: Exec stderr: ""
Dec  3 14:28:26.514: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:26.514: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:26.657: INFO: Exec stderr: ""
Dec  3 14:28:26.657: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:26.657: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:26.812: INFO: Exec stderr: ""
Dec  3 14:28:26.812: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:26.812: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:26.992: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  3 14:28:26.992: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:26.992: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:27.130: INFO: Exec stderr: ""
Dec  3 14:28:27.131: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:27.131: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:27.254: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  3 14:28:27.254: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:27.254: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:27.388: INFO: Exec stderr: ""
Dec  3 14:28:27.389: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:27.389: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:27.504: INFO: Exec stderr: ""
Dec  3 14:28:27.504: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:27.504: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:27.650: INFO: Exec stderr: ""
Dec  3 14:28:27.650: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqp8z PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:28:27.650: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:28:27.772: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:28:27.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-rqp8z" for this suite.
Dec  3 14:29:19.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:29:20.048: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-rqp8z, resource: bindings, ignored listing per whitelist
Dec  3 14:29:20.098: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-rqp8z deletion completed in 52.319012762s

• [SLOW TEST:62.092 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:29:20.098: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vnznz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-d2924052-f707-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:29:20.475: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d2936f15-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-vnznz" to be "success or failure"
Dec  3 14:29:20.487: INFO: Pod "pod-projected-secrets-d2936f15-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.394366ms
Dec  3 14:29:22.493: INFO: Pod "pod-projected-secrets-d2936f15-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017257098s
Dec  3 14:29:24.504: INFO: Pod "pod-projected-secrets-d2936f15-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028053374s
STEP: Saw pod success
Dec  3 14:29:24.504: INFO: Pod "pod-projected-secrets-d2936f15-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:29:24.511: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-secrets-d2936f15-f707-11e8-a394-16db9a3896d3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:29:24.570: INFO: Waiting for pod pod-projected-secrets-d2936f15-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:29:24.594: INFO: Pod pod-projected-secrets-d2936f15-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:29:24.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vnznz" for this suite.
Dec  3 14:29:30.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:29:30.762: INFO: namespace: e2e-tests-projected-vnznz, resource: bindings, ignored listing per whitelist
Dec  3 14:29:30.879: INFO: namespace e2e-tests-projected-vnznz deletion completed in 6.272778306s

• [SLOW TEST:10.781 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:29:30.879: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4tv9b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 14:29:31.229: INFO: Waiting up to 5m0s for pod "downward-api-d8fdfe72-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-4tv9b" to be "success or failure"
Dec  3 14:29:31.241: INFO: Pod "downward-api-d8fdfe72-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.189362ms
Dec  3 14:29:33.250: INFO: Pod "downward-api-d8fdfe72-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020979316s
Dec  3 14:29:35.255: INFO: Pod "downward-api-d8fdfe72-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026033228s
STEP: Saw pod success
Dec  3 14:29:35.256: INFO: Pod "downward-api-d8fdfe72-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:29:35.261: INFO: Trying to get logs from node k8s-master-3 pod downward-api-d8fdfe72-f707-11e8-a394-16db9a3896d3 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:29:35.304: INFO: Waiting for pod downward-api-d8fdfe72-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:29:35.315: INFO: Pod downward-api-d8fdfe72-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:29:35.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4tv9b" for this suite.
Dec  3 14:29:41.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:29:41.535: INFO: namespace: e2e-tests-downward-api-4tv9b, resource: bindings, ignored listing per whitelist
Dec  3 14:29:41.595: INFO: namespace e2e-tests-downward-api-4tv9b deletion completed in 6.264887357s

• [SLOW TEST:10.716 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:29:41.596: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zb8mk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:29:41.890: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df5857cb-f707-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-zb8mk" to be "success or failure"
Dec  3 14:29:41.926: INFO: Pod "downwardapi-volume-df5857cb-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 35.835026ms
Dec  3 14:29:43.938: INFO: Pod "downwardapi-volume-df5857cb-f707-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048605564s
Dec  3 14:29:45.947: INFO: Pod "downwardapi-volume-df5857cb-f707-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056874055s
STEP: Saw pod success
Dec  3 14:29:45.947: INFO: Pod "downwardapi-volume-df5857cb-f707-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:29:45.956: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-df5857cb-f707-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:29:46.005: INFO: Waiting for pod downwardapi-volume-df5857cb-f707-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:29:46.016: INFO: Pod downwardapi-volume-df5857cb-f707-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:29:46.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zb8mk" for this suite.
Dec  3 14:29:52.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:29:52.133: INFO: namespace: e2e-tests-projected-zb8mk, resource: bindings, ignored listing per whitelist
Dec  3 14:29:52.315: INFO: namespace e2e-tests-projected-zb8mk deletion completed in 6.287533318s

• [SLOW TEST:10.719 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:29:52.316: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-swgj2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-swgj2
Dec  3 14:29:56.705: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-swgj2
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:29:56.715: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:33:58.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-swgj2" for this suite.
Dec  3 14:34:04.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:34:04.202: INFO: namespace: e2e-tests-container-probe-swgj2, resource: bindings, ignored listing per whitelist
Dec  3 14:34:04.535: INFO: namespace e2e-tests-container-probe-swgj2 deletion completed in 6.461329338s

• [SLOW TEST:252.218 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:34:04.535: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-b4mlm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  3 14:34:08.964: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-7c1bf249-f708-11e8-a394-16db9a3896d3,GenerateName:,Namespace:e2e-tests-events-b4mlm,SelfLink:/api/v1/namespaces/e2e-tests-events-b4mlm/pods/send-events-7c1bf249-f708-11e8-a394-16db9a3896d3,UID:73c5c319-f708-11e8-849a-005056852a45,ResourceVersion:96533,Generation:0,CreationTimestamp:2018-12-03 14:33:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 880554174,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l9q92 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9q92,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-l9q92 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4204c8f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4204c8fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:34:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:34:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:34:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 14:33:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:172.31.140.126,StartTime:2018-12-03 14:34:04 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-03 14:34:06 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:5792caa151fd823f01e765c535bcdb0386e0e9c9a2b5687e4a613cecadfa3505 docker://46326a68d5b5e410eac3350cbdd45f6d10c87104fa5e3a17bdff8d196255cb28}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  3 14:34:10.983: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  3 14:34:13.014: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:34:13.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-b4mlm" for this suite.
Dec  3 14:34:57.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:34:57.290: INFO: namespace: e2e-tests-events-b4mlm, resource: bindings, ignored listing per whitelist
Dec  3 14:34:57.448: INFO: namespace e2e-tests-events-b4mlm deletion completed in 44.392591201s

• [SLOW TEST:52.913 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:34:57.448: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-zs2h5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zs2h5
Dec  3 14:35:01.748: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zs2h5
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:35:01.760: INFO: Initial restart count of pod liveness-http is 0
Dec  3 14:35:15.819: INFO: Restart count of pod e2e-tests-container-probe-zs2h5/liveness-http is now 1 (14.059627452s elapsed)
Dec  3 14:35:35.888: INFO: Restart count of pod e2e-tests-container-probe-zs2h5/liveness-http is now 2 (34.12824264s elapsed)
Dec  3 14:35:55.977: INFO: Restart count of pod e2e-tests-container-probe-zs2h5/liveness-http is now 3 (54.217739024s elapsed)
Dec  3 14:36:16.064: INFO: Restart count of pod e2e-tests-container-probe-zs2h5/liveness-http is now 4 (1m14.304159213s elapsed)
Dec  3 14:37:16.306: INFO: Restart count of pod e2e-tests-container-probe-zs2h5/liveness-http is now 5 (2m14.546622822s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:37:16.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zs2h5" for this suite.
Dec  3 14:37:22.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:37:22.556: INFO: namespace: e2e-tests-container-probe-zs2h5, resource: bindings, ignored listing per whitelist
Dec  3 14:37:22.587: INFO: namespace e2e-tests-container-probe-zs2h5 deletion completed in 6.233498012s

• [SLOW TEST:145.139 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:37:22.588: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-xj5qs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  3 14:37:22.879: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:37:26.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xj5qs" for this suite.
Dec  3 14:37:32.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:37:32.912: INFO: namespace: e2e-tests-init-container-xj5qs, resource: bindings, ignored listing per whitelist
Dec  3 14:37:33.287: INFO: namespace e2e-tests-init-container-xj5qs deletion completed in 6.436151494s

• [SLOW TEST:10.700 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:37:33.288: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wb29m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  3 14:37:33.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-wb29m'
Dec  3 14:37:34.866: INFO: stderr: ""
Dec  3 14:37:34.866: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 14:37:35.873: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:35.873: INFO: Found 0 / 1
Dec  3 14:37:36.886: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:36.886: INFO: Found 0 / 1
Dec  3 14:37:37.885: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:37.885: INFO: Found 1 / 1
Dec  3 14:37:37.885: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  3 14:37:37.894: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:37.895: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 14:37:37.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 patch pod redis-master-5w84s --namespace=e2e-tests-kubectl-wb29m -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  3 14:37:38.164: INFO: stderr: ""
Dec  3 14:37:38.165: INFO: stdout: "pod/redis-master-5w84s patched\n"
STEP: checking annotations
Dec  3 14:37:38.192: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:38.193: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:37:38.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wb29m" for this suite.
Dec  3 14:38:02.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:38:02.350: INFO: namespace: e2e-tests-kubectl-wb29m, resource: bindings, ignored listing per whitelist
Dec  3 14:38:02.511: INFO: namespace e2e-tests-kubectl-wb29m deletion completed in 24.306040641s

• [SLOW TEST:29.223 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:38:02.512: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hjf7z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 14:38:02.859: INFO: Waiting up to 5m0s for pod "pod-09f16599-f709-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-hjf7z" to be "success or failure"
Dec  3 14:38:02.872: INFO: Pod "pod-09f16599-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.8934ms
Dec  3 14:38:04.881: INFO: Pod "pod-09f16599-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021431807s
Dec  3 14:38:06.889: INFO: Pod "pod-09f16599-f709-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029243453s
STEP: Saw pod success
Dec  3 14:38:06.889: INFO: Pod "pod-09f16599-f709-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:38:06.899: INFO: Trying to get logs from node k8s-master-3 pod pod-09f16599-f709-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:38:06.963: INFO: Waiting for pod pod-09f16599-f709-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:38:06.971: INFO: Pod pod-09f16599-f709-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:38:06.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hjf7z" for this suite.
Dec  3 14:38:13.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:38:13.174: INFO: namespace: e2e-tests-emptydir-hjf7z, resource: bindings, ignored listing per whitelist
Dec  3 14:38:13.343: INFO: namespace e2e-tests-emptydir-hjf7z deletion completed in 6.361709198s

• [SLOW TEST:10.832 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:38:13.344: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vhgjt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-106e8709-f709-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 14:38:13.761: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-106f82a1-f709-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-vhgjt" to be "success or failure"
Dec  3 14:38:13.771: INFO: Pod "pod-projected-configmaps-106f82a1-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.948423ms
Dec  3 14:38:15.778: INFO: Pod "pod-projected-configmaps-106f82a1-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017045925s
Dec  3 14:38:17.789: INFO: Pod "pod-projected-configmaps-106f82a1-f709-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02786178s
STEP: Saw pod success
Dec  3 14:38:17.789: INFO: Pod "pod-projected-configmaps-106f82a1-f709-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:38:17.796: INFO: Trying to get logs from node k8s-master-3 pod pod-projected-configmaps-106f82a1-f709-11e8-a394-16db9a3896d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:38:17.949: INFO: Waiting for pod pod-projected-configmaps-106f82a1-f709-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:38:17.957: INFO: Pod pod-projected-configmaps-106f82a1-f709-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:38:17.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vhgjt" for this suite.
Dec  3 14:38:24.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:38:24.375: INFO: namespace: e2e-tests-projected-vhgjt, resource: bindings, ignored listing per whitelist
Dec  3 14:38:24.404: INFO: namespace e2e-tests-projected-vhgjt deletion completed in 6.423508931s

• [SLOW TEST:11.060 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:38:24.404: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-6bl8q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1203 14:38:30.974973      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 14:38:30.975: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:38:30.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6bl8q" for this suite.
Dec  3 14:38:37.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:38:37.169: INFO: namespace: e2e-tests-gc-6bl8q, resource: bindings, ignored listing per whitelist
Dec  3 14:38:37.359: INFO: namespace e2e-tests-gc-6bl8q deletion completed in 6.342017037s

• [SLOW TEST:12.955 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:38:37.359: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-k4dgr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  3 14:38:38.233: INFO: created pod pod-service-account-defaultsa
Dec  3 14:38:38.233: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  3 14:38:38.249: INFO: created pod pod-service-account-mountsa
Dec  3 14:38:38.249: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  3 14:38:38.274: INFO: created pod pod-service-account-nomountsa
Dec  3 14:38:38.275: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  3 14:38:38.294: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  3 14:38:38.294: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  3 14:38:38.313: INFO: created pod pod-service-account-mountsa-mountspec
Dec  3 14:38:38.313: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  3 14:38:38.348: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  3 14:38:38.349: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  3 14:38:38.367: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  3 14:38:38.367: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  3 14:38:38.394: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  3 14:38:38.394: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  3 14:38:38.438: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  3 14:38:38.438: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:38:38.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-k4dgr" for this suite.
Dec  3 14:39:02.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:02.785: INFO: namespace: e2e-tests-svcaccounts-k4dgr, resource: bindings, ignored listing per whitelist
Dec  3 14:39:02.864: INFO: namespace e2e-tests-svcaccounts-k4dgr deletion completed in 24.351523321s

• [SLOW TEST:25.504 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:39:02.864: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-qf68w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  3 14:39:03.376: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-qf68w,SelfLink:/api/v1/namespaces/e2e-tests-watch-qf68w/configmaps/e2e-watch-test-resource-version,UID:25a5a32f-f709-11e8-849a-005056852a45,ResourceVersion:97610,Generation:0,CreationTimestamp:2018-12-03 14:38:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 14:39:03.376: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-qf68w,SelfLink:/api/v1/namespaces/e2e-tests-watch-qf68w/configmaps/e2e-watch-test-resource-version,UID:25a5a32f-f709-11e8-849a-005056852a45,ResourceVersion:97611,Generation:0,CreationTimestamp:2018-12-03 14:38:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:39:03.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qf68w" for this suite.
Dec  3 14:39:09.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:09.611: INFO: namespace: e2e-tests-watch-qf68w, resource: bindings, ignored listing per whitelist
Dec  3 14:39:09.651: INFO: namespace e2e-tests-watch-qf68w deletion completed in 6.265248217s

• [SLOW TEST:6.787 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:39:09.651: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-ccjf8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  3 14:39:10.000: INFO: Waiting up to 5m0s for pod "var-expansion-31f68d79-f709-11e8-a394-16db9a3896d3" in namespace "e2e-tests-var-expansion-ccjf8" to be "success or failure"
Dec  3 14:39:10.009: INFO: Pod "var-expansion-31f68d79-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.63055ms
Dec  3 14:39:12.019: INFO: Pod "var-expansion-31f68d79-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019444075s
Dec  3 14:39:14.028: INFO: Pod "var-expansion-31f68d79-f709-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028346773s
STEP: Saw pod success
Dec  3 14:39:14.028: INFO: Pod "var-expansion-31f68d79-f709-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:39:14.039: INFO: Trying to get logs from node k8s-master-3 pod var-expansion-31f68d79-f709-11e8-a394-16db9a3896d3 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:39:14.097: INFO: Waiting for pod var-expansion-31f68d79-f709-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:39:14.106: INFO: Pod var-expansion-31f68d79-f709-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:39:14.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ccjf8" for this suite.
Dec  3 14:39:20.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:20.295: INFO: namespace: e2e-tests-var-expansion-ccjf8, resource: bindings, ignored listing per whitelist
Dec  3 14:39:20.436: INFO: namespace e2e-tests-var-expansion-ccjf8 deletion completed in 6.319480204s

• [SLOW TEST:10.785 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:39:20.437: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qx9jk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  3 14:39:20.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:21.221: INFO: stderr: ""
Dec  3 14:39:21.221: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:39:21.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:21.443: INFO: stderr: ""
Dec  3 14:39:21.443: INFO: stdout: "update-demo-nautilus-6hw7d update-demo-nautilus-ns9lt "
Dec  3 14:39:21.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-6hw7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:21.697: INFO: stderr: ""
Dec  3 14:39:21.697: INFO: stdout: ""
Dec  3 14:39:21.697: INFO: update-demo-nautilus-6hw7d is created but not running
Dec  3 14:39:26.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:27.020: INFO: stderr: ""
Dec  3 14:39:27.021: INFO: stdout: "update-demo-nautilus-6hw7d update-demo-nautilus-ns9lt "
Dec  3 14:39:27.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-6hw7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:27.276: INFO: stderr: ""
Dec  3 14:39:27.277: INFO: stdout: "true"
Dec  3 14:39:27.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-6hw7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:27.517: INFO: stderr: ""
Dec  3 14:39:27.517: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:39:27.517: INFO: validating pod update-demo-nautilus-6hw7d
Dec  3 14:39:27.533: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:39:27.533: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:39:27.533: INFO: update-demo-nautilus-6hw7d is verified up and running
Dec  3 14:39:27.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-ns9lt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:27.767: INFO: stderr: ""
Dec  3 14:39:27.767: INFO: stdout: "true"
Dec  3 14:39:27.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-ns9lt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:28.013: INFO: stderr: ""
Dec  3 14:39:28.013: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:39:28.013: INFO: validating pod update-demo-nautilus-ns9lt
Dec  3 14:39:28.025: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:39:28.025: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:39:28.025: INFO: update-demo-nautilus-ns9lt is verified up and running
STEP: scaling down the replication controller
Dec  3 14:39:28.028: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:39:28.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:29.350: INFO: stderr: ""
Dec  3 14:39:29.350: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:39:29.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:29.600: INFO: stderr: ""
Dec  3 14:39:29.600: INFO: stdout: "update-demo-nautilus-6hw7d update-demo-nautilus-ns9lt "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 14:39:34.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:34.901: INFO: stderr: ""
Dec  3 14:39:34.902: INFO: stdout: "update-demo-nautilus-6hw7d update-demo-nautilus-ns9lt "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 14:39:39.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:40.164: INFO: stderr: ""
Dec  3 14:39:40.164: INFO: stdout: "update-demo-nautilus-ns9lt "
Dec  3 14:39:40.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-ns9lt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:40.440: INFO: stderr: ""
Dec  3 14:39:40.440: INFO: stdout: "true"
Dec  3 14:39:40.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-ns9lt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:40.647: INFO: stderr: ""
Dec  3 14:39:40.647: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:39:40.647: INFO: validating pod update-demo-nautilus-ns9lt
Dec  3 14:39:40.654: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:39:40.654: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:39:40.654: INFO: update-demo-nautilus-ns9lt is verified up and running
STEP: scaling up the replication controller
Dec  3 14:39:40.657: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:39:40.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:41.914: INFO: stderr: ""
Dec  3 14:39:41.914: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:39:41.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:42.198: INFO: stderr: ""
Dec  3 14:39:42.198: INFO: stdout: "update-demo-nautilus-bctxl update-demo-nautilus-ns9lt "
Dec  3 14:39:42.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-bctxl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:42.543: INFO: stderr: ""
Dec  3 14:39:42.543: INFO: stdout: ""
Dec  3 14:39:42.543: INFO: update-demo-nautilus-bctxl is created but not running
Dec  3 14:39:47.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:47.787: INFO: stderr: ""
Dec  3 14:39:47.787: INFO: stdout: "update-demo-nautilus-bctxl update-demo-nautilus-ns9lt "
Dec  3 14:39:47.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-bctxl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:48.027: INFO: stderr: ""
Dec  3 14:39:48.028: INFO: stdout: "true"
Dec  3 14:39:48.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-bctxl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:48.271: INFO: stderr: ""
Dec  3 14:39:48.271: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:39:48.271: INFO: validating pod update-demo-nautilus-bctxl
Dec  3 14:39:48.281: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:39:48.281: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:39:48.281: INFO: update-demo-nautilus-bctxl is verified up and running
Dec  3 14:39:48.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-ns9lt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:48.501: INFO: stderr: ""
Dec  3 14:39:48.501: INFO: stdout: "true"
Dec  3 14:39:48.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods update-demo-nautilus-ns9lt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:48.667: INFO: stderr: ""
Dec  3 14:39:48.667: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:39:48.667: INFO: validating pod update-demo-nautilus-ns9lt
Dec  3 14:39:48.673: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:39:48.673: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:39:48.673: INFO: update-demo-nautilus-ns9lt is verified up and running
STEP: using delete to clean up resources
Dec  3 14:39:48.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:48.884: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:39:48.884: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 14:39:48.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-qx9jk'
Dec  3 14:39:49.132: INFO: stderr: "No resources found.\n"
Dec  3 14:39:49.132: INFO: stdout: ""
Dec  3 14:39:49.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -l name=update-demo --namespace=e2e-tests-kubectl-qx9jk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 14:39:49.439: INFO: stderr: ""
Dec  3 14:39:49.439: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:39:49.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qx9jk" for this suite.
Dec  3 14:40:13.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:13.557: INFO: namespace: e2e-tests-kubectl-qx9jk, resource: bindings, ignored listing per whitelist
Dec  3 14:40:13.734: INFO: namespace e2e-tests-kubectl-qx9jk deletion completed in 24.285284245s

• [SLOW TEST:53.297 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:40:13.735: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-bh6d2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 14:40:22.105: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:22.122: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:24.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:24.128: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:26.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:26.130: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:28.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:28.142: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:30.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:30.135: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:32.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:32.130: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:34.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:34.131: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:36.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:36.132: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:38.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:38.136: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:40:40.122: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:40:40.130: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:40:40.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bh6d2" for this suite.
Dec  3 14:41:04.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:04.269: INFO: namespace: e2e-tests-container-lifecycle-hook-bh6d2, resource: bindings, ignored listing per whitelist
Dec  3 14:41:04.471: INFO: namespace e2e-tests-container-lifecycle-hook-bh6d2 deletion completed in 24.333431787s

• [SLOW TEST:50.736 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:41:04.471: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d25gq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  3 14:41:09.567: INFO: Successfully updated pod "annotationupdate768003e9-f709-11e8-a394-16db9a3896d3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:41:11.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d25gq" for this suite.
Dec  3 14:41:33.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:33.807: INFO: namespace: e2e-tests-projected-d25gq, resource: bindings, ignored listing per whitelist
Dec  3 14:41:33.878: INFO: namespace e2e-tests-projected-d25gq deletion completed in 22.255309604s

• [SLOW TEST:29.407 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:41:33.879: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g64zq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:41:34.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-g64zq'
Dec  3 14:41:34.356: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 14:41:34.356: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  3 14:41:34.370: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec  3 14:41:34.377: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  3 14:41:34.403: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:41:34.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-g64zq'
Dec  3 14:41:50.456: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 14:41:50.456: INFO: stdout: "Created e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5\nScaling up e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  3 14:41:50.457: INFO: stdout: "Created e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5\nScaling up e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  3 14:41:50.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g64zq'
Dec  3 14:41:50.705: INFO: stderr: ""
Dec  3 14:41:50.705: INFO: stdout: "e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5-z79qt "
Dec  3 14:41:50.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5-z79qt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g64zq'
Dec  3 14:41:50.938: INFO: stderr: ""
Dec  3 14:41:50.938: INFO: stdout: "true"
Dec  3 14:41:50.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5-z79qt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g64zq'
Dec  3 14:41:51.153: INFO: stderr: ""
Dec  3 14:41:51.153: INFO: stdout: "nginx:1.14-alpine"
Dec  3 14:41:51.153: INFO: e2e-test-nginx-rc-6dfdac47c90ec439b376a5cf7a1107c5-z79qt is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Dec  3 14:41:51.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g64zq'
Dec  3 14:41:51.378: INFO: stderr: ""
Dec  3 14:41:51.378: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:41:51.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g64zq" for this suite.
Dec  3 14:42:15.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:42:15.558: INFO: namespace: e2e-tests-kubectl-g64zq, resource: bindings, ignored listing per whitelist
Dec  3 14:42:15.911: INFO: namespace e2e-tests-kubectl-g64zq deletion completed in 24.514624422s

• [SLOW TEST:42.033 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:42:15.912: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2zc2r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 14:42:16.224: INFO: Waiting up to 5m0s for pod "pod-a0f63101-f709-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-2zc2r" to be "success or failure"
Dec  3 14:42:16.239: INFO: Pod "pod-a0f63101-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.455526ms
Dec  3 14:42:18.247: INFO: Pod "pod-a0f63101-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02271508s
Dec  3 14:42:20.254: INFO: Pod "pod-a0f63101-f709-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030028056s
STEP: Saw pod success
Dec  3 14:42:20.254: INFO: Pod "pod-a0f63101-f709-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:42:20.259: INFO: Trying to get logs from node k8s-node-2 pod pod-a0f63101-f709-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:42:20.321: INFO: Waiting for pod pod-a0f63101-f709-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:42:20.334: INFO: Pod pod-a0f63101-f709-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:42:20.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2zc2r" for this suite.
Dec  3 14:42:26.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:42:26.510: INFO: namespace: e2e-tests-emptydir-2zc2r, resource: bindings, ignored listing per whitelist
Dec  3 14:42:26.640: INFO: namespace e2e-tests-emptydir-2zc2r deletion completed in 6.294259456s

• [SLOW TEST:10.728 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:42:26.640: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-j6mwd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:42:26.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 version --client'
Dec  3 14:42:27.095: INFO: stderr: ""
Dec  3 14:42:27.095: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  3 14:42:27.098: INFO: Not supported for server versions before "1.12.1"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:42:27.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j6mwd" for this suite.
Dec  3 14:42:33.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:42:33.456: INFO: namespace: e2e-tests-kubectl-j6mwd, resource: bindings, ignored listing per whitelist
Dec  3 14:42:33.591: INFO: namespace e2e-tests-kubectl-j6mwd deletion completed in 6.481726174s

S [SKIPPING] [6.951 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance] [It]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

    Dec  3 14:42:27.098: Not supported for server versions before "1.12.1"

    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:42:33.593: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-54d2d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-fvfl
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:42:34.164: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fvfl" in namespace "e2e-tests-subpath-54d2d" to be "success or failure"
Dec  3 14:42:34.172: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.03882ms
Dec  3 14:42:36.184: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020508118s
Dec  3 14:42:38.207: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043302332s
Dec  3 14:42:40.218: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 6.054199423s
Dec  3 14:42:42.229: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 8.065372814s
Dec  3 14:42:44.237: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 10.072961506s
Dec  3 14:42:46.246: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 12.082401242s
Dec  3 14:42:48.272: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 14.108158626s
Dec  3 14:42:50.283: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 16.11898328s
Dec  3 14:42:52.292: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 18.12876142s
Dec  3 14:42:54.306: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 20.14224686s
Dec  3 14:42:56.313: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 22.149578782s
Dec  3 14:42:58.324: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Running", Reason="", readiness=false. Elapsed: 24.160584733s
Dec  3 14:43:00.332: INFO: Pod "pod-subpath-test-configmap-fvfl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.167918014s
STEP: Saw pod success
Dec  3 14:43:00.332: INFO: Pod "pod-subpath-test-configmap-fvfl" satisfied condition "success or failure"
Dec  3 14:43:00.341: INFO: Trying to get logs from node k8s-master-3 pod pod-subpath-test-configmap-fvfl container test-container-subpath-configmap-fvfl: <nil>
STEP: delete the pod
Dec  3 14:43:00.380: INFO: Waiting for pod pod-subpath-test-configmap-fvfl to disappear
Dec  3 14:43:00.387: INFO: Pod pod-subpath-test-configmap-fvfl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fvfl
Dec  3 14:43:00.387: INFO: Deleting pod "pod-subpath-test-configmap-fvfl" in namespace "e2e-tests-subpath-54d2d"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:43:00.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-54d2d" for this suite.
Dec  3 14:43:06.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:43:06.531: INFO: namespace: e2e-tests-subpath-54d2d, resource: bindings, ignored listing per whitelist
Dec  3 14:43:06.800: INFO: namespace e2e-tests-subpath-54d2d deletion completed in 6.388044458s

• [SLOW TEST:33.207 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:43:06.801: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-d4zlj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 14:43:07.155: INFO: Waiting up to 5m0s for pod "pod-bf51d2a9-f709-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-d4zlj" to be "success or failure"
Dec  3 14:43:07.164: INFO: Pod "pod-bf51d2a9-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.528772ms
Dec  3 14:43:09.175: INFO: Pod "pod-bf51d2a9-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020456874s
Dec  3 14:43:11.181: INFO: Pod "pod-bf51d2a9-f709-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026783174s
STEP: Saw pod success
Dec  3 14:43:11.182: INFO: Pod "pod-bf51d2a9-f709-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:43:11.187: INFO: Trying to get logs from node k8s-node-2 pod pod-bf51d2a9-f709-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:43:11.277: INFO: Waiting for pod pod-bf51d2a9-f709-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:43:11.285: INFO: Pod pod-bf51d2a9-f709-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:43:11.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d4zlj" for this suite.
Dec  3 14:43:17.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:43:17.570: INFO: namespace: e2e-tests-emptydir-d4zlj, resource: bindings, ignored listing per whitelist
Dec  3 14:43:17.766: INFO: namespace e2e-tests-emptydir-d4zlj deletion completed in 6.473590992s

• [SLOW TEST:10.966 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:43:17.767: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-2w65k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-5zgs
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:43:18.270: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5zgs" in namespace "e2e-tests-subpath-2w65k" to be "success or failure"
Dec  3 14:43:18.292: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Pending", Reason="", readiness=false. Elapsed: 21.242179ms
Dec  3 14:43:20.302: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032088766s
Dec  3 14:43:22.310: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039857982s
Dec  3 14:43:24.318: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 6.047451926s
Dec  3 14:43:26.325: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 8.05436367s
Dec  3 14:43:28.333: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 10.063084962s
Dec  3 14:43:30.340: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 12.069315398s
Dec  3 14:43:32.347: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 14.076785278s
Dec  3 14:43:34.355: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 16.084662892s
Dec  3 14:43:36.362: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 18.09184364s
Dec  3 14:43:38.371: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 20.100480858s
Dec  3 14:43:40.377: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Running", Reason="", readiness=false. Elapsed: 22.106394876s
Dec  3 14:43:42.385: INFO: Pod "pod-subpath-test-configmap-5zgs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.11422992s
STEP: Saw pod success
Dec  3 14:43:42.385: INFO: Pod "pod-subpath-test-configmap-5zgs" satisfied condition "success or failure"
Dec  3 14:43:42.397: INFO: Trying to get logs from node k8s-master-3 pod pod-subpath-test-configmap-5zgs container test-container-subpath-configmap-5zgs: <nil>
STEP: delete the pod
Dec  3 14:43:42.464: INFO: Waiting for pod pod-subpath-test-configmap-5zgs to disappear
Dec  3 14:43:42.473: INFO: Pod pod-subpath-test-configmap-5zgs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5zgs
Dec  3 14:43:42.473: INFO: Deleting pod "pod-subpath-test-configmap-5zgs" in namespace "e2e-tests-subpath-2w65k"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:43:42.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2w65k" for this suite.
Dec  3 14:43:48.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:43:48.737: INFO: namespace: e2e-tests-subpath-2w65k, resource: bindings, ignored listing per whitelist
Dec  3 14:43:48.894: INFO: namespace e2e-tests-subpath-2w65k deletion completed in 6.383582384s

• [SLOW TEST:31.127 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:43:48.895: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-h79x4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:43:49.268: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d86b0601-f709-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-h79x4" to be "success or failure"
Dec  3 14:43:49.285: INFO: Pod "downwardapi-volume-d86b0601-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.503678ms
Dec  3 14:43:51.290: INFO: Pod "downwardapi-volume-d86b0601-f709-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022277902s
Dec  3 14:43:53.300: INFO: Pod "downwardapi-volume-d86b0601-f709-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03137901s
STEP: Saw pod success
Dec  3 14:43:53.300: INFO: Pod "downwardapi-volume-d86b0601-f709-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:43:53.307: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-d86b0601-f709-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:43:53.395: INFO: Waiting for pod downwardapi-volume-d86b0601-f709-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:43:53.413: INFO: Pod downwardapi-volume-d86b0601-f709-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:43:53.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-h79x4" for this suite.
Dec  3 14:43:59.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:43:59.765: INFO: namespace: e2e-tests-downward-api-h79x4, resource: bindings, ignored listing per whitelist
Dec  3 14:43:59.897: INFO: namespace e2e-tests-downward-api-h79x4 deletion completed in 6.474238792s

• [SLOW TEST:11.003 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:43:59.898: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-w9nrx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-defa9fd6-f709-11e8-a394-16db9a3896d3
Dec  3 14:44:00.280: INFO: Pod name my-hostname-basic-defa9fd6-f709-11e8-a394-16db9a3896d3: Found 0 pods out of 1
Dec  3 14:44:05.305: INFO: Pod name my-hostname-basic-defa9fd6-f709-11e8-a394-16db9a3896d3: Found 1 pods out of 1
Dec  3 14:44:05.305: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-defa9fd6-f709-11e8-a394-16db9a3896d3" are running
Dec  3 14:44:05.315: INFO: Pod "my-hostname-basic-defa9fd6-f709-11e8-a394-16db9a3896d3-bph6d" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 14:44:00 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 14:44:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 14:44:02 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 14:43:46 +0000 UTC Reason: Message:}])
Dec  3 14:44:05.316: INFO: Trying to dial the pod
Dec  3 14:44:10.417: INFO: Controller my-hostname-basic-defa9fd6-f709-11e8-a394-16db9a3896d3: Got expected result from replica 1 [my-hostname-basic-defa9fd6-f709-11e8-a394-16db9a3896d3-bph6d]: "my-hostname-basic-defa9fd6-f709-11e8-a394-16db9a3896d3-bph6d", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:44:10.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-w9nrx" for this suite.
Dec  3 14:44:16.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:16.787: INFO: namespace: e2e-tests-replication-controller-w9nrx, resource: bindings, ignored listing per whitelist
Dec  3 14:44:16.853: INFO: namespace e2e-tests-replication-controller-w9nrx deletion completed in 6.407064254s

• [SLOW TEST:16.955 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:44:16.853: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-pzlv6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 14:44:17.432: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:17.446: INFO: Number of nodes with available pods: 0
Dec  3 14:44:17.446: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:44:18.470: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:18.513: INFO: Number of nodes with available pods: 0
Dec  3 14:44:18.513: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:44:19.483: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:19.508: INFO: Number of nodes with available pods: 0
Dec  3 14:44:19.508: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:44:20.526: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:20.544: INFO: Number of nodes with available pods: 0
Dec  3 14:44:20.544: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:44:21.461: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:21.476: INFO: Number of nodes with available pods: 2
Dec  3 14:44:21.476: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  3 14:44:21.527: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:21.533: INFO: Number of nodes with available pods: 1
Dec  3 14:44:21.533: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:22.544: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:22.551: INFO: Number of nodes with available pods: 1
Dec  3 14:44:22.551: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:23.545: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:23.556: INFO: Number of nodes with available pods: 1
Dec  3 14:44:23.556: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:24.552: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:24.568: INFO: Number of nodes with available pods: 1
Dec  3 14:44:24.568: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:25.543: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:25.549: INFO: Number of nodes with available pods: 1
Dec  3 14:44:25.549: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:26.562: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:26.578: INFO: Number of nodes with available pods: 1
Dec  3 14:44:26.578: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:27.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:27.549: INFO: Number of nodes with available pods: 1
Dec  3 14:44:27.549: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:28.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:28.553: INFO: Number of nodes with available pods: 1
Dec  3 14:44:28.553: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:29.541: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:29.552: INFO: Number of nodes with available pods: 1
Dec  3 14:44:29.552: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:30.544: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:30.552: INFO: Number of nodes with available pods: 1
Dec  3 14:44:30.552: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:31.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:31.551: INFO: Number of nodes with available pods: 1
Dec  3 14:44:31.551: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:32.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:32.551: INFO: Number of nodes with available pods: 1
Dec  3 14:44:32.551: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:33.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:33.554: INFO: Number of nodes with available pods: 1
Dec  3 14:44:33.554: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:34.545: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:34.553: INFO: Number of nodes with available pods: 1
Dec  3 14:44:34.553: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:35.541: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:35.552: INFO: Number of nodes with available pods: 1
Dec  3 14:44:35.552: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:36.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:36.549: INFO: Number of nodes with available pods: 1
Dec  3 14:44:36.549: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:37.540: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:37.546: INFO: Number of nodes with available pods: 1
Dec  3 14:44:37.546: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:38.548: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:38.557: INFO: Number of nodes with available pods: 1
Dec  3 14:44:38.557: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:39.558: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:39.563: INFO: Number of nodes with available pods: 1
Dec  3 14:44:39.563: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:40.568: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:40.583: INFO: Number of nodes with available pods: 1
Dec  3 14:44:40.583: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:41.541: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:41.548: INFO: Number of nodes with available pods: 1
Dec  3 14:44:41.549: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:42.579: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:42.593: INFO: Number of nodes with available pods: 1
Dec  3 14:44:42.593: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:43.548: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:43.560: INFO: Number of nodes with available pods: 1
Dec  3 14:44:43.560: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:44.551: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:44.562: INFO: Number of nodes with available pods: 1
Dec  3 14:44:44.562: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:45.569: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:45.588: INFO: Number of nodes with available pods: 1
Dec  3 14:44:45.588: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:46.561: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:46.573: INFO: Number of nodes with available pods: 1
Dec  3 14:44:46.573: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:47.550: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:47.562: INFO: Number of nodes with available pods: 1
Dec  3 14:44:47.562: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:48.558: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:48.567: INFO: Number of nodes with available pods: 1
Dec  3 14:44:48.567: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:49.560: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:49.621: INFO: Number of nodes with available pods: 1
Dec  3 14:44:49.621: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:50.556: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:50.573: INFO: Number of nodes with available pods: 1
Dec  3 14:44:50.573: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:51.548: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:51.563: INFO: Number of nodes with available pods: 1
Dec  3 14:44:51.563: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:52.547: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:52.560: INFO: Number of nodes with available pods: 1
Dec  3 14:44:52.560: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:53.545: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:53.575: INFO: Number of nodes with available pods: 1
Dec  3 14:44:53.575: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:54.554: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:54.566: INFO: Number of nodes with available pods: 1
Dec  3 14:44:54.566: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:55.540: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:55.550: INFO: Number of nodes with available pods: 1
Dec  3 14:44:55.550: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:56.563: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:56.572: INFO: Number of nodes with available pods: 1
Dec  3 14:44:56.572: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:57.557: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:57.568: INFO: Number of nodes with available pods: 1
Dec  3 14:44:57.568: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:58.545: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:58.553: INFO: Number of nodes with available pods: 1
Dec  3 14:44:58.553: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:44:59.544: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:44:59.556: INFO: Number of nodes with available pods: 1
Dec  3 14:44:59.556: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:00.557: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:00.567: INFO: Number of nodes with available pods: 1
Dec  3 14:45:00.567: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:01.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:01.549: INFO: Number of nodes with available pods: 1
Dec  3 14:45:01.549: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:02.543: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:02.553: INFO: Number of nodes with available pods: 1
Dec  3 14:45:02.553: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:03.541: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:03.548: INFO: Number of nodes with available pods: 1
Dec  3 14:45:03.549: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:04.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:04.551: INFO: Number of nodes with available pods: 1
Dec  3 14:45:04.551: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:05.542: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:05.551: INFO: Number of nodes with available pods: 1
Dec  3 14:45:05.551: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:06.549: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:06.556: INFO: Number of nodes with available pods: 1
Dec  3 14:45:06.556: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:07.545: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:07.551: INFO: Number of nodes with available pods: 1
Dec  3 14:45:07.551: INFO: Node k8s-node-2 is running more than one daemon pod
Dec  3 14:45:08.540: INFO: DaemonSet pods can't tolerate node k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 14:45:08.552: INFO: Number of nodes with available pods: 2
Dec  3 14:45:08.552: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-pzlv6, will wait for the garbage collector to delete the pods
Dec  3 14:45:08.630: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.084222ms
Dec  3 14:45:08.734: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 103.444738ms
Dec  3 14:45:42.645: INFO: Number of nodes with available pods: 0
Dec  3 14:45:42.645: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:45:42.658: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pzlv6/daemonsets","resourceVersion":"98923"},"items":null}

Dec  3 14:45:42.684: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pzlv6/pods","resourceVersion":"98923"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:45:42.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pzlv6" for this suite.
Dec  3 14:45:48.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:48.946: INFO: namespace: e2e-tests-daemonsets-pzlv6, resource: bindings, ignored listing per whitelist
Dec  3 14:45:49.040: INFO: namespace e2e-tests-daemonsets-pzlv6 deletion completed in 6.259691337s

• [SLOW TEST:92.188 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:45:49.041: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-8l29n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-8l29n
Dec  3 14:45:53.333: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-8l29n
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:45:53.338: INFO: Initial restart count of pod liveness-exec is 0
Dec  3 14:46:43.535: INFO: Restart count of pod e2e-tests-container-probe-8l29n/liveness-exec is now 1 (50.196801008s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:46:43.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8l29n" for this suite.
Dec  3 14:46:49.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:49.797: INFO: namespace: e2e-tests-container-probe-8l29n, resource: bindings, ignored listing per whitelist
Dec  3 14:46:49.849: INFO: namespace e2e-tests-container-probe-8l29n deletion completed in 6.278651789s

• [SLOW TEST:60.808 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:46:49.849: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-gt56s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gt56s
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 14:46:50.132: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 14:47:16.333: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.31.140.92:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gt56s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:47:16.333: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:47:16.508: INFO: Found all expected endpoints: [netserver-0]
Dec  3 14:47:16.522: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.31.168.19:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gt56s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:47:16.522: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:47:16.727: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:47:16.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gt56s" for this suite.
Dec  3 14:47:40.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:41.082: INFO: namespace: e2e-tests-pod-network-test-gt56s, resource: bindings, ignored listing per whitelist
Dec  3 14:47:41.092: INFO: namespace e2e-tests-pod-network-test-gt56s deletion completed in 24.324916636s

• [SLOW TEST:51.244 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:47:41.093: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j985d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  3 14:47:45.924: INFO: Successfully updated pod "labelsupdate62bf75c6-f70a-11e8-a394-16db9a3896d3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:47:47.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j985d" for this suite.
Dec  3 14:48:11.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:12.166: INFO: namespace: e2e-tests-projected-j985d, resource: bindings, ignored listing per whitelist
Dec  3 14:48:12.222: INFO: namespace e2e-tests-projected-j985d deletion completed in 24.25147233s

• [SLOW TEST:31.130 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:48:12.223: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-j5bgg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1203 14:48:22.697900      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 14:48:22.698: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:48:22.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-j5bgg" for this suite.
Dec  3 14:48:30.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:30.791: INFO: namespace: e2e-tests-gc-j5bgg, resource: bindings, ignored listing per whitelist
Dec  3 14:48:30.985: INFO: namespace e2e-tests-gc-j5bgg deletion completed in 8.274150305s

• [SLOW TEST:18.762 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:48:30.985: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b8swf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:48:31.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-b8swf'
Dec  3 14:48:32.276: INFO: stderr: ""
Dec  3 14:48:32.276: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Dec  3 14:48:32.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-b8swf'
Dec  3 14:48:36.174: INFO: stderr: ""
Dec  3 14:48:36.174: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:48:36.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b8swf" for this suite.
Dec  3 14:48:42.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:42.370: INFO: namespace: e2e-tests-kubectl-b8swf, resource: bindings, ignored listing per whitelist
Dec  3 14:48:42.400: INFO: namespace e2e-tests-kubectl-b8swf deletion completed in 6.211603858s

• [SLOW TEST:11.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:48:42.401: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-twzz6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 14:48:47.254: INFO: Successfully updated pod "pod-update-874fe724-f70a-11e8-a394-16db9a3896d3"
STEP: verifying the updated pod is in kubernetes
Dec  3 14:48:47.277: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:48:47.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-twzz6" for this suite.
Dec  3 14:49:11.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:11.456: INFO: namespace: e2e-tests-pods-twzz6, resource: bindings, ignored listing per whitelist
Dec  3 14:49:11.486: INFO: namespace e2e-tests-pods-twzz6 deletion completed in 24.194123856s

• [SLOW TEST:29.086 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:49:11.487: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-hgfwh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hgfwh
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  3 14:49:11.893: INFO: Found 0 stateful pods, waiting for 3
Dec  3 14:49:21.908: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 14:49:21.908: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 14:49:21.908: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  3 14:49:22.018: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  3 14:49:32.094: INFO: Updating stateful set ss2
Dec  3 14:49:32.119: INFO: Waiting for Pod e2e-tests-statefulset-hgfwh/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  3 14:49:42.212: INFO: Found 1 stateful pods, waiting for 3
Dec  3 14:49:52.249: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 14:49:52.249: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 14:49:52.249: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  3 14:49:52.307: INFO: Updating stateful set ss2
Dec  3 14:49:52.330: INFO: Waiting for Pod e2e-tests-statefulset-hgfwh/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  3 14:50:02.351: INFO: Waiting for Pod e2e-tests-statefulset-hgfwh/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  3 14:50:12.379: INFO: Updating stateful set ss2
Dec  3 14:50:12.417: INFO: Waiting for StatefulSet e2e-tests-statefulset-hgfwh/ss2 to complete update
Dec  3 14:50:12.417: INFO: Waiting for Pod e2e-tests-statefulset-hgfwh/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  3 14:50:22.430: INFO: Waiting for StatefulSet e2e-tests-statefulset-hgfwh/ss2 to complete update
Dec  3 14:50:22.430: INFO: Waiting for Pod e2e-tests-statefulset-hgfwh/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 14:50:32.430: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hgfwh
Dec  3 14:50:32.444: INFO: Scaling statefulset ss2 to 0
Dec  3 14:50:52.475: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 14:50:52.490: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:50:52.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hgfwh" for this suite.
Dec  3 14:51:00.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:00.655: INFO: namespace: e2e-tests-statefulset-hgfwh, resource: bindings, ignored listing per whitelist
Dec  3 14:51:00.806: INFO: namespace e2e-tests-statefulset-hgfwh deletion completed in 8.274827526s

• [SLOW TEST:109.319 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:51:00.806: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tbk2j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:51:01.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-tbk2j'
Dec  3 14:51:01.521: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 14:51:01.521: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Dec  3 14:51:05.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-tbk2j'
Dec  3 14:51:05.895: INFO: stderr: ""
Dec  3 14:51:05.895: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:51:05.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tbk2j" for this suite.
Dec  3 14:51:29.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:30.036: INFO: namespace: e2e-tests-kubectl-tbk2j, resource: bindings, ignored listing per whitelist
Dec  3 14:51:30.184: INFO: namespace e2e-tests-kubectl-tbk2j deletion completed in 24.250562096s

• [SLOW TEST:29.378 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:51:30.185: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-m9598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-p4cs6
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-2pwvt
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:51:36.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-m9598" for this suite.
Dec  3 14:51:42.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:43.033: INFO: namespace: e2e-tests-namespaces-m9598, resource: bindings, ignored listing per whitelist
Dec  3 14:51:43.234: INFO: namespace e2e-tests-namespaces-m9598 deletion completed in 6.285812305s
STEP: Destroying namespace "e2e-tests-nsdeletetest-p4cs6" for this suite.
Dec  3 14:51:43.240: INFO: Namespace e2e-tests-nsdeletetest-p4cs6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-2pwvt" for this suite.
Dec  3 14:51:49.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:49.297: INFO: namespace: e2e-tests-nsdeletetest-2pwvt, resource: bindings, ignored listing per whitelist
Dec  3 14:51:49.405: INFO: namespace e2e-tests-nsdeletetest-2pwvt deletion completed in 6.165136427s

• [SLOW TEST:19.220 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:51:49.406: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6vbss
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:51:49.695: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f6c4ddb5-f70a-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-6vbss" to be "success or failure"
Dec  3 14:51:49.713: INFO: Pod "downwardapi-volume-f6c4ddb5-f70a-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 18.283258ms
Dec  3 14:51:51.724: INFO: Pod "downwardapi-volume-f6c4ddb5-f70a-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029039652s
Dec  3 14:51:53.735: INFO: Pod "downwardapi-volume-f6c4ddb5-f70a-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040075s
STEP: Saw pod success
Dec  3 14:51:53.735: INFO: Pod "downwardapi-volume-f6c4ddb5-f70a-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:51:53.742: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-f6c4ddb5-f70a-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:51:53.904: INFO: Waiting for pod downwardapi-volume-f6c4ddb5-f70a-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:51:53.911: INFO: Pod downwardapi-volume-f6c4ddb5-f70a-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:51:53.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6vbss" for this suite.
Dec  3 14:51:59.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:00.147: INFO: namespace: e2e-tests-downward-api-6vbss, resource: bindings, ignored listing per whitelist
Dec  3 14:52:00.334: INFO: namespace e2e-tests-downward-api-6vbss deletion completed in 6.41273057s

• [SLOW TEST:10.928 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:52:00.334: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-g7797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:52:00.729: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd58c13c-f70a-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-g7797" to be "success or failure"
Dec  3 14:52:00.740: INFO: Pod "downwardapi-volume-fd58c13c-f70a-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.104826ms
Dec  3 14:52:02.759: INFO: Pod "downwardapi-volume-fd58c13c-f70a-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029433032s
STEP: Saw pod success
Dec  3 14:52:02.759: INFO: Pod "downwardapi-volume-fd58c13c-f70a-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:52:02.769: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-fd58c13c-f70a-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:52:02.845: INFO: Waiting for pod downwardapi-volume-fd58c13c-f70a-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:52:02.869: INFO: Pod downwardapi-volume-fd58c13c-f70a-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:52:02.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g7797" for this suite.
Dec  3 14:52:08.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:09.016: INFO: namespace: e2e-tests-projected-g7797, resource: bindings, ignored listing per whitelist
Dec  3 14:52:09.128: INFO: namespace e2e-tests-projected-g7797 deletion completed in 6.22762335s

• [SLOW TEST:8.794 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:52:09.128: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-9f26q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:52:09.378: INFO: (0) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.863653ms)
Dec  3 14:52:09.388: INFO: (1) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.909971ms)
Dec  3 14:52:09.397: INFO: (2) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.849947ms)
Dec  3 14:52:09.409: INFO: (3) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.503615ms)
Dec  3 14:52:09.417: INFO: (4) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.334098ms)
Dec  3 14:52:09.427: INFO: (5) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.119437ms)
Dec  3 14:52:09.434: INFO: (6) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.011384ms)
Dec  3 14:52:09.441: INFO: (7) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.157545ms)
Dec  3 14:52:09.449: INFO: (8) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.181287ms)
Dec  3 14:52:09.459: INFO: (9) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.929978ms)
Dec  3 14:52:09.467: INFO: (10) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.195144ms)
Dec  3 14:52:09.479: INFO: (11) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.789951ms)
Dec  3 14:52:09.494: INFO: (12) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 14.495401ms)
Dec  3 14:52:09.503: INFO: (13) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.131157ms)
Dec  3 14:52:09.513: INFO: (14) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.055208ms)
Dec  3 14:52:09.523: INFO: (15) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.062328ms)
Dec  3 14:52:09.531: INFO: (16) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.700121ms)
Dec  3 14:52:09.545: INFO: (17) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.765943ms)
Dec  3 14:52:09.555: INFO: (18) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.239111ms)
Dec  3 14:52:09.563: INFO: (19) /api/v1/nodes/k8s-master-3/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.486547ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:52:09.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9f26q" for this suite.
Dec  3 14:52:15.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:15.905: INFO: namespace: e2e-tests-proxy-9f26q, resource: bindings, ignored listing per whitelist
Dec  3 14:52:15.917: INFO: namespace e2e-tests-proxy-9f26q deletion completed in 6.338434087s

• [SLOW TEST:6.789 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:52:15.918: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hs6tj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  3 14:52:16.252: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-442087039 proxy --unix-socket=/tmp/kubectl-proxy-unix605737426/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:52:16.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hs6tj" for this suite.
Dec  3 14:52:22.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:22.525: INFO: namespace: e2e-tests-kubectl-hs6tj, resource: bindings, ignored listing per whitelist
Dec  3 14:52:22.639: INFO: namespace e2e-tests-kubectl-hs6tj deletion completed in 6.20240245s

• [SLOW TEST:6.722 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:52:22.640: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-pqvlf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:52:22.923: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  3 14:52:22.950: INFO: Number of nodes with available pods: 0
Dec  3 14:52:22.950: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  3 14:52:22.990: INFO: Number of nodes with available pods: 0
Dec  3 14:52:22.990: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:23.998: INFO: Number of nodes with available pods: 0
Dec  3 14:52:23.998: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:25.002: INFO: Number of nodes with available pods: 0
Dec  3 14:52:25.002: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:25.998: INFO: Number of nodes with available pods: 1
Dec  3 14:52:25.998: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  3 14:52:26.067: INFO: Number of nodes with available pods: 1
Dec  3 14:52:26.067: INFO: Number of running nodes: 0, number of available pods: 1
Dec  3 14:52:27.076: INFO: Number of nodes with available pods: 0
Dec  3 14:52:27.076: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  3 14:52:27.100: INFO: Number of nodes with available pods: 0
Dec  3 14:52:27.100: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:28.110: INFO: Number of nodes with available pods: 0
Dec  3 14:52:28.110: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:29.105: INFO: Number of nodes with available pods: 0
Dec  3 14:52:29.105: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:30.109: INFO: Number of nodes with available pods: 0
Dec  3 14:52:30.109: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:31.107: INFO: Number of nodes with available pods: 0
Dec  3 14:52:31.107: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:32.107: INFO: Number of nodes with available pods: 0
Dec  3 14:52:32.107: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:33.108: INFO: Number of nodes with available pods: 0
Dec  3 14:52:33.108: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:34.105: INFO: Number of nodes with available pods: 0
Dec  3 14:52:34.105: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:35.106: INFO: Number of nodes with available pods: 0
Dec  3 14:52:35.106: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:36.115: INFO: Number of nodes with available pods: 0
Dec  3 14:52:36.115: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:37.107: INFO: Number of nodes with available pods: 0
Dec  3 14:52:37.107: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:38.107: INFO: Number of nodes with available pods: 0
Dec  3 14:52:38.107: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:39.110: INFO: Number of nodes with available pods: 0
Dec  3 14:52:39.110: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:40.116: INFO: Number of nodes with available pods: 0
Dec  3 14:52:40.116: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:41.105: INFO: Number of nodes with available pods: 0
Dec  3 14:52:41.105: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:42.111: INFO: Number of nodes with available pods: 0
Dec  3 14:52:42.111: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:43.107: INFO: Number of nodes with available pods: 0
Dec  3 14:52:43.107: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:44.106: INFO: Number of nodes with available pods: 0
Dec  3 14:52:44.106: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:45.110: INFO: Number of nodes with available pods: 0
Dec  3 14:52:45.110: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:46.107: INFO: Number of nodes with available pods: 0
Dec  3 14:52:46.107: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:47.105: INFO: Number of nodes with available pods: 0
Dec  3 14:52:47.105: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:48.108: INFO: Number of nodes with available pods: 0
Dec  3 14:52:48.108: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:49.107: INFO: Number of nodes with available pods: 0
Dec  3 14:52:49.107: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:50.106: INFO: Number of nodes with available pods: 0
Dec  3 14:52:50.106: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:51.105: INFO: Number of nodes with available pods: 0
Dec  3 14:52:51.105: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:52.105: INFO: Number of nodes with available pods: 0
Dec  3 14:52:52.105: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:53.106: INFO: Number of nodes with available pods: 0
Dec  3 14:52:53.106: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:54.109: INFO: Number of nodes with available pods: 0
Dec  3 14:52:54.109: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:55.112: INFO: Number of nodes with available pods: 0
Dec  3 14:52:55.112: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:56.106: INFO: Number of nodes with available pods: 0
Dec  3 14:52:56.106: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:57.105: INFO: Number of nodes with available pods: 0
Dec  3 14:52:57.105: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:58.107: INFO: Number of nodes with available pods: 0
Dec  3 14:52:58.107: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:52:59.106: INFO: Number of nodes with available pods: 0
Dec  3 14:52:59.106: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:53:00.107: INFO: Number of nodes with available pods: 0
Dec  3 14:53:00.108: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:53:01.106: INFO: Number of nodes with available pods: 0
Dec  3 14:53:01.106: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:53:02.108: INFO: Number of nodes with available pods: 0
Dec  3 14:53:02.108: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:53:03.108: INFO: Number of nodes with available pods: 0
Dec  3 14:53:03.109: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:53:04.105: INFO: Number of nodes with available pods: 0
Dec  3 14:53:04.105: INFO: Node k8s-master-3 is running more than one daemon pod
Dec  3 14:53:05.106: INFO: Number of nodes with available pods: 1
Dec  3 14:53:05.107: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-pqvlf, will wait for the garbage collector to delete the pods
Dec  3 14:53:05.207: INFO: Deleting {extensions DaemonSet} daemon-set took: 21.837826ms
Dec  3 14:53:05.307: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.567766ms
Dec  3 14:53:42.614: INFO: Number of nodes with available pods: 0
Dec  3 14:53:42.614: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:53:42.627: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pqvlf/daemonsets","resourceVersion":"100796"},"items":null}

Dec  3 14:53:42.642: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pqvlf/pods","resourceVersion":"100796"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:53:42.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pqvlf" for this suite.
Dec  3 14:53:48.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:48.894: INFO: namespace: e2e-tests-daemonsets-pqvlf, resource: bindings, ignored listing per whitelist
Dec  3 14:53:48.927: INFO: namespace e2e-tests-daemonsets-pqvlf deletion completed in 6.23526591s

• [SLOW TEST:86.287 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:53:48.927: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-vf6zp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 14:53:57.377: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 14:53:57.392: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 14:53:59.392: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 14:53:59.404: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 14:54:01.392: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 14:54:01.404: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 14:54:03.392: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 14:54:03.403: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 14:54:05.394: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 14:54:05.463: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 14:54:07.392: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 14:54:07.407: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:54:07.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vf6zp" for this suite.
Dec  3 14:54:25.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:25.817: INFO: namespace: e2e-tests-container-lifecycle-hook-vf6zp, resource: bindings, ignored listing per whitelist
Dec  3 14:54:26.000: INFO: namespace e2e-tests-container-lifecycle-hook-vf6zp deletion completed in 18.554118117s

• [SLOW TEST:37.073 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:54:26.000: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-6tnxw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  3 14:54:26.277: INFO: Waiting up to 5m0s for pod "var-expansion-541b8bc6-f70b-11e8-a394-16db9a3896d3" in namespace "e2e-tests-var-expansion-6tnxw" to be "success or failure"
Dec  3 14:54:26.291: INFO: Pod "var-expansion-541b8bc6-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.227285ms
Dec  3 14:54:28.302: INFO: Pod "var-expansion-541b8bc6-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024704798s
Dec  3 14:54:30.308: INFO: Pod "var-expansion-541b8bc6-f70b-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031019862s
STEP: Saw pod success
Dec  3 14:54:30.308: INFO: Pod "var-expansion-541b8bc6-f70b-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:54:30.315: INFO: Trying to get logs from node k8s-master-3 pod var-expansion-541b8bc6-f70b-11e8-a394-16db9a3896d3 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:54:30.365: INFO: Waiting for pod var-expansion-541b8bc6-f70b-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:54:30.380: INFO: Pod var-expansion-541b8bc6-f70b-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:54:30.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6tnxw" for this suite.
Dec  3 14:54:36.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:36.504: INFO: namespace: e2e-tests-var-expansion-6tnxw, resource: bindings, ignored listing per whitelist
Dec  3 14:54:36.682: INFO: namespace e2e-tests-var-expansion-6tnxw deletion completed in 6.29051472s

• [SLOW TEST:10.682 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:54:36.682: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-gwbm5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 14:54:41.059: INFO: Waiting up to 5m0s for pod "client-envvars-5ceb6fce-f70b-11e8-a394-16db9a3896d3" in namespace "e2e-tests-pods-gwbm5" to be "success or failure"
Dec  3 14:54:41.069: INFO: Pod "client-envvars-5ceb6fce-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.303794ms
Dec  3 14:54:43.078: INFO: Pod "client-envvars-5ceb6fce-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019460682s
Dec  3 14:54:45.090: INFO: Pod "client-envvars-5ceb6fce-f70b-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031404544s
STEP: Saw pod success
Dec  3 14:54:45.090: INFO: Pod "client-envvars-5ceb6fce-f70b-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:54:45.096: INFO: Trying to get logs from node k8s-master-3 pod client-envvars-5ceb6fce-f70b-11e8-a394-16db9a3896d3 container env3cont: <nil>
STEP: delete the pod
Dec  3 14:54:45.382: INFO: Waiting for pod client-envvars-5ceb6fce-f70b-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:54:45.390: INFO: Pod client-envvars-5ceb6fce-f70b-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:54:45.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-gwbm5" for this suite.
Dec  3 14:55:27.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:27.551: INFO: namespace: e2e-tests-pods-gwbm5, resource: bindings, ignored listing per whitelist
Dec  3 14:55:27.815: INFO: namespace e2e-tests-pods-gwbm5 deletion completed in 42.41348416s

• [SLOW TEST:51.133 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:55:27.816: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-k488z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  3 14:55:28.213: INFO: Waiting up to 5m0s for pod "client-containers-7905a008-f70b-11e8-a394-16db9a3896d3" in namespace "e2e-tests-containers-k488z" to be "success or failure"
Dec  3 14:55:28.225: INFO: Pod "client-containers-7905a008-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.432634ms
Dec  3 14:55:30.232: INFO: Pod "client-containers-7905a008-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018944862s
Dec  3 14:55:32.252: INFO: Pod "client-containers-7905a008-f70b-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039561256s
STEP: Saw pod success
Dec  3 14:55:32.252: INFO: Pod "client-containers-7905a008-f70b-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:55:32.262: INFO: Trying to get logs from node k8s-node-2 pod client-containers-7905a008-f70b-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 14:55:32.441: INFO: Waiting for pod client-containers-7905a008-f70b-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:55:32.454: INFO: Pod client-containers-7905a008-f70b-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:55:32.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-k488z" for this suite.
Dec  3 14:55:38.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:38.580: INFO: namespace: e2e-tests-containers-k488z, resource: bindings, ignored listing per whitelist
Dec  3 14:55:38.958: INFO: namespace e2e-tests-containers-k488z deletion completed in 6.468565894s

• [SLOW TEST:11.142 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:55:38.958: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9k7nh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7fa7921d-f70b-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 14:55:39.351: INFO: Waiting up to 5m0s for pod "pod-configmaps-7fa9b362-f70b-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-9k7nh" to be "success or failure"
Dec  3 14:55:39.359: INFO: Pod "pod-configmaps-7fa9b362-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.7349ms
Dec  3 14:55:41.364: INFO: Pod "pod-configmaps-7fa9b362-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012838194s
Dec  3 14:55:43.373: INFO: Pod "pod-configmaps-7fa9b362-f70b-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021725408s
STEP: Saw pod success
Dec  3 14:55:43.373: INFO: Pod "pod-configmaps-7fa9b362-f70b-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:55:43.378: INFO: Trying to get logs from node k8s-master-3 pod pod-configmaps-7fa9b362-f70b-11e8-a394-16db9a3896d3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:55:43.423: INFO: Waiting for pod pod-configmaps-7fa9b362-f70b-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:55:43.434: INFO: Pod pod-configmaps-7fa9b362-f70b-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:55:43.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9k7nh" for this suite.
Dec  3 14:55:49.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:49.564: INFO: namespace: e2e-tests-configmap-9k7nh, resource: bindings, ignored listing per whitelist
Dec  3 14:55:49.746: INFO: namespace e2e-tests-configmap-9k7nh deletion completed in 6.29875064s

• [SLOW TEST:10.788 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:55:49.747: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-bwckt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-bwckt/secret-test-860d193e-f70b-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 14:55:50.080: INFO: Waiting up to 5m0s for pod "pod-configmaps-860f5348-f70b-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-bwckt" to be "success or failure"
Dec  3 14:55:50.090: INFO: Pod "pod-configmaps-860f5348-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.68562ms
Dec  3 14:55:52.096: INFO: Pod "pod-configmaps-860f5348-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01642377s
Dec  3 14:55:54.107: INFO: Pod "pod-configmaps-860f5348-f70b-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027248032s
STEP: Saw pod success
Dec  3 14:55:54.107: INFO: Pod "pod-configmaps-860f5348-f70b-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:55:54.112: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-860f5348-f70b-11e8-a394-16db9a3896d3 container env-test: <nil>
STEP: delete the pod
Dec  3 14:55:54.151: INFO: Waiting for pod pod-configmaps-860f5348-f70b-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:55:54.156: INFO: Pod pod-configmaps-860f5348-f70b-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:55:54.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bwckt" for this suite.
Dec  3 14:56:00.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:00.247: INFO: namespace: e2e-tests-secrets-bwckt, resource: bindings, ignored listing per whitelist
Dec  3 14:56:00.449: INFO: namespace e2e-tests-secrets-bwckt deletion completed in 6.28700929s

• [SLOW TEST:10.702 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:56:00.449: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t2gj2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:56:00.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-t2gj2'
Dec  3 14:56:01.040: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 14:56:01.040: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  3 14:56:01.093: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-5qf56]
Dec  3 14:56:01.093: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-5qf56" in namespace "e2e-tests-kubectl-t2gj2" to be "running and ready"
Dec  3 14:56:01.103: INFO: Pod "e2e-test-nginx-rc-5qf56": Phase="Pending", Reason="", readiness=false. Elapsed: 9.33533ms
Dec  3 14:56:03.163: INFO: Pod "e2e-test-nginx-rc-5qf56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069470018s
Dec  3 14:56:05.174: INFO: Pod "e2e-test-nginx-rc-5qf56": Phase="Running", Reason="", readiness=true. Elapsed: 4.080690658s
Dec  3 14:56:05.174: INFO: Pod "e2e-test-nginx-rc-5qf56" satisfied condition "running and ready"
Dec  3 14:56:05.174: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-5qf56]
Dec  3 14:56:05.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-t2gj2'
Dec  3 14:56:05.708: INFO: stderr: ""
Dec  3 14:56:05.708: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Dec  3 14:56:05.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-t2gj2'
Dec  3 14:56:06.078: INFO: stderr: ""
Dec  3 14:56:06.078: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:56:06.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t2gj2" for this suite.
Dec  3 14:56:12.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:12.252: INFO: namespace: e2e-tests-kubectl-t2gj2, resource: bindings, ignored listing per whitelist
Dec  3 14:56:12.348: INFO: namespace e2e-tests-kubectl-t2gj2 deletion completed in 6.262301282s

• [SLOW TEST:11.899 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:56:12.349: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wz42n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:56:12.658: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93852b78-f70b-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-wz42n" to be "success or failure"
Dec  3 14:56:12.665: INFO: Pod "downwardapi-volume-93852b78-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.33054ms
Dec  3 14:56:14.678: INFO: Pod "downwardapi-volume-93852b78-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019556256s
Dec  3 14:56:16.689: INFO: Pod "downwardapi-volume-93852b78-f70b-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031112596s
STEP: Saw pod success
Dec  3 14:56:16.689: INFO: Pod "downwardapi-volume-93852b78-f70b-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:56:16.702: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-93852b78-f70b-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:56:16.747: INFO: Waiting for pod downwardapi-volume-93852b78-f70b-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:56:16.756: INFO: Pod downwardapi-volume-93852b78-f70b-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:56:16.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wz42n" for this suite.
Dec  3 14:56:22.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:22.963: INFO: namespace: e2e-tests-downward-api-wz42n, resource: bindings, ignored listing per whitelist
Dec  3 14:56:23.009: INFO: namespace e2e-tests-downward-api-wz42n deletion completed in 6.242823762s

• [SLOW TEST:10.660 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:56:23.010: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-qzwfv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qzwfv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 14:56:23.375: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 14:56:47.623: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.31.140.101 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-qzwfv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:56:47.624: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:56:48.930: INFO: Found all expected endpoints: [netserver-0]
Dec  3 14:56:48.942: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.31.168.42 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-qzwfv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:56:48.942: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 14:56:50.139: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:56:50.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qzwfv" for this suite.
Dec  3 14:57:14.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:14.285: INFO: namespace: e2e-tests-pod-network-test-qzwfv, resource: bindings, ignored listing per whitelist
Dec  3 14:57:14.370: INFO: namespace e2e-tests-pod-network-test-qzwfv deletion completed in 24.218755002s

• [SLOW TEST:51.360 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:57:14.370: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-8vr5x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  3 14:57:14.689: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-a,UID:b01e0635-f70b-11e8-849a-005056852a45,ResourceVersion:101569,Generation:0,CreationTimestamp:2018-12-03 14:57:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 14:57:14.689: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-a,UID:b01e0635-f70b-11e8-849a-005056852a45,ResourceVersion:101569,Generation:0,CreationTimestamp:2018-12-03 14:57:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  3 14:57:24.710: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-a,UID:b01e0635-f70b-11e8-849a-005056852a45,ResourceVersion:101584,Generation:0,CreationTimestamp:2018-12-03 14:57:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 14:57:24.710: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-a,UID:b01e0635-f70b-11e8-849a-005056852a45,ResourceVersion:101584,Generation:0,CreationTimestamp:2018-12-03 14:57:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  3 14:57:34.731: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-a,UID:b01e0635-f70b-11e8-849a-005056852a45,ResourceVersion:101599,Generation:0,CreationTimestamp:2018-12-03 14:57:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 14:57:34.731: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-a,UID:b01e0635-f70b-11e8-849a-005056852a45,ResourceVersion:101599,Generation:0,CreationTimestamp:2018-12-03 14:57:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  3 14:57:44.744: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-a,UID:b01e0635-f70b-11e8-849a-005056852a45,ResourceVersion:101615,Generation:0,CreationTimestamp:2018-12-03 14:57:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 14:57:44.745: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-a,UID:b01e0635-f70b-11e8-849a-005056852a45,ResourceVersion:101615,Generation:0,CreationTimestamp:2018-12-03 14:57:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  3 14:57:54.763: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-b,UID:c800483a-f70b-11e8-849a-005056852a45,ResourceVersion:101629,Generation:0,CreationTimestamp:2018-12-03 14:57:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 14:57:54.763: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-b,UID:c800483a-f70b-11e8-849a-005056852a45,ResourceVersion:101629,Generation:0,CreationTimestamp:2018-12-03 14:57:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  3 14:58:04.811: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-b,UID:c800483a-f70b-11e8-849a-005056852a45,ResourceVersion:101644,Generation:0,CreationTimestamp:2018-12-03 14:57:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 14:58:04.812: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-8vr5x,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vr5x/configmaps/e2e-watch-test-configmap-b,UID:c800483a-f70b-11e8-849a-005056852a45,ResourceVersion:101644,Generation:0,CreationTimestamp:2018-12-03 14:57:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:58:14.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8vr5x" for this suite.
Dec  3 14:58:20.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:20.969: INFO: namespace: e2e-tests-watch-8vr5x, resource: bindings, ignored listing per whitelist
Dec  3 14:58:21.145: INFO: namespace e2e-tests-watch-8vr5x deletion completed in 6.318421782s

• [SLOW TEST:66.775 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:58:21.146: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cs85g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:58:21.435: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e045674c-f70b-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-cs85g" to be "success or failure"
Dec  3 14:58:21.450: INFO: Pod "downwardapi-volume-e045674c-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.06175ms
Dec  3 14:58:23.464: INFO: Pod "downwardapi-volume-e045674c-f70b-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028249818s
Dec  3 14:58:25.498: INFO: Pod "downwardapi-volume-e045674c-f70b-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06301921s
STEP: Saw pod success
Dec  3 14:58:25.499: INFO: Pod "downwardapi-volume-e045674c-f70b-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 14:58:25.521: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-e045674c-f70b-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 14:58:25.617: INFO: Waiting for pod downwardapi-volume-e045674c-f70b-11e8-a394-16db9a3896d3 to disappear
Dec  3 14:58:25.649: INFO: Pod downwardapi-volume-e045674c-f70b-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:58:25.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cs85g" for this suite.
Dec  3 14:58:31.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:31.781: INFO: namespace: e2e-tests-projected-cs85g, resource: bindings, ignored listing per whitelist
Dec  3 14:58:31.940: INFO: namespace e2e-tests-projected-cs85g deletion completed in 6.264324705s

• [SLOW TEST:10.794 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 14:58:31.943: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kmfrl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  3 14:58:32.217: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  3 14:58:32.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:58:33.276: INFO: stderr: ""
Dec  3 14:58:33.276: INFO: stdout: "service/redis-slave created\n"
Dec  3 14:58:33.277: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  3 14:58:33.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:58:33.813: INFO: stderr: ""
Dec  3 14:58:33.813: INFO: stdout: "service/redis-master created\n"
Dec  3 14:58:33.814: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  3 14:58:33.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:58:34.330: INFO: stderr: ""
Dec  3 14:58:34.330: INFO: stdout: "service/frontend created\n"
Dec  3 14:58:34.330: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  3 14:58:34.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:58:34.856: INFO: stderr: ""
Dec  3 14:58:34.856: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  3 14:58:34.857: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 14:58:34.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:58:35.516: INFO: stderr: ""
Dec  3 14:58:35.516: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  3 14:58:35.516: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  3 14:58:35.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:58:36.043: INFO: stderr: ""
Dec  3 14:58:36.044: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  3 14:58:36.044: INFO: Waiting for all frontend pods to be Running.
Dec  3 14:58:41.095: INFO: Waiting for frontend to serve content.
Dec  3 14:58:41.203: INFO: Trying to add a new entry to the guestbook.
Dec  3 14:58:46.342: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-master:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-mas...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Str in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec  3 14:58:51.385: INFO: Verifying that added entry can be retrieved.
Dec  3 14:58:51.457: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:58:56.492: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:59:01.518: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:59:06.551: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:59:11.592: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:59:16.629: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:59:21.681: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:59:26.715: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:59:31.748: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:59:36.775: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Dec  3 14:59:41.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:59:42.098: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:59:42.098: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:59:42.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:59:42.490: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:59:42.490: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:59:42.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:59:42.735: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:59:42.735: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:59:42.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:59:42.934: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:59:42.934: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:59:42.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:59:43.186: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:59:43.186: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:59:43.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kmfrl'
Dec  3 14:59:43.449: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:59:43.449: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 14:59:43.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kmfrl" for this suite.
Dec  3 15:00:27.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:27.672: INFO: namespace: e2e-tests-kubectl-kmfrl, resource: bindings, ignored listing per whitelist
Dec  3 15:00:27.810: INFO: namespace e2e-tests-kubectl-kmfrl deletion completed in 44.345127956s

• [SLOW TEST:115.868 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:00:27.811: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-fs78k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2bd42bdc-f70c-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 15:00:28.237: INFO: Waiting up to 5m0s for pod "pod-configmaps-2bd57e44-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-fs78k" to be "success or failure"
Dec  3 15:00:28.243: INFO: Pod "pod-configmaps-2bd57e44-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.179892ms
Dec  3 15:00:30.255: INFO: Pod "pod-configmaps-2bd57e44-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018431883s
Dec  3 15:00:32.267: INFO: Pod "pod-configmaps-2bd57e44-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030209956s
STEP: Saw pod success
Dec  3 15:00:32.267: INFO: Pod "pod-configmaps-2bd57e44-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:00:32.276: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-2bd57e44-f70c-11e8-a394-16db9a3896d3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:00:32.355: INFO: Waiting for pod pod-configmaps-2bd57e44-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:00:32.374: INFO: Pod pod-configmaps-2bd57e44-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:00:32.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fs78k" for this suite.
Dec  3 15:00:38.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:38.688: INFO: namespace: e2e-tests-configmap-fs78k, resource: bindings, ignored listing per whitelist
Dec  3 15:00:38.822: INFO: namespace e2e-tests-configmap-fs78k deletion completed in 6.414199863s

• [SLOW TEST:11.011 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:00:38.822: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7k59f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:00:39.142: INFO: Waiting up to 5m0s for pod "downwardapi-volume-325950d7-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-7k59f" to be "success or failure"
Dec  3 15:00:39.156: INFO: Pod "downwardapi-volume-325950d7-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.942921ms
Dec  3 15:00:41.162: INFO: Pod "downwardapi-volume-325950d7-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019910017s
Dec  3 15:00:43.169: INFO: Pod "downwardapi-volume-325950d7-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027018301s
STEP: Saw pod success
Dec  3 15:00:43.169: INFO: Pod "downwardapi-volume-325950d7-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:00:43.177: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-325950d7-f70c-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 15:00:43.251: INFO: Waiting for pod downwardapi-volume-325950d7-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:00:43.261: INFO: Pod downwardapi-volume-325950d7-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:00:43.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7k59f" for this suite.
Dec  3 15:00:49.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:49.339: INFO: namespace: e2e-tests-projected-7k59f, resource: bindings, ignored listing per whitelist
Dec  3 15:00:49.651: INFO: namespace e2e-tests-projected-7k59f deletion completed in 6.379852271s

• [SLOW TEST:10.829 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:00:49.651: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-hw724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  3 15:00:50.100: INFO: PodSpec: initContainers in spec.initContainers
Dec  3 15:01:35.725: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-38e511e2-f70c-11e8-a394-16db9a3896d3", GenerateName:"", Namespace:"e2e-tests-init-container-hw724", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-hw724/pods/pod-init-38e511e2-f70c-11e8-a394-16db9a3896d3", UID:"3084a613-f70c-11e8-849a-005056852a45", ResourceVersion:"102371", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679446036, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"100513786", "name":"foo"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-c9czh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421ab8940), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c9czh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c9czh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c9czh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421cd39d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421983500), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421cd3a70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421cd3a90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421cd3a98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679446050, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679446050, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679446050, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679446036, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.233", PodIP:"172.31.140.106", StartTime:(*v1.Time)(0xc421b90a80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421d56ee0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421d56f50)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://13e7af423239807790940d965e41cd2158fdfa65ed6770588617f308e516e86e"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421b90ac0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421b90aa0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:01:35.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hw724" for this suite.
Dec  3 15:01:57.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:57.835: INFO: namespace: e2e-tests-init-container-hw724, resource: bindings, ignored listing per whitelist
Dec  3 15:01:58.001: INFO: namespace e2e-tests-init-container-hw724 deletion completed in 22.261823862s

• [SLOW TEST:68.350 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:01:58.002: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-c7n8c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  3 15:01:58.282: INFO: Waiting up to 5m0s for pod "client-containers-6186fe30-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-containers-c7n8c" to be "success or failure"
Dec  3 15:01:58.289: INFO: Pod "client-containers-6186fe30-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.283331ms
Dec  3 15:02:00.298: INFO: Pod "client-containers-6186fe30-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016270844s
Dec  3 15:02:02.305: INFO: Pod "client-containers-6186fe30-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023089707s
STEP: Saw pod success
Dec  3 15:02:02.305: INFO: Pod "client-containers-6186fe30-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:02:02.314: INFO: Trying to get logs from node k8s-master-3 pod client-containers-6186fe30-f70c-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 15:02:02.345: INFO: Waiting for pod client-containers-6186fe30-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:02:02.358: INFO: Pod client-containers-6186fe30-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:02:02.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-c7n8c" for this suite.
Dec  3 15:02:08.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:08.504: INFO: namespace: e2e-tests-containers-c7n8c, resource: bindings, ignored listing per whitelist
Dec  3 15:02:08.614: INFO: namespace e2e-tests-containers-c7n8c deletion completed in 6.246720607s

• [SLOW TEST:10.612 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:02:08.614: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-m5v5l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-67e3038b-f70c-11e8-a394-16db9a3896d3
STEP: Creating secret with name s-test-opt-upd-67e30435-f70c-11e8-a394-16db9a3896d3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-67e3038b-f70c-11e8-a394-16db9a3896d3
STEP: Updating secret s-test-opt-upd-67e30435-f70c-11e8-a394-16db9a3896d3
STEP: Creating secret with name s-test-opt-create-67e3046f-f70c-11e8-a394-16db9a3896d3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:02:17.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m5v5l" for this suite.
Dec  3 15:02:39.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:39.447: INFO: namespace: e2e-tests-projected-m5v5l, resource: bindings, ignored listing per whitelist
Dec  3 15:02:39.460: INFO: namespace e2e-tests-projected-m5v5l deletion completed in 22.209965644s

• [SLOW TEST:30.846 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:02:39.461: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-t5rk7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-7a4355de-f70c-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 15:02:39.786: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7a4451e9-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-t5rk7" to be "success or failure"
Dec  3 15:02:39.791: INFO: Pod "pod-projected-configmaps-7a4451e9-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.928026ms
Dec  3 15:02:41.797: INFO: Pod "pod-projected-configmaps-7a4451e9-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010741302s
Dec  3 15:02:43.807: INFO: Pod "pod-projected-configmaps-7a4451e9-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020994686s
STEP: Saw pod success
Dec  3 15:02:43.807: INFO: Pod "pod-projected-configmaps-7a4451e9-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:02:43.819: INFO: Trying to get logs from node k8s-master-3 pod pod-projected-configmaps-7a4451e9-f70c-11e8-a394-16db9a3896d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:02:43.867: INFO: Waiting for pod pod-projected-configmaps-7a4451e9-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:02:43.871: INFO: Pod pod-projected-configmaps-7a4451e9-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:02:43.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t5rk7" for this suite.
Dec  3 15:02:49.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:50.090: INFO: namespace: e2e-tests-projected-t5rk7, resource: bindings, ignored listing per whitelist
Dec  3 15:02:50.120: INFO: namespace e2e-tests-projected-t5rk7 deletion completed in 6.23951547s

• [SLOW TEST:10.660 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:02:50.121: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-h99m9
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-80a158b3-f70c-11e8-a394-16db9a3896d3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:02:54.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h99m9" for this suite.
Dec  3 15:03:16.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:16.769: INFO: namespace: e2e-tests-configmap-h99m9, resource: bindings, ignored listing per whitelist
Dec  3 15:03:16.869: INFO: namespace e2e-tests-configmap-h99m9 deletion completed in 22.298586304s

• [SLOW TEST:26.748 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:03:16.870: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9q8zh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:03:17.211: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9090ed4b-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-9q8zh" to be "success or failure"
Dec  3 15:03:17.224: INFO: Pod "downwardapi-volume-9090ed4b-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.018528ms
Dec  3 15:03:19.233: INFO: Pod "downwardapi-volume-9090ed4b-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022521372s
Dec  3 15:03:21.242: INFO: Pod "downwardapi-volume-9090ed4b-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030675924s
STEP: Saw pod success
Dec  3 15:03:21.242: INFO: Pod "downwardapi-volume-9090ed4b-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:03:21.251: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-9090ed4b-f70c-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 15:03:21.308: INFO: Waiting for pod downwardapi-volume-9090ed4b-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:03:21.313: INFO: Pod downwardapi-volume-9090ed4b-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:03:21.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9q8zh" for this suite.
Dec  3 15:03:27.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:27.548: INFO: namespace: e2e-tests-downward-api-9q8zh, resource: bindings, ignored listing per whitelist
Dec  3 15:03:27.549: INFO: namespace e2e-tests-downward-api-9q8zh deletion completed in 6.21998319s

• [SLOW TEST:10.679 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:03:27.549: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-s89xq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-96ebcafd-f70c-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 15:03:27.877: INFO: Waiting up to 5m0s for pod "pod-secrets-96ece842-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-secrets-s89xq" to be "success or failure"
Dec  3 15:03:27.889: INFO: Pod "pod-secrets-96ece842-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.862704ms
Dec  3 15:03:29.894: INFO: Pod "pod-secrets-96ece842-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017392826s
Dec  3 15:03:31.902: INFO: Pod "pod-secrets-96ece842-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024636182s
STEP: Saw pod success
Dec  3 15:03:31.902: INFO: Pod "pod-secrets-96ece842-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:03:31.909: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-96ece842-f70c-11e8-a394-16db9a3896d3 container secret-env-test: <nil>
STEP: delete the pod
Dec  3 15:03:31.958: INFO: Waiting for pod pod-secrets-96ece842-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:03:31.967: INFO: Pod pod-secrets-96ece842-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:03:31.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s89xq" for this suite.
Dec  3 15:03:38.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:38.149: INFO: namespace: e2e-tests-secrets-s89xq, resource: bindings, ignored listing per whitelist
Dec  3 15:03:38.230: INFO: namespace e2e-tests-secrets-s89xq deletion completed in 6.253007s

• [SLOW TEST:10.681 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:03:38.231: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ssw5k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  3 15:03:38.577: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-442087039 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:03:38.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ssw5k" for this suite.
Dec  3 15:03:44.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:44.845: INFO: namespace: e2e-tests-kubectl-ssw5k, resource: bindings, ignored listing per whitelist
Dec  3 15:03:45.010: INFO: namespace e2e-tests-kubectl-ssw5k deletion completed in 6.21571216s

• [SLOW TEST:6.780 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:03:45.010: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vggt9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1203 15:04:15.937287      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 15:04:15.937: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:04:15.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vggt9" for this suite.
Dec  3 15:04:21.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:22.092: INFO: namespace: e2e-tests-gc-vggt9, resource: bindings, ignored listing per whitelist
Dec  3 15:04:22.186: INFO: namespace e2e-tests-gc-vggt9 deletion completed in 6.235586416s

• [SLOW TEST:37.175 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:04:22.186: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-d2vrl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  3 15:04:22.532: INFO: Waiting up to 5m0s for pod "var-expansion-b78139ea-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-var-expansion-d2vrl" to be "success or failure"
Dec  3 15:04:22.542: INFO: Pod "var-expansion-b78139ea-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.986346ms
Dec  3 15:04:24.553: INFO: Pod "var-expansion-b78139ea-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021418466s
Dec  3 15:04:26.559: INFO: Pod "var-expansion-b78139ea-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02747189s
STEP: Saw pod success
Dec  3 15:04:26.560: INFO: Pod "var-expansion-b78139ea-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:04:26.565: INFO: Trying to get logs from node k8s-master-3 pod var-expansion-b78139ea-f70c-11e8-a394-16db9a3896d3 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:04:26.661: INFO: Waiting for pod var-expansion-b78139ea-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:04:26.668: INFO: Pod var-expansion-b78139ea-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:04:26.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-d2vrl" for this suite.
Dec  3 15:04:32.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:32.841: INFO: namespace: e2e-tests-var-expansion-d2vrl, resource: bindings, ignored listing per whitelist
Dec  3 15:04:32.911: INFO: namespace e2e-tests-var-expansion-d2vrl deletion completed in 6.230836912s

• [SLOW TEST:10.725 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:04:32.911: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-55jjw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 15:04:33.237: INFO: Waiting up to 5m0s for pod "pod-bde187c4-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-emptydir-55jjw" to be "success or failure"
Dec  3 15:04:33.243: INFO: Pod "pod-bde187c4-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.529742ms
Dec  3 15:04:35.251: INFO: Pod "pod-bde187c4-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013369463s
Dec  3 15:04:37.259: INFO: Pod "pod-bde187c4-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02124892s
STEP: Saw pod success
Dec  3 15:04:37.259: INFO: Pod "pod-bde187c4-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:04:37.272: INFO: Trying to get logs from node k8s-node-2 pod pod-bde187c4-f70c-11e8-a394-16db9a3896d3 container test-container: <nil>
STEP: delete the pod
Dec  3 15:04:37.335: INFO: Waiting for pod pod-bde187c4-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:04:37.346: INFO: Pod pod-bde187c4-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:04:37.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-55jjw" for this suite.
Dec  3 15:04:43.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:43.551: INFO: namespace: e2e-tests-emptydir-55jjw, resource: bindings, ignored listing per whitelist
Dec  3 15:04:43.598: INFO: namespace e2e-tests-emptydir-55jjw deletion completed in 6.236105746s

• [SLOW TEST:10.687 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:04:43.598: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-qx7g5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  3 15:04:43.854: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qx7g5,SelfLink:/api/v1/namespaces/e2e-tests-watch-qx7g5/configmaps/e2e-watch-test-watch-closed,UID:bbd26a7a-f70c-11e8-849a-005056852a45,ResourceVersion:103120,Generation:0,CreationTimestamp:2018-12-03 15:04:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:04:43.854: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qx7g5,SelfLink:/api/v1/namespaces/e2e-tests-watch-qx7g5/configmaps/e2e-watch-test-watch-closed,UID:bbd26a7a-f70c-11e8-849a-005056852a45,ResourceVersion:103121,Generation:0,CreationTimestamp:2018-12-03 15:04:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  3 15:04:43.882: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qx7g5,SelfLink:/api/v1/namespaces/e2e-tests-watch-qx7g5/configmaps/e2e-watch-test-watch-closed,UID:bbd26a7a-f70c-11e8-849a-005056852a45,ResourceVersion:103122,Generation:0,CreationTimestamp:2018-12-03 15:04:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:04:43.883: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qx7g5,SelfLink:/api/v1/namespaces/e2e-tests-watch-qx7g5/configmaps/e2e-watch-test-watch-closed,UID:bbd26a7a-f70c-11e8-849a-005056852a45,ResourceVersion:103123,Generation:0,CreationTimestamp:2018-12-03 15:04:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:04:43.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qx7g5" for this suite.
Dec  3 15:04:49.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:50.046: INFO: namespace: e2e-tests-watch-qx7g5, resource: bindings, ignored listing per whitelist
Dec  3 15:04:50.286: INFO: namespace e2e-tests-watch-qx7g5 deletion completed in 6.386702857s

• [SLOW TEST:6.688 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:04:50.287: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-hzjdh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hzjdh A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-hzjdh;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hzjdh A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hzjdh.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hzjdh.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hzjdh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 163.192.101.10.in-addr.arpa. PTR)" && echo OK > /results/10.101.192.163_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 163.192.101.10.in-addr.arpa. PTR)" && echo OK > /results/10.101.192.163_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hzjdh A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-hzjdh;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hzjdh A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-hzjdh.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-hzjdh.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hzjdh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 163.192.101.10.in-addr.arpa. PTR)" && echo OK > /results/10.101.192.163_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 163.192.101.10.in-addr.arpa. PTR)" && echo OK > /results/10.101.192.163_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:05:06.732: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.744: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.752: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-hzjdh from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.766: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.779: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.789: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.798: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.810: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.824: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.836: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.845: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.854: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.870: INFO: Unable to read 10.101.192.163_udp@PTR from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.884: INFO: Unable to read 10.101.192.163_tcp@PTR from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.894: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.911: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.930: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-hzjdh from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.951: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.962: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.969: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.981: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:06.994: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:07.006: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:07.017: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:07.032: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:07.042: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:07.053: INFO: Unable to read 10.101.192.163_udp@PTR from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:07.064: INFO: Unable to read 10.101.192.163_tcp@PTR from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:07.064: INFO: Lookups using e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-hzjdh wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh wheezy_udp@dns-test-service.e2e-tests-dns-hzjdh.svc wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.101.192.163_udp@PTR 10.101.192.163_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-hzjdh jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh jessie_udp@dns-test-service.e2e-tests-dns-hzjdh.svc jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.101.192.163_udp@PTR 10.101.192.163_tcp@PTR]

Dec  3 15:05:16.718: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:16.732: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:16.749: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-hzjdh from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:16.759: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:16.788: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:16.915: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:16.934: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:16.964: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-hzjdh from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:16.984: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.001: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.026: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.042: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.054: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.067: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.087: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.100: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.117: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3: the server could not find the requested resource (get pods dns-test-c846af00-f70c-11e8-a394-16db9a3896d3)
Dec  3 15:05:17.146: INFO: Lookups using e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-hzjdh wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh wheezy_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-hzjdh jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh jessie_udp@dns-test-service.e2e-tests-dns-hzjdh.svc jessie_tcp@dns-test-service.e2e-tests-dns-hzjdh.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-hzjdh.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-hzjdh.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Dec  3 15:05:26.932: INFO: DNS probes using e2e-tests-dns-hzjdh/dns-test-c846af00-f70c-11e8-a394-16db9a3896d3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:05:27.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-hzjdh" for this suite.
Dec  3 15:05:33.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:33.245: INFO: namespace: e2e-tests-dns-hzjdh, resource: bindings, ignored listing per whitelist
Dec  3 15:05:33.330: INFO: namespace e2e-tests-dns-hzjdh deletion completed in 6.296440686s

• [SLOW TEST:43.043 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:05:33.330: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-67868
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e1ded17c-f70c-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 15:05:33.619: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e1e01214-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-67868" to be "success or failure"
Dec  3 15:05:33.626: INFO: Pod "pod-projected-secrets-e1e01214-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.622378ms
Dec  3 15:05:35.633: INFO: Pod "pod-projected-secrets-e1e01214-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013637738s
Dec  3 15:05:37.639: INFO: Pod "pod-projected-secrets-e1e01214-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019668694s
STEP: Saw pod success
Dec  3 15:05:37.639: INFO: Pod "pod-projected-secrets-e1e01214-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:05:37.644: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-secrets-e1e01214-f70c-11e8-a394-16db9a3896d3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:05:37.730: INFO: Waiting for pod pod-projected-secrets-e1e01214-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:05:37.741: INFO: Pod pod-projected-secrets-e1e01214-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:05:37.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-67868" for this suite.
Dec  3 15:05:43.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:43.846: INFO: namespace: e2e-tests-projected-67868, resource: bindings, ignored listing per whitelist
Dec  3 15:05:44.067: INFO: namespace e2e-tests-projected-67868 deletion completed in 6.317561148s

• [SLOW TEST:10.737 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:05:44.068: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-245xv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-e846887b-f70c-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume secrets
Dec  3 15:05:44.380: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e848dc83-f70c-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-245xv" to be "success or failure"
Dec  3 15:05:44.396: INFO: Pod "pod-projected-secrets-e848dc83-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.388696ms
Dec  3 15:05:46.409: INFO: Pod "pod-projected-secrets-e848dc83-f70c-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028587139s
Dec  3 15:05:48.416: INFO: Pod "pod-projected-secrets-e848dc83-f70c-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035589132s
STEP: Saw pod success
Dec  3 15:05:48.416: INFO: Pod "pod-projected-secrets-e848dc83-f70c-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:05:48.422: INFO: Trying to get logs from node k8s-master-3 pod pod-projected-secrets-e848dc83-f70c-11e8-a394-16db9a3896d3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:05:48.525: INFO: Waiting for pod pod-projected-secrets-e848dc83-f70c-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:05:48.549: INFO: Pod pod-projected-secrets-e848dc83-f70c-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:05:48.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-245xv" for this suite.
Dec  3 15:05:54.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:54.764: INFO: namespace: e2e-tests-projected-245xv, resource: bindings, ignored listing per whitelist
Dec  3 15:05:54.954: INFO: namespace e2e-tests-projected-245xv deletion completed in 6.398945532s

• [SLOW TEST:10.887 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:05:54.955: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-bxhf4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 15:06:03.337: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:06:03.351: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 15:06:05.352: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:06:05.359: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 15:06:07.351: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:06:07.364: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 15:06:09.354: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:06:09.361: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 15:06:11.351: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:06:11.357: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 15:06:13.352: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:06:13.360: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:06:13.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bxhf4" for this suite.
Dec  3 15:06:37.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:37.561: INFO: namespace: e2e-tests-container-lifecycle-hook-bxhf4, resource: bindings, ignored listing per whitelist
Dec  3 15:06:37.595: INFO: namespace e2e-tests-container-lifecycle-hook-bxhf4 deletion completed in 24.224763626s

• [SLOW TEST:42.640 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:06:37.595: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zhsd2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-zhsd2/configmap-test-082d68fa-f70d-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 15:06:37.887: INFO: Waiting up to 5m0s for pod "pod-configmaps-082e8f41-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-zhsd2" to be "success or failure"
Dec  3 15:06:37.898: INFO: Pod "pod-configmaps-082e8f41-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.553584ms
Dec  3 15:06:39.904: INFO: Pod "pod-configmaps-082e8f41-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016857574s
Dec  3 15:06:41.912: INFO: Pod "pod-configmaps-082e8f41-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024577734s
STEP: Saw pod success
Dec  3 15:06:41.912: INFO: Pod "pod-configmaps-082e8f41-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:06:41.918: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-082e8f41-f70d-11e8-a394-16db9a3896d3 container env-test: <nil>
STEP: delete the pod
Dec  3 15:06:41.979: INFO: Waiting for pod pod-configmaps-082e8f41-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:06:41.995: INFO: Pod pod-configmaps-082e8f41-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:06:41.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zhsd2" for this suite.
Dec  3 15:06:48.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:48.128: INFO: namespace: e2e-tests-configmap-zhsd2, resource: bindings, ignored listing per whitelist
Dec  3 15:06:48.331: INFO: namespace e2e-tests-configmap-zhsd2 deletion completed in 6.327560378s

• [SLOW TEST:10.736 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:06:48.331: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tk7fn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:06:48.746: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ea609ce-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-tk7fn" to be "success or failure"
Dec  3 15:06:48.758: INFO: Pod "downwardapi-volume-0ea609ce-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009684ms
Dec  3 15:06:50.769: INFO: Pod "downwardapi-volume-0ea609ce-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022933402s
Dec  3 15:06:52.776: INFO: Pod "downwardapi-volume-0ea609ce-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030432308s
STEP: Saw pod success
Dec  3 15:06:52.777: INFO: Pod "downwardapi-volume-0ea609ce-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:06:52.783: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-0ea609ce-f70d-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 15:06:52.835: INFO: Waiting for pod downwardapi-volume-0ea609ce-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:06:52.849: INFO: Pod downwardapi-volume-0ea609ce-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:06:52.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tk7fn" for this suite.
Dec  3 15:06:58.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:59.116: INFO: namespace: e2e-tests-projected-tk7fn, resource: bindings, ignored listing per whitelist
Dec  3 15:06:59.170: INFO: namespace e2e-tests-projected-tk7fn deletion completed in 6.31119681s

• [SLOW TEST:10.839 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:06:59.170: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pgwg9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-151794ec-f70d-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 15:06:59.562: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-15192f31-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-pgwg9" to be "success or failure"
Dec  3 15:06:59.572: INFO: Pod "pod-projected-configmaps-15192f31-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.350512ms
Dec  3 15:07:01.580: INFO: Pod "pod-projected-configmaps-15192f31-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017723577s
Dec  3 15:07:03.587: INFO: Pod "pod-projected-configmaps-15192f31-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024731613s
STEP: Saw pod success
Dec  3 15:07:03.587: INFO: Pod "pod-projected-configmaps-15192f31-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:07:03.601: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-configmaps-15192f31-f70d-11e8-a394-16db9a3896d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:07:03.679: INFO: Waiting for pod pod-projected-configmaps-15192f31-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:07:03.686: INFO: Pod pod-projected-configmaps-15192f31-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:07:03.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pgwg9" for this suite.
Dec  3 15:07:09.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:09.925: INFO: namespace: e2e-tests-projected-pgwg9, resource: bindings, ignored listing per whitelist
Dec  3 15:07:09.999: INFO: namespace e2e-tests-projected-pgwg9 deletion completed in 6.296197658s

• [SLOW TEST:10.829 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:07:10.000: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-ghmbb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 15:07:10.235: INFO: Creating ReplicaSet my-hostname-basic-1b79050d-f70d-11e8-a394-16db9a3896d3
Dec  3 15:07:10.251: INFO: Pod name my-hostname-basic-1b79050d-f70d-11e8-a394-16db9a3896d3: Found 0 pods out of 1
Dec  3 15:07:15.270: INFO: Pod name my-hostname-basic-1b79050d-f70d-11e8-a394-16db9a3896d3: Found 1 pods out of 1
Dec  3 15:07:15.270: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-1b79050d-f70d-11e8-a394-16db9a3896d3" is running
Dec  3 15:07:15.284: INFO: Pod "my-hostname-basic-1b79050d-f70d-11e8-a394-16db9a3896d3-bv8rr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 15:07:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 15:07:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 15:07:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 15:06:56 +0000 UTC Reason: Message:}])
Dec  3 15:07:15.284: INFO: Trying to dial the pod
Dec  3 15:07:20.309: INFO: Controller my-hostname-basic-1b79050d-f70d-11e8-a394-16db9a3896d3: Got expected result from replica 1 [my-hostname-basic-1b79050d-f70d-11e8-a394-16db9a3896d3-bv8rr]: "my-hostname-basic-1b79050d-f70d-11e8-a394-16db9a3896d3-bv8rr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:07:20.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-ghmbb" for this suite.
Dec  3 15:07:26.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:26.520: INFO: namespace: e2e-tests-replicaset-ghmbb, resource: bindings, ignored listing per whitelist
Dec  3 15:07:26.743: INFO: namespace e2e-tests-replicaset-ghmbb deletion completed in 6.423264628s

• [SLOW TEST:16.743 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:07:26.744: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-f29wf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 15:07:27.115: INFO: Waiting up to 5m0s for pod "downward-api-2585f141-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-f29wf" to be "success or failure"
Dec  3 15:07:27.137: INFO: Pod "downward-api-2585f141-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 21.832927ms
Dec  3 15:07:29.169: INFO: Pod "downward-api-2585f141-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054556892s
Dec  3 15:07:31.182: INFO: Pod "downward-api-2585f141-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067381725s
STEP: Saw pod success
Dec  3 15:07:31.182: INFO: Pod "downward-api-2585f141-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:07:31.198: INFO: Trying to get logs from node k8s-master-3 pod downward-api-2585f141-f70d-11e8-a394-16db9a3896d3 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:07:31.247: INFO: Waiting for pod downward-api-2585f141-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:07:31.257: INFO: Pod downward-api-2585f141-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:07:31.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f29wf" for this suite.
Dec  3 15:07:37.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:37.376: INFO: namespace: e2e-tests-downward-api-f29wf, resource: bindings, ignored listing per whitelist
Dec  3 15:07:37.498: INFO: namespace e2e-tests-downward-api-f29wf deletion completed in 6.222575136s

• [SLOW TEST:10.755 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:07:37.499: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-22fvq
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 15:07:37.831: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:07:39.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-22fvq" for this suite.
Dec  3 15:07:45.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:45.087: INFO: namespace: e2e-tests-custom-resource-definition-22fvq, resource: bindings, ignored listing per whitelist
Dec  3 15:07:45.284: INFO: namespace e2e-tests-custom-resource-definition-22fvq deletion completed in 6.265943324s

• [SLOW TEST:7.786 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:07:45.285: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-d4vjw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 15:07:45.664: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Dec  3 15:07:45.680: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-d4vjw/daemonsets","resourceVersion":"103819"},"items":null}

Dec  3 15:07:45.685: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-d4vjw/pods","resourceVersion":"103819"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:07:45.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-d4vjw" for this suite.
Dec  3 15:07:51.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:51.955: INFO: namespace: e2e-tests-daemonsets-d4vjw, resource: bindings, ignored listing per whitelist
Dec  3 15:07:51.969: INFO: namespace e2e-tests-daemonsets-d4vjw deletion completed in 6.255118498s

S [SKIPPING] [6.684 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  3 15:07:45.664: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:07:51.969: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-ndr84
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-vtxg
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:07:52.263: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-vtxg" in namespace "e2e-tests-subpath-ndr84" to be "success or failure"
Dec  3 15:07:52.272: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Pending", Reason="", readiness=false. Elapsed: 8.50809ms
Dec  3 15:07:54.277: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014426936s
Dec  3 15:07:56.285: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021966636s
Dec  3 15:07:58.294: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 6.031073717s
Dec  3 15:08:00.302: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 8.03902073s
Dec  3 15:08:02.308: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 10.045389632s
Dec  3 15:08:04.315: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 12.05192687s
Dec  3 15:08:06.320: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 14.057240468s
Dec  3 15:08:08.328: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 16.064675448s
Dec  3 15:08:10.345: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 18.082136646s
Dec  3 15:08:12.352: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 20.08861922s
Dec  3 15:08:14.357: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 22.094044909s
Dec  3 15:08:16.364: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Running", Reason="", readiness=false. Elapsed: 24.101321055s
Dec  3 15:08:18.371: INFO: Pod "pod-subpath-test-downwardapi-vtxg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.10828063s
STEP: Saw pod success
Dec  3 15:08:18.371: INFO: Pod "pod-subpath-test-downwardapi-vtxg" satisfied condition "success or failure"
Dec  3 15:08:18.377: INFO: Trying to get logs from node k8s-master-3 pod pod-subpath-test-downwardapi-vtxg container test-container-subpath-downwardapi-vtxg: <nil>
STEP: delete the pod
Dec  3 15:08:18.415: INFO: Waiting for pod pod-subpath-test-downwardapi-vtxg to disappear
Dec  3 15:08:18.431: INFO: Pod pod-subpath-test-downwardapi-vtxg no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-vtxg
Dec  3 15:08:18.431: INFO: Deleting pod "pod-subpath-test-downwardapi-vtxg" in namespace "e2e-tests-subpath-ndr84"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:08:18.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ndr84" for this suite.
Dec  3 15:08:24.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:24.740: INFO: namespace: e2e-tests-subpath-ndr84, resource: bindings, ignored listing per whitelist
Dec  3 15:08:24.753: INFO: namespace e2e-tests-subpath-ndr84 deletion completed in 6.306971006s

• [SLOW TEST:32.784 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:08:24.754: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-pqpw2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 15:08:25.114: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  3 15:08:25.132: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  3 15:08:30.143: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 15:08:30.143: INFO: Creating deployment "test-rolling-update-deployment"
Dec  3 15:08:30.158: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  3 15:08:30.173: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  3 15:08:32.188: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  3 15:08:32.194: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679446496, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679446496, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679446496, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679446496, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:08:34.206: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 15:08:34.243: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-pqpw2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pqpw2/deployments/test-rolling-update-deployment,UID:42b63489-f70d-11e8-849a-005056852a45,ResourceVersion:104042,Generation:1,CreationTimestamp:2018-12-03 15:08:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-03 15:08:16 +0000 UTC 2018-12-03 15:08:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-03 15:08:19 +0000 UTC 2018-12-03 15:08:16 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 15:08:34.253: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-pqpw2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pqpw2/replicasets/test-rolling-update-deployment-65b7695dcf,UID:42bc4b10-f70d-11e8-849a-005056852a45,ResourceVersion:104033,Generation:1,CreationTimestamp:2018-12-03 15:08:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 42b63489-f70d-11e8-849a-005056852a45 0xc421c6a547 0xc421c6a548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 15:08:34.253: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  3 15:08:34.254: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-pqpw2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pqpw2/replicasets/test-rolling-update-controller,UID:3fb6e1a7-f70d-11e8-849a-005056852a45,ResourceVersion:104041,Generation:2,CreationTimestamp:2018-12-03 15:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 42b63489-f70d-11e8-849a-005056852a45 0xc421c6a47e 0xc421c6a47f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:08:34.266: INFO: Pod "test-rolling-update-deployment-65b7695dcf-crgrq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-crgrq,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-pqpw2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-pqpw2/pods/test-rolling-update-deployment-65b7695dcf-crgrq,UID:42be7b6d-f70d-11e8-849a-005056852a45,ResourceVersion:104032,Generation:0,CreationTimestamp:2018-12-03 15:08:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 42bc4b10-f70d-11e8-849a-005056852a45 0xc421c6afa7 0xc421c6afa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7hmpj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7hmpj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7hmpj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c6b020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c6b040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:08:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:08:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:08:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:08:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:172.31.168.17,StartTime:2018-12-03 15:08:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-03 15:08:32 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f docker://7aec261151a3191662e15bdbc5319a741775de1e30b90d4e0937c3b7f27be851}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:08:34.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-pqpw2" for this suite.
Dec  3 15:08:40.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:40.309: INFO: namespace: e2e-tests-deployment-pqpw2, resource: bindings, ignored listing per whitelist
Dec  3 15:08:40.422: INFO: namespace e2e-tests-deployment-pqpw2 deletion completed in 6.149021566s

• [SLOW TEST:15.668 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:08:40.422: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-n2k9v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-515ed52b-f70d-11e8-a394-16db9a3896d3
STEP: Creating secret with name secret-projected-all-test-volume-515ed50f-f70d-11e8-a394-16db9a3896d3
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  3 15:08:40.691: INFO: Waiting up to 5m0s for pod "projected-volume-515ed4c3-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-n2k9v" to be "success or failure"
Dec  3 15:08:40.698: INFO: Pod "projected-volume-515ed4c3-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.165022ms
Dec  3 15:08:42.714: INFO: Pod "projected-volume-515ed4c3-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023239085s
Dec  3 15:08:44.725: INFO: Pod "projected-volume-515ed4c3-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034479324s
STEP: Saw pod success
Dec  3 15:08:44.725: INFO: Pod "projected-volume-515ed4c3-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:08:44.744: INFO: Trying to get logs from node k8s-node-2 pod projected-volume-515ed4c3-f70d-11e8-a394-16db9a3896d3 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  3 15:08:44.804: INFO: Waiting for pod projected-volume-515ed4c3-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:08:44.812: INFO: Pod projected-volume-515ed4c3-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:08:44.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n2k9v" for this suite.
Dec  3 15:08:50.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:50.976: INFO: namespace: e2e-tests-projected-n2k9v, resource: bindings, ignored listing per whitelist
Dec  3 15:08:51.040: INFO: namespace e2e-tests-projected-n2k9v deletion completed in 6.219278498s

• [SLOW TEST:10.618 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:08:51.041: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dkjts
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:08:51.315: INFO: Waiting up to 5m0s for pod "downwardapi-volume-57b662b9-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-dkjts" to be "success or failure"
Dec  3 15:08:51.325: INFO: Pod "downwardapi-volume-57b662b9-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.607486ms
Dec  3 15:08:53.345: INFO: Pod "downwardapi-volume-57b662b9-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029345158s
Dec  3 15:08:55.351: INFO: Pod "downwardapi-volume-57b662b9-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035298882s
STEP: Saw pod success
Dec  3 15:08:55.351: INFO: Pod "downwardapi-volume-57b662b9-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:08:55.357: INFO: Trying to get logs from node k8s-master-3 pod downwardapi-volume-57b662b9-f70d-11e8-a394-16db9a3896d3 container client-container: <nil>
STEP: delete the pod
Dec  3 15:08:55.397: INFO: Waiting for pod downwardapi-volume-57b662b9-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:08:55.407: INFO: Pod downwardapi-volume-57b662b9-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:08:55.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dkjts" for this suite.
Dec  3 15:09:01.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:01.585: INFO: namespace: e2e-tests-downward-api-dkjts, resource: bindings, ignored listing per whitelist
Dec  3 15:09:01.649: INFO: namespace e2e-tests-downward-api-dkjts deletion completed in 6.23371535s

• [SLOW TEST:10.608 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:09:01.649: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-47npt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-47npt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:09:01.937: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:09:22.092: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.31.168.58:8080/dial?request=hostName&protocol=udp&host=172.31.168.10&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-47npt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:09:22.092: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 15:09:22.262: INFO: Waiting for endpoints: map[]
Dec  3 15:09:22.270: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.31.168.58:8080/dial?request=hostName&protocol=udp&host=172.31.140.119&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-47npt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:09:22.270: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
Dec  3 15:09:22.452: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:09:22.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-47npt" for this suite.
Dec  3 15:09:46.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:46.555: INFO: namespace: e2e-tests-pod-network-test-47npt, resource: bindings, ignored listing per whitelist
Dec  3 15:09:46.705: INFO: namespace e2e-tests-pod-network-test-47npt deletion completed in 24.239165252s

• [SLOW TEST:45.056 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:09:46.706: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gg7mg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-gg7mg/configmap-test-78eae706-f70d-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 15:09:47.027: INFO: Waiting up to 5m0s for pod "pod-configmaps-78ebe053-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-configmap-gg7mg" to be "success or failure"
Dec  3 15:09:47.032: INFO: Pod "pod-configmaps-78ebe053-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.557266ms
Dec  3 15:09:49.040: INFO: Pod "pod-configmaps-78ebe053-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012910584s
STEP: Saw pod success
Dec  3 15:09:49.041: INFO: Pod "pod-configmaps-78ebe053-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:09:49.055: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-78ebe053-f70d-11e8-a394-16db9a3896d3 container env-test: <nil>
STEP: delete the pod
Dec  3 15:09:49.134: INFO: Waiting for pod pod-configmaps-78ebe053-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:09:49.150: INFO: Pod pod-configmaps-78ebe053-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:09:49.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gg7mg" for this suite.
Dec  3 15:09:55.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:55.288: INFO: namespace: e2e-tests-configmap-gg7mg, resource: bindings, ignored listing per whitelist
Dec  3 15:09:55.366: INFO: namespace e2e-tests-configmap-gg7mg deletion completed in 6.202175725s

• [SLOW TEST:8.661 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:09:55.367: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ggd4m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  3 15:09:55.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 cluster-info'
Dec  3 15:09:56.530: INFO: stderr: ""
Dec  3 15:09:56.530: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:09:56.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ggd4m" for this suite.
Dec  3 15:10:02.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:02.752: INFO: namespace: e2e-tests-kubectl-ggd4m, resource: bindings, ignored listing per whitelist
Dec  3 15:10:02.982: INFO: namespace e2e-tests-kubectl-ggd4m deletion completed in 6.44126454s

• [SLOW TEST:7.615 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:10:02.982: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xmnjf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 15:10:03.331: INFO: Waiting up to 5m0s for pod "downward-api-82a3195b-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-downward-api-xmnjf" to be "success or failure"
Dec  3 15:10:03.342: INFO: Pod "downward-api-82a3195b-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.500776ms
Dec  3 15:10:05.356: INFO: Pod "downward-api-82a3195b-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02477077s
Dec  3 15:10:07.362: INFO: Pod "downward-api-82a3195b-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03112269s
STEP: Saw pod success
Dec  3 15:10:07.362: INFO: Pod "downward-api-82a3195b-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:10:07.377: INFO: Trying to get logs from node k8s-master-3 pod downward-api-82a3195b-f70d-11e8-a394-16db9a3896d3 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:10:07.439: INFO: Waiting for pod downward-api-82a3195b-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:10:07.453: INFO: Pod downward-api-82a3195b-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:10:07.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xmnjf" for this suite.
Dec  3 15:10:13.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:13.744: INFO: namespace: e2e-tests-downward-api-xmnjf, resource: bindings, ignored listing per whitelist
Dec  3 15:10:13.863: INFO: namespace e2e-tests-downward-api-xmnjf deletion completed in 6.402123504s

• [SLOW TEST:10.881 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:10:13.864: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nphdm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-89191997-f70d-11e8-a394-16db9a3896d3
STEP: Creating a pod to test consume configMaps
Dec  3 15:10:14.177: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8919efac-f70d-11e8-a394-16db9a3896d3" in namespace "e2e-tests-projected-nphdm" to be "success or failure"
Dec  3 15:10:14.183: INFO: Pod "pod-projected-configmaps-8919efac-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.547098ms
Dec  3 15:10:16.190: INFO: Pod "pod-projected-configmaps-8919efac-f70d-11e8-a394-16db9a3896d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01303112s
Dec  3 15:10:18.197: INFO: Pod "pod-projected-configmaps-8919efac-f70d-11e8-a394-16db9a3896d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019658704s
STEP: Saw pod success
Dec  3 15:10:18.197: INFO: Pod "pod-projected-configmaps-8919efac-f70d-11e8-a394-16db9a3896d3" satisfied condition "success or failure"
Dec  3 15:10:18.211: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-configmaps-8919efac-f70d-11e8-a394-16db9a3896d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:10:18.259: INFO: Waiting for pod pod-projected-configmaps-8919efac-f70d-11e8-a394-16db9a3896d3 to disappear
Dec  3 15:10:18.268: INFO: Pod pod-projected-configmaps-8919efac-f70d-11e8-a394-16db9a3896d3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:10:18.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nphdm" for this suite.
Dec  3 15:10:24.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:24.347: INFO: namespace: e2e-tests-projected-nphdm, resource: bindings, ignored listing per whitelist
Dec  3 15:10:24.530: INFO: namespace e2e-tests-projected-nphdm deletion completed in 6.253604356s

• [SLOW TEST:10.665 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:10:24.530: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-4h4mj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  3 15:10:24.838: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:10:24.873: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:10:24.881: INFO: 
Logging pods the kubelet thinks is on node k8s-master-3 before test
Dec  3 15:10:24.896: INFO: kubectl-cf7vk from kube-system started at 2018-12-03 04:10:12 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:24.896: INFO: 	Container kubectl ready: true, restart count 0
Dec  3 15:10:24.896: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-03 13:45:48 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:24.896: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 15:10:24.896: INFO: kube-proxy-s9v52 from kube-system started at 2018-12-03 04:08:32 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:24.896: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:10:24.896: INFO: sonobuoy-e2e-job-f27511e7d13f414e from heptio-sonobuoy started at 2018-12-03 13:45:52 +0000 UTC (2 container statuses recorded)
Dec  3 15:10:24.896: INFO: 	Container e2e ready: true, restart count 0
Dec  3 15:10:24.896: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 15:10:24.896: INFO: calico-node-6sjrk from kube-system started at 2018-12-03 06:28:28 +0000 UTC (2 container statuses recorded)
Dec  3 15:10:24.896: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:10:24.896: INFO: 	Container install-cni ready: true, restart count 0
Dec  3 15:10:24.896: INFO: 
Logging pods the kubelet thinks is on node k8s-node-2 before test
Dec  3 15:10:24.908: INFO: kubectl-prk85 from kube-system started at 2018-12-03 04:12:22 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:24.908: INFO: 	Container kubectl ready: true, restart count 0
Dec  3 15:10:24.908: INFO: calico-node-lps99 from kube-system started at 2018-12-03 06:28:28 +0000 UTC (2 container statuses recorded)
Dec  3 15:10:24.908: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:10:24.908: INFO: 	Container install-cni ready: true, restart count 0
Dec  3 15:10:24.908: INFO: kube-proxy-54j8t from kube-system started at 2018-12-03 04:10:52 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:24.908: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-91efc8e7-f70d-11e8-a394-16db9a3896d3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-91efc8e7-f70d-11e8-a394-16db9a3896d3 off the node k8s-master-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-91efc8e7-f70d-11e8-a394-16db9a3896d3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:10:33.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4h4mj" for this suite.
Dec  3 15:10:43.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:43.276: INFO: namespace: e2e-tests-sched-pred-4h4mj, resource: bindings, ignored listing per whitelist
Dec  3 15:10:43.367: INFO: namespace e2e-tests-sched-pred-4h4mj deletion completed in 10.240647414s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:18.838 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:10:43.368: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-7q79p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7q79p
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-7q79p
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-7q79p
Dec  3 15:10:43.712: INFO: Found 0 stateful pods, waiting for 1
Dec  3 15:10:53.744: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  3 15:10:53.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-7q79p ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:10:54.167: INFO: stderr: ""
Dec  3 15:10:54.167: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:10:54.167: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:10:54.182: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 15:11:04.190: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:11:04.190: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:11:04.229: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998748s
Dec  3 15:11:05.244: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991822486s
Dec  3 15:11:06.258: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.976414304s
Dec  3 15:11:07.266: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.962265044s
Dec  3 15:11:08.275: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.95425887s
Dec  3 15:11:09.290: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.945119056s
Dec  3 15:11:10.295: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.930954354s
Dec  3 15:11:11.305: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.925334602s
Dec  3 15:11:12.313: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.915938216s
Dec  3 15:11:13.321: INFO: Verifying statefulset ss doesn't scale past 1 for another 907.15206ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-7q79p
Dec  3 15:11:14.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-7q79p ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:11:14.714: INFO: stderr: ""
Dec  3 15:11:14.715: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:11:14.715: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:11:14.724: INFO: Found 1 stateful pods, waiting for 3
Dec  3 15:11:24.732: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:11:24.732: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:11:24.732: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  3 15:11:24.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-7q79p ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:11:25.114: INFO: stderr: ""
Dec  3 15:11:25.114: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:11:25.114: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:11:25.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-7q79p ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:11:25.635: INFO: stderr: ""
Dec  3 15:11:25.635: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:11:25.635: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:11:25.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-7q79p ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:11:26.034: INFO: stderr: ""
Dec  3 15:11:26.034: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:11:26.034: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:11:26.034: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:11:26.052: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 15:11:36.070: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:11:36.071: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:11:36.071: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:11:36.110: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998495s
Dec  3 15:11:37.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.983630492s
Dec  3 15:11:38.126: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.975363017s
Dec  3 15:11:39.134: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.967436517s
Dec  3 15:11:40.143: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.959479872s
Dec  3 15:11:41.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.951168999s
Dec  3 15:11:42.160: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.943685017s
Dec  3 15:11:43.176: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.93366021s
Dec  3 15:11:44.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.917216329s
Dec  3 15:11:45.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 906.555909ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-7q79p
Dec  3 15:11:46.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-7q79p ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:11:46.602: INFO: stderr: ""
Dec  3 15:11:46.602: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:11:46.602: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:11:46.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-7q79p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:11:47.043: INFO: stderr: ""
Dec  3 15:11:47.043: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:11:47.043: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:11:47.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 exec --namespace=e2e-tests-statefulset-7q79p ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:11:47.526: INFO: stderr: ""
Dec  3 15:11:47.526: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:11:47.526: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:11:47.526: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 15:12:07.565: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7q79p
Dec  3 15:12:07.575: INFO: Scaling statefulset ss to 0
Dec  3 15:12:07.599: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:12:07.606: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:12:07.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7q79p" for this suite.
Dec  3 15:12:13.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:12:13.815: INFO: namespace: e2e-tests-statefulset-7q79p, resource: bindings, ignored listing per whitelist
Dec  3 15:12:14.010: INFO: namespace e2e-tests-statefulset-7q79p deletion completed in 6.358304744s

• [SLOW TEST:90.642 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:12:14.011: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-f8fcd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-4ckrz
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec  3 15:12:18.596: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-bkdtk
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:12:42.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-f8fcd" for this suite.
Dec  3 15:12:48.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:12:48.926: INFO: namespace: e2e-tests-namespaces-f8fcd, resource: bindings, ignored listing per whitelist
Dec  3 15:12:49.080: INFO: namespace e2e-tests-namespaces-f8fcd deletion completed in 6.231495485s
STEP: Destroying namespace "e2e-tests-nsdeletetest-4ckrz" for this suite.
Dec  3 15:12:49.088: INFO: Namespace e2e-tests-nsdeletetest-4ckrz was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-bkdtk" for this suite.
Dec  3 15:12:55.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:12:55.166: INFO: namespace: e2e-tests-nsdeletetest-bkdtk, resource: bindings, ignored listing per whitelist
Dec  3 15:12:55.322: INFO: namespace e2e-tests-nsdeletetest-bkdtk deletion completed in 6.233819144s

• [SLOW TEST:41.312 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:12:55.323: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tpp7n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Dec  3 15:12:55.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 create -f - --namespace=e2e-tests-kubectl-tpp7n'
Dec  3 15:12:56.027: INFO: stderr: ""
Dec  3 15:12:56.027: INFO: stdout: "pod/pause created\n"
Dec  3 15:12:56.027: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  3 15:12:56.027: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-tpp7n" to be "running and ready"
Dec  3 15:12:56.044: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 17.09302ms
Dec  3 15:12:58.063: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035893497s
Dec  3 15:13:00.069: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.042365592s
Dec  3 15:13:00.069: INFO: Pod "pause" satisfied condition "running and ready"
Dec  3 15:13:00.070: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  3 15:13:00.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-tpp7n'
Dec  3 15:13:00.335: INFO: stderr: ""
Dec  3 15:13:00.335: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  3 15:13:00.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pod pause -L testing-label --namespace=e2e-tests-kubectl-tpp7n'
Dec  3 15:13:00.568: INFO: stderr: ""
Dec  3 15:13:00.568: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  3 15:13:00.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 label pods pause testing-label- --namespace=e2e-tests-kubectl-tpp7n'
Dec  3 15:13:00.857: INFO: stderr: ""
Dec  3 15:13:00.857: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  3 15:13:00.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pod pause -L testing-label --namespace=e2e-tests-kubectl-tpp7n'
Dec  3 15:13:01.102: INFO: stderr: ""
Dec  3 15:13:01.103: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          6s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Dec  3 15:13:01.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tpp7n'
Dec  3 15:13:01.322: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:13:01.322: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  3 15:13:01.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-tpp7n'
Dec  3 15:13:01.515: INFO: stderr: "No resources found.\n"
Dec  3 15:13:01.515: INFO: stdout: ""
Dec  3 15:13:01.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-442087039 get pods -l name=pause --namespace=e2e-tests-kubectl-tpp7n -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:13:01.810: INFO: stderr: ""
Dec  3 15:13:01.810: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:13:01.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tpp7n" for this suite.
Dec  3 15:13:07.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:08.020: INFO: namespace: e2e-tests-kubectl-tpp7n, resource: bindings, ignored listing per whitelist
Dec  3 15:13:08.034: INFO: namespace e2e-tests-kubectl-tpp7n deletion completed in 6.214428797s

• [SLOW TEST:12.711 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:13:08.034: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cr9p8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  3 15:13:10.958: INFO: Successfully updated pod "labelsupdatef0f04deb-f70d-11e8-a394-16db9a3896d3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:13:12.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cr9p8" for this suite.
Dec  3 15:13:37.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:37.055: INFO: namespace: e2e-tests-downward-api-cr9p8, resource: bindings, ignored listing per whitelist
Dec  3 15:13:37.272: INFO: namespace e2e-tests-downward-api-cr9p8 deletion completed in 24.263876015s

• [SLOW TEST:29.238 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:13:37.273: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-lwk8k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  3 15:13:37.535: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:13:37.550: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:13:37.555: INFO: 
Logging pods the kubelet thinks is on node k8s-master-3 before test
Dec  3 15:13:37.566: INFO: kubectl-cf7vk from kube-system started at 2018-12-03 04:10:12 +0000 UTC (1 container statuses recorded)
Dec  3 15:13:37.566: INFO: 	Container kubectl ready: true, restart count 0
Dec  3 15:13:37.566: INFO: kube-proxy-s9v52 from kube-system started at 2018-12-03 04:08:32 +0000 UTC (1 container statuses recorded)
Dec  3 15:13:37.566: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:13:37.566: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-03 13:45:48 +0000 UTC (1 container statuses recorded)
Dec  3 15:13:37.566: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 15:13:37.566: INFO: calico-node-6sjrk from kube-system started at 2018-12-03 06:28:28 +0000 UTC (2 container statuses recorded)
Dec  3 15:13:37.566: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:13:37.566: INFO: 	Container install-cni ready: true, restart count 0
Dec  3 15:13:37.566: INFO: sonobuoy-e2e-job-f27511e7d13f414e from heptio-sonobuoy started at 2018-12-03 13:45:52 +0000 UTC (2 container statuses recorded)
Dec  3 15:13:37.566: INFO: 	Container e2e ready: true, restart count 0
Dec  3 15:13:37.566: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 15:13:37.566: INFO: 
Logging pods the kubelet thinks is on node k8s-node-2 before test
Dec  3 15:13:37.581: INFO: kubectl-prk85 from kube-system started at 2018-12-03 04:12:22 +0000 UTC (1 container statuses recorded)
Dec  3 15:13:37.581: INFO: 	Container kubectl ready: true, restart count 0
Dec  3 15:13:37.581: INFO: calico-node-lps99 from kube-system started at 2018-12-03 06:28:28 +0000 UTC (2 container statuses recorded)
Dec  3 15:13:37.581: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:13:37.581: INFO: 	Container install-cni ready: true, restart count 0
Dec  3 15:13:37.581: INFO: kube-proxy-54j8t from kube-system started at 2018-12-03 04:10:52 +0000 UTC (1 container statuses recorded)
Dec  3 15:13:37.581: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156cdb6606f278c9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:13:38.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-lwk8k" for this suite.
Dec  3 15:13:44.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:44.827: INFO: namespace: e2e-tests-sched-pred-lwk8k, resource: bindings, ignored listing per whitelist
Dec  3 15:13:44.858: INFO: namespace e2e-tests-sched-pred-lwk8k deletion completed in 6.211532715s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.585 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:13:44.858: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-2xrz5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-2xrz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2xrz5 to expose endpoints map[]
Dec  3 15:13:45.126: INFO: Get endpoints failed (11.92236ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  3 15:13:46.131: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2xrz5 exposes endpoints map[] (1.016952623s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-2xrz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2xrz5 to expose endpoints map[pod1:[100]]
Dec  3 15:13:49.207: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2xrz5 exposes endpoints map[pod1:[100]] (3.061565026s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-2xrz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2xrz5 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  3 15:13:52.336: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2xrz5 exposes endpoints map[pod1:[100] pod2:[101]] (3.105592735s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-2xrz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2xrz5 to expose endpoints map[pod2:[101]]
Dec  3 15:13:53.412: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2xrz5 exposes endpoints map[pod2:[101]] (1.052841925s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-2xrz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2xrz5 to expose endpoints map[]
Dec  3 15:13:53.450: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2xrz5 exposes endpoints map[] (19.107431ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:13:53.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2xrz5" for this suite.
Dec  3 15:14:17.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:17.738: INFO: namespace: e2e-tests-services-2xrz5, resource: bindings, ignored listing per whitelist
Dec  3 15:14:17.817: INFO: namespace e2e-tests-services-2xrz5 deletion completed in 24.212584592s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:32.959 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 15:14:17.818: INFO: >>> kubeConfig: /tmp/kubeconfig-442087039
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-926lt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 15:14:18.091: INFO: Creating deployment "nginx-deployment"
Dec  3 15:14:18.104: INFO: Waiting for observed generation 1
Dec  3 15:14:20.127: INFO: Waiting for all required pods to come up
Dec  3 15:14:20.146: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  3 15:14:28.176: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  3 15:14:28.201: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  3 15:14:28.227: INFO: Updating deployment nginx-deployment
Dec  3 15:14:28.227: INFO: Waiting for observed generation 2
Dec  3 15:14:30.272: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  3 15:14:30.277: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  3 15:14:30.286: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  3 15:14:30.317: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  3 15:14:30.317: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  3 15:14:30.327: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  3 15:14:30.339: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  3 15:14:30.339: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  3 15:14:30.363: INFO: Updating deployment nginx-deployment
Dec  3 15:14:30.363: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  3 15:14:30.408: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  3 15:14:30.499: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 15:14:32.558: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-926lt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-926lt/deployments/nginx-deployment,UID:1216d774-f70e-11e8-849a-005056852a45,ResourceVersion:105755,Generation:3,CreationTimestamp:2018-12-03 15:14:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-12-03 15:14:16 +0000 UTC 2018-12-03 15:14:16 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-03 15:14:16 +0000 UTC 2018-12-03 15:14:04 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  3 15:14:32.564: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-926lt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-926lt/replicasets/nginx-deployment-7dc8f79789,UID:18239993-f70e-11e8-849a-005056852a45,ResourceVersion:105746,Generation:3,CreationTimestamp:2018-12-03 15:14:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 1216d774-f70e-11e8-849a-005056852a45 0xc422001517 0xc422001518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:14:32.564: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  3 15:14:32.565: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-926lt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-926lt/replicasets/nginx-deployment-7f9675fb8b,UID:121a0ba4-f70e-11e8-849a-005056852a45,ResourceVersion:105743,Generation:3,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 1216d774-f70e-11e8-849a-005056852a45 0xc4220015d7 0xc4220015d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  3 15:14:32.583: INFO: Pod "nginx-deployment-7dc8f79789-4slwp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4slwp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-4slwp,UID:1972733e-f70e-11e8-849a-005056852a45,ResourceVersion:105802,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc422001f37 0xc422001f38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422001fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422001fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.583: INFO: Pod "nginx-deployment-7dc8f79789-5dtc2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5dtc2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-5dtc2,UID:182dff22-f70e-11e8-849a-005056852a45,ResourceVersion:105655,Generation:0,CreationTimestamp:2018-12-03 15:14:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc420234180 0xc420234181}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420234200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420234220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:14 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.583: INFO: Pod "nginx-deployment-7dc8f79789-5g46x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5g46x,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-5g46x,UID:1987108b-f70e-11e8-849a-005056852a45,ResourceVersion:105741,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc4202342e0 0xc4202342e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420234380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4202344e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.584: INFO: Pod "nginx-deployment-7dc8f79789-9jwhz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9jwhz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-9jwhz,UID:197f0cf0-f70e-11e8-849a-005056852a45,ResourceVersion:105766,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc420234570 0xc420234571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420234730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420234750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.584: INFO: Pod "nginx-deployment-7dc8f79789-cb624" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cb624,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-cb624,UID:18474eba-f70e-11e8-849a-005056852a45,ResourceVersion:105670,Generation:0,CreationTimestamp:2018-12-03 15:14:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc420234810 0xc420234811}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420234930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420234960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:14 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.584: INFO: Pod "nginx-deployment-7dc8f79789-fpz8n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fpz8n,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-fpz8n,UID:182a02c1-f70e-11e8-849a-005056852a45,ResourceVersion:105653,Generation:0,CreationTimestamp:2018-12-03 15:14:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc420234b20 0xc420234b21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420234d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420234dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:14 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.584: INFO: Pod "nginx-deployment-7dc8f79789-ppcj6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ppcj6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-ppcj6,UID:182701a7-f70e-11e8-849a-005056852a45,ResourceVersion:105652,Generation:0,CreationTimestamp:2018-12-03 15:14:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc4202350a0 0xc4202350a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4202353e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4202354d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:14 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.585: INFO: Pod "nginx-deployment-7dc8f79789-qkxjf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qkxjf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-qkxjf,UID:1849195c-f70e-11e8-849a-005056852a45,ResourceVersion:105674,Generation:0,CreationTimestamp:2018-12-03 15:14:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc4202356d0 0xc4202356d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420235750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420235770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:14 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.585: INFO: Pod "nginx-deployment-7dc8f79789-t74mx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-t74mx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-t74mx,UID:196de473-f70e-11e8-849a-005056852a45,ResourceVersion:105732,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc420235830 0xc420235831}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420235930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420235950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.586: INFO: Pod "nginx-deployment-7dc8f79789-vp6dj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vp6dj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-vp6dj,UID:197e89eb-f70e-11e8-849a-005056852a45,ResourceVersion:105805,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc420235a10 0xc420235a11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420235a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420235ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.586: INFO: Pod "nginx-deployment-7dc8f79789-x76nw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-x76nw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-x76nw,UID:19741d29-f70e-11e8-849a-005056852a45,ResourceVersion:105751,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc420235c20 0xc420235c21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420235de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9a010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.586: INFO: Pod "nginx-deployment-7dc8f79789-z52lj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-z52lj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-z52lj,UID:197e87e3-f70e-11e8-849a-005056852a45,ResourceVersion:105726,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc421b9a0d0 0xc421b9a0d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9a150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9a170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.587: INFO: Pod "nginx-deployment-7dc8f79789-zsh4w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zsh4w,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7dc8f79789-zsh4w,UID:197eed85-f70e-11e8-849a-005056852a45,ResourceVersion:105736,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 18239993-f70e-11e8-849a-005056852a45 0xc421b9a1f0 0xc421b9a1f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9a280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9a3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.587: INFO: Pod "nginx-deployment-7f9675fb8b-2f7lr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2f7lr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-2f7lr,UID:196b2557-f70e-11e8-849a-005056852a45,ResourceVersion:105700,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9a470 0xc421b9a471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9a4e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9a500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.587: INFO: Pod "nginx-deployment-7f9675fb8b-4s27j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4s27j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-4s27j,UID:19847c54-f70e-11e8-849a-005056852a45,ResourceVersion:105778,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9a5d7 0xc421b9a5d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9a6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9a700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.588: INFO: Pod "nginx-deployment-7f9675fb8b-4tmhv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4tmhv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-4tmhv,UID:197c0635-f70e-11e8-849a-005056852a45,ResourceVersion:105764,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9a7b7 0xc421b9a7b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9a830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9a850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.592: INFO: Pod "nginx-deployment-7f9675fb8b-74m9c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-74m9c,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-74m9c,UID:12291cdc-f70e-11e8-849a-005056852a45,ResourceVersion:105605,Generation:0,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9aad7 0xc421b9aad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9ab60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9ab80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:172.31.140.66,StartTime:2018-12-03 15:14:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 15:14:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://6629575d418f516faf125ad716fd590700fce3e5be08dc3d17049a381e039e5e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.592: INFO: Pod "nginx-deployment-7f9675fb8b-8hfc6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8hfc6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-8hfc6,UID:196f904b-f70e-11e8-849a-005056852a45,ResourceVersion:105801,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9ad57 0xc421b9ad58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9add0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9adf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.593: INFO: Pod "nginx-deployment-7f9675fb8b-bx9qm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bx9qm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-bx9qm,UID:1222fbc5-f70e-11e8-849a-005056852a45,ResourceVersion:105590,Generation:0,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9aea7 0xc421b9aea8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9af20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9af40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:172.31.168.13,StartTime:2018-12-03 15:14:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 15:14:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://c8432909feaa3a04b98806f91d31f353559845c17e444508c4a7e6a68e0ea315}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.593: INFO: Pod "nginx-deployment-7f9675fb8b-c7p8s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-c7p8s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-c7p8s,UID:197a1ca6-f70e-11e8-849a-005056852a45,ResourceVersion:105809,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9b047 0xc421b9b048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9b0d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9b0f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.593: INFO: Pod "nginx-deployment-7f9675fb8b-cdr2d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cdr2d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-cdr2d,UID:197b91d0-f70e-11e8-849a-005056852a45,ResourceVersion:105804,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9b1b7 0xc421b9b1b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9b260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9b290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.593: INFO: Pod "nginx-deployment-7f9675fb8b-dx8sq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dx8sq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-dx8sq,UID:1983c68d-f70e-11e8-849a-005056852a45,ResourceVersion:105771,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9b347 0xc421b9b348}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9b3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9b3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.597: INFO: Pod "nginx-deployment-7f9675fb8b-g28pj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-g28pj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-g28pj,UID:1984448e-f70e-11e8-849a-005056852a45,ResourceVersion:105794,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9b547 0xc421b9b548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9b5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9b5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:,StartTime:2018-12-03 15:14:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.597: INFO: Pod "nginx-deployment-7f9675fb8b-gcsmd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gcsmd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-gcsmd,UID:122365f5-f70e-11e8-849a-005056852a45,ResourceVersion:105587,Generation:0,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9b9b7 0xc421b9b9b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9ba30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9ba50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:172.31.168.11,StartTime:2018-12-03 15:14:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 15:14:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://92ff21cc07d8e4508ac62c66b6faa515e75f9c59bcf3de73c5ca1d68bc234d2e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.597: INFO: Pod "nginx-deployment-7f9675fb8b-h29cd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h29cd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-h29cd,UID:1222ea69-f70e-11e8-849a-005056852a45,ResourceVersion:105602,Generation:0,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421b9be07 0xc421b9be08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b9bef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b9bf10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:172.31.140.127,StartTime:2018-12-03 15:14:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 15:14:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://f30d60e2262bf06670c90cb3a6d29d14a1e827ab1e22e804cc8cfc85e2fb2e5a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.598: INFO: Pod "nginx-deployment-7f9675fb8b-jxs5x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jxs5x,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-jxs5x,UID:19840fec-f70e-11e8-849a-005056852a45,ResourceVersion:105739,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421878057 0xc421878058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218780d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218780f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.598: INFO: Pod "nginx-deployment-7f9675fb8b-qnclk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qnclk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-qnclk,UID:1984094f-f70e-11e8-849a-005056852a45,ResourceVersion:105738,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421878170 0xc421878171}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421878220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421878240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.599: INFO: Pod "nginx-deployment-7f9675fb8b-tt7r8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tt7r8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-tt7r8,UID:196f6949-f70e-11e8-849a-005056852a45,ResourceVersion:105800,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc4218782b0 0xc4218782b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421878320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421878340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.599: INFO: Pod "nginx-deployment-7f9675fb8b-vldrd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vldrd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-vldrd,UID:121e3e99-f70e-11e8-849a-005056852a45,ResourceVersion:105614,Generation:0,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421878407 0xc421878408}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421878480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218784a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:172.31.168.1,StartTime:2018-12-03 15:14:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 15:14:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://b42e03889749db08d050fdb6fbb88e316653b0b4ddcffb36009a85b7e11edd03}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.599: INFO: Pod "nginx-deployment-7f9675fb8b-wppfj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wppfj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-wppfj,UID:1229fb35-f70e-11e8-849a-005056852a45,ResourceVersion:105596,Generation:0,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421878567 0xc421878568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421878610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421878630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:172.31.140.125,StartTime:2018-12-03 15:14:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 15:14:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://8c3d0d5d69028b1194cf86f6c554546e306967046a3e807980af07e7fe29b616}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.600: INFO: Pod "nginx-deployment-7f9675fb8b-z2h7v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z2h7v,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-z2h7v,UID:1977109d-f70e-11e8-849a-005056852a45,ResourceVersion:105803,Generation:0,CreationTimestamp:2018-12-03 15:14:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421878867 0xc421878868}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421878910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421879160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.237,PodIP:,StartTime:2018-12-03 15:14:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.600: INFO: Pod "nginx-deployment-7f9675fb8b-z7dxc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z7dxc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-z7dxc,UID:1223707c-f70e-11e8-849a-005056852a45,ResourceVersion:105582,Generation:0,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc4218792e7 0xc4218792e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218796b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421879750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:172.31.140.65,StartTime:2018-12-03 15:14:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 15:14:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://2ac1f844db0dc742784b32a2f9b394265095a4a5c0abff4088f94482f195f275}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 15:14:32.600: INFO: Pod "nginx-deployment-7f9675fb8b-zfbkw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zfbkw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-926lt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-926lt/pods/nginx-deployment-7f9675fb8b-zfbkw,UID:121f7db7-f70e-11e8-849a-005056852a45,ResourceVersion:105598,Generation:0,CreationTimestamp:2018-12-03 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 121a0ba4-f70e-11e8-849a-005056852a45 0xc421879897 0xc421879898}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rn2r4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rn2r4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rn2r4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421879b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421879b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.233,PodIP:172.31.140.126,StartTime:2018-12-03 15:14:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 15:14:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://3cbeb11cc2171e45f8c9be17c6fb5a3a0bf76995f78e476e8fc17f13ee90526a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 15:14:32.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-926lt" for this suite.
Dec  3 15:14:40.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:40.919: INFO: namespace: e2e-tests-deployment-926lt, resource: bindings, ignored listing per whitelist
Dec  3 15:14:41.000: INFO: namespace e2e-tests-deployment-926lt deletion completed in 8.371059831s

• [SLOW TEST:23.183 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
Dec  3 15:14:41.001: INFO: Running AfterSuite actions on all node
Dec  3 15:14:41.003: INFO: Running AfterSuite actions on node 1
Dec  3 15:14:41.003: INFO: Skipping dumping logs from cluster

Ran 186 of 1814 Specs in 5321.467 seconds
SUCCESS! -- 186 Passed | 0 Failed | 0 Pending | 1628 Skipped PASS

Ginkgo ran 1 suite in 1h28m44.062421268s
Test Suite Passed
