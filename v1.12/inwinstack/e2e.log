Dec  8 15:39:15.931: INFO: Overriding default scale value of zero to 1
Dec  8 15:39:15.931: INFO: Overriding default milliseconds value of zero to 5000
I1208 15:39:16.253395      20 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-260986308
I1208 15:39:16.253463      20 e2e.go:304] Starting e2e run "6b504022-faff-11e8-b692-aec8003d5667" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544283555 - Will randomize all specs
Will run 188 of 1814 specs

Dec  8 15:39:16.349: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 15:39:16.350: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  8 15:39:16.360: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  8 15:39:16.388: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  8 15:39:16.388: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec  8 15:39:16.388: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  8 15:39:16.395: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  8 15:39:16.395: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  8 15:39:16.395: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset-1.12' (0 seconds elapsed)
Dec  8 15:39:16.395: INFO: e2e test version: v1.12.1
Dec  8 15:39:16.397: INFO: kube-apiserver version: v1.12.3
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:39:16.397: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename gc
Dec  8 15:39:16.914: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1208 15:39:27.757146      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 15:39:27.757: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:39:27.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cp9gc" for this suite.
Dec  8 15:39:36.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:39:36.984: INFO: namespace: e2e-tests-gc-cp9gc, resource: bindings, ignored listing per whitelist
Dec  8 15:39:37.074: INFO: namespace e2e-tests-gc-cp9gc deletion completed in 9.299687336s

• [SLOW TEST:20.677 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:39:37.074: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 15:39:37.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 version --client'
Dec  8 15:39:37.907: INFO: stderr: ""
Dec  8 15:39:37.907: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  8 15:39:37.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-p98b7'
Dec  8 15:39:43.239: INFO: stderr: ""
Dec  8 15:39:43.239: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  8 15:39:43.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-p98b7'
Dec  8 15:39:47.462: INFO: stderr: ""
Dec  8 15:39:47.462: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 15:39:48.467: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:39:48.467: INFO: Found 0 / 1
Dec  8 15:39:49.468: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:39:49.468: INFO: Found 0 / 1
Dec  8 15:39:50.476: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:39:50.476: INFO: Found 0 / 1
Dec  8 15:39:51.475: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:39:51.475: INFO: Found 1 / 1
Dec  8 15:39:51.475: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 15:39:51.479: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:39:51.479: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 15:39:51.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 describe pod redis-master-jb5cx --namespace=e2e-tests-kubectl-p98b7'
Dec  8 15:39:51.556: INFO: stderr: ""
Dec  8 15:39:51.556: INFO: stdout: "Name:               redis-master-jb5cx\nNamespace:          e2e-tests-kubectl-p98b7\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s-g2/172.22.132.14\nStart Time:         Sat, 08 Dec 2018 15:39:43 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.244.3.18/32\nStatus:             Running\nIP:                 10.244.3.18\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://2d727db55266dfa267df31e779be58d51454d8e1a2ace17debb5757d54b13ee8\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 08 Dec 2018 15:39:50 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-j4q44 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-j4q44:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-j4q44\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  8s    default-scheduler  Successfully assigned e2e-tests-kubectl-p98b7/redis-master-jb5cx to k8s-g2\n  Normal  Pulling    5s    kubelet, k8s-g2    pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, k8s-g2    Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, k8s-g2    Created container\n  Normal  Started    0s    kubelet, k8s-g2    Started container\n"
Dec  8 15:39:51.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 describe rc redis-master --namespace=e2e-tests-kubectl-p98b7'
Dec  8 15:39:51.640: INFO: stderr: ""
Dec  8 15:39:51.640: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-p98b7\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  8s    replication-controller  Created pod: redis-master-jb5cx\n"
Dec  8 15:39:51.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 describe service redis-master --namespace=e2e-tests-kubectl-p98b7'
Dec  8 15:39:51.716: INFO: stderr: ""
Dec  8 15:39:51.716: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-p98b7\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.109.50.220\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.3.18:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  8 15:39:51.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 describe node k8s-g1'
Dec  8 15:39:51.811: INFO: stderr: ""
Dec  8 15:39:51.811: INFO: stdout: "Name:               k8s-g1\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=k8s-g1\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 172.22.132.13/24\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 08 Dec 2018 15:12:21 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Sat, 08 Dec 2018 15:39:42 +0000   Sat, 08 Dec 2018 15:12:21 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Sat, 08 Dec 2018 15:39:42 +0000   Sat, 08 Dec 2018 15:12:21 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 08 Dec 2018 15:39:42 +0000   Sat, 08 Dec 2018 15:12:21 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 08 Dec 2018 15:39:42 +0000   Sat, 08 Dec 2018 15:12:21 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 08 Dec 2018 15:39:42 +0000   Sat, 08 Dec 2018 15:13:12 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.22.132.13\n  Hostname:    k8s-g1\nCapacity:\n cpu:                4\n ephemeral-storage:  961302540Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16365776Ki\n nvidia.com/gpu:     1\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  885936419398\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16263376Ki\n nvidia.com/gpu:     1\n pods:               110\nSystem Info:\n Machine ID:                 5d9197e8949045c890fc367ea7126bc2\n System UUID:                00000000-0000-0000-0000-448A5BA4BD34\n Boot ID:                    9b22f364-d7cf-4023-bf5a-9f64e88a9c02\n Kernel Version:             4.4.0-138-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.3.0\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nPodCIDR:                     10.244.4.0/24\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-e2e-job-b2f0b9428b2343be                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-dprzm    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-j2p5w                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-npf4v                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                nvidia-device-plugin-daemonset-1.12-wtl6n                  0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource        Requests   Limits\n  --------        --------   ------\n  cpu             250m (6%)  0 (0%)\n  memory          0 (0%)     0 (0%)\n  nvidia.com/gpu  0          0\nEvents:\n  Type    Reason                   Age   From                Message\n  ----    ------                   ----  ----                -------\n  Normal  Starting                 27m   kubelet, k8s-g1     Starting kubelet.\n  Normal  NodeHasSufficientDisk    27m   kubelet, k8s-g1     Node k8s-g1 status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  27m   kubelet, k8s-g1     Node k8s-g1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    27m   kubelet, k8s-g1     Node k8s-g1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     27m   kubelet, k8s-g1     Node k8s-g1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  27m   kubelet, k8s-g1     Updated Node Allocatable limit across pods\n  Normal  NodeReady                26m   kubelet, k8s-g1     Node k8s-g1 status is now: NodeReady\n  Normal  Starting                 26m   kube-proxy, k8s-g1  Starting kube-proxy.\n"
Dec  8 15:39:51.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 describe namespace e2e-tests-kubectl-p98b7'
Dec  8 15:39:51.885: INFO: stderr: ""
Dec  8 15:39:51.885: INFO: stdout: "Name:         e2e-tests-kubectl-p98b7\nLabels:       e2e-framework=kubectl\n              e2e-run=6b504022-faff-11e8-b692-aec8003d5667\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:39:51.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p98b7" for this suite.
Dec  8 15:40:15.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:40:16.064: INFO: namespace: e2e-tests-kubectl-p98b7, resource: bindings, ignored listing per whitelist
Dec  8 15:40:16.109: INFO: namespace e2e-tests-kubectl-p98b7 deletion completed in 24.217731647s

• [SLOW TEST:39.034 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:40:16.109: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 15:40:16.332: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  8 15:40:16.351: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  8 15:40:21.356: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 15:40:21.356: INFO: Creating deployment "test-rolling-update-deployment"
Dec  8 15:40:21.374: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  8 15:40:21.384: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  8 15:40:23.455: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  8 15:40:23.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679880421, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679880421, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679880421, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679880421, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 15:40:25.464: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 15:40:25.475: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-kfmsx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kfmsx/deployments/test-rolling-update-deployment,UID:92569a25-faff-11e8-b4e1-448a5b81d79a,ResourceVersion:4346,Generation:1,CreationTimestamp:2018-12-08 15:40:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-08 15:40:21 +0000 UTC 2018-12-08 15:40:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-08 15:40:24 +0000 UTC 2018-12-08 15:40:21 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  8 15:40:25.479: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-kfmsx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kfmsx/replicasets/test-rolling-update-deployment-65b7695dcf,UID:925e623e-faff-11e8-9316-54a05085d523,ResourceVersion:4337,Generation:1,CreationTimestamp:2018-12-08 15:40:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 92569a25-faff-11e8-b4e1-448a5b81d79a 0xc421724267 0xc421724268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  8 15:40:25.479: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  8 15:40:25.480: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-kfmsx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kfmsx/replicasets/test-rolling-update-controller,UID:8f57ebab-faff-11e8-b4e1-448a5b81d79a,ResourceVersion:4345,Generation:2,CreationTimestamp:2018-12-08 15:40:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 92569a25-faff-11e8-b4e1-448a5b81d79a 0xc4217241b7 0xc4217241b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 15:40:25.483: INFO: Pod "test-rolling-update-deployment-65b7695dcf-82vdq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-82vdq,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-kfmsx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kfmsx/pods/test-rolling-update-deployment-65b7695dcf-82vdq,UID:92678be3-faff-11e8-9316-54a05085d523,ResourceVersion:4336,Generation:0,CreationTimestamp:2018-12-08 15:40:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.3.19/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 925e623e-faff-11e8-9316-54a05085d523 0xc421279097 0xc421279098}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wz59z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wz59z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wz59z true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421279110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421279130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 15:40:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 15:40:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 15:40:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 15:40:21 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:10.244.3.19,StartTime:2018-12-08 15:40:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-08 15:40:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://dec32178ffd0edb62fd3f5645b32128ae7228bb4cea8df43f216681dad1a1b24}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:40:25.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kfmsx" for this suite.
Dec  8 15:40:33.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:40:33.608: INFO: namespace: e2e-tests-deployment-kfmsx, resource: bindings, ignored listing per whitelist
Dec  8 15:40:33.679: INFO: namespace e2e-tests-deployment-kfmsx deletion completed in 8.168542385s

• [SLOW TEST:17.570 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:40:33.679: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 15:40:33.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-glpn5'
Dec  8 15:40:34.049: INFO: stderr: ""
Dec  8 15:40:34.049: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Dec  8 15:40:34.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-glpn5'
Dec  8 15:40:41.678: INFO: stderr: ""
Dec  8 15:40:41.678: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:40:41.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-glpn5" for this suite.
Dec  8 15:40:47.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:40:47.779: INFO: namespace: e2e-tests-kubectl-glpn5, resource: bindings, ignored listing per whitelist
Dec  8 15:40:47.854: INFO: namespace e2e-tests-kubectl-glpn5 deletion completed in 6.168576573s

• [SLOW TEST:14.175 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:40:47.854: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-a24313c9-faff-11e8-b692-aec8003d5667
STEP: Creating configMap with name cm-test-opt-upd-a24313ec-faff-11e8-b692-aec8003d5667
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a24313c9-faff-11e8-b692-aec8003d5667
STEP: Updating configmap cm-test-opt-upd-a24313ec-faff-11e8-b692-aec8003d5667
STEP: Creating configMap with name cm-test-opt-create-a24313f9-faff-11e8-b692-aec8003d5667
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:40:58.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pkj5j" for this suite.
Dec  8 15:41:22.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:41:22.524: INFO: namespace: e2e-tests-configmap-pkj5j, resource: bindings, ignored listing per whitelist
Dec  8 15:41:22.616: INFO: namespace e2e-tests-configmap-pkj5j deletion completed in 24.183552539s

• [SLOW TEST:34.762 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:41:22.616: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b7003fa2-faff-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 15:41:22.939: INFO: Waiting up to 5m0s for pod "pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-cpcrm" to be "success or failure"
Dec  8 15:41:22.960: INFO: Pod "pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 21.231315ms
Dec  8 15:41:24.964: INFO: Pod "pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025165619s
Dec  8 15:41:26.968: INFO: Pod "pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029064594s
Dec  8 15:41:28.972: INFO: Pod "pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03284487s
STEP: Saw pod success
Dec  8 15:41:28.972: INFO: Pod "pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:41:28.975: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 15:41:29.072: INFO: Waiting for pod pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667 to disappear
Dec  8 15:41:29.075: INFO: Pod pod-configmaps-b705dd76-faff-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:41:29.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cpcrm" for this suite.
Dec  8 15:41:35.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:41:35.166: INFO: namespace: e2e-tests-configmap-cpcrm, resource: bindings, ignored listing per whitelist
Dec  8 15:41:35.281: INFO: namespace e2e-tests-configmap-cpcrm deletion completed in 6.198279041s

• [SLOW TEST:12.664 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:41:35.281: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  8 15:41:35.527: INFO: Waiting up to 5m0s for pod "pod-be8669f9-faff-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-rz2xm" to be "success or failure"
Dec  8 15:41:35.531: INFO: Pod "pod-be8669f9-faff-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.747747ms
Dec  8 15:41:37.539: INFO: Pod "pod-be8669f9-faff-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011836435s
Dec  8 15:41:39.554: INFO: Pod "pod-be8669f9-faff-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026973259s
STEP: Saw pod success
Dec  8 15:41:39.554: INFO: Pod "pod-be8669f9-faff-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:41:39.557: INFO: Trying to get logs from node k8s-g2 pod pod-be8669f9-faff-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 15:41:39.598: INFO: Waiting for pod pod-be8669f9-faff-11e8-b692-aec8003d5667 to disappear
Dec  8 15:41:39.603: INFO: Pod pod-be8669f9-faff-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:41:39.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rz2xm" for this suite.
Dec  8 15:41:45.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:41:45.744: INFO: namespace: e2e-tests-emptydir-rz2xm, resource: bindings, ignored listing per whitelist
Dec  8 15:41:45.774: INFO: namespace e2e-tests-emptydir-rz2xm deletion completed in 6.163105115s

• [SLOW TEST:10.493 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:41:45.774: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 15:41:46.007: INFO: PodSpec: initContainers in spec.initContainers
Dec  8 15:42:42.549: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c4cb84cb-faff-11e8-b692-aec8003d5667", GenerateName:"", Namespace:"e2e-tests-init-container-bx42k", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-bx42k/pods/pod-init-c4cb84cb-faff-11e8-b692-aec8003d5667", UID:"c4cba256-faff-11e8-b4e1-448a5b81d79a", ResourceVersion:"4773", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679880506, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"7677392", "name":"foo"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.244.4.13/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4lgs6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421fb07c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4lgs6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4lgs6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4lgs6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc422a32de8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-g1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421eb7980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422a32e70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422a32e90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc422a32e98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679880506, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679880506, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679880506, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679880506, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.22.132.13", PodIP:"10.244.4.13", StartTime:(*v1.Time)(0xc4209c2ae0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421dacb60)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421dacbd0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://6aafbc7f665185d2fd9bb3a2a7c16c0328ffd175e982363d91cadc6702b44732"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4209c2b40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4209c2b00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:42:42.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bx42k" for this suite.
Dec  8 15:43:06.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:43:06.726: INFO: namespace: e2e-tests-init-container-bx42k, resource: bindings, ignored listing per whitelist
Dec  8 15:43:06.765: INFO: namespace e2e-tests-init-container-bx42k deletion completed in 24.184813087s

• [SLOW TEST:80.992 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:43:06.765: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f5163310-faff-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 15:43:07.177: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f523bcb1-faff-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-czcv4" to be "success or failure"
Dec  8 15:43:07.188: INFO: Pod "pod-projected-configmaps-f523bcb1-faff-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 11.110527ms
Dec  8 15:43:09.192: INFO: Pod "pod-projected-configmaps-f523bcb1-faff-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015376692s
Dec  8 15:43:11.196: INFO: Pod "pod-projected-configmaps-f523bcb1-faff-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019708601s
STEP: Saw pod success
Dec  8 15:43:11.196: INFO: Pod "pod-projected-configmaps-f523bcb1-faff-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:43:11.200: INFO: Trying to get logs from node k8s-g2 pod pod-projected-configmaps-f523bcb1-faff-11e8-b692-aec8003d5667 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 15:43:11.271: INFO: Waiting for pod pod-projected-configmaps-f523bcb1-faff-11e8-b692-aec8003d5667 to disappear
Dec  8 15:43:11.274: INFO: Pod pod-projected-configmaps-f523bcb1-faff-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:43:11.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-czcv4" for this suite.
Dec  8 15:43:17.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:43:17.444: INFO: namespace: e2e-tests-projected-czcv4, resource: bindings, ignored listing per whitelist
Dec  8 15:43:17.457: INFO: namespace e2e-tests-projected-czcv4 deletion completed in 6.17564521s

• [SLOW TEST:10.692 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:43:17.457: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  8 15:43:29.875: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 15:43:29.879: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 15:43:31.879: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 15:43:31.883: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 15:43:33.879: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 15:43:33.884: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:43:33.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xdjtl" for this suite.
Dec  8 15:43:57.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:43:58.002: INFO: namespace: e2e-tests-container-lifecycle-hook-xdjtl, resource: bindings, ignored listing per whitelist
Dec  8 15:43:58.065: INFO: namespace e2e-tests-container-lifecycle-hook-xdjtl deletion completed in 24.166607276s

• [SLOW TEST:40.608 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:43:58.066: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  8 15:43:58.326: INFO: Waiting up to 5m0s for pod "client-containers-13a3238c-fb00-11e8-b692-aec8003d5667" in namespace "e2e-tests-containers-rxzc9" to be "success or failure"
Dec  8 15:43:58.348: INFO: Pod "client-containers-13a3238c-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 22.126024ms
Dec  8 15:44:00.367: INFO: Pod "client-containers-13a3238c-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041523796s
Dec  8 15:44:02.371: INFO: Pod "client-containers-13a3238c-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045878505s
Dec  8 15:44:04.376: INFO: Pod "client-containers-13a3238c-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 6.050128634s
Dec  8 15:44:06.379: INFO: Pod "client-containers-13a3238c-fb00-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.05381519s
STEP: Saw pod success
Dec  8 15:44:06.379: INFO: Pod "client-containers-13a3238c-fb00-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:44:06.383: INFO: Trying to get logs from node k8s-g1 pod client-containers-13a3238c-fb00-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 15:44:06.470: INFO: Waiting for pod client-containers-13a3238c-fb00-11e8-b692-aec8003d5667 to disappear
Dec  8 15:44:06.476: INFO: Pod client-containers-13a3238c-fb00-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:44:06.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rxzc9" for this suite.
Dec  8 15:44:12.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:44:12.612: INFO: namespace: e2e-tests-containers-rxzc9, resource: bindings, ignored listing per whitelist
Dec  8 15:44:12.675: INFO: namespace e2e-tests-containers-rxzc9 deletion completed in 6.192535131s

• [SLOW TEST:14.610 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:44:12.676: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-mt29m
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-mt29m
STEP: Deleting pre-stop pod
Dec  8 15:44:30.218: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:44:30.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-mt29m" for this suite.
Dec  8 15:45:10.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:45:10.416: INFO: namespace: e2e-tests-prestop-mt29m, resource: bindings, ignored listing per whitelist
Dec  8 15:45:10.420: INFO: namespace e2e-tests-prestop-mt29m deletion completed in 40.167708342s

• [SLOW TEST:57.744 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:45:10.420: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 15:45:10.788: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3eca0858-fb00-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-2r2lm" to be "success or failure"
Dec  8 15:45:10.792: INFO: Pod "downwardapi-volume-3eca0858-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.797247ms
Dec  8 15:45:12.796: INFO: Pod "downwardapi-volume-3eca0858-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0082929s
Dec  8 15:45:14.800: INFO: Pod "downwardapi-volume-3eca0858-fb00-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012605394s
STEP: Saw pod success
Dec  8 15:45:14.800: INFO: Pod "downwardapi-volume-3eca0858-fb00-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:45:14.804: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-3eca0858-fb00-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 15:45:14.888: INFO: Waiting for pod downwardapi-volume-3eca0858-fb00-11e8-b692-aec8003d5667 to disappear
Dec  8 15:45:14.893: INFO: Pod downwardapi-volume-3eca0858-fb00-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:45:14.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2r2lm" for this suite.
Dec  8 15:45:20.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:45:20.949: INFO: namespace: e2e-tests-downward-api-2r2lm, resource: bindings, ignored listing per whitelist
Dec  8 15:45:21.068: INFO: namespace e2e-tests-downward-api-2r2lm deletion completed in 6.167767217s

• [SLOW TEST:10.648 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:45:21.068: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4529d9eb-fb00-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 15:45:21.721: INFO: Waiting up to 5m0s for pod "pod-secrets-455886ad-fb00-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-sl7m2" to be "success or failure"
Dec  8 15:45:21.725: INFO: Pod "pod-secrets-455886ad-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.731379ms
Dec  8 15:45:23.728: INFO: Pod "pod-secrets-455886ad-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007459044s
Dec  8 15:45:25.733: INFO: Pod "pod-secrets-455886ad-fb00-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012140201s
STEP: Saw pod success
Dec  8 15:45:25.733: INFO: Pod "pod-secrets-455886ad-fb00-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:45:25.737: INFO: Trying to get logs from node k8s-g1 pod pod-secrets-455886ad-fb00-11e8-b692-aec8003d5667 container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 15:45:25.813: INFO: Waiting for pod pod-secrets-455886ad-fb00-11e8-b692-aec8003d5667 to disappear
Dec  8 15:45:25.817: INFO: Pod pod-secrets-455886ad-fb00-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:45:25.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sl7m2" for this suite.
Dec  8 15:45:31.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:45:31.876: INFO: namespace: e2e-tests-secrets-sl7m2, resource: bindings, ignored listing per whitelist
Dec  8 15:45:32.020: INFO: namespace e2e-tests-secrets-sl7m2 deletion completed in 6.196347531s
STEP: Destroying namespace "e2e-tests-secret-namespace-sc2dm" for this suite.
Dec  8 15:45:38.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:45:38.207: INFO: namespace: e2e-tests-secret-namespace-sc2dm, resource: bindings, ignored listing per whitelist
Dec  8 15:45:38.231: INFO: namespace e2e-tests-secret-namespace-sc2dm deletion completed in 6.211140776s

• [SLOW TEST:17.163 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:45:38.231: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  8 15:45:38.500: INFO: namespace e2e-tests-kubectl-lnwvp
Dec  8 15:45:38.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-lnwvp'
Dec  8 15:45:38.784: INFO: stderr: ""
Dec  8 15:45:38.784: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 15:45:39.790: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:45:39.790: INFO: Found 0 / 1
Dec  8 15:45:40.789: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:45:40.789: INFO: Found 0 / 1
Dec  8 15:45:41.788: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:45:41.788: INFO: Found 1 / 1
Dec  8 15:45:41.788: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 15:45:41.791: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 15:45:41.791: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 15:45:41.791: INFO: wait on redis-master startup in e2e-tests-kubectl-lnwvp 
Dec  8 15:45:41.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 logs redis-master-xjzz4 redis-master --namespace=e2e-tests-kubectl-lnwvp'
Dec  8 15:45:41.865: INFO: stderr: ""
Dec  8 15:45:41.865: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 15:45:40.866 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 15:45:40.866 # Server started, Redis version 3.2.12\n1:M 08 Dec 15:45:40.866 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 15:45:40.866 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  8 15:45:41.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-lnwvp'
Dec  8 15:45:42.017: INFO: stderr: ""
Dec  8 15:45:42.017: INFO: stdout: "service/rm2 exposed\n"
Dec  8 15:45:42.023: INFO: Service rm2 in namespace e2e-tests-kubectl-lnwvp found.
STEP: exposing service
Dec  8 15:45:44.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-lnwvp'
Dec  8 15:45:44.177: INFO: stderr: ""
Dec  8 15:45:44.177: INFO: stdout: "service/rm3 exposed\n"
Dec  8 15:45:44.225: INFO: Service rm3 in namespace e2e-tests-kubectl-lnwvp found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:45:46.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lnwvp" for this suite.
Dec  8 15:46:06.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:46:06.376: INFO: namespace: e2e-tests-kubectl-lnwvp, resource: bindings, ignored listing per whitelist
Dec  8 15:46:06.415: INFO: namespace e2e-tests-kubectl-lnwvp deletion completed in 20.174868001s

• [SLOW TEST:28.184 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:46:06.415: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-j4vt
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 15:46:06.727: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-j4vt" in namespace "e2e-tests-subpath-dhkdt" to be "success or failure"
Dec  8 15:46:06.731: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.244241ms
Dec  8 15:46:08.739: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011850095s
Dec  8 15:46:10.744: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016845401s
Dec  8 15:46:12.748: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 6.021281916s
Dec  8 15:46:14.754: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 8.026707857s
Dec  8 15:46:16.758: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 10.030954971s
Dec  8 15:46:18.762: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 12.035118342s
Dec  8 15:46:20.767: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 14.039722334s
Dec  8 15:46:22.771: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 16.044076857s
Dec  8 15:46:24.776: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 18.048778276s
Dec  8 15:46:26.780: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 20.053175067s
Dec  8 15:46:28.784: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 22.056938921s
Dec  8 15:46:30.789: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Running", Reason="", readiness=false. Elapsed: 24.061862164s
Dec  8 15:46:32.794: INFO: Pod "pod-subpath-test-downwardapi-j4vt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.066703847s
STEP: Saw pod success
Dec  8 15:46:32.794: INFO: Pod "pod-subpath-test-downwardapi-j4vt" satisfied condition "success or failure"
Dec  8 15:46:32.797: INFO: Trying to get logs from node k8s-g1 pod pod-subpath-test-downwardapi-j4vt container test-container-subpath-downwardapi-j4vt: <nil>
STEP: delete the pod
Dec  8 15:46:32.911: INFO: Waiting for pod pod-subpath-test-downwardapi-j4vt to disappear
Dec  8 15:46:32.917: INFO: Pod pod-subpath-test-downwardapi-j4vt no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-j4vt
Dec  8 15:46:32.917: INFO: Deleting pod "pod-subpath-test-downwardapi-j4vt" in namespace "e2e-tests-subpath-dhkdt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:46:32.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dhkdt" for this suite.
Dec  8 15:46:38.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:46:39.001: INFO: namespace: e2e-tests-subpath-dhkdt, resource: bindings, ignored listing per whitelist
Dec  8 15:46:39.099: INFO: namespace e2e-tests-subpath-dhkdt deletion completed in 6.17198924s

• [SLOW TEST:32.684 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:46:39.100: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  8 15:46:39.385: INFO: Waiting up to 5m0s for pod "client-containers-739d218e-fb00-11e8-b692-aec8003d5667" in namespace "e2e-tests-containers-s945t" to be "success or failure"
Dec  8 15:46:39.427: INFO: Pod "client-containers-739d218e-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 41.449841ms
Dec  8 15:46:41.431: INFO: Pod "client-containers-739d218e-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045979723s
Dec  8 15:46:43.435: INFO: Pod "client-containers-739d218e-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050016378s
Dec  8 15:46:45.439: INFO: Pod "client-containers-739d218e-fb00-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054058058s
STEP: Saw pod success
Dec  8 15:46:45.439: INFO: Pod "client-containers-739d218e-fb00-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:46:45.443: INFO: Trying to get logs from node k8s-g2 pod client-containers-739d218e-fb00-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 15:46:45.488: INFO: Waiting for pod client-containers-739d218e-fb00-11e8-b692-aec8003d5667 to disappear
Dec  8 15:46:45.494: INFO: Pod client-containers-739d218e-fb00-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:46:45.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-s945t" for this suite.
Dec  8 15:46:51.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:46:51.693: INFO: namespace: e2e-tests-containers-s945t, resource: bindings, ignored listing per whitelist
Dec  8 15:46:51.719: INFO: namespace e2e-tests-containers-s945t deletion completed in 6.217396354s

• [SLOW TEST:12.619 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:46:51.719: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 15:46:52.028: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  8 15:46:52.068: INFO: Number of nodes with available pods: 0
Dec  8 15:46:52.068: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  8 15:46:52.200: INFO: Number of nodes with available pods: 0
Dec  8 15:46:52.200: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:46:53.205: INFO: Number of nodes with available pods: 0
Dec  8 15:46:53.205: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:46:54.204: INFO: Number of nodes with available pods: 0
Dec  8 15:46:54.204: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:46:55.204: INFO: Number of nodes with available pods: 0
Dec  8 15:46:55.204: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:46:56.217: INFO: Number of nodes with available pods: 0
Dec  8 15:46:56.217: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:46:57.216: INFO: Number of nodes with available pods: 0
Dec  8 15:46:57.216: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:46:58.204: INFO: Number of nodes with available pods: 0
Dec  8 15:46:58.204: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:46:59.204: INFO: Number of nodes with available pods: 1
Dec  8 15:46:59.204: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  8 15:46:59.266: INFO: Number of nodes with available pods: 1
Dec  8 15:46:59.266: INFO: Number of running nodes: 0, number of available pods: 1
Dec  8 15:47:00.271: INFO: Number of nodes with available pods: 0
Dec  8 15:47:00.271: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  8 15:47:00.303: INFO: Number of nodes with available pods: 0
Dec  8 15:47:00.303: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:01.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:01.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:02.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:02.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:03.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:03.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:04.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:04.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:05.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:05.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:06.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:06.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:07.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:07.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:08.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:08.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:09.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:09.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:10.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:10.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:11.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:11.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:12.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:12.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:13.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:13.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:14.309: INFO: Number of nodes with available pods: 0
Dec  8 15:47:14.309: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:15.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:15.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:16.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:16.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:17.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:17.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:18.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:18.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:19.308: INFO: Number of nodes with available pods: 0
Dec  8 15:47:19.308: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:20.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:20.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:21.308: INFO: Number of nodes with available pods: 0
Dec  8 15:47:21.308: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:22.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:22.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:23.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:23.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:24.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:24.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:25.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:25.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:26.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:26.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:27.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:27.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:28.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:28.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:29.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:29.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:30.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:30.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:31.308: INFO: Number of nodes with available pods: 0
Dec  8 15:47:31.308: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:32.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:32.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:33.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:33.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:34.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:34.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:35.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:35.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:36.322: INFO: Number of nodes with available pods: 0
Dec  8 15:47:36.322: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:37.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:37.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:38.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:38.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:39.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:39.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:40.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:40.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:41.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:41.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:42.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:42.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:43.307: INFO: Number of nodes with available pods: 0
Dec  8 15:47:43.307: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:44.306: INFO: Number of nodes with available pods: 0
Dec  8 15:47:44.306: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 15:47:45.308: INFO: Number of nodes with available pods: 1
Dec  8 15:47:45.308: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-t9gbf, will wait for the garbage collector to delete the pods
Dec  8 15:47:45.426: INFO: Deleting {extensions DaemonSet} daemon-set took: 49.135428ms
Dec  8 15:47:45.526: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.203143ms
Dec  8 15:48:21.730: INFO: Number of nodes with available pods: 0
Dec  8 15:48:21.730: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 15:48:21.735: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-t9gbf/daemonsets","resourceVersion":"5772"},"items":null}

Dec  8 15:48:21.739: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-t9gbf/pods","resourceVersion":"5772"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:48:21.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-t9gbf" for this suite.
Dec  8 15:48:27.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:48:27.969: INFO: namespace: e2e-tests-daemonsets-t9gbf, resource: bindings, ignored listing per whitelist
Dec  8 15:48:28.054: INFO: namespace e2e-tests-daemonsets-t9gbf deletion completed in 6.219293958s

• [SLOW TEST:96.335 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:48:28.054: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jdq9d
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-jdq9d
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-jdq9d
Dec  8 15:48:28.441: INFO: Found 0 stateful pods, waiting for 1
Dec  8 15:48:38.445: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  8 15:48:38.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-jdq9d ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 15:48:38.646: INFO: stderr: ""
Dec  8 15:48:38.646: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 15:48:38.646: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 15:48:38.650: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  8 15:48:48.655: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 15:48:48.655: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 15:48:48.689: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999812s
Dec  8 15:48:49.693: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995834065s
Dec  8 15:48:50.697: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991900371s
Dec  8 15:48:51.702: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987458078s
Dec  8 15:48:52.706: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982925807s
Dec  8 15:48:53.710: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978784368s
Dec  8 15:48:54.714: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.975153198s
Dec  8 15:48:55.718: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970395823s
Dec  8 15:48:56.729: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.966403621s
Dec  8 15:48:57.734: INFO: Verifying statefulset ss doesn't scale past 1 for another 955.744752ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-jdq9d
Dec  8 15:48:58.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-jdq9d ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 15:48:58.876: INFO: stderr: ""
Dec  8 15:48:58.876: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 15:48:58.876: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 15:48:58.879: INFO: Found 1 stateful pods, waiting for 3
Dec  8 15:49:08.883: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 15:49:08.883: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 15:49:08.883: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  8 15:49:08.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-jdq9d ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 15:49:09.019: INFO: stderr: ""
Dec  8 15:49:09.019: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 15:49:09.019: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 15:49:09.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-jdq9d ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 15:49:09.208: INFO: stderr: ""
Dec  8 15:49:09.208: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 15:49:09.208: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 15:49:09.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-jdq9d ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 15:49:09.375: INFO: stderr: ""
Dec  8 15:49:09.375: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 15:49:09.375: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 15:49:09.375: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 15:49:09.379: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  8 15:49:19.387: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 15:49:19.387: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 15:49:19.387: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 15:49:19.444: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999679s
Dec  8 15:49:20.448: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99600486s
Dec  8 15:49:21.453: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991545528s
Dec  8 15:49:22.457: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987272197s
Dec  8 15:49:23.463: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982399538s
Dec  8 15:49:24.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977313929s
Dec  8 15:49:25.481: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963040924s
Dec  8 15:49:26.503: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958454451s
Dec  8 15:49:27.507: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.937136544s
Dec  8 15:49:28.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.565825ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-jdq9d
Dec  8 15:49:29.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-jdq9d ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 15:49:29.720: INFO: stderr: ""
Dec  8 15:49:29.720: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 15:49:29.720: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 15:49:29.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-jdq9d ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 15:49:29.868: INFO: stderr: ""
Dec  8 15:49:29.868: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 15:49:29.868: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 15:49:29.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-jdq9d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 15:49:29.999: INFO: stderr: ""
Dec  8 15:49:29.999: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 15:49:29.999: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 15:49:29.999: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 15:49:50.016: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jdq9d
Dec  8 15:49:50.021: INFO: Scaling statefulset ss to 0
Dec  8 15:49:50.035: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 15:49:50.039: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:49:50.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jdq9d" for this suite.
Dec  8 15:49:58.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:49:58.207: INFO: namespace: e2e-tests-statefulset-jdq9d, resource: bindings, ignored listing per whitelist
Dec  8 15:49:58.288: INFO: namespace e2e-tests-statefulset-jdq9d deletion completed in 8.171670566s

• [SLOW TEST:90.235 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:49:58.289: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ea592e77-fb00-11e8-b692-aec8003d5667
STEP: Creating secret with name s-test-opt-upd-ea592ea1-fb00-11e8-b692-aec8003d5667
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ea592e77-fb00-11e8-b692-aec8003d5667
STEP: Updating secret s-test-opt-upd-ea592ea1-fb00-11e8-b692-aec8003d5667
STEP: Creating secret with name s-test-opt-create-ea592eb0-fb00-11e8-b692-aec8003d5667
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:50:06.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xslvk" for this suite.
Dec  8 15:50:30.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:50:31.100: INFO: namespace: e2e-tests-projected-xslvk, resource: bindings, ignored listing per whitelist
Dec  8 15:50:31.104: INFO: namespace e2e-tests-projected-xslvk deletion completed in 24.184047596s

• [SLOW TEST:32.815 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:50:31.104: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fdf11578-fb00-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 15:50:31.459: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fdf8f317-fb00-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-djgsk" to be "success or failure"
Dec  8 15:50:31.471: INFO: Pod "pod-projected-configmaps-fdf8f317-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 12.925442ms
Dec  8 15:50:33.522: INFO: Pod "pod-projected-configmaps-fdf8f317-fb00-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06384783s
Dec  8 15:50:35.526: INFO: Pod "pod-projected-configmaps-fdf8f317-fb00-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067889019s
STEP: Saw pod success
Dec  8 15:50:35.526: INFO: Pod "pod-projected-configmaps-fdf8f317-fb00-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:50:35.531: INFO: Trying to get logs from node k8s-g1 pod pod-projected-configmaps-fdf8f317-fb00-11e8-b692-aec8003d5667 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 15:50:35.578: INFO: Waiting for pod pod-projected-configmaps-fdf8f317-fb00-11e8-b692-aec8003d5667 to disappear
Dec  8 15:50:35.582: INFO: Pod pod-projected-configmaps-fdf8f317-fb00-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:50:35.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-djgsk" for this suite.
Dec  8 15:50:41.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:50:41.723: INFO: namespace: e2e-tests-projected-djgsk, resource: bindings, ignored listing per whitelist
Dec  8 15:50:41.795: INFO: namespace e2e-tests-projected-djgsk deletion completed in 6.203839839s

• [SLOW TEST:10.690 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:50:41.795: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-d76fj/configmap-test-0450374e-fb01-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 15:50:42.127: INFO: Waiting up to 5m0s for pod "pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-d76fj" to be "success or failure"
Dec  8 15:50:42.130: INFO: Pod "pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.493489ms
Dec  8 15:50:44.144: INFO: Pod "pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016797717s
Dec  8 15:50:46.148: INFO: Pod "pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021257567s
Dec  8 15:50:48.152: INFO: Pod "pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025538628s
Dec  8 15:50:50.157: INFO: Pod "pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.029807435s
STEP: Saw pod success
Dec  8 15:50:50.157: INFO: Pod "pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:50:50.160: INFO: Trying to get logs from node k8s-g2 pod pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667 container env-test: <nil>
STEP: delete the pod
Dec  8 15:50:50.244: INFO: Waiting for pod pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667 to disappear
Dec  8 15:50:50.249: INFO: Pod pod-configmaps-0456faa0-fb01-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:50:50.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d76fj" for this suite.
Dec  8 15:50:56.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:50:56.337: INFO: namespace: e2e-tests-configmap-d76fj, resource: bindings, ignored listing per whitelist
Dec  8 15:50:56.479: INFO: namespace e2e-tests-configmap-d76fj deletion completed in 6.222959204s

• [SLOW TEST:14.685 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:50:56.479: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-pd78d
Dec  8 15:51:00.737: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-pd78d
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 15:51:00.742: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:55:01.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pd78d" for this suite.
Dec  8 15:55:07.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:55:07.574: INFO: namespace: e2e-tests-container-probe-pd78d, resource: bindings, ignored listing per whitelist
Dec  8 15:55:07.582: INFO: namespace e2e-tests-container-probe-pd78d deletion completed in 6.192516927s

• [SLOW TEST:251.102 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:55:07.582: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  8 15:55:07.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:11.107: INFO: stderr: ""
Dec  8 15:55:11.107: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 15:55:11.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:11.178: INFO: stderr: ""
Dec  8 15:55:11.178: INFO: stdout: "update-demo-nautilus-f9zgg "
STEP: Replicas for name=update-demo: expected=2 actual=1
Dec  8 15:55:16.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:16.241: INFO: stderr: ""
Dec  8 15:55:16.241: INFO: stdout: "update-demo-nautilus-f9zgg update-demo-nautilus-qj49v "
Dec  8 15:55:16.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-f9zgg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:16.305: INFO: stderr: ""
Dec  8 15:55:16.305: INFO: stdout: ""
Dec  8 15:55:16.305: INFO: update-demo-nautilus-f9zgg is created but not running
Dec  8 15:55:21.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:21.372: INFO: stderr: ""
Dec  8 15:55:21.372: INFO: stdout: "update-demo-nautilus-f9zgg update-demo-nautilus-qj49v "
Dec  8 15:55:21.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-f9zgg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:21.433: INFO: stderr: ""
Dec  8 15:55:21.433: INFO: stdout: "true"
Dec  8 15:55:21.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-f9zgg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:21.494: INFO: stderr: ""
Dec  8 15:55:21.494: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 15:55:21.494: INFO: validating pod update-demo-nautilus-f9zgg
Dec  8 15:55:21.499: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 15:55:21.499: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 15:55:21.499: INFO: update-demo-nautilus-f9zgg is verified up and running
Dec  8 15:55:21.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-qj49v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:21.560: INFO: stderr: ""
Dec  8 15:55:21.560: INFO: stdout: "true"
Dec  8 15:55:21.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-qj49v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:21.622: INFO: stderr: ""
Dec  8 15:55:21.622: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 15:55:21.622: INFO: validating pod update-demo-nautilus-qj49v
Dec  8 15:55:21.628: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 15:55:21.628: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 15:55:21.628: INFO: update-demo-nautilus-qj49v is verified up and running
STEP: rolling-update to new replication controller
Dec  8 15:55:21.629: INFO: scanned /root for discovery docs: <nil>
Dec  8 15:55:21.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:48.516: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  8 15:55:48.517: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 15:55:48.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:48.660: INFO: stderr: ""
Dec  8 15:55:48.660: INFO: stdout: "update-demo-kitten-bpxgt update-demo-kitten-w6khp "
Dec  8 15:55:48.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-kitten-bpxgt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:48.721: INFO: stderr: ""
Dec  8 15:55:48.721: INFO: stdout: "true"
Dec  8 15:55:48.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-kitten-bpxgt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:48.781: INFO: stderr: ""
Dec  8 15:55:48.781: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  8 15:55:48.781: INFO: validating pod update-demo-kitten-bpxgt
Dec  8 15:55:48.786: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  8 15:55:48.786: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  8 15:55:48.786: INFO: update-demo-kitten-bpxgt is verified up and running
Dec  8 15:55:48.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-kitten-w6khp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:48.847: INFO: stderr: ""
Dec  8 15:55:48.847: INFO: stdout: "true"
Dec  8 15:55:48.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-kitten-w6khp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k79kl'
Dec  8 15:55:48.907: INFO: stderr: ""
Dec  8 15:55:48.907: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  8 15:55:48.907: INFO: validating pod update-demo-kitten-w6khp
Dec  8 15:55:48.913: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  8 15:55:48.913: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  8 15:55:48.913: INFO: update-demo-kitten-w6khp is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:55:48.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k79kl" for this suite.
Dec  8 15:56:04.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:56:04.999: INFO: namespace: e2e-tests-kubectl-k79kl, resource: bindings, ignored listing per whitelist
Dec  8 15:56:05.117: INFO: namespace e2e-tests-kubectl-k79kl deletion completed in 16.196701446s

• [SLOW TEST:57.535 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:56:05.117: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 15:56:11.501: INFO: Waiting up to 5m0s for pod "client-envvars-c8a6a5dd-fb01-11e8-b692-aec8003d5667" in namespace "e2e-tests-pods-k6mkg" to be "success or failure"
Dec  8 15:56:11.537: INFO: Pod "client-envvars-c8a6a5dd-fb01-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 36.221522ms
Dec  8 15:56:13.541: INFO: Pod "client-envvars-c8a6a5dd-fb01-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040236293s
Dec  8 15:56:15.547: INFO: Pod "client-envvars-c8a6a5dd-fb01-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045893874s
STEP: Saw pod success
Dec  8 15:56:15.547: INFO: Pod "client-envvars-c8a6a5dd-fb01-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 15:56:15.552: INFO: Trying to get logs from node k8s-g1 pod client-envvars-c8a6a5dd-fb01-11e8-b692-aec8003d5667 container env3cont: <nil>
STEP: delete the pod
Dec  8 15:56:15.598: INFO: Waiting for pod client-envvars-c8a6a5dd-fb01-11e8-b692-aec8003d5667 to disappear
Dec  8 15:56:15.602: INFO: Pod client-envvars-c8a6a5dd-fb01-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:56:15.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-k6mkg" for this suite.
Dec  8 15:57:03.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:57:03.819: INFO: namespace: e2e-tests-pods-k6mkg, resource: bindings, ignored listing per whitelist
Dec  8 15:57:03.878: INFO: namespace e2e-tests-pods-k6mkg deletion completed in 48.268146316s

• [SLOW TEST:58.761 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:57:03.879: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1208 15:57:44.192789      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 15:57:44.192: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:57:44.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kgns5" for this suite.
Dec  8 15:57:52.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:57:52.257: INFO: namespace: e2e-tests-gc-kgns5, resource: bindings, ignored listing per whitelist
Dec  8 15:57:52.374: INFO: namespace e2e-tests-gc-kgns5 deletion completed in 8.174927738s

• [SLOW TEST:48.495 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:57:52.374: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 15:57:52.599: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:57:57.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-d4qdm" for this suite.
Dec  8 15:58:21.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:58:21.677: INFO: namespace: e2e-tests-init-container-d4qdm, resource: bindings, ignored listing per whitelist
Dec  8 15:58:21.846: INFO: namespace e2e-tests-init-container-d4qdm deletion completed in 24.215594845s

• [SLOW TEST:29.472 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:58:21.846: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 15:58:26.741: INFO: Successfully updated pod "annotationupdate167f2b60-fb02-11e8-b692-aec8003d5667"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:58:28.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gvvxl" for this suite.
Dec  8 15:58:52.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:58:52.813: INFO: namespace: e2e-tests-downward-api-gvvxl, resource: bindings, ignored listing per whitelist
Dec  8 15:58:52.932: INFO: namespace e2e-tests-downward-api-gvvxl deletion completed in 24.168434409s

• [SLOW TEST:31.085 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:58:52.932: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1208 15:58:59.180986      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 15:58:59.181: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:58:59.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kpk4t" for this suite.
Dec  8 15:59:07.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 15:59:07.277: INFO: namespace: e2e-tests-gc-kpk4t, resource: bindings, ignored listing per whitelist
Dec  8 15:59:07.350: INFO: namespace e2e-tests-gc-kpk4t deletion completed in 8.163509603s

• [SLOW TEST:14.418 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 15:59:07.350: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-jvv7k
I1208 15:59:07.671460      20 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-jvv7k, replica count: 1
I1208 15:59:08.721749      20 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 15:59:09.721906      20 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 15:59:10.722080      20 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  8 15:59:10.904: INFO: Created: latency-svc-8h9q4
Dec  8 15:59:11.020: INFO: Got endpoints: latency-svc-8h9q4 [198.347792ms]
Dec  8 15:59:11.091: INFO: Created: latency-svc-bt28w
Dec  8 15:59:11.154: INFO: Got endpoints: latency-svc-bt28w [134.371121ms]
Dec  8 15:59:11.305: INFO: Created: latency-svc-6kl77
Dec  8 15:59:11.368: INFO: Got endpoints: latency-svc-6kl77 [347.838632ms]
Dec  8 15:59:11.398: INFO: Created: latency-svc-b4l76
Dec  8 15:59:11.496: INFO: Got endpoints: latency-svc-b4l76 [475.513263ms]
Dec  8 15:59:11.597: INFO: Created: latency-svc-fhrjl
Dec  8 15:59:11.750: INFO: Created: latency-svc-p8wqw
Dec  8 15:59:11.785: INFO: Got endpoints: latency-svc-fhrjl [765.080094ms]
Dec  8 15:59:11.799: INFO: Got endpoints: latency-svc-p8wqw [778.946252ms]
Dec  8 15:59:12.021: INFO: Created: latency-svc-95ddj
Dec  8 15:59:12.111: INFO: Got endpoints: latency-svc-95ddj [1.090198999s]
Dec  8 15:59:12.171: INFO: Created: latency-svc-gf9fd
Dec  8 15:59:12.338: INFO: Got endpoints: latency-svc-gf9fd [1.317606974s]
Dec  8 15:59:12.338: INFO: Created: latency-svc-2qsq6
Dec  8 15:59:12.420: INFO: Got endpoints: latency-svc-2qsq6 [1.39936009s]
Dec  8 15:59:12.489: INFO: Created: latency-svc-7gcz2
Dec  8 15:59:12.578: INFO: Got endpoints: latency-svc-7gcz2 [1.557437902s]
Dec  8 15:59:12.607: INFO: Created: latency-svc-lf6z6
Dec  8 15:59:12.621: INFO: Got endpoints: latency-svc-lf6z6 [1.600609655s]
Dec  8 15:59:12.670: INFO: Created: latency-svc-gcb54
Dec  8 15:59:12.795: INFO: Got endpoints: latency-svc-gcb54 [1.774517918s]
Dec  8 15:59:12.805: INFO: Created: latency-svc-d7q9x
Dec  8 15:59:12.853: INFO: Got endpoints: latency-svc-d7q9x [1.832918558s]
Dec  8 15:59:12.871: INFO: Created: latency-svc-p9b2m
Dec  8 15:59:12.966: INFO: Got endpoints: latency-svc-p9b2m [1.945676708s]
Dec  8 15:59:12.989: INFO: Created: latency-svc-6h9kt
Dec  8 15:59:13.096: INFO: Got endpoints: latency-svc-6h9kt [2.075844709s]
Dec  8 15:59:13.137: INFO: Created: latency-svc-92chw
Dec  8 15:59:13.246: INFO: Got endpoints: latency-svc-92chw [2.225690074s]
Dec  8 15:59:13.430: INFO: Created: latency-svc-mv2jn
Dec  8 15:59:13.554: INFO: Got endpoints: latency-svc-mv2jn [2.399960383s]
Dec  8 15:59:13.597: INFO: Created: latency-svc-8s46r
Dec  8 15:59:13.679: INFO: Got endpoints: latency-svc-8s46r [2.31133424s]
Dec  8 15:59:13.701: INFO: Created: latency-svc-p5tvc
Dec  8 15:59:13.841: INFO: Got endpoints: latency-svc-p5tvc [2.344721139s]
Dec  8 15:59:13.883: INFO: Created: latency-svc-jqmkh
Dec  8 15:59:13.984: INFO: Got endpoints: latency-svc-jqmkh [2.198447516s]
Dec  8 15:59:13.994: INFO: Created: latency-svc-h64fr
Dec  8 15:59:14.121: INFO: Got endpoints: latency-svc-h64fr [2.321709386s]
Dec  8 15:59:14.171: INFO: Created: latency-svc-v24sn
Dec  8 15:59:14.193: INFO: Got endpoints: latency-svc-v24sn [2.082872519s]
Dec  8 15:59:14.364: INFO: Created: latency-svc-cfvmr
Dec  8 15:59:14.471: INFO: Got endpoints: latency-svc-cfvmr [2.133033252s]
Dec  8 15:59:14.481: INFO: Created: latency-svc-wcqkr
Dec  8 15:59:14.629: INFO: Got endpoints: latency-svc-wcqkr [2.209672389s]
Dec  8 15:59:14.655: INFO: Created: latency-svc-wrtrq
Dec  8 15:59:14.804: INFO: Got endpoints: latency-svc-wrtrq [2.22634839s]
Dec  8 15:59:14.824: INFO: Created: latency-svc-t4mfh
Dec  8 15:59:14.864: INFO: Got endpoints: latency-svc-t4mfh [2.243010871s]
Dec  8 15:59:14.988: INFO: Created: latency-svc-jbtg9
Dec  8 15:59:15.034: INFO: Got endpoints: latency-svc-jbtg9 [2.238843091s]
Dec  8 15:59:15.138: INFO: Created: latency-svc-fh8v5
Dec  8 15:59:15.190: INFO: Got endpoints: latency-svc-fh8v5 [2.336531692s]
Dec  8 15:59:15.231: INFO: Created: latency-svc-jhj77
Dec  8 15:59:15.365: INFO: Got endpoints: latency-svc-jhj77 [2.398861532s]
Dec  8 15:59:15.391: INFO: Created: latency-svc-mftcb
Dec  8 15:59:15.516: INFO: Got endpoints: latency-svc-mftcb [2.41959173s]
Dec  8 15:59:15.549: INFO: Created: latency-svc-l4nfp
Dec  8 15:59:15.574: INFO: Got endpoints: latency-svc-l4nfp [2.327428731s]
Dec  8 15:59:15.699: INFO: Created: latency-svc-ccnw5
Dec  8 15:59:15.715: INFO: Got endpoints: latency-svc-ccnw5 [2.16044507s]
Dec  8 15:59:15.822: INFO: Created: latency-svc-hvlfm
Dec  8 15:59:15.890: INFO: Got endpoints: latency-svc-hvlfm [2.2102507s]
Dec  8 15:59:16.025: INFO: Created: latency-svc-6r9nl
Dec  8 15:59:16.082: INFO: Got endpoints: latency-svc-6r9nl [2.24149533s]
Dec  8 15:59:16.163: INFO: Created: latency-svc-ktw22
Dec  8 15:59:16.307: INFO: Got endpoints: latency-svc-ktw22 [2.323368304s]
Dec  8 15:59:16.336: INFO: Created: latency-svc-lcdbp
Dec  8 15:59:16.385: INFO: Got endpoints: latency-svc-lcdbp [2.263843643s]
Dec  8 15:59:16.502: INFO: Created: latency-svc-dwprt
Dec  8 15:59:16.629: INFO: Got endpoints: latency-svc-dwprt [2.435878052s]
Dec  8 15:59:16.630: INFO: Created: latency-svc-2hb9t
Dec  8 15:59:16.754: INFO: Got endpoints: latency-svc-2hb9t [2.283241575s]
Dec  8 15:59:16.779: INFO: Created: latency-svc-2x758
Dec  8 15:59:16.846: INFO: Got endpoints: latency-svc-2x758 [2.216365449s]
Dec  8 15:59:16.906: INFO: Created: latency-svc-mtfbk
Dec  8 15:59:17.094: INFO: Created: latency-svc-tfxm5
Dec  8 15:59:17.095: INFO: Got endpoints: latency-svc-mtfbk [2.291011478s]
Dec  8 15:59:17.266: INFO: Got endpoints: latency-svc-tfxm5 [2.401343723s]
Dec  8 15:59:17.316: INFO: Created: latency-svc-tktzb
Dec  8 15:59:17.524: INFO: Got endpoints: latency-svc-tktzb [2.490561059s]
Dec  8 15:59:17.540: INFO: Created: latency-svc-bwmlv
Dec  8 15:59:17.671: INFO: Got endpoints: latency-svc-bwmlv [2.481441891s]
Dec  8 15:59:17.712: INFO: Created: latency-svc-tbpcf
Dec  8 15:59:17.897: INFO: Got endpoints: latency-svc-tbpcf [2.532051534s]
Dec  8 15:59:17.917: INFO: Created: latency-svc-nmx4m
Dec  8 15:59:17.975: INFO: Got endpoints: latency-svc-nmx4m [2.458905258s]
Dec  8 15:59:18.063: INFO: Created: latency-svc-956bc
Dec  8 15:59:18.126: INFO: Got endpoints: latency-svc-956bc [2.551854101s]
Dec  8 15:59:18.231: INFO: Created: latency-svc-ss7zd
Dec  8 15:59:18.272: INFO: Got endpoints: latency-svc-ss7zd [2.556970024s]
Dec  8 15:59:18.294: INFO: Created: latency-svc-nd9lp
Dec  8 15:59:18.421: INFO: Got endpoints: latency-svc-nd9lp [2.531263369s]
Dec  8 15:59:18.450: INFO: Created: latency-svc-qzj4c
Dec  8 15:59:18.513: INFO: Got endpoints: latency-svc-qzj4c [2.43126358s]
Dec  8 15:59:18.604: INFO: Created: latency-svc-7prrl
Dec  8 15:59:18.662: INFO: Got endpoints: latency-svc-7prrl [2.354407961s]
Dec  8 15:59:18.680: INFO: Created: latency-svc-lc4dg
Dec  8 15:59:18.806: INFO: Got endpoints: latency-svc-lc4dg [2.420663491s]
Dec  8 15:59:18.830: INFO: Created: latency-svc-tskcg
Dec  8 15:59:18.881: INFO: Got endpoints: latency-svc-tskcg [2.251602585s]
Dec  8 15:59:18.907: INFO: Created: latency-svc-lw2bj
Dec  8 15:59:18.996: INFO: Got endpoints: latency-svc-lw2bj [2.241741227s]
Dec  8 15:59:19.064: INFO: Created: latency-svc-bxqms
Dec  8 15:59:19.206: INFO: Got endpoints: latency-svc-bxqms [2.360211709s]
Dec  8 15:59:19.247: INFO: Created: latency-svc-pl5gg
Dec  8 15:59:19.363: INFO: Got endpoints: latency-svc-pl5gg [2.267375971s]
Dec  8 15:59:19.522: INFO: Created: latency-svc-655r7
Dec  8 15:59:19.591: INFO: Got endpoints: latency-svc-655r7 [2.325594469s]
Dec  8 15:59:19.683: INFO: Created: latency-svc-rvxh5
Dec  8 15:59:19.749: INFO: Got endpoints: latency-svc-rvxh5 [2.224849711s]
Dec  8 15:59:19.866: INFO: Created: latency-svc-qjppv
Dec  8 15:59:19.975: INFO: Got endpoints: latency-svc-qjppv [2.303451117s]
Dec  8 15:59:20.051: INFO: Created: latency-svc-fndmb
Dec  8 15:59:20.197: INFO: Got endpoints: latency-svc-fndmb [2.300328408s]
Dec  8 15:59:20.239: INFO: Created: latency-svc-w8pcn
Dec  8 15:59:20.338: INFO: Got endpoints: latency-svc-w8pcn [2.363645902s]
Dec  8 15:59:20.538: INFO: Created: latency-svc-8k8rd
Dec  8 15:59:20.730: INFO: Got endpoints: latency-svc-8k8rd [2.604632929s]
Dec  8 15:59:20.824: INFO: Created: latency-svc-xtl56
Dec  8 15:59:20.955: INFO: Got endpoints: latency-svc-xtl56 [2.682880697s]
Dec  8 15:59:20.977: INFO: Created: latency-svc-st2hq
Dec  8 15:59:21.018: INFO: Got endpoints: latency-svc-st2hq [2.597021491s]
Dec  8 15:59:21.179: INFO: Created: latency-svc-k4b2z
Dec  8 15:59:21.341: INFO: Created: latency-svc-mhzn5
Dec  8 15:59:21.346: INFO: Got endpoints: latency-svc-k4b2z [2.83295268s]
Dec  8 15:59:21.383: INFO: Got endpoints: latency-svc-mhzn5 [2.72131658s]
Dec  8 15:59:21.406: INFO: Created: latency-svc-6c9rm
Dec  8 15:59:21.517: INFO: Got endpoints: latency-svc-6c9rm [2.711255695s]
Dec  8 15:59:21.549: INFO: Created: latency-svc-8dxgw
Dec  8 15:59:21.654: INFO: Got endpoints: latency-svc-8dxgw [2.773372085s]
Dec  8 15:59:21.718: INFO: Created: latency-svc-c92rb
Dec  8 15:59:21.829: INFO: Got endpoints: latency-svc-c92rb [2.832993433s]
Dec  8 15:59:21.865: INFO: Created: latency-svc-ff2tk
Dec  8 15:59:21.996: INFO: Got endpoints: latency-svc-ff2tk [2.789731254s]
Dec  8 15:59:22.016: INFO: Created: latency-svc-xznc2
Dec  8 15:59:22.179: INFO: Got endpoints: latency-svc-xznc2 [2.816639035s]
Dec  8 15:59:22.217: INFO: Created: latency-svc-m6gcw
Dec  8 15:59:22.266: INFO: Got endpoints: latency-svc-m6gcw [2.674870532s]
Dec  8 15:59:22.346: INFO: Created: latency-svc-jv2zh
Dec  8 15:59:22.483: INFO: Got endpoints: latency-svc-jv2zh [2.733475012s]
Dec  8 15:59:22.527: INFO: Created: latency-svc-l9rw7
Dec  8 15:59:22.675: INFO: Got endpoints: latency-svc-l9rw7 [2.699570588s]
Dec  8 15:59:22.695: INFO: Created: latency-svc-rmrwn
Dec  8 15:59:22.829: INFO: Got endpoints: latency-svc-rmrwn [2.631770662s]
Dec  8 15:59:22.844: INFO: Created: latency-svc-pd898
Dec  8 15:59:22.870: INFO: Got endpoints: latency-svc-pd898 [2.531882295s]
Dec  8 15:59:22.921: INFO: Created: latency-svc-snwgx
Dec  8 15:59:23.021: INFO: Got endpoints: latency-svc-snwgx [2.290649554s]
Dec  8 15:59:23.053: INFO: Created: latency-svc-7mbfx
Dec  8 15:59:23.230: INFO: Got endpoints: latency-svc-7mbfx [2.211628505s]
Dec  8 15:59:23.292: INFO: Created: latency-svc-b4n8k
Dec  8 15:59:23.421: INFO: Got endpoints: latency-svc-b4n8k [2.466533271s]
Dec  8 15:59:23.439: INFO: Created: latency-svc-2lzwl
Dec  8 15:59:23.501: INFO: Got endpoints: latency-svc-2lzwl [2.15432789s]
Dec  8 15:59:23.588: INFO: Created: latency-svc-vd4rt
Dec  8 15:59:23.757: INFO: Got endpoints: latency-svc-vd4rt [2.374127799s]
Dec  8 15:59:23.795: INFO: Created: latency-svc-kjv9h
Dec  8 15:59:24.067: INFO: Got endpoints: latency-svc-kjv9h [2.550567204s]
Dec  8 15:59:24.084: INFO: Created: latency-svc-b57cf
Dec  8 15:59:24.122: INFO: Got endpoints: latency-svc-b57cf [2.46788554s]
Dec  8 15:59:24.287: INFO: Created: latency-svc-2dxz5
Dec  8 15:59:24.411: INFO: Got endpoints: latency-svc-2dxz5 [2.581686198s]
Dec  8 15:59:24.490: INFO: Created: latency-svc-z29qk
Dec  8 15:59:24.602: INFO: Got endpoints: latency-svc-z29qk [2.60649524s]
Dec  8 15:59:24.738: INFO: Created: latency-svc-djwjl
Dec  8 15:59:24.780: INFO: Got endpoints: latency-svc-djwjl [2.600175225s]
Dec  8 15:59:24.803: INFO: Created: latency-svc-9x5bd
Dec  8 15:59:24.936: INFO: Got endpoints: latency-svc-9x5bd [2.670272579s]
Dec  8 15:59:24.937: INFO: Created: latency-svc-2f8q2
Dec  8 15:59:25.079: INFO: Got endpoints: latency-svc-2f8q2 [2.596113625s]
Dec  8 15:59:25.120: INFO: Created: latency-svc-jxsxg
Dec  8 15:59:25.163: INFO: Got endpoints: latency-svc-jxsxg [2.488925277s]
Dec  8 15:59:25.246: INFO: Created: latency-svc-xjlqh
Dec  8 15:59:25.379: INFO: Got endpoints: latency-svc-xjlqh [2.549909305s]
Dec  8 15:59:25.414: INFO: Created: latency-svc-4wgdl
Dec  8 15:59:25.471: INFO: Got endpoints: latency-svc-4wgdl [2.600230372s]
Dec  8 15:59:25.546: INFO: Created: latency-svc-rdbkl
Dec  8 15:59:25.729: INFO: Got endpoints: latency-svc-rdbkl [2.7084213s]
Dec  8 15:59:25.742: INFO: Created: latency-svc-t7vj6
Dec  8 15:59:25.803: INFO: Got endpoints: latency-svc-t7vj6 [2.573076644s]
Dec  8 15:59:25.965: INFO: Created: latency-svc-kpjb7
Dec  8 15:59:26.071: INFO: Got endpoints: latency-svc-kpjb7 [2.649321516s]
Dec  8 15:59:26.133: INFO: Created: latency-svc-w89xb
Dec  8 15:59:26.229: INFO: Got endpoints: latency-svc-w89xb [2.728350502s]
Dec  8 15:59:26.266: INFO: Created: latency-svc-48jp8
Dec  8 15:59:26.319: INFO: Got endpoints: latency-svc-48jp8 [2.561348599s]
Dec  8 15:59:26.485: INFO: Created: latency-svc-cwjcl
Dec  8 15:59:26.562: INFO: Got endpoints: latency-svc-cwjcl [2.494859551s]
Dec  8 15:59:26.739: INFO: Created: latency-svc-t5hjg
Dec  8 15:59:26.818: INFO: Got endpoints: latency-svc-t5hjg [2.695976046s]
Dec  8 15:59:26.949: INFO: Created: latency-svc-sjhgk
Dec  8 15:59:26.979: INFO: Got endpoints: latency-svc-sjhgk [2.568224849s]
Dec  8 15:59:27.070: INFO: Created: latency-svc-b9vx5
Dec  8 15:59:27.354: INFO: Got endpoints: latency-svc-b9vx5 [2.751670449s]
Dec  8 15:59:27.361: INFO: Created: latency-svc-cvssz
Dec  8 15:59:27.521: INFO: Created: latency-svc-9rpvj
Dec  8 15:59:27.521: INFO: Got endpoints: latency-svc-cvssz [2.741799447s]
Dec  8 15:59:27.560: INFO: Got endpoints: latency-svc-9rpvj [2.623685935s]
Dec  8 15:59:27.708: INFO: Created: latency-svc-hwtxq
Dec  8 15:59:27.871: INFO: Got endpoints: latency-svc-hwtxq [2.791691097s]
Dec  8 15:59:27.891: INFO: Created: latency-svc-lxw2w
Dec  8 15:59:27.945: INFO: Got endpoints: latency-svc-lxw2w [2.781033452s]
Dec  8 15:59:28.039: INFO: Created: latency-svc-sh24v
Dec  8 15:59:28.102: INFO: Got endpoints: latency-svc-sh24v [2.72275325s]
Dec  8 15:59:28.244: INFO: Created: latency-svc-rptpc
Dec  8 15:59:28.268: INFO: Got endpoints: latency-svc-rptpc [2.797003638s]
Dec  8 15:59:28.359: INFO: Created: latency-svc-bnp7h
Dec  8 15:59:28.512: INFO: Got endpoints: latency-svc-bnp7h [2.782959836s]
Dec  8 15:59:28.545: INFO: Created: latency-svc-lxqnb
Dec  8 15:59:28.679: INFO: Got endpoints: latency-svc-lxqnb [2.87619496s]
Dec  8 15:59:28.702: INFO: Created: latency-svc-fhgn9
Dec  8 15:59:28.749: INFO: Got endpoints: latency-svc-fhgn9 [2.67791649s]
Dec  8 15:59:28.769: INFO: Created: latency-svc-vvqcg
Dec  8 15:59:28.911: INFO: Got endpoints: latency-svc-vvqcg [2.681677367s]
Dec  8 15:59:28.953: INFO: Created: latency-svc-bd67m
Dec  8 15:59:29.046: INFO: Got endpoints: latency-svc-bd67m [2.727758075s]
Dec  8 15:59:29.187: INFO: Created: latency-svc-bs5xc
Dec  8 15:59:29.246: INFO: Got endpoints: latency-svc-bs5xc [2.684111295s]
Dec  8 15:59:29.329: INFO: Created: latency-svc-9mc2n
Dec  8 15:59:29.380: INFO: Got endpoints: latency-svc-9mc2n [2.561515739s]
Dec  8 15:59:29.406: INFO: Created: latency-svc-vpvvs
Dec  8 15:59:29.512: INFO: Got endpoints: latency-svc-vpvvs [2.532564732s]
Dec  8 15:59:29.532: INFO: Created: latency-svc-zfbrc
Dec  8 15:59:29.582: INFO: Got endpoints: latency-svc-zfbrc [2.227991266s]
Dec  8 15:59:29.595: INFO: Created: latency-svc-vsntv
Dec  8 15:59:29.742: INFO: Got endpoints: latency-svc-vsntv [2.220443379s]
Dec  8 15:59:29.816: INFO: Created: latency-svc-nrv74
Dec  8 15:59:29.924: INFO: Got endpoints: latency-svc-nrv74 [2.363536819s]
Dec  8 15:59:29.933: INFO: Created: latency-svc-rlrpk
Dec  8 15:59:30.071: INFO: Got endpoints: latency-svc-rlrpk [2.199934071s]
Dec  8 15:59:30.093: INFO: Created: latency-svc-64htj
Dec  8 15:59:30.138: INFO: Got endpoints: latency-svc-64htj [2.193076332s]
Dec  8 15:59:30.164: INFO: Created: latency-svc-rqw86
Dec  8 15:59:30.270: INFO: Got endpoints: latency-svc-rqw86 [2.168660361s]
Dec  8 15:59:30.421: INFO: Created: latency-svc-s6qm9
Dec  8 15:59:30.512: INFO: Got endpoints: latency-svc-s6qm9 [2.243753929s]
Dec  8 15:59:30.653: INFO: Created: latency-svc-tckcn
Dec  8 15:59:30.823: INFO: Got endpoints: latency-svc-tckcn [2.310420806s]
Dec  8 15:59:30.922: INFO: Created: latency-svc-tvwcd
Dec  8 15:59:31.011: INFO: Got endpoints: latency-svc-tvwcd [2.332190729s]
Dec  8 15:59:31.111: INFO: Created: latency-svc-56slz
Dec  8 15:59:31.223: INFO: Got endpoints: latency-svc-56slz [2.474129739s]
Dec  8 15:59:31.421: INFO: Created: latency-svc-wn6r2
Dec  8 15:59:31.561: INFO: Created: latency-svc-cnq9q
Dec  8 15:59:31.695: INFO: Got endpoints: latency-svc-wn6r2 [2.784444005s]
Dec  8 15:59:31.720: INFO: Got endpoints: latency-svc-cnq9q [2.673169696s]
Dec  8 15:59:31.756: INFO: Created: latency-svc-xcpjh
Dec  8 15:59:31.862: INFO: Got endpoints: latency-svc-xcpjh [2.615823415s]
Dec  8 15:59:31.882: INFO: Created: latency-svc-r9hrp
Dec  8 15:59:31.956: INFO: Got endpoints: latency-svc-r9hrp [2.5765941s]
Dec  8 15:59:32.021: INFO: Created: latency-svc-ffhm9
Dec  8 15:59:32.099: INFO: Got endpoints: latency-svc-ffhm9 [2.587099985s]
Dec  8 15:59:32.116: INFO: Created: latency-svc-vjhq5
Dec  8 15:59:32.271: INFO: Got endpoints: latency-svc-vjhq5 [2.688770265s]
Dec  8 15:59:32.299: INFO: Created: latency-svc-j8zvn
Dec  8 15:59:32.310: INFO: Got endpoints: latency-svc-j8zvn [2.568647879s]
Dec  8 15:59:32.518: INFO: Created: latency-svc-6h26m
Dec  8 15:59:32.637: INFO: Got endpoints: latency-svc-6h26m [2.713689874s]
Dec  8 15:59:32.717: INFO: Created: latency-svc-sc5rp
Dec  8 15:59:32.854: INFO: Got endpoints: latency-svc-sc5rp [2.783053085s]
Dec  8 15:59:32.918: INFO: Created: latency-svc-btkc6
Dec  8 15:59:33.029: INFO: Got endpoints: latency-svc-btkc6 [2.891272196s]
Dec  8 15:59:33.054: INFO: Created: latency-svc-9s5f8
Dec  8 15:59:33.196: INFO: Got endpoints: latency-svc-9s5f8 [2.925441805s]
Dec  8 15:59:33.277: INFO: Created: latency-svc-4mltp
Dec  8 15:59:33.387: INFO: Got endpoints: latency-svc-4mltp [2.875487227s]
Dec  8 15:59:33.417: INFO: Created: latency-svc-ph7nk
Dec  8 15:59:33.485: INFO: Got endpoints: latency-svc-ph7nk [2.661908473s]
Dec  8 15:59:33.554: INFO: Created: latency-svc-9ldtm
Dec  8 15:59:33.746: INFO: Created: latency-svc-gcf54
Dec  8 15:59:33.746: INFO: Got endpoints: latency-svc-9ldtm [2.73449465s]
Dec  8 15:59:33.897: INFO: Got endpoints: latency-svc-gcf54 [2.674139113s]
Dec  8 15:59:33.965: INFO: Created: latency-svc-2jwpf
Dec  8 15:59:34.079: INFO: Got endpoints: latency-svc-2jwpf [2.383365454s]
Dec  8 15:59:34.136: INFO: Created: latency-svc-krsgg
Dec  8 15:59:34.246: INFO: Got endpoints: latency-svc-krsgg [2.526040507s]
Dec  8 15:59:34.301: INFO: Created: latency-svc-j7n5j
Dec  8 15:59:34.412: INFO: Got endpoints: latency-svc-j7n5j [2.549796267s]
Dec  8 15:59:34.477: INFO: Created: latency-svc-cshx4
Dec  8 15:59:34.577: INFO: Got endpoints: latency-svc-cshx4 [2.620786893s]
Dec  8 15:59:34.612: INFO: Created: latency-svc-s44zf
Dec  8 15:59:34.761: INFO: Got endpoints: latency-svc-s44zf [2.66248397s]
Dec  8 15:59:34.785: INFO: Created: latency-svc-rtf8z
Dec  8 15:59:34.969: INFO: Got endpoints: latency-svc-rtf8z [2.697709578s]
Dec  8 15:59:35.113: INFO: Created: latency-svc-s8sps
Dec  8 15:59:35.195: INFO: Got endpoints: latency-svc-s8sps [2.884707661s]
Dec  8 15:59:35.239: INFO: Created: latency-svc-vd6r5
Dec  8 15:59:35.371: INFO: Got endpoints: latency-svc-vd6r5 [2.733204732s]
Dec  8 15:59:35.371: INFO: Created: latency-svc-cltv5
Dec  8 15:59:35.414: INFO: Got endpoints: latency-svc-cltv5 [2.559733909s]
Dec  8 15:59:35.538: INFO: Created: latency-svc-2m59q
Dec  8 15:59:35.596: INFO: Got endpoints: latency-svc-2m59q [2.566874465s]
Dec  8 15:59:35.630: INFO: Created: latency-svc-kxxsn
Dec  8 15:59:35.704: INFO: Got endpoints: latency-svc-kxxsn [2.508055918s]
Dec  8 15:59:35.855: INFO: Created: latency-svc-qxmmr
Dec  8 15:59:35.916: INFO: Got endpoints: latency-svc-qxmmr [2.529393234s]
Dec  8 15:59:36.039: INFO: Created: latency-svc-dv5sv
Dec  8 15:59:36.228: INFO: Got endpoints: latency-svc-dv5sv [2.743787399s]
Dec  8 15:59:36.238: INFO: Created: latency-svc-p7nlq
Dec  8 15:59:36.454: INFO: Got endpoints: latency-svc-p7nlq [2.707971252s]
Dec  8 15:59:36.531: INFO: Created: latency-svc-754nv
Dec  8 15:59:36.629: INFO: Got endpoints: latency-svc-754nv [2.731801556s]
Dec  8 15:59:36.821: INFO: Created: latency-svc-jg4qx
Dec  8 15:59:36.881: INFO: Got endpoints: latency-svc-jg4qx [2.801843106s]
Dec  8 15:59:36.988: INFO: Created: latency-svc-p4vm5
Dec  8 15:59:37.058: INFO: Got endpoints: latency-svc-p4vm5 [2.812040637s]
Dec  8 15:59:37.076: INFO: Created: latency-svc-spklp
Dec  8 15:59:37.227: INFO: Got endpoints: latency-svc-spklp [2.814748386s]
Dec  8 15:59:37.236: INFO: Created: latency-svc-qbvpf
Dec  8 15:59:37.337: INFO: Got endpoints: latency-svc-qbvpf [2.759596336s]
Dec  8 15:59:37.374: INFO: Created: latency-svc-vd97m
Dec  8 15:59:37.556: INFO: Got endpoints: latency-svc-vd97m [2.794942762s]
Dec  8 15:59:37.598: INFO: Created: latency-svc-92x9r
Dec  8 15:59:37.721: INFO: Got endpoints: latency-svc-92x9r [2.7527551s]
Dec  8 15:59:37.757: INFO: Created: latency-svc-qs8jj
Dec  8 15:59:37.814: INFO: Got endpoints: latency-svc-qs8jj [2.618671033s]
Dec  8 15:59:37.879: INFO: Created: latency-svc-dxmsd
Dec  8 15:59:38.037: INFO: Created: latency-svc-xp4dt
Dec  8 15:59:38.037: INFO: Got endpoints: latency-svc-dxmsd [2.666109647s]
Dec  8 15:59:38.117: INFO: Got endpoints: latency-svc-xp4dt [2.703038072s]
Dec  8 15:59:38.196: INFO: Created: latency-svc-fvh2v
Dec  8 15:59:38.337: INFO: Got endpoints: latency-svc-fvh2v [2.741036393s]
Dec  8 15:59:38.359: INFO: Created: latency-svc-ddwkl
Dec  8 15:59:38.512: INFO: Got endpoints: latency-svc-ddwkl [2.807825412s]
Dec  8 15:59:38.575: INFO: Created: latency-svc-8pvw2
Dec  8 15:59:38.704: INFO: Got endpoints: latency-svc-8pvw2 [2.787426182s]
Dec  8 15:59:38.734: INFO: Created: latency-svc-ls2z6
Dec  8 15:59:38.971: INFO: Got endpoints: latency-svc-ls2z6 [2.742337476s]
Dec  8 15:59:38.993: INFO: Created: latency-svc-ktwp4
Dec  8 15:59:39.053: INFO: Got endpoints: latency-svc-ktwp4 [2.598846433s]
Dec  8 15:59:39.176: INFO: Created: latency-svc-z6w8v
Dec  8 15:59:39.298: INFO: Got endpoints: latency-svc-z6w8v [2.669153629s]
Dec  8 15:59:39.330: INFO: Created: latency-svc-cnkvj
Dec  8 15:59:39.370: INFO: Got endpoints: latency-svc-cnkvj [2.489404711s]
Dec  8 15:59:39.501: INFO: Created: latency-svc-r25tg
Dec  8 15:59:39.622: INFO: Got endpoints: latency-svc-r25tg [2.563879633s]
Dec  8 15:59:39.746: INFO: Created: latency-svc-gxn8s
Dec  8 15:59:39.804: INFO: Got endpoints: latency-svc-gxn8s [2.576861146s]
Dec  8 15:59:39.904: INFO: Created: latency-svc-ghvvm
Dec  8 15:59:40.055: INFO: Got endpoints: latency-svc-ghvvm [2.718052873s]
Dec  8 15:59:40.069: INFO: Created: latency-svc-86kq2
Dec  8 15:59:40.204: INFO: Got endpoints: latency-svc-86kq2 [2.647404477s]
Dec  8 15:59:40.238: INFO: Created: latency-svc-z2wd7
Dec  8 15:59:40.266: INFO: Got endpoints: latency-svc-z2wd7 [2.544259525s]
Dec  8 15:59:40.396: INFO: Created: latency-svc-c967z
Dec  8 15:59:40.545: INFO: Got endpoints: latency-svc-c967z [2.730878075s]
Dec  8 15:59:40.567: INFO: Created: latency-svc-98t9t
Dec  8 15:59:40.643: INFO: Got endpoints: latency-svc-98t9t [2.606413568s]
Dec  8 15:59:40.800: INFO: Created: latency-svc-t595t
Dec  8 15:59:40.945: INFO: Got endpoints: latency-svc-t595t [2.828527373s]
Dec  8 15:59:41.008: INFO: Created: latency-svc-d5tgz
Dec  8 15:59:41.129: INFO: Got endpoints: latency-svc-d5tgz [2.791798001s]
Dec  8 15:59:41.213: INFO: Created: latency-svc-kq4x2
Dec  8 15:59:41.321: INFO: Got endpoints: latency-svc-kq4x2 [2.808699195s]
Dec  8 15:59:41.402: INFO: Created: latency-svc-gpkzs
Dec  8 15:59:41.520: INFO: Got endpoints: latency-svc-gpkzs [2.816288002s]
Dec  8 15:59:41.572: INFO: Created: latency-svc-cmblg
Dec  8 15:59:41.739: INFO: Created: latency-svc-8zzvm
Dec  8 15:59:41.770: INFO: Got endpoints: latency-svc-cmblg [2.799427359s]
Dec  8 15:59:41.913: INFO: Got endpoints: latency-svc-8zzvm [2.860091705s]
Dec  8 15:59:41.971: INFO: Created: latency-svc-8bn65
Dec  8 15:59:42.104: INFO: Got endpoints: latency-svc-8bn65 [2.805665724s]
Dec  8 15:59:42.271: INFO: Created: latency-svc-qjbl8
Dec  8 15:59:42.298: INFO: Got endpoints: latency-svc-qjbl8 [2.927518829s]
Dec  8 15:59:42.470: INFO: Created: latency-svc-dc62m
Dec  8 15:59:42.539: INFO: Got endpoints: latency-svc-dc62m [2.91751002s]
Dec  8 15:59:42.654: INFO: Created: latency-svc-f5qk4
Dec  8 15:59:42.737: INFO: Got endpoints: latency-svc-f5qk4 [2.933137512s]
Dec  8 15:59:42.845: INFO: Created: latency-svc-58txh
Dec  8 15:59:42.940: INFO: Got endpoints: latency-svc-58txh [2.885188315s]
Dec  8 15:59:42.988: INFO: Created: latency-svc-gm7bj
Dec  8 15:59:43.053: INFO: Got endpoints: latency-svc-gm7bj [2.849244905s]
Dec  8 15:59:43.162: INFO: Created: latency-svc-9qz56
Dec  8 15:59:43.213: INFO: Got endpoints: latency-svc-9qz56 [2.947300093s]
Dec  8 15:59:43.234: INFO: Created: latency-svc-q2n5z
Dec  8 15:59:43.426: INFO: Got endpoints: latency-svc-q2n5z [2.88057793s]
Dec  8 15:59:43.434: INFO: Created: latency-svc-6nrn7
Dec  8 15:59:43.630: INFO: Got endpoints: latency-svc-6nrn7 [2.986987482s]
Dec  8 15:59:43.685: INFO: Created: latency-svc-6n7ht
Dec  8 15:59:43.795: INFO: Got endpoints: latency-svc-6n7ht [2.849924596s]
Dec  8 15:59:43.834: INFO: Created: latency-svc-f8mgx
Dec  8 15:59:43.871: INFO: Got endpoints: latency-svc-f8mgx [2.742745554s]
Dec  8 15:59:44.019: INFO: Created: latency-svc-2hpjh
Dec  8 15:59:44.058: INFO: Got endpoints: latency-svc-2hpjh [2.7374165s]
Dec  8 15:59:44.196: INFO: Created: latency-svc-n2k92
Dec  8 15:59:44.328: INFO: Got endpoints: latency-svc-n2k92 [2.807971229s]
Dec  8 15:59:44.329: INFO: Created: latency-svc-jq9s2
Dec  8 15:59:44.503: INFO: Got endpoints: latency-svc-jq9s2 [2.73309138s]
Dec  8 15:59:44.505: INFO: Created: latency-svc-hlmt6
Dec  8 15:59:44.589: INFO: Got endpoints: latency-svc-hlmt6 [2.676503792s]
Dec  8 15:59:44.598: INFO: Created: latency-svc-gln9k
Dec  8 15:59:44.697: INFO: Got endpoints: latency-svc-gln9k [2.59360058s]
Dec  8 15:59:44.759: INFO: Created: latency-svc-c5pwl
Dec  8 15:59:44.941: INFO: Got endpoints: latency-svc-c5pwl [2.643143077s]
Dec  8 15:59:45.012: INFO: Created: latency-svc-pd8lj
Dec  8 15:59:45.068: INFO: Got endpoints: latency-svc-pd8lj [2.528674833s]
Dec  8 15:59:45.091: INFO: Created: latency-svc-vbjnj
Dec  8 15:59:45.099: INFO: Got endpoints: latency-svc-vbjnj [2.362156765s]
Dec  8 15:59:45.099: INFO: Latencies: [134.371121ms 347.838632ms 475.513263ms 765.080094ms 778.946252ms 1.090198999s 1.317606974s 1.39936009s 1.557437902s 1.600609655s 1.774517918s 1.832918558s 1.945676708s 2.075844709s 2.082872519s 2.133033252s 2.15432789s 2.16044507s 2.168660361s 2.193076332s 2.198447516s 2.199934071s 2.209672389s 2.2102507s 2.211628505s 2.216365449s 2.220443379s 2.224849711s 2.225690074s 2.22634839s 2.227991266s 2.238843091s 2.24149533s 2.241741227s 2.243010871s 2.243753929s 2.251602585s 2.263843643s 2.267375971s 2.283241575s 2.290649554s 2.291011478s 2.300328408s 2.303451117s 2.310420806s 2.31133424s 2.321709386s 2.323368304s 2.325594469s 2.327428731s 2.332190729s 2.336531692s 2.344721139s 2.354407961s 2.360211709s 2.362156765s 2.363536819s 2.363645902s 2.374127799s 2.383365454s 2.398861532s 2.399960383s 2.401343723s 2.41959173s 2.420663491s 2.43126358s 2.435878052s 2.458905258s 2.466533271s 2.46788554s 2.474129739s 2.481441891s 2.488925277s 2.489404711s 2.490561059s 2.494859551s 2.508055918s 2.526040507s 2.528674833s 2.529393234s 2.531263369s 2.531882295s 2.532051534s 2.532564732s 2.544259525s 2.549796267s 2.549909305s 2.550567204s 2.551854101s 2.556970024s 2.559733909s 2.561348599s 2.561515739s 2.563879633s 2.566874465s 2.568224849s 2.568647879s 2.573076644s 2.5765941s 2.576861146s 2.581686198s 2.587099985s 2.59360058s 2.596113625s 2.597021491s 2.598846433s 2.600175225s 2.600230372s 2.604632929s 2.606413568s 2.60649524s 2.615823415s 2.618671033s 2.620786893s 2.623685935s 2.631770662s 2.643143077s 2.647404477s 2.649321516s 2.661908473s 2.66248397s 2.666109647s 2.669153629s 2.670272579s 2.673169696s 2.674139113s 2.674870532s 2.676503792s 2.67791649s 2.681677367s 2.682880697s 2.684111295s 2.688770265s 2.695976046s 2.697709578s 2.699570588s 2.703038072s 2.707971252s 2.7084213s 2.711255695s 2.713689874s 2.718052873s 2.72131658s 2.72275325s 2.727758075s 2.728350502s 2.730878075s 2.731801556s 2.73309138s 2.733204732s 2.733475012s 2.73449465s 2.7374165s 2.741036393s 2.741799447s 2.742337476s 2.742745554s 2.743787399s 2.751670449s 2.7527551s 2.759596336s 2.773372085s 2.781033452s 2.782959836s 2.783053085s 2.784444005s 2.787426182s 2.789731254s 2.791691097s 2.791798001s 2.794942762s 2.797003638s 2.799427359s 2.801843106s 2.805665724s 2.807825412s 2.807971229s 2.808699195s 2.812040637s 2.814748386s 2.816288002s 2.816639035s 2.828527373s 2.83295268s 2.832993433s 2.849244905s 2.849924596s 2.860091705s 2.875487227s 2.87619496s 2.88057793s 2.884707661s 2.885188315s 2.891272196s 2.91751002s 2.925441805s 2.927518829s 2.933137512s 2.947300093s 2.986987482s]
Dec  8 15:59:45.099: INFO: 50 %ile: 2.581686198s
Dec  8 15:59:45.099: INFO: 90 %ile: 2.816288002s
Dec  8 15:59:45.099: INFO: 99 %ile: 2.947300093s
Dec  8 15:59:45.099: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 15:59:45.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-jvv7k" for this suite.
Dec  8 16:00:43.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:00:43.385: INFO: namespace: e2e-tests-svc-latency-jvv7k, resource: bindings, ignored listing per whitelist
Dec  8 16:00:43.391: INFO: namespace e2e-tests-svc-latency-jvv7k deletion completed in 58.282608265s

• [SLOW TEST:96.040 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:00:43.391: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  8 16:00:57.735: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:00:57.739: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:00:59.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:00:59.743: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:01.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:01.766: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:03.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:03.745: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:05.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:05.744: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:07.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:07.743: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:09.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:09.743: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:11.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:11.767: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:13.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:13.743: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:15.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:15.744: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:17.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:17.744: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:19.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:19.745: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 16:01:21.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 16:01:21.782: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:01:21.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9rsbj" for this suite.
Dec  8 16:01:45.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:01:45.930: INFO: namespace: e2e-tests-container-lifecycle-hook-9rsbj, resource: bindings, ignored listing per whitelist
Dec  8 16:01:45.976: INFO: namespace e2e-tests-container-lifecycle-hook-9rsbj deletion completed in 24.16791796s

• [SLOW TEST:62.585 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:01:45.977: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  8 16:01:50.287: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-902b6c0e-fb02-11e8-b692-aec8003d5667,GenerateName:,Namespace:e2e-tests-events-65rcj,SelfLink:/api/v1/namespaces/e2e-tests-events-65rcj/pods/send-events-902b6c0e-fb02-11e8-b692-aec8003d5667,UID:902c023d-fb02-11e8-b4e1-448a5b81d79a,ResourceVersion:9495,Generation:0,CreationTimestamp:2018-12-08 16:01:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 207144709,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.42/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5cgf2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5cgf2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-5cgf2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ba6720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ba6740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:01:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:01:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:01:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:01:46 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:10.244.4.42,StartTime:2018-12-08 16:01:46 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-08 16:01:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://f0b29fc98deaff10861a35c9cf5182c7ff8a7b8c0b06b844f9d71511b3bc8b0f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  8 16:01:52.307: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  8 16:01:54.312: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:01:54.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-65rcj" for this suite.
Dec  8 16:02:34.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:02:34.446: INFO: namespace: e2e-tests-events-65rcj, resource: bindings, ignored listing per whitelist
Dec  8 16:02:34.557: INFO: namespace e2e-tests-events-65rcj deletion completed in 40.181441321s

• [SLOW TEST:48.580 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:02:34.557: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  8 16:02:34.889: INFO: Waiting up to 5m0s for pod "var-expansion-ad2221af-fb02-11e8-b692-aec8003d5667" in namespace "e2e-tests-var-expansion-ztk5d" to be "success or failure"
Dec  8 16:02:34.915: INFO: Pod "var-expansion-ad2221af-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 26.585161ms
Dec  8 16:02:36.919: INFO: Pod "var-expansion-ad2221af-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030924711s
Dec  8 16:02:38.924: INFO: Pod "var-expansion-ad2221af-fb02-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035243373s
STEP: Saw pod success
Dec  8 16:02:38.924: INFO: Pod "var-expansion-ad2221af-fb02-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:02:38.927: INFO: Trying to get logs from node k8s-g2 pod var-expansion-ad2221af-fb02-11e8-b692-aec8003d5667 container dapi-container: <nil>
STEP: delete the pod
Dec  8 16:02:39.025: INFO: Waiting for pod var-expansion-ad2221af-fb02-11e8-b692-aec8003d5667 to disappear
Dec  8 16:02:39.029: INFO: Pod var-expansion-ad2221af-fb02-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:02:39.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ztk5d" for this suite.
Dec  8 16:02:45.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:02:45.149: INFO: namespace: e2e-tests-var-expansion-ztk5d, resource: bindings, ignored listing per whitelist
Dec  8 16:02:45.272: INFO: namespace e2e-tests-var-expansion-ztk5d deletion completed in 6.168247604s

• [SLOW TEST:10.715 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:02:45.272: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  8 16:02:45.668: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-kr427,SelfLink:/api/v1/namespaces/e2e-tests-watch-kr427/configmaps/e2e-watch-test-resource-version,UID:b38966b5-fb02-11e8-b4e1-448a5b81d79a,ResourceVersion:9640,Generation:0,CreationTimestamp:2018-12-08 16:02:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 16:02:45.668: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-kr427,SelfLink:/api/v1/namespaces/e2e-tests-watch-kr427/configmaps/e2e-watch-test-resource-version,UID:b38966b5-fb02-11e8-b4e1-448a5b81d79a,ResourceVersion:9641,Generation:0,CreationTimestamp:2018-12-08 16:02:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:02:45.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-kr427" for this suite.
Dec  8 16:02:51.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:02:51.780: INFO: namespace: e2e-tests-watch-kr427, resource: bindings, ignored listing per whitelist
Dec  8 16:02:51.865: INFO: namespace e2e-tests-watch-kr427 deletion completed in 6.188485992s

• [SLOW TEST:6.592 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:02:51.865: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  8 16:02:52.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 --namespace=e2e-tests-kubectl-jbw4r run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  8 16:02:54.902: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  8 16:02:54.902: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:02:56.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jbw4r" for this suite.
Dec  8 16:03:02.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:03:03.134: INFO: namespace: e2e-tests-kubectl-jbw4r, resource: bindings, ignored listing per whitelist
Dec  8 16:03:03.136: INFO: namespace e2e-tests-kubectl-jbw4r deletion completed in 6.218139693s

• [SLOW TEST:11.271 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:03:03.136: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-be2dcfe2-fb02-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:03:03.461: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-be332b12-fb02-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-dkbwf" to be "success or failure"
Dec  8 16:03:03.520: INFO: Pod "pod-projected-secrets-be332b12-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 59.267721ms
Dec  8 16:03:05.524: INFO: Pod "pod-projected-secrets-be332b12-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063375858s
Dec  8 16:03:07.529: INFO: Pod "pod-projected-secrets-be332b12-fb02-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068136583s
STEP: Saw pod success
Dec  8 16:03:07.529: INFO: Pod "pod-projected-secrets-be332b12-fb02-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:03:07.533: INFO: Trying to get logs from node k8s-g2 pod pod-projected-secrets-be332b12-fb02-11e8-b692-aec8003d5667 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:03:07.656: INFO: Waiting for pod pod-projected-secrets-be332b12-fb02-11e8-b692-aec8003d5667 to disappear
Dec  8 16:03:07.661: INFO: Pod pod-projected-secrets-be332b12-fb02-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:03:07.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dkbwf" for this suite.
Dec  8 16:03:13.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:03:13.711: INFO: namespace: e2e-tests-projected-dkbwf, resource: bindings, ignored listing per whitelist
Dec  8 16:03:13.837: INFO: namespace e2e-tests-projected-dkbwf deletion completed in 6.16802982s

• [SLOW TEST:10.701 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:03:13.837: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:03:14.131: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c48c05d5-fb02-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-l6h47" to be "success or failure"
Dec  8 16:03:14.221: INFO: Pod "downwardapi-volume-c48c05d5-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 90.915914ms
Dec  8 16:03:16.226: INFO: Pod "downwardapi-volume-c48c05d5-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095204677s
Dec  8 16:03:18.230: INFO: Pod "downwardapi-volume-c48c05d5-fb02-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.098989467s
STEP: Saw pod success
Dec  8 16:03:18.230: INFO: Pod "downwardapi-volume-c48c05d5-fb02-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:03:18.233: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-c48c05d5-fb02-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:03:18.296: INFO: Waiting for pod downwardapi-volume-c48c05d5-fb02-11e8-b692-aec8003d5667 to disappear
Dec  8 16:03:18.300: INFO: Pod downwardapi-volume-c48c05d5-fb02-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:03:18.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l6h47" for this suite.
Dec  8 16:03:24.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:03:24.563: INFO: namespace: e2e-tests-downward-api-l6h47, resource: bindings, ignored listing per whitelist
Dec  8 16:03:24.598: INFO: namespace e2e-tests-downward-api-l6h47 deletion completed in 6.290431866s

• [SLOW TEST:10.761 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:03:24.599: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 16:03:24.966: INFO: Waiting up to 5m0s for pod "downward-api-cb02f686-fb02-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-nvknk" to be "success or failure"
Dec  8 16:03:24.998: INFO: Pod "downward-api-cb02f686-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 32.180735ms
Dec  8 16:03:27.002: INFO: Pod "downward-api-cb02f686-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036545052s
Dec  8 16:03:29.007: INFO: Pod "downward-api-cb02f686-fb02-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041673515s
STEP: Saw pod success
Dec  8 16:03:29.007: INFO: Pod "downward-api-cb02f686-fb02-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:03:29.013: INFO: Trying to get logs from node k8s-g2 pod downward-api-cb02f686-fb02-11e8-b692-aec8003d5667 container dapi-container: <nil>
STEP: delete the pod
Dec  8 16:03:29.154: INFO: Waiting for pod downward-api-cb02f686-fb02-11e8-b692-aec8003d5667 to disappear
Dec  8 16:03:29.158: INFO: Pod downward-api-cb02f686-fb02-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:03:29.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nvknk" for this suite.
Dec  8 16:03:35.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:03:35.406: INFO: namespace: e2e-tests-downward-api-nvknk, resource: bindings, ignored listing per whitelist
Dec  8 16:03:35.410: INFO: namespace e2e-tests-downward-api-nvknk deletion completed in 6.244454536s

• [SLOW TEST:10.811 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:03:35.410: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:03:35.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-94nfm" for this suite.
Dec  8 16:03:57.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:03:57.941: INFO: namespace: e2e-tests-pods-94nfm, resource: bindings, ignored listing per whitelist
Dec  8 16:03:58.097: INFO: namespace e2e-tests-pods-94nfm deletion completed in 22.249221344s

• [SLOW TEST:22.688 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:03:58.098: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-w42w
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 16:03:58.502: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w42w" in namespace "e2e-tests-subpath-c9vp6" to be "success or failure"
Dec  8 16:03:58.539: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Pending", Reason="", readiness=false. Elapsed: 36.055753ms
Dec  8 16:04:00.544: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041378709s
Dec  8 16:04:02.551: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048098862s
Dec  8 16:04:04.556: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 6.053267374s
Dec  8 16:04:06.561: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 8.058500517s
Dec  8 16:04:08.566: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 10.063238761s
Dec  8 16:04:10.571: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 12.06862602s
Dec  8 16:04:12.576: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 14.073672046s
Dec  8 16:04:14.581: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 16.078040102s
Dec  8 16:04:16.586: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 18.083208256s
Dec  8 16:04:18.590: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 20.087014063s
Dec  8 16:04:20.594: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Running", Reason="", readiness=false. Elapsed: 22.091224426s
Dec  8 16:04:22.598: INFO: Pod "pod-subpath-test-configmap-w42w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.095371777s
STEP: Saw pod success
Dec  8 16:04:22.598: INFO: Pod "pod-subpath-test-configmap-w42w" satisfied condition "success or failure"
Dec  8 16:04:22.602: INFO: Trying to get logs from node k8s-g2 pod pod-subpath-test-configmap-w42w container test-container-subpath-configmap-w42w: <nil>
STEP: delete the pod
Dec  8 16:04:22.693: INFO: Waiting for pod pod-subpath-test-configmap-w42w to disappear
Dec  8 16:04:22.696: INFO: Pod pod-subpath-test-configmap-w42w no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w42w
Dec  8 16:04:22.696: INFO: Deleting pod "pod-subpath-test-configmap-w42w" in namespace "e2e-tests-subpath-c9vp6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:04:22.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-c9vp6" for this suite.
Dec  8 16:04:28.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:04:28.864: INFO: namespace: e2e-tests-subpath-c9vp6, resource: bindings, ignored listing per whitelist
Dec  8 16:04:28.973: INFO: namespace e2e-tests-subpath-c9vp6 deletion completed in 6.225840952s

• [SLOW TEST:30.876 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:04:28.974: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-d8zvt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8zvt to expose endpoints map[]
Dec  8 16:04:29.357: INFO: Get endpoints failed (5.09469ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  8 16:04:30.361: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8zvt exposes endpoints map[] (1.009687718s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-d8zvt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8zvt to expose endpoints map[pod1:[100]]
Dec  8 16:04:33.492: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8zvt exposes endpoints map[pod1:[100]] (3.105310388s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-d8zvt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8zvt to expose endpoints map[pod1:[100] pod2:[101]]
Dec  8 16:04:36.609: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8zvt exposes endpoints map[pod1:[100] pod2:[101]] (3.096316382s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-d8zvt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8zvt to expose endpoints map[pod2:[101]]
Dec  8 16:04:36.668: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8zvt exposes endpoints map[pod2:[101]] (26.674069ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-d8zvt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8zvt to expose endpoints map[]
Dec  8 16:04:37.738: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8zvt exposes endpoints map[] (1.008093126s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:04:37.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-d8zvt" for this suite.
Dec  8 16:04:43.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:04:44.005: INFO: namespace: e2e-tests-services-d8zvt, resource: bindings, ignored listing per whitelist
Dec  8 16:04:44.054: INFO: namespace e2e-tests-services-d8zvt deletion completed in 6.223466488s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:15.081 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:04:44.054: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  8 16:04:44.280: INFO: Waiting up to 5m0s for pod "pod-fa4a7678-fb02-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-gg4n6" to be "success or failure"
Dec  8 16:04:44.284: INFO: Pod "pod-fa4a7678-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.46266ms
Dec  8 16:04:46.289: INFO: Pod "pod-fa4a7678-fb02-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009022701s
Dec  8 16:04:48.302: INFO: Pod "pod-fa4a7678-fb02-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021791597s
STEP: Saw pod success
Dec  8 16:04:48.302: INFO: Pod "pod-fa4a7678-fb02-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:04:48.306: INFO: Trying to get logs from node k8s-g1 pod pod-fa4a7678-fb02-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:04:48.400: INFO: Waiting for pod pod-fa4a7678-fb02-11e8-b692-aec8003d5667 to disappear
Dec  8 16:04:48.403: INFO: Pod pod-fa4a7678-fb02-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:04:48.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gg4n6" for this suite.
Dec  8 16:04:54.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:04:54.477: INFO: namespace: e2e-tests-emptydir-gg4n6, resource: bindings, ignored listing per whitelist
Dec  8 16:04:54.605: INFO: namespace e2e-tests-emptydir-gg4n6 deletion completed in 6.195142413s

• [SLOW TEST:10.551 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:04:54.605: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9f45r in namespace e2e-tests-proxy-qzjhw
I1208 16:04:55.117367      20 runners.go:180] Created replication controller with name: proxy-service-9f45r, namespace: e2e-tests-proxy-qzjhw, replica count: 1
I1208 16:04:56.167677      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 16:04:57.167787      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 16:04:58.167922      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 16:04:59.168047      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 16:05:00.168189      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 16:05:01.168339      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 16:05:02.168507      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 16:05:03.168708      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 16:05:04.168924      20 runners.go:180] proxy-service-9f45r Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  8 16:05:04.173: INFO: setup took 9.263347114s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  8 16:05:04.182: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.063558ms)
Dec  8 16:05:04.182: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 8.251187ms)
Dec  8 16:05:04.182: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.609023ms)
Dec  8 16:05:04.183: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 8.981335ms)
Dec  8 16:05:04.183: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.557237ms)
Dec  8 16:05:04.183: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 8.744517ms)
Dec  8 16:05:04.183: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.329243ms)
Dec  8 16:05:04.184: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 8.647909ms)
Dec  8 16:05:04.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 14.89603ms)
Dec  8 16:05:04.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 14.379976ms)
Dec  8 16:05:04.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 14.838521ms)
Dec  8 16:05:04.191: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 17.997797ms)
Dec  8 16:05:04.193: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 17.466436ms)
Dec  8 16:05:04.193: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 18.021234ms)
Dec  8 16:05:04.193: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 18.483459ms)
Dec  8 16:05:04.193: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 18.940606ms)
Dec  8 16:05:04.201: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 7.016387ms)
Dec  8 16:05:04.201: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 7.742502ms)
Dec  8 16:05:04.201: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.516644ms)
Dec  8 16:05:04.202: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.22625ms)
Dec  8 16:05:04.202: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 7.885456ms)
Dec  8 16:05:04.202: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 7.778863ms)
Dec  8 16:05:04.202: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.626ms)
Dec  8 16:05:04.202: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 8.395777ms)
Dec  8 16:05:04.202: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 7.991073ms)
Dec  8 16:05:04.203: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 9.45353ms)
Dec  8 16:05:04.203: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.697034ms)
Dec  8 16:05:04.203: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 10.101501ms)
Dec  8 16:05:04.203: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 9.991674ms)
Dec  8 16:05:04.203: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 9.978278ms)
Dec  8 16:05:04.204: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 10.11634ms)
Dec  8 16:05:04.205: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 11.325829ms)
Dec  8 16:05:04.211: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 5.707928ms)
Dec  8 16:05:04.212: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 6.317801ms)
Dec  8 16:05:04.212: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 7.113677ms)
Dec  8 16:05:04.212: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.090553ms)
Dec  8 16:05:04.212: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 7.126418ms)
Dec  8 16:05:04.212: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 7.188825ms)
Dec  8 16:05:04.212: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 7.117225ms)
Dec  8 16:05:04.212: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.02937ms)
Dec  8 16:05:04.212: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 7.247874ms)
Dec  8 16:05:04.213: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 7.785451ms)
Dec  8 16:05:04.214: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 8.72898ms)
Dec  8 16:05:04.217: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 11.45173ms)
Dec  8 16:05:04.217: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 11.616089ms)
Dec  8 16:05:04.217: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 11.480805ms)
Dec  8 16:05:04.217: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 11.732733ms)
Dec  8 16:05:04.217: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 11.568166ms)
Dec  8 16:05:04.222: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 4.615053ms)
Dec  8 16:05:04.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.743242ms)
Dec  8 16:05:04.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.550919ms)
Dec  8 16:05:04.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.505151ms)
Dec  8 16:05:04.225: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.576626ms)
Dec  8 16:05:04.226: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.443738ms)
Dec  8 16:05:04.226: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 8.463931ms)
Dec  8 16:05:04.226: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.451755ms)
Dec  8 16:05:04.226: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.568859ms)
Dec  8 16:05:04.226: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 8.517062ms)
Dec  8 16:05:04.227: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 10.092152ms)
Dec  8 16:05:04.228: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 11.087032ms)
Dec  8 16:05:04.228: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 11.124945ms)
Dec  8 16:05:04.228: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 11.141812ms)
Dec  8 16:05:04.228: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 11.073803ms)
Dec  8 16:05:04.229: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 11.886408ms)
Dec  8 16:05:04.234: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 5.146935ms)
Dec  8 16:05:04.237: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 7.798196ms)
Dec  8 16:05:04.237: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 7.938089ms)
Dec  8 16:05:04.237: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.827588ms)
Dec  8 16:05:04.237: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.330351ms)
Dec  8 16:05:04.237: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.406716ms)
Dec  8 16:05:04.237: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.397418ms)
Dec  8 16:05:04.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 9.029518ms)
Dec  8 16:05:04.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 9.017802ms)
Dec  8 16:05:04.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 9.138774ms)
Dec  8 16:05:04.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 9.724213ms)
Dec  8 16:05:04.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 10.435134ms)
Dec  8 16:05:04.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 11.064278ms)
Dec  8 16:05:04.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 11.088971ms)
Dec  8 16:05:04.240: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 11.059495ms)
Dec  8 16:05:04.241: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 11.977821ms)
Dec  8 16:05:04.249: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.698058ms)
Dec  8 16:05:04.249: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.775916ms)
Dec  8 16:05:04.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.541587ms)
Dec  8 16:05:04.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 8.677271ms)
Dec  8 16:05:04.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.633516ms)
Dec  8 16:05:04.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 8.624603ms)
Dec  8 16:05:04.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.792262ms)
Dec  8 16:05:04.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.732471ms)
Dec  8 16:05:04.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 8.61622ms)
Dec  8 16:05:04.250: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.725832ms)
Dec  8 16:05:04.251: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 9.72044ms)
Dec  8 16:05:04.252: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 10.539349ms)
Dec  8 16:05:04.252: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 10.433702ms)
Dec  8 16:05:04.252: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 10.433302ms)
Dec  8 16:05:04.252: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 10.518533ms)
Dec  8 16:05:04.252: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 10.478674ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.356549ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.268515ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 8.218855ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.282295ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 8.457176ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 8.436296ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.313575ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 8.409117ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.350079ms)
Dec  8 16:05:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 8.417341ms)
Dec  8 16:05:04.261: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 9.072422ms)
Dec  8 16:05:04.261: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.987175ms)
Dec  8 16:05:04.262: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 10.351611ms)
Dec  8 16:05:04.263: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 11.194642ms)
Dec  8 16:05:04.263: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 11.307398ms)
Dec  8 16:05:04.263: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 11.222207ms)
Dec  8 16:05:04.270: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 7.040625ms)
Dec  8 16:05:04.271: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.75462ms)
Dec  8 16:05:04.271: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 7.801596ms)
Dec  8 16:05:04.271: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 7.749387ms)
Dec  8 16:05:04.272: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.670801ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 9.553317ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 9.560331ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 9.54746ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 9.71581ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 9.580176ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 9.646684ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 9.803645ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 10.326351ms)
Dec  8 16:05:04.273: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 10.305692ms)
Dec  8 16:05:04.274: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 11.11275ms)
Dec  8 16:05:04.277: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 14.167551ms)
Dec  8 16:05:04.285: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 7.740105ms)
Dec  8 16:05:04.287: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 9.981507ms)
Dec  8 16:05:04.287: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 10.040933ms)
Dec  8 16:05:04.287: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 9.957785ms)
Dec  8 16:05:04.287: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 10.102104ms)
Dec  8 16:05:04.287: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 10.020077ms)
Dec  8 16:05:04.288: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 9.967889ms)
Dec  8 16:05:04.289: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 11.038006ms)
Dec  8 16:05:04.289: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 10.975877ms)
Dec  8 16:05:04.289: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 11.04637ms)
Dec  8 16:05:04.290: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 12.79402ms)
Dec  8 16:05:04.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 14.51936ms)
Dec  8 16:05:04.294: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 16.837441ms)
Dec  8 16:05:04.294: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 16.909235ms)
Dec  8 16:05:04.294: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 16.823693ms)
Dec  8 16:05:04.294: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 16.771103ms)
Dec  8 16:05:04.300: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 5.40387ms)
Dec  8 16:05:04.301: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 5.973849ms)
Dec  8 16:05:04.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.971061ms)
Dec  8 16:05:04.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.867448ms)
Dec  8 16:05:04.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.969446ms)
Dec  8 16:05:04.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.865241ms)
Dec  8 16:05:04.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.891605ms)
Dec  8 16:05:04.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.866731ms)
Dec  8 16:05:04.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 9.019539ms)
Dec  8 16:05:04.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 8.924966ms)
Dec  8 16:05:04.304: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 9.504842ms)
Dec  8 16:05:04.305: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 10.514447ms)
Dec  8 16:05:04.305: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 10.535823ms)
Dec  8 16:05:04.306: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 11.454865ms)
Dec  8 16:05:04.306: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 11.372978ms)
Dec  8 16:05:04.306: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 11.460787ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.839455ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 8.840785ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.812269ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 8.780293ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.767541ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.746734ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.75563ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 8.937644ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.817239ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.802074ms)
Dec  8 16:05:04.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 9.056444ms)
Dec  8 16:05:04.316: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 9.859707ms)
Dec  8 16:05:04.316: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 9.965773ms)
Dec  8 16:05:04.316: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 9.978832ms)
Dec  8 16:05:04.317: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 10.670054ms)
Dec  8 16:05:04.317: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 10.741158ms)
Dec  8 16:05:04.322: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 4.630918ms)
Dec  8 16:05:04.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 6.938605ms)
Dec  8 16:05:04.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 6.810397ms)
Dec  8 16:05:04.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 6.86081ms)
Dec  8 16:05:04.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 6.887427ms)
Dec  8 16:05:04.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 6.946452ms)
Dec  8 16:05:04.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 6.841223ms)
Dec  8 16:05:04.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.514971ms)
Dec  8 16:05:04.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 7.549741ms)
Dec  8 16:05:04.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.692359ms)
Dec  8 16:05:04.326: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 9.410191ms)
Dec  8 16:05:04.326: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 9.200341ms)
Dec  8 16:05:04.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 10.695024ms)
Dec  8 16:05:04.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 10.726678ms)
Dec  8 16:05:04.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 10.866892ms)
Dec  8 16:05:04.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 10.798599ms)
Dec  8 16:05:04.333: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 4.714875ms)
Dec  8 16:05:04.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 7.879074ms)
Dec  8 16:05:04.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 7.965509ms)
Dec  8 16:05:04.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.822575ms)
Dec  8 16:05:04.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 7.888186ms)
Dec  8 16:05:04.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.87414ms)
Dec  8 16:05:04.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 9.010214ms)
Dec  8 16:05:04.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 9.086197ms)
Dec  8 16:05:04.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 9.027624ms)
Dec  8 16:05:04.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 9.037542ms)
Dec  8 16:05:04.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 9.065603ms)
Dec  8 16:05:04.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 9.847165ms)
Dec  8 16:05:04.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 9.892073ms)
Dec  8 16:05:04.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 9.69392ms)
Dec  8 16:05:04.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 9.878855ms)
Dec  8 16:05:04.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 10.307079ms)
Dec  8 16:05:04.345: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 6.181299ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.990252ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 8.071364ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.708955ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.69677ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 8.874907ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.923849ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.938648ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.872668ms)
Dec  8 16:05:04.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.903112ms)
Dec  8 16:05:04.349: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 10.394732ms)
Dec  8 16:05:04.351: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 12.716314ms)
Dec  8 16:05:04.351: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 12.803963ms)
Dec  8 16:05:04.351: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 12.701743ms)
Dec  8 16:05:04.351: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 12.885678ms)
Dec  8 16:05:04.351: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 12.740784ms)
Dec  8 16:05:04.361: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 9.961893ms)
Dec  8 16:05:04.362: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 10.316839ms)
Dec  8 16:05:04.364: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 12.479458ms)
Dec  8 16:05:04.364: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 12.311151ms)
Dec  8 16:05:04.364: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 12.629356ms)
Dec  8 16:05:04.364: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 12.628724ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 13.202911ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 13.169677ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 13.119527ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 13.114227ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 13.052232ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 13.505737ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 13.713967ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 13.566142ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 13.609379ms)
Dec  8 16:05:04.365: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 13.724615ms)
Dec  8 16:05:04.373: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.801775ms)
Dec  8 16:05:04.373: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.728359ms)
Dec  8 16:05:04.373: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 7.795017ms)
Dec  8 16:05:04.374: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.571505ms)
Dec  8 16:05:04.374: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.603677ms)
Dec  8 16:05:04.374: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 8.507271ms)
Dec  8 16:05:04.374: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.705378ms)
Dec  8 16:05:04.374: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 8.794167ms)
Dec  8 16:05:04.375: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 9.389221ms)
Dec  8 16:05:04.375: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 9.432682ms)
Dec  8 16:05:04.375: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 9.376536ms)
Dec  8 16:05:04.375: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 9.487965ms)
Dec  8 16:05:04.377: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 11.242572ms)
Dec  8 16:05:04.377: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 11.273657ms)
Dec  8 16:05:04.377: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 11.308922ms)
Dec  8 16:05:04.377: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 11.32245ms)
Dec  8 16:05:04.382: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 5.219648ms)
Dec  8 16:05:04.384: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 7.541718ms)
Dec  8 16:05:04.384: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.251456ms)
Dec  8 16:05:04.385: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 7.504899ms)
Dec  8 16:05:04.385: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.079206ms)
Dec  8 16:05:04.385: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 7.612933ms)
Dec  8 16:05:04.385: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 7.843672ms)
Dec  8 16:05:04.386: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.202049ms)
Dec  8 16:05:04.386: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.686194ms)
Dec  8 16:05:04.387: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 9.249313ms)
Dec  8 16:05:04.387: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 9.990923ms)
Dec  8 16:05:04.387: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 10.048848ms)
Dec  8 16:05:04.388: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 10.318974ms)
Dec  8 16:05:04.388: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 10.674464ms)
Dec  8 16:05:04.389: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 11.13687ms)
Dec  8 16:05:04.389: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 11.116386ms)
Dec  8 16:05:04.395: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 6.710245ms)
Dec  8 16:05:04.397: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.375407ms)
Dec  8 16:05:04.397: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.420305ms)
Dec  8 16:05:04.398: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 9.320006ms)
Dec  8 16:05:04.398: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 9.247499ms)
Dec  8 16:05:04.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 9.90463ms)
Dec  8 16:05:04.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 10.09701ms)
Dec  8 16:05:04.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 10.078267ms)
Dec  8 16:05:04.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 9.918419ms)
Dec  8 16:05:04.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 9.999529ms)
Dec  8 16:05:04.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 10.543547ms)
Dec  8 16:05:04.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 10.611036ms)
Dec  8 16:05:04.400: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 11.255555ms)
Dec  8 16:05:04.400: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 11.339252ms)
Dec  8 16:05:04.400: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 11.222895ms)
Dec  8 16:05:04.400: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 11.330502ms)
Dec  8 16:05:04.406: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 5.844828ms)
Dec  8 16:05:04.407: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 6.995812ms)
Dec  8 16:05:04.407: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 7.280459ms)
Dec  8 16:05:04.407: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.165117ms)
Dec  8 16:05:04.407: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 7.336618ms)
Dec  8 16:05:04.407: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 7.396897ms)
Dec  8 16:05:04.407: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 7.335903ms)
Dec  8 16:05:04.407: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 7.263372ms)
Dec  8 16:05:04.408: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 7.78973ms)
Dec  8 16:05:04.409: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 8.749179ms)
Dec  8 16:05:04.409: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.645207ms)
Dec  8 16:05:04.410: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 10.11017ms)
Dec  8 16:05:04.410: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 10.328327ms)
Dec  8 16:05:04.411: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 10.46933ms)
Dec  8 16:05:04.411: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 10.323653ms)
Dec  8 16:05:04.411: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 10.316074ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.365072ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.486208ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:162/proxy/: bar (200; 8.423797ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:462/proxy/: tls qux (200; 8.441624ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/http:proxy-service-9f45r-rfjnw:1080/proxy/... (200; 8.496005ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:160/proxy/: foo (200; 8.551144ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw:1080/proxy/rewri... (200; 8.461016ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:460/proxy/: tls baz (200; 8.441753ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/proxy-service-9f45r-rfjnw/proxy/rewriteme"... (200; 8.485341ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname2/proxy/: tls qux (200; 8.621378ms)
Dec  8 16:05:04.419: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-qzjhw/pods/https:proxy-service-9f45r-rfjnw:443/proxy/... (200; 8.502073ms)
Dec  8 16:05:04.420: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname2/proxy/: bar (200; 9.686572ms)
Dec  8 16:05:04.423: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/proxy-service-9f45r:portname1/proxy/: foo (200; 12.106632ms)
Dec  8 16:05:04.423: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname2/proxy/: bar (200; 12.019506ms)
Dec  8 16:05:04.423: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/https:proxy-service-9f45r:tlsportname1/proxy/: tls baz (200; 12.180714ms)
Dec  8 16:05:04.423: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-qzjhw/services/http:proxy-service-9f45r:portname1/proxy/: foo (200; 12.087458ms)
STEP: deleting { ReplicationController} proxy-service-9f45r in namespace e2e-tests-proxy-qzjhw, will wait for the garbage collector to delete the pods
Dec  8 16:05:04.518: INFO: Deleting { ReplicationController} proxy-service-9f45r took: 41.055647ms
Dec  8 16:05:04.618: INFO: Terminating { ReplicationController} proxy-service-9f45r pods took: 100.147691ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:05:11.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-qzjhw" for this suite.
Dec  8 16:05:17.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:05:17.740: INFO: namespace: e2e-tests-proxy-qzjhw, resource: bindings, ignored listing per whitelist
Dec  8 16:05:17.803: INFO: namespace e2e-tests-proxy-qzjhw deletion completed in 6.176436474s

• [SLOW TEST:23.197 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:05:17.803: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-lm87v
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  8 16:05:18.085: INFO: Found 0 stateful pods, waiting for 3
Dec  8 16:05:28.089: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:05:28.089: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:05:28.089: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:05:28.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-lm87v ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 16:05:28.264: INFO: stderr: ""
Dec  8 16:05:28.264: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 16:05:28.264: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  8 16:05:38.317: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  8 16:05:48.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-lm87v ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 16:05:48.520: INFO: stderr: ""
Dec  8 16:05:48.520: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 16:05:48.520: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 16:05:58.541: INFO: Waiting for StatefulSet e2e-tests-statefulset-lm87v/ss2 to complete update
Dec  8 16:05:58.541: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:05:58.541: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:05:58.541: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:06:08.553: INFO: Waiting for StatefulSet e2e-tests-statefulset-lm87v/ss2 to complete update
Dec  8 16:06:08.553: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:06:08.553: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:06:18.549: INFO: Waiting for StatefulSet e2e-tests-statefulset-lm87v/ss2 to complete update
Dec  8 16:06:18.549: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:06:18.549: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:06:28.549: INFO: Waiting for StatefulSet e2e-tests-statefulset-lm87v/ss2 to complete update
Dec  8 16:06:28.549: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Dec  8 16:06:38.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-lm87v ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 16:06:38.719: INFO: stderr: ""
Dec  8 16:06:38.719: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 16:06:38.719: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 16:06:48.771: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  8 16:06:58.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-lm87v ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 16:06:58.915: INFO: stderr: ""
Dec  8 16:06:58.916: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 16:06:58.916: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 16:07:18.939: INFO: Waiting for StatefulSet e2e-tests-statefulset-lm87v/ss2 to complete update
Dec  8 16:07:18.939: INFO: Waiting for Pod e2e-tests-statefulset-lm87v/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 16:07:28.949: INFO: Deleting all statefulset in ns e2e-tests-statefulset-lm87v
Dec  8 16:07:28.952: INFO: Scaling statefulset ss2 to 0
Dec  8 16:08:08.988: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 16:08:08.991: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:08:09.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-lm87v" for this suite.
Dec  8 16:08:17.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:08:17.115: INFO: namespace: e2e-tests-statefulset-lm87v, resource: bindings, ignored listing per whitelist
Dec  8 16:08:17.308: INFO: namespace e2e-tests-statefulset-lm87v deletion completed in 8.27173336s

• [SLOW TEST:179.505 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:08:17.308: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-s6lfp
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  8 16:08:17.697: INFO: Found 0 stateful pods, waiting for 3
Dec  8 16:08:27.702: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:08:27.702: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:08:27.702: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
Dec  8 16:08:37.701: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:08:37.701: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:08:37.701: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  8 16:08:37.784: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  8 16:08:47.868: INFO: Updating stateful set ss2
Dec  8 16:08:47.876: INFO: Waiting for Pod e2e-tests-statefulset-s6lfp/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:08:57.886: INFO: Waiting for Pod e2e-tests-statefulset-s6lfp/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  8 16:09:08.177: INFO: Found 2 stateful pods, waiting for 3
Dec  8 16:09:18.182: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:09:18.182: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:09:18.182: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  8 16:09:18.224: INFO: Updating stateful set ss2
Dec  8 16:09:18.254: INFO: Waiting for Pod e2e-tests-statefulset-s6lfp/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:09:28.302: INFO: Updating stateful set ss2
Dec  8 16:09:28.366: INFO: Waiting for StatefulSet e2e-tests-statefulset-s6lfp/ss2 to complete update
Dec  8 16:09:28.366: INFO: Waiting for Pod e2e-tests-statefulset-s6lfp/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 16:09:38.373: INFO: Waiting for StatefulSet e2e-tests-statefulset-s6lfp/ss2 to complete update
Dec  8 16:09:38.373: INFO: Waiting for Pod e2e-tests-statefulset-s6lfp/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 16:09:48.373: INFO: Deleting all statefulset in ns e2e-tests-statefulset-s6lfp
Dec  8 16:09:48.376: INFO: Scaling statefulset ss2 to 0
Dec  8 16:10:18.420: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 16:10:18.423: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:10:18.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-s6lfp" for this suite.
Dec  8 16:10:26.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:10:26.616: INFO: namespace: e2e-tests-statefulset-s6lfp, resource: bindings, ignored listing per whitelist
Dec  8 16:10:26.668: INFO: namespace e2e-tests-statefulset-s6lfp deletion completed in 8.198481663s

• [SLOW TEST:129.360 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:10:26.668: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 16:10:26.931: INFO: Waiting up to 5m0s for pod "downward-api-c683bdaf-fb03-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-gstl8" to be "success or failure"
Dec  8 16:10:26.935: INFO: Pod "downward-api-c683bdaf-fb03-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.797363ms
Dec  8 16:10:28.940: INFO: Pod "downward-api-c683bdaf-fb03-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008823017s
Dec  8 16:10:30.944: INFO: Pod "downward-api-c683bdaf-fb03-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013684895s
STEP: Saw pod success
Dec  8 16:10:30.944: INFO: Pod "downward-api-c683bdaf-fb03-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:10:30.948: INFO: Trying to get logs from node k8s-g2 pod downward-api-c683bdaf-fb03-11e8-b692-aec8003d5667 container dapi-container: <nil>
STEP: delete the pod
Dec  8 16:10:30.992: INFO: Waiting for pod downward-api-c683bdaf-fb03-11e8-b692-aec8003d5667 to disappear
Dec  8 16:10:31.001: INFO: Pod downward-api-c683bdaf-fb03-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:10:31.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gstl8" for this suite.
Dec  8 16:10:37.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:10:37.123: INFO: namespace: e2e-tests-downward-api-gstl8, resource: bindings, ignored listing per whitelist
Dec  8 16:10:37.229: INFO: namespace e2e-tests-downward-api-gstl8 deletion completed in 6.211425002s

• [SLOW TEST:10.560 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:10:37.229: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  8 16:10:41.599: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-ccd45f52-fb03-11e8-b692-aec8003d5667", GenerateName:"", Namespace:"e2e-tests-pods-cvt26", SelfLink:"/api/v1/namespaces/e2e-tests-pods-cvt26/pods/pod-submit-remove-ccd45f52-fb03-11e8-b692-aec8003d5667", UID:"ccd5f016-fb03-11e8-b4e1-448a5b81d79a", ResourceVersion:"11446", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679882237, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"474392993", "name":"foo"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.244.4.56/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jg6kz", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421e262c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jg6kz", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421bce9e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-g1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4229ff860), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421bcea30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421bcea50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421bcea58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882237, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882239, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882239, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882237, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.22.132.13", PodIP:"10.244.4.56", StartTime:(*v1.Time)(0xc420d53b40), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc420d53b60), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6", ContainerID:"docker://c0d7333b86c60865de073d71d40c3ca36d2c76308a5180c88ccc35026a760fde"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  8 16:10:46.693: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:10:46.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cvt26" for this suite.
Dec  8 16:10:52.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:10:52.867: INFO: namespace: e2e-tests-pods-cvt26, resource: bindings, ignored listing per whitelist
Dec  8 16:10:52.870: INFO: namespace e2e-tests-pods-cvt26 deletion completed in 6.166658757s

• [SLOW TEST:15.641 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:10:52.870: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d627ad47-fb03-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:10:53.186: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d62d6efc-fb03-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-6fs9s" to be "success or failure"
Dec  8 16:10:53.227: INFO: Pod "pod-projected-configmaps-d62d6efc-fb03-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 41.526883ms
Dec  8 16:10:55.232: INFO: Pod "pod-projected-configmaps-d62d6efc-fb03-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045769212s
Dec  8 16:10:57.236: INFO: Pod "pod-projected-configmaps-d62d6efc-fb03-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049948757s
STEP: Saw pod success
Dec  8 16:10:57.236: INFO: Pod "pod-projected-configmaps-d62d6efc-fb03-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:10:57.239: INFO: Trying to get logs from node k8s-g2 pod pod-projected-configmaps-d62d6efc-fb03-11e8-b692-aec8003d5667 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:10:57.300: INFO: Waiting for pod pod-projected-configmaps-d62d6efc-fb03-11e8-b692-aec8003d5667 to disappear
Dec  8 16:10:57.318: INFO: Pod pod-projected-configmaps-d62d6efc-fb03-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:10:57.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6fs9s" for this suite.
Dec  8 16:11:03.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:11:03.420: INFO: namespace: e2e-tests-projected-6fs9s, resource: bindings, ignored listing per whitelist
Dec  8 16:11:03.482: INFO: namespace e2e-tests-projected-6fs9s deletion completed in 6.156917631s

• [SLOW TEST:10.612 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:11:03.482: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-dc75be66-fb03-11e8-b692-aec8003d5667
STEP: Creating configMap with name cm-test-opt-upd-dc75be8e-fb03-11e8-b692-aec8003d5667
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-dc75be66-fb03-11e8-b692-aec8003d5667
STEP: Updating configmap cm-test-opt-upd-dc75be8e-fb03-11e8-b692-aec8003d5667
STEP: Creating configMap with name cm-test-opt-create-dc75be9a-fb03-11e8-b692-aec8003d5667
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:11:09.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x8z6j" for this suite.
Dec  8 16:11:34.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:11:34.052: INFO: namespace: e2e-tests-projected-x8z6j, resource: bindings, ignored listing per whitelist
Dec  8 16:11:34.152: INFO: namespace e2e-tests-projected-x8z6j deletion completed in 24.166395778s

• [SLOW TEST:30.670 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:11:34.152: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  8 16:11:34.377: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 16:11:34.389: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 16:11:34.392: INFO: 
Logging pods the kubelet thinks is on node k8s-g1 before test
Dec  8 16:11:34.408: INFO: sonobuoy-e2e-job-b2f0b9428b2343be from heptio-sonobuoy started at 2018-12-08 15:38:14 +0000 UTC (2 container statuses recorded)
Dec  8 16:11:34.408: INFO: 	Container e2e ready: true, restart count 0
Dec  8 16:11:34.408: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 16:11:34.408: INFO: sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-dprzm from heptio-sonobuoy started at 2018-12-08 15:38:15 +0000 UTC (2 container statuses recorded)
Dec  8 16:11:34.408: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  8 16:11:34.408: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 16:11:34.408: INFO: kube-proxy-npf4v from kube-system started at 2018-12-08 15:13:14 +0000 UTC (1 container statuses recorded)
Dec  8 16:11:34.408: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 16:11:34.408: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 15:38:07 +0000 UTC (1 container statuses recorded)
Dec  8 16:11:34.408: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  8 16:11:34.408: INFO: calico-node-j2p5w from kube-system started at 2018-12-08 15:12:24 +0000 UTC (2 container statuses recorded)
Dec  8 16:11:34.408: INFO: 	Container calico-node ready: true, restart count 0
Dec  8 16:11:34.408: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 16:11:34.408: INFO: nvidia-device-plugin-daemonset-1.12-wtl6n from kube-system started at 2018-12-08 15:13:14 +0000 UTC (1 container statuses recorded)
Dec  8 16:11:34.408: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  8 16:11:34.408: INFO: 
Logging pods the kubelet thinks is on node k8s-g2 before test
Dec  8 16:11:34.417: INFO: calico-node-gqg76 from kube-system started at 2018-12-08 15:12:24 +0000 UTC (2 container statuses recorded)
Dec  8 16:11:34.417: INFO: 	Container calico-node ready: true, restart count 0
Dec  8 16:11:34.417: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 16:11:34.417: INFO: sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-jlvwf from heptio-sonobuoy started at 2018-12-08 15:38:15 +0000 UTC (2 container statuses recorded)
Dec  8 16:11:34.417: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  8 16:11:34.417: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 16:11:34.417: INFO: nvidia-device-plugin-daemonset-1.12-wv4wg from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:11:34.417: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  8 16:11:34.417: INFO: kube-proxy-mn5f4 from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:11:34.417: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 16:11:34.417: INFO: coredns-84ff64cf58-psbbm from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:11:34.417: INFO: 	Container coredns ready: true, restart count 0
Dec  8 16:11:34.417: INFO: coredns-84ff64cf58-x62gl from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:11:34.417: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f1342f6a-fb03-11e8-b692-aec8003d5667 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f1342f6a-fb03-11e8-b692-aec8003d5667 off the node k8s-g2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f1342f6a-fb03-11e8-b692-aec8003d5667
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:11:42.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ln6pn" for this suite.
Dec  8 16:11:52.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:11:52.993: INFO: namespace: e2e-tests-sched-pred-ln6pn, resource: bindings, ignored listing per whitelist
Dec  8 16:11:53.030: INFO: namespace e2e-tests-sched-pred-ln6pn deletion completed in 10.222023688s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:18.878 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:11:53.030: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fa095516-fb03-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:11:53.363: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fa0d880d-fb03-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-plwj6" to be "success or failure"
Dec  8 16:11:53.394: INFO: Pod "pod-projected-configmaps-fa0d880d-fb03-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 31.453292ms
Dec  8 16:11:55.398: INFO: Pod "pod-projected-configmaps-fa0d880d-fb03-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035310917s
Dec  8 16:11:57.403: INFO: Pod "pod-projected-configmaps-fa0d880d-fb03-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039956302s
STEP: Saw pod success
Dec  8 16:11:57.403: INFO: Pod "pod-projected-configmaps-fa0d880d-fb03-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:11:57.406: INFO: Trying to get logs from node k8s-g1 pod pod-projected-configmaps-fa0d880d-fb03-11e8-b692-aec8003d5667 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:11:57.496: INFO: Waiting for pod pod-projected-configmaps-fa0d880d-fb03-11e8-b692-aec8003d5667 to disappear
Dec  8 16:11:57.500: INFO: Pod pod-projected-configmaps-fa0d880d-fb03-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:11:57.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-plwj6" for this suite.
Dec  8 16:12:03.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:12:03.720: INFO: namespace: e2e-tests-projected-plwj6, resource: bindings, ignored listing per whitelist
Dec  8 16:12:03.750: INFO: namespace e2e-tests-projected-plwj6 deletion completed in 6.223833075s

• [SLOW TEST:10.720 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:12:03.750: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:12:04.017: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00671232-fb04-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-sl846" to be "success or failure"
Dec  8 16:12:04.048: INFO: Pod "downwardapi-volume-00671232-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 31.195088ms
Dec  8 16:12:06.066: INFO: Pod "downwardapi-volume-00671232-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049281893s
Dec  8 16:12:08.071: INFO: Pod "downwardapi-volume-00671232-fb04-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054190791s
STEP: Saw pod success
Dec  8 16:12:08.071: INFO: Pod "downwardapi-volume-00671232-fb04-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:12:08.076: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-00671232-fb04-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:12:08.126: INFO: Waiting for pod downwardapi-volume-00671232-fb04-11e8-b692-aec8003d5667 to disappear
Dec  8 16:12:08.141: INFO: Pod downwardapi-volume-00671232-fb04-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:12:08.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sl846" for this suite.
Dec  8 16:12:14.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:12:14.289: INFO: namespace: e2e-tests-projected-sl846, resource: bindings, ignored listing per whitelist
Dec  8 16:12:14.342: INFO: namespace e2e-tests-projected-sl846 deletion completed in 6.192603697s

• [SLOW TEST:10.592 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:12:14.342: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-06b4dd47-fb04-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:12:14.600: INFO: Waiting up to 5m0s for pod "pod-secrets-06b73e79-fb04-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-nx66h" to be "success or failure"
Dec  8 16:12:14.707: INFO: Pod "pod-secrets-06b73e79-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 107.116711ms
Dec  8 16:12:16.711: INFO: Pod "pod-secrets-06b73e79-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110899909s
Dec  8 16:12:18.715: INFO: Pod "pod-secrets-06b73e79-fb04-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114693489s
STEP: Saw pod success
Dec  8 16:12:18.715: INFO: Pod "pod-secrets-06b73e79-fb04-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:12:18.719: INFO: Trying to get logs from node k8s-g1 pod pod-secrets-06b73e79-fb04-11e8-b692-aec8003d5667 container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:12:18.779: INFO: Waiting for pod pod-secrets-06b73e79-fb04-11e8-b692-aec8003d5667 to disappear
Dec  8 16:12:18.784: INFO: Pod pod-secrets-06b73e79-fb04-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:12:18.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nx66h" for this suite.
Dec  8 16:12:24.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:12:24.985: INFO: namespace: e2e-tests-secrets-nx66h, resource: bindings, ignored listing per whitelist
Dec  8 16:12:24.991: INFO: namespace e2e-tests-secrets-nx66h deletion completed in 6.199454256s

• [SLOW TEST:10.649 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:12:24.992: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  8 16:12:25.894: INFO: created pod pod-service-account-defaultsa
Dec  8 16:12:25.894: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  8 16:12:25.903: INFO: created pod pod-service-account-mountsa
Dec  8 16:12:25.903: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  8 16:12:25.970: INFO: created pod pod-service-account-nomountsa
Dec  8 16:12:25.970: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  8 16:12:26.039: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  8 16:12:26.039: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  8 16:12:26.104: INFO: created pod pod-service-account-mountsa-mountspec
Dec  8 16:12:26.104: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  8 16:12:26.359: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  8 16:12:26.359: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  8 16:12:26.420: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  8 16:12:26.420: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  8 16:12:26.574: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  8 16:12:26.574: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  8 16:12:26.645: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  8 16:12:26.645: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:12:26.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-n6plz" for this suite.
Dec  8 16:12:51.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:12:51.348: INFO: namespace: e2e-tests-svcaccounts-n6plz, resource: bindings, ignored listing per whitelist
Dec  8 16:12:51.348: INFO: namespace e2e-tests-svcaccounts-n6plz deletion completed in 24.346699398s

• [SLOW TEST:26.357 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:12:51.349: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1cc8e2cc-fb04-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:12:51.807: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1cd258be-fb04-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-4hngc" to be "success or failure"
Dec  8 16:12:51.881: INFO: Pod "pod-projected-secrets-1cd258be-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 74.030607ms
Dec  8 16:12:53.885: INFO: Pod "pod-projected-secrets-1cd258be-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078310832s
Dec  8 16:12:55.889: INFO: Pod "pod-projected-secrets-1cd258be-fb04-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.082486829s
STEP: Saw pod success
Dec  8 16:12:55.889: INFO: Pod "pod-projected-secrets-1cd258be-fb04-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:12:55.893: INFO: Trying to get logs from node k8s-g1 pod pod-projected-secrets-1cd258be-fb04-11e8-b692-aec8003d5667 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:12:55.960: INFO: Waiting for pod pod-projected-secrets-1cd258be-fb04-11e8-b692-aec8003d5667 to disappear
Dec  8 16:12:55.963: INFO: Pod pod-projected-secrets-1cd258be-fb04-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:12:55.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4hngc" for this suite.
Dec  8 16:13:02.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:13:02.077: INFO: namespace: e2e-tests-projected-4hngc, resource: bindings, ignored listing per whitelist
Dec  8 16:13:02.266: INFO: namespace e2e-tests-projected-4hngc deletion completed in 6.295535486s

• [SLOW TEST:10.917 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:13:02.266: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:13:02.463: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:13:03.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-nzvtl" for this suite.
Dec  8 16:13:09.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:13:09.896: INFO: namespace: e2e-tests-custom-resource-definition-nzvtl, resource: bindings, ignored listing per whitelist
Dec  8 16:13:09.953: INFO: namespace e2e-tests-custom-resource-definition-nzvtl deletion completed in 6.221522441s

• [SLOW TEST:7.687 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:13:09.953: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 16:13:10.146: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:13:14.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-76kg9" for this suite.
Dec  8 16:13:20.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:13:20.821: INFO: namespace: e2e-tests-init-container-76kg9, resource: bindings, ignored listing per whitelist
Dec  8 16:13:20.905: INFO: namespace e2e-tests-init-container-76kg9 deletion completed in 6.185228061s

• [SLOW TEST:10.952 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:13:20.905: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-xfqml
Dec  8 16:13:25.185: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-xfqml
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 16:13:25.189: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:17:26.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xfqml" for this suite.
Dec  8 16:17:32.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:17:32.785: INFO: namespace: e2e-tests-container-probe-xfqml, resource: bindings, ignored listing per whitelist
Dec  8 16:17:32.887: INFO: namespace e2e-tests-container-probe-xfqml deletion completed in 6.221983253s

• [SLOW TEST:251.982 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:17:32.888: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:17:33.167: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c490311d-fb04-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-dhk6k" to be "success or failure"
Dec  8 16:17:33.171: INFO: Pod "downwardapi-volume-c490311d-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.365179ms
Dec  8 16:17:35.175: INFO: Pod "downwardapi-volume-c490311d-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00875428s
Dec  8 16:17:37.186: INFO: Pod "downwardapi-volume-c490311d-fb04-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019495055s
STEP: Saw pod success
Dec  8 16:17:37.186: INFO: Pod "downwardapi-volume-c490311d-fb04-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:17:37.189: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-c490311d-fb04-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:17:37.251: INFO: Waiting for pod downwardapi-volume-c490311d-fb04-11e8-b692-aec8003d5667 to disappear
Dec  8 16:17:37.255: INFO: Pod downwardapi-volume-c490311d-fb04-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:17:37.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dhk6k" for this suite.
Dec  8 16:17:43.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:17:43.427: INFO: namespace: e2e-tests-downward-api-dhk6k, resource: bindings, ignored listing per whitelist
Dec  8 16:17:43.502: INFO: namespace e2e-tests-downward-api-dhk6k deletion completed in 6.187180005s

• [SLOW TEST:10.615 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:17:43.502: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  8 16:17:43.788: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-260986308 proxy --unix-socket=/tmp/kubectl-proxy-unix320607315/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:17:43.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nqdlw" for this suite.
Dec  8 16:17:49.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:17:49.980: INFO: namespace: e2e-tests-kubectl-nqdlw, resource: bindings, ignored listing per whitelist
Dec  8 16:17:50.002: INFO: namespace e2e-tests-kubectl-nqdlw deletion completed in 6.154272666s

• [SLOW TEST:6.500 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:17:50.002: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  8 16:17:50.230: INFO: Waiting up to 5m0s for pod "var-expansion-cec348ac-fb04-11e8-b692-aec8003d5667" in namespace "e2e-tests-var-expansion-7cl99" to be "success or failure"
Dec  8 16:17:50.238: INFO: Pod "var-expansion-cec348ac-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 7.981001ms
Dec  8 16:17:52.242: INFO: Pod "var-expansion-cec348ac-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01246204s
Dec  8 16:17:54.246: INFO: Pod "var-expansion-cec348ac-fb04-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016859607s
STEP: Saw pod success
Dec  8 16:17:54.246: INFO: Pod "var-expansion-cec348ac-fb04-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:17:54.250: INFO: Trying to get logs from node k8s-g1 pod var-expansion-cec348ac-fb04-11e8-b692-aec8003d5667 container dapi-container: <nil>
STEP: delete the pod
Dec  8 16:17:54.321: INFO: Waiting for pod var-expansion-cec348ac-fb04-11e8-b692-aec8003d5667 to disappear
Dec  8 16:17:54.327: INFO: Pod var-expansion-cec348ac-fb04-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:17:54.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7cl99" for this suite.
Dec  8 16:18:00.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:18:00.421: INFO: namespace: e2e-tests-var-expansion-7cl99, resource: bindings, ignored listing per whitelist
Dec  8 16:18:00.515: INFO: namespace e2e-tests-var-expansion-7cl99 deletion completed in 6.180164608s

• [SLOW TEST:10.513 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:18:00.516: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  8 16:18:00.794: INFO: Waiting up to 5m0s for pod "pod-d50b52c9-fb04-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-2cpnf" to be "success or failure"
Dec  8 16:18:00.797: INFO: Pod "pod-d50b52c9-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.599593ms
Dec  8 16:18:02.801: INFO: Pod "pod-d50b52c9-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007915481s
Dec  8 16:18:04.805: INFO: Pod "pod-d50b52c9-fb04-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011527026s
STEP: Saw pod success
Dec  8 16:18:04.805: INFO: Pod "pod-d50b52c9-fb04-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:18:04.808: INFO: Trying to get logs from node k8s-g2 pod pod-d50b52c9-fb04-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:18:04.894: INFO: Waiting for pod pod-d50b52c9-fb04-11e8-b692-aec8003d5667 to disappear
Dec  8 16:18:04.898: INFO: Pod pod-d50b52c9-fb04-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:18:04.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2cpnf" for this suite.
Dec  8 16:18:10.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:18:10.995: INFO: namespace: e2e-tests-emptydir-2cpnf, resource: bindings, ignored listing per whitelist
Dec  8 16:18:11.068: INFO: namespace e2e-tests-emptydir-2cpnf deletion completed in 6.162360112s

• [SLOW TEST:10.552 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:18:11.068: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 16:18:16.008: INFO: Successfully updated pod "annotationupdatedb57860a-fb04-11e8-b692-aec8003d5667"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:18:18.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8fvhj" for this suite.
Dec  8 16:18:40.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:18:40.084: INFO: namespace: e2e-tests-projected-8fvhj, resource: bindings, ignored listing per whitelist
Dec  8 16:18:40.205: INFO: namespace e2e-tests-projected-8fvhj deletion completed in 22.17058475s

• [SLOW TEST:29.137 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:18:40.205: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ecc12fd5-fb04-11e8-b692-aec8003d5667
STEP: Creating secret with name s-test-opt-upd-ecc1300d-fb04-11e8-b692-aec8003d5667
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ecc12fd5-fb04-11e8-b692-aec8003d5667
STEP: Updating secret s-test-opt-upd-ecc1300d-fb04-11e8-b692-aec8003d5667
STEP: Creating secret with name s-test-opt-create-ecc13023-fb04-11e8-b692-aec8003d5667
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:18:46.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4bprr" for this suite.
Dec  8 16:19:10.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:19:11.059: INFO: namespace: e2e-tests-secrets-4bprr, resource: bindings, ignored listing per whitelist
Dec  8 16:19:11.183: INFO: namespace e2e-tests-secrets-4bprr deletion completed in 24.228381745s

• [SLOW TEST:30.978 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:19:11.184: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  8 16:19:11.508: INFO: Waiting up to 5m0s for pod "pod-ff2bc12f-fb04-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-cdnk9" to be "success or failure"
Dec  8 16:19:11.512: INFO: Pod "pod-ff2bc12f-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.219229ms
Dec  8 16:19:13.517: INFO: Pod "pod-ff2bc12f-fb04-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008791182s
Dec  8 16:19:15.603: INFO: Pod "pod-ff2bc12f-fb04-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095543698s
STEP: Saw pod success
Dec  8 16:19:15.603: INFO: Pod "pod-ff2bc12f-fb04-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:19:15.609: INFO: Trying to get logs from node k8s-g1 pod pod-ff2bc12f-fb04-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:19:15.733: INFO: Waiting for pod pod-ff2bc12f-fb04-11e8-b692-aec8003d5667 to disappear
Dec  8 16:19:15.736: INFO: Pod pod-ff2bc12f-fb04-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:19:15.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cdnk9" for this suite.
Dec  8 16:19:21.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:19:21.848: INFO: namespace: e2e-tests-emptydir-cdnk9, resource: bindings, ignored listing per whitelist
Dec  8 16:19:21.919: INFO: namespace e2e-tests-emptydir-cdnk9 deletion completed in 6.17561657s

• [SLOW TEST:10.735 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:19:21.919: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:19:22.189: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0590ffc5-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-zkwbl" to be "success or failure"
Dec  8 16:19:22.250: INFO: Pod "downwardapi-volume-0590ffc5-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 60.437439ms
Dec  8 16:19:24.254: INFO: Pod "downwardapi-volume-0590ffc5-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064658803s
Dec  8 16:19:26.258: INFO: Pod "downwardapi-volume-0590ffc5-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069107906s
STEP: Saw pod success
Dec  8 16:19:26.258: INFO: Pod "downwardapi-volume-0590ffc5-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:19:26.262: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-0590ffc5-fb05-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:19:26.347: INFO: Waiting for pod downwardapi-volume-0590ffc5-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:19:26.352: INFO: Pod downwardapi-volume-0590ffc5-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:19:26.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zkwbl" for this suite.
Dec  8 16:19:32.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:19:32.423: INFO: namespace: e2e-tests-downward-api-zkwbl, resource: bindings, ignored listing per whitelist
Dec  8 16:19:32.544: INFO: namespace e2e-tests-downward-api-zkwbl deletion completed in 6.185064513s

• [SLOW TEST:10.625 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:19:32.544: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  8 16:19:40.938: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:40.943: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:42.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:42.948: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:44.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:44.948: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:46.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:46.948: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:48.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:48.950: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:50.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:50.948: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:52.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:52.947: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:54.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:54.947: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:56.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:56.948: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 16:19:58.943: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 16:19:58.947: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:19:58.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ltpx9" for this suite.
Dec  8 16:20:23.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:20:23.063: INFO: namespace: e2e-tests-container-lifecycle-hook-ltpx9, resource: bindings, ignored listing per whitelist
Dec  8 16:20:23.156: INFO: namespace e2e-tests-container-lifecycle-hook-ltpx9 deletion completed in 24.195083956s

• [SLOW TEST:50.612 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:20:23.156: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:20:23.480: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a140669-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-dzbds" to be "success or failure"
Dec  8 16:20:23.483: INFO: Pod "downwardapi-volume-2a140669-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.312616ms
Dec  8 16:20:25.488: INFO: Pod "downwardapi-volume-2a140669-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008715964s
Dec  8 16:20:27.492: INFO: Pod "downwardapi-volume-2a140669-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012647011s
STEP: Saw pod success
Dec  8 16:20:27.492: INFO: Pod "downwardapi-volume-2a140669-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:20:27.496: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-2a140669-fb05-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:20:27.576: INFO: Waiting for pod downwardapi-volume-2a140669-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:20:27.579: INFO: Pod downwardapi-volume-2a140669-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:20:27.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dzbds" for this suite.
Dec  8 16:20:33.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:20:33.737: INFO: namespace: e2e-tests-downward-api-dzbds, resource: bindings, ignored listing per whitelist
Dec  8 16:20:33.780: INFO: namespace e2e-tests-downward-api-dzbds deletion completed in 6.193299317s

• [SLOW TEST:10.624 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:20:33.780: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  8 16:20:34.080: INFO: Waiting up to 5m0s for pod "pod-30689506-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-qhmwb" to be "success or failure"
Dec  8 16:20:34.133: INFO: Pod "pod-30689506-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 53.79316ms
Dec  8 16:20:36.177: INFO: Pod "pod-30689506-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097863983s
Dec  8 16:20:38.182: INFO: Pod "pod-30689506-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.102220244s
Dec  8 16:20:40.186: INFO: Pod "pod-30689506-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.106221623s
STEP: Saw pod success
Dec  8 16:20:40.186: INFO: Pod "pod-30689506-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:20:40.189: INFO: Trying to get logs from node k8s-g2 pod pod-30689506-fb05-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:20:40.288: INFO: Waiting for pod pod-30689506-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:20:40.292: INFO: Pod pod-30689506-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:20:40.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qhmwb" for this suite.
Dec  8 16:20:46.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:20:46.427: INFO: namespace: e2e-tests-emptydir-qhmwb, resource: bindings, ignored listing per whitelist
Dec  8 16:20:46.465: INFO: namespace e2e-tests-emptydir-qhmwb deletion completed in 6.166182263s

• [SLOW TEST:12.685 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:20:46.465: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-37f332e4-fb05-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:20:46.779: INFO: Waiting up to 5m0s for pod "pod-configmaps-37f9619c-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-wkvlj" to be "success or failure"
Dec  8 16:20:46.816: INFO: Pod "pod-configmaps-37f9619c-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 36.314465ms
Dec  8 16:20:48.820: INFO: Pod "pod-configmaps-37f9619c-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040618641s
Dec  8 16:20:50.824: INFO: Pod "pod-configmaps-37f9619c-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044848266s
STEP: Saw pod success
Dec  8 16:20:50.824: INFO: Pod "pod-configmaps-37f9619c-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:20:50.828: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-37f9619c-fb05-11e8-b692-aec8003d5667 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:20:50.933: INFO: Waiting for pod pod-configmaps-37f9619c-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:20:50.937: INFO: Pod pod-configmaps-37f9619c-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:20:50.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wkvlj" for this suite.
Dec  8 16:20:56.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:20:57.098: INFO: namespace: e2e-tests-configmap-wkvlj, resource: bindings, ignored listing per whitelist
Dec  8 16:20:57.211: INFO: namespace e2e-tests-configmap-wkvlj deletion completed in 6.267653555s

• [SLOW TEST:10.746 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:20:57.211: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:20:57.523: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  8 16:21:02.529: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 16:21:02.529: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  8 16:21:04.534: INFO: Creating deployment "test-rollover-deployment"
Dec  8 16:21:04.572: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  8 16:21:06.580: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  8 16:21:06.588: INFO: Ensure that both replica sets have 1 created replica
Dec  8 16:21:06.595: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  8 16:21:06.634: INFO: Updating deployment test-rollover-deployment
Dec  8 16:21:06.635: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  8 16:21:08.643: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  8 16:21:08.651: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  8 16:21:08.658: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 16:21:08.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882867, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 16:21:10.666: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 16:21:10.666: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882869, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 16:21:12.667: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 16:21:12.667: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882869, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 16:21:14.668: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 16:21:14.668: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882869, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 16:21:16.666: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 16:21:16.666: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882869, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 16:21:18.668: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 16:21:18.668: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882869, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679882864, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 16:21:20.667: INFO: 
Dec  8 16:21:20.667: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 16:21:20.679: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-zz8ft,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zz8ft/deployments/test-rollover-deployment,UID:429695c5-fb05-11e8-b4e1-448a5b81d79a,ResourceVersion:13432,Generation:2,CreationTimestamp:2018-12-08 16:21:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-08 16:21:04 +0000 UTC 2018-12-08 16:21:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-08 16:21:19 +0000 UTC 2018-12-08 16:21:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  8 16:21:20.684: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-zz8ft,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zz8ft/replicasets/test-rollover-deployment-5b76ff8c4,UID:43d70932-fb05-11e8-9316-54a05085d523,ResourceVersion:13421,Generation:2,CreationTimestamp:2018-12-08 16:21:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 429695c5-fb05-11e8-b4e1-448a5b81d79a 0xc42232dc07 0xc42232dc08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  8 16:21:20.684: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  8 16:21:20.684: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-zz8ft,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zz8ft/replicasets/test-rollover-controller,UID:3e622986-fb05-11e8-b4e1-448a5b81d79a,ResourceVersion:13430,Generation:2,CreationTimestamp:2018-12-08 16:20:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 429695c5-fb05-11e8-b4e1-448a5b81d79a 0xc42232db3e 0xc42232db3f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 16:21:20.684: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-zz8ft,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zz8ft/replicasets/test-rollover-deployment-6975f4fb87,UID:42aca503-fb05-11e8-9316-54a05085d523,ResourceVersion:13388,Generation:2,CreationTimestamp:2018-12-08 16:21:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 429695c5-fb05-11e8-b4e1-448a5b81d79a 0xc42232dcc7 0xc42232dcc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 16:21:20.688: INFO: Pod "test-rollover-deployment-5b76ff8c4-x5g7k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-x5g7k,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-zz8ft,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zz8ft/pods/test-rollover-deployment-5b76ff8c4-x5g7k,UID:4402109f-fb05-11e8-9316-54a05085d523,ResourceVersion:13400,Generation:0,CreationTimestamp:2018-12-08 16:21:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.3.84/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 43d70932-fb05-11e8-9316-54a05085d523 0xc4211d4ac0 0xc4211d4ac1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-chss5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-chss5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-chss5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211d4b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211d4bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:21:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:21:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:21:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:21:06 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:10.244.3.84,StartTime:2018-12-08 16:21:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-08 16:21:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c305be2477d442ff0f6d82b3ae26e1312a881ecd87588ccf8d1e39a437f4cb7c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:21:20.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-zz8ft" for this suite.
Dec  8 16:21:28.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:21:28.841: INFO: namespace: e2e-tests-deployment-zz8ft, resource: bindings, ignored listing per whitelist
Dec  8 16:21:28.909: INFO: namespace e2e-tests-deployment-zz8ft deletion completed in 8.21237463s

• [SLOW TEST:31.698 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:21:28.910: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  8 16:21:29.188: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5s4t6,SelfLink:/api/v1/namespaces/e2e-tests-watch-5s4t6/configmaps/e2e-watch-test-watch-closed,UID:51400994-fb05-11e8-b4e1-448a5b81d79a,ResourceVersion:13489,Generation:0,CreationTimestamp:2018-12-08 16:21:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 16:21:29.188: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5s4t6,SelfLink:/api/v1/namespaces/e2e-tests-watch-5s4t6/configmaps/e2e-watch-test-watch-closed,UID:51400994-fb05-11e8-b4e1-448a5b81d79a,ResourceVersion:13490,Generation:0,CreationTimestamp:2018-12-08 16:21:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  8 16:21:29.252: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5s4t6,SelfLink:/api/v1/namespaces/e2e-tests-watch-5s4t6/configmaps/e2e-watch-test-watch-closed,UID:51400994-fb05-11e8-b4e1-448a5b81d79a,ResourceVersion:13491,Generation:0,CreationTimestamp:2018-12-08 16:21:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 16:21:29.252: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5s4t6,SelfLink:/api/v1/namespaces/e2e-tests-watch-5s4t6/configmaps/e2e-watch-test-watch-closed,UID:51400994-fb05-11e8-b4e1-448a5b81d79a,ResourceVersion:13492,Generation:0,CreationTimestamp:2018-12-08 16:21:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:21:29.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5s4t6" for this suite.
Dec  8 16:21:35.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:21:35.377: INFO: namespace: e2e-tests-watch-5s4t6, resource: bindings, ignored listing per whitelist
Dec  8 16:21:35.474: INFO: namespace e2e-tests-watch-5s4t6 deletion completed in 6.213463306s

• [SLOW TEST:6.564 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:21:35.474: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:21:35.699: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Dec  8 16:21:35.706: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-n64s7/daemonsets","resourceVersion":"13513"},"items":null}

Dec  8 16:21:35.710: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-n64s7/pods","resourceVersion":"13513"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:21:35.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-n64s7" for this suite.
Dec  8 16:21:41.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:21:41.859: INFO: namespace: e2e-tests-daemonsets-n64s7, resource: bindings, ignored listing per whitelist
Dec  8 16:21:41.995: INFO: namespace e2e-tests-daemonsets-n64s7 deletion completed in 6.252959645s

S [SKIPPING] [6.522 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  8 16:21:35.699: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:21:41.995: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-pgjh
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 16:21:42.319: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pgjh" in namespace "e2e-tests-subpath-kl29j" to be "success or failure"
Dec  8 16:21:42.354: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Pending", Reason="", readiness=false. Elapsed: 34.603905ms
Dec  8 16:21:44.358: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038313102s
Dec  8 16:21:46.361: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041915395s
Dec  8 16:21:48.365: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 6.045735956s
Dec  8 16:21:50.426: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 8.107009883s
Dec  8 16:21:52.430: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 10.11068007s
Dec  8 16:21:54.434: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 12.115055937s
Dec  8 16:21:56.438: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 14.118645487s
Dec  8 16:21:58.467: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 16.147695975s
Dec  8 16:22:00.475: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 18.155842385s
Dec  8 16:22:02.484: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 20.164803834s
Dec  8 16:22:04.488: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Running", Reason="", readiness=false. Elapsed: 22.168672641s
Dec  8 16:22:06.519: INFO: Pod "pod-subpath-test-configmap-pgjh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.199108456s
STEP: Saw pod success
Dec  8 16:22:06.519: INFO: Pod "pod-subpath-test-configmap-pgjh" satisfied condition "success or failure"
Dec  8 16:22:06.522: INFO: Trying to get logs from node k8s-g1 pod pod-subpath-test-configmap-pgjh container test-container-subpath-configmap-pgjh: <nil>
STEP: delete the pod
Dec  8 16:22:06.652: INFO: Waiting for pod pod-subpath-test-configmap-pgjh to disappear
Dec  8 16:22:06.665: INFO: Pod pod-subpath-test-configmap-pgjh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pgjh
Dec  8 16:22:06.665: INFO: Deleting pod "pod-subpath-test-configmap-pgjh" in namespace "e2e-tests-subpath-kl29j"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:22:06.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-kl29j" for this suite.
Dec  8 16:22:12.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:22:12.743: INFO: namespace: e2e-tests-subpath-kl29j, resource: bindings, ignored listing per whitelist
Dec  8 16:22:12.890: INFO: namespace e2e-tests-subpath-kl29j deletion completed in 6.215279432s

• [SLOW TEST:30.895 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:22:12.891: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-gm5rd/configmap-test-6b7920a7-fb05-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:22:13.210: INFO: Waiting up to 5m0s for pod "pod-configmaps-6b7b6d81-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-gm5rd" to be "success or failure"
Dec  8 16:22:13.236: INFO: Pod "pod-configmaps-6b7b6d81-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 25.927404ms
Dec  8 16:22:15.240: INFO: Pod "pod-configmaps-6b7b6d81-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03072209s
Dec  8 16:22:17.244: INFO: Pod "pod-configmaps-6b7b6d81-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034621014s
STEP: Saw pod success
Dec  8 16:22:17.244: INFO: Pod "pod-configmaps-6b7b6d81-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:22:17.247: INFO: Trying to get logs from node k8s-g2 pod pod-configmaps-6b7b6d81-fb05-11e8-b692-aec8003d5667 container env-test: <nil>
STEP: delete the pod
Dec  8 16:22:17.312: INFO: Waiting for pod pod-configmaps-6b7b6d81-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:22:17.315: INFO: Pod pod-configmaps-6b7b6d81-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:22:17.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gm5rd" for this suite.
Dec  8 16:22:23.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:22:23.494: INFO: namespace: e2e-tests-configmap-gm5rd, resource: bindings, ignored listing per whitelist
Dec  8 16:22:23.500: INFO: namespace e2e-tests-configmap-gm5rd deletion completed in 6.176994345s

• [SLOW TEST:10.609 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:22:23.500: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-d4hqc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-d4hqc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-d4hqc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-d4hqc;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-d4hqc.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-d4hqc.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-d4hqc.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-d4hqc.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-d4hqc.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d4hqc.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 180.210.105.10.in-addr.arpa. PTR)" && echo OK > /results/10.105.210.180_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 180.210.105.10.in-addr.arpa. PTR)" && echo OK > /results/10.105.210.180_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-d4hqc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-d4hqc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-d4hqc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-d4hqc;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-d4hqc.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-d4hqc.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-d4hqc.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-d4hqc.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-d4hqc.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-d4hqc.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d4hqc.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 180.210.105.10.in-addr.arpa. PTR)" && echo OK > /results/10.105.210.180_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 180.210.105.10.in-addr.arpa. PTR)" && echo OK > /results/10.105.210.180_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  8 16:22:58.077: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.083: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.093: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-d4hqc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.103: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-d4hqc.svc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.108: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.113: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.145: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.150: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.155: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-d4hqc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.160: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-d4hqc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.165: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-d4hqc.svc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.170: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-d4hqc.svc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.175: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.181: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc from pod e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667: the server could not find the requested resource (get pods dns-test-71eb1363-fb05-11e8-b692-aec8003d5667)
Dec  8 16:22:58.207: INFO: Lookups using e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-d4hqc wheezy_tcp@dns-test-service.e2e-tests-dns-d4hqc.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-d4hqc jessie_tcp@dns-test-service.e2e-tests-dns-d4hqc jessie_udp@dns-test-service.e2e-tests-dns-d4hqc.svc jessie_tcp@dns-test-service.e2e-tests-dns-d4hqc.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d4hqc.svc]

Dec  8 16:23:08.199: INFO: DNS probes using e2e-tests-dns-d4hqc/dns-test-71eb1363-fb05-11e8-b692-aec8003d5667 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:23:08.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-d4hqc" for this suite.
Dec  8 16:23:16.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:23:16.863: INFO: namespace: e2e-tests-dns-d4hqc, resource: bindings, ignored listing per whitelist
Dec  8 16:23:16.911: INFO: namespace e2e-tests-dns-d4hqc deletion completed in 8.208132261s

• [SLOW TEST:53.412 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:23:16.911: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:23:17.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91aebf0d-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-2hqb6" to be "success or failure"
Dec  8 16:23:17.360: INFO: Pod "downwardapi-volume-91aebf0d-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 80.822173ms
Dec  8 16:23:19.364: INFO: Pod "downwardapi-volume-91aebf0d-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084610785s
Dec  8 16:23:21.368: INFO: Pod "downwardapi-volume-91aebf0d-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.088859407s
STEP: Saw pod success
Dec  8 16:23:21.368: INFO: Pod "downwardapi-volume-91aebf0d-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:23:21.372: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-91aebf0d-fb05-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:23:21.489: INFO: Waiting for pod downwardapi-volume-91aebf0d-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:23:21.493: INFO: Pod downwardapi-volume-91aebf0d-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:23:21.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2hqb6" for this suite.
Dec  8 16:23:27.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:23:27.656: INFO: namespace: e2e-tests-downward-api-2hqb6, resource: bindings, ignored listing per whitelist
Dec  8 16:23:27.684: INFO: namespace e2e-tests-downward-api-2hqb6 deletion completed in 6.184113894s

• [SLOW TEST:10.773 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:23:27.685: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:23:27.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 version'
Dec  8 16:23:28.040: INFO: stderr: ""
Dec  8 16:23:28.040: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:23:28.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vpcvd" for this suite.
Dec  8 16:23:34.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:23:34.111: INFO: namespace: e2e-tests-kubectl-vpcvd, resource: bindings, ignored listing per whitelist
Dec  8 16:23:34.215: INFO: namespace e2e-tests-kubectl-vpcvd deletion completed in 6.167805064s

• [SLOW TEST:6.531 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:23:34.215: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  8 16:23:34.477: INFO: Waiting up to 5m0s for pod "pod-9befef62-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-vf9tq" to be "success or failure"
Dec  8 16:23:34.497: INFO: Pod "pod-9befef62-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 19.953047ms
Dec  8 16:23:36.501: INFO: Pod "pod-9befef62-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02393834s
Dec  8 16:23:38.504: INFO: Pod "pod-9befef62-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027460062s
STEP: Saw pod success
Dec  8 16:23:38.504: INFO: Pod "pod-9befef62-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:23:38.507: INFO: Trying to get logs from node k8s-g1 pod pod-9befef62-fb05-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:23:38.596: INFO: Waiting for pod pod-9befef62-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:23:38.600: INFO: Pod pod-9befef62-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:23:38.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vf9tq" for this suite.
Dec  8 16:23:44.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:23:44.701: INFO: namespace: e2e-tests-emptydir-vf9tq, resource: bindings, ignored listing per whitelist
Dec  8 16:23:44.793: INFO: namespace e2e-tests-emptydir-vf9tq deletion completed in 6.185164759s

• [SLOW TEST:10.577 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:23:44.793: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1208 16:23:46.129720      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 16:23:46.129: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:23:46.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-snvph" for this suite.
Dec  8 16:23:52.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:23:52.260: INFO: namespace: e2e-tests-gc-snvph, resource: bindings, ignored listing per whitelist
Dec  8 16:23:52.303: INFO: namespace e2e-tests-gc-snvph deletion completed in 6.165835763s

• [SLOW TEST:7.510 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:23:52.303: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 16:23:52.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-72mg5'
Dec  8 16:23:55.463: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 16:23:55.463: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  8 16:23:55.491: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec  8 16:23:55.578: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  8 16:23:55.647: INFO: scanned /root for discovery docs: <nil>
Dec  8 16:23:55.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-72mg5'
Dec  8 16:24:11.769: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  8 16:24:11.769: INFO: stdout: "Created e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe\nScaling up e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  8 16:24:11.769: INFO: stdout: "Created e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe\nScaling up e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  8 16:24:11.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-72mg5'
Dec  8 16:24:11.905: INFO: stderr: ""
Dec  8 16:24:11.905: INFO: stdout: "e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe-nrgj8 "
Dec  8 16:24:11.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe-nrgj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72mg5'
Dec  8 16:24:11.966: INFO: stderr: ""
Dec  8 16:24:11.966: INFO: stdout: "true"
Dec  8 16:24:11.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe-nrgj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72mg5'
Dec  8 16:24:12.027: INFO: stderr: ""
Dec  8 16:24:12.027: INFO: stdout: "nginx:1.14-alpine"
Dec  8 16:24:12.027: INFO: e2e-test-nginx-rc-0c03dab91d4c726701793be5a20102fe-nrgj8 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Dec  8 16:24:12.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-72mg5'
Dec  8 16:24:12.116: INFO: stderr: ""
Dec  8 16:24:12.116: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:24:12.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-72mg5" for this suite.
Dec  8 16:24:18.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:24:18.271: INFO: namespace: e2e-tests-kubectl-72mg5, resource: bindings, ignored listing per whitelist
Dec  8 16:24:18.307: INFO: namespace e2e-tests-kubectl-72mg5 deletion completed in 6.183720875s

• [SLOW TEST:26.004 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:24:18.307: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 16:24:18.655: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:24:24.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-j9bbs" for this suite.
Dec  8 16:24:30.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:24:30.282: INFO: namespace: e2e-tests-init-container-j9bbs, resource: bindings, ignored listing per whitelist
Dec  8 16:24:30.407: INFO: namespace e2e-tests-init-container-j9bbs deletion completed in 6.184201253s

• [SLOW TEST:12.100 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:24:30.407: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:24:30.676: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 16:24:30.731: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:30.731: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:30.731: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:30.735: INFO: Number of nodes with available pods: 0
Dec  8 16:24:30.735: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:24:31.741: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:31.741: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:31.741: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:31.745: INFO: Number of nodes with available pods: 0
Dec  8 16:24:31.745: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:24:32.743: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:32.743: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:32.743: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:32.747: INFO: Number of nodes with available pods: 0
Dec  8 16:24:32.747: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:24:33.741: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:33.741: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:33.741: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:33.745: INFO: Number of nodes with available pods: 2
Dec  8 16:24:33.745: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  8 16:24:33.783: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:33.783: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:33.814: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:33.814: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:33.814: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:34.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:34.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:34.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:34.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:34.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:35.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:35.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:35.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:35.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:35.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:36.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:36.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:36.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:36.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:36.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:37.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:37.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:37.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:37.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:37.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:38.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:38.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:38.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:38.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:38.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:39.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:39.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:39.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:39.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:39.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:40.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:40.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:40.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:40.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:40.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:41.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:41.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:41.826: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:41.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:41.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:42.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:42.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:42.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:42.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:42.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:43.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:43.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:43.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:43.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:43.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:44.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:44.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:44.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:44.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:44.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:45.837: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:45.837: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:45.841: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:45.842: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:45.842: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:46.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:46.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:46.828: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:46.828: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:46.828: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:47.820: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:47.820: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:47.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:47.825: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:47.825: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:48.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:48.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:48.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:48.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:48.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:49.824: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:49.824: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:49.829: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:49.829: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:49.829: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:50.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:50.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:50.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:50.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:50.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:51.874: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:51.874: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:51.879: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:51.879: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:51.879: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:52.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:52.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:52.827: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:52.827: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:52.827: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:53.845: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:53.845: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:53.911: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:53.911: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:53.911: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:54.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:54.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:54.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:54.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:54.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:55.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:55.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:55.826: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:55.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:55.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:56.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:56.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:56.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:56.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:56.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:57.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:57.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:57.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:57.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:57.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:58.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:58.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:58.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:58.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:58.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:59.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:59.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:24:59.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:59.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:24:59.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:00.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:00.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:00.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:00.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:00.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:01.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:01.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:01.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:01.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:01.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:02.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:02.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:02.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:02.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:02.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:03.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:03.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:03.826: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:03.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:03.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:04.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:04.819: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:04.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:04.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:04.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:05.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:05.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:05.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:05.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:05.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:06.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:06.818: INFO: Wrong image for pod: daemon-set-wxbts. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:06.818: INFO: Pod daemon-set-wxbts is not available
Dec  8 16:25:06.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:06.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:06.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:07.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:07.818: INFO: Pod daemon-set-wfdnl is not available
Dec  8 16:25:07.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:07.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:07.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:08.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:08.819: INFO: Pod daemon-set-wfdnl is not available
Dec  8 16:25:08.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:08.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:08.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:09.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:09.819: INFO: Pod daemon-set-wfdnl is not available
Dec  8 16:25:09.825: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:09.825: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:09.825: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:10.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:10.818: INFO: Pod daemon-set-wfdnl is not available
Dec  8 16:25:10.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:10.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:10.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:11.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:11.819: INFO: Pod daemon-set-wfdnl is not available
Dec  8 16:25:11.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:11.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:11.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:12.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:12.818: INFO: Pod daemon-set-wfdnl is not available
Dec  8 16:25:12.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:12.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:12.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:13.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:13.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:13.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:13.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:14.832: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:14.861: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:14.861: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:14.861: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:15.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:15.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:15.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:15.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:16.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:16.825: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:16.825: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:16.825: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:17.821: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:17.829: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:17.830: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:17.830: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:18.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:18.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:18.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:18.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:19.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:19.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:19.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:19.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:20.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:20.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:20.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:20.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:21.851: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:21.927: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:21.927: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:21.927: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:22.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:22.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:22.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:22.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:23.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:23.826: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:23.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:23.827: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:24.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:24.826: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:24.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:24.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:25.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:25.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:25.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:25.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:26.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:26.826: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:26.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:26.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:27.820: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:27.830: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:27.830: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:27.830: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:28.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:28.825: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:28.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:28.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:29.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:29.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:29.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:29.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:30.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:30.825: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:30.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:30.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:31.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:31.859: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:31.859: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:31.859: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:32.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:32.828: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:32.828: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:32.829: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:33.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:33.826: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:33.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:33.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:34.843: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:34.851: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:34.851: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:34.851: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:35.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:35.826: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:35.826: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:35.826: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:36.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:36.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:36.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:36.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:37.821: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:37.828: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:37.829: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:37.829: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:38.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:38.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:38.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:38.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:39.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:39.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:39.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:39.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:40.835: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:40.839: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:40.839: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:40.839: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:41.843: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:41.848: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:41.848: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:41.848: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:42.818: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:42.823: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:42.823: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:42.823: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:43.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:43.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:43.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:43.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:44.835: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:44.839: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:44.839: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:44.839: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:45.819: INFO: Wrong image for pod: daemon-set-ph7tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 16:25:45.819: INFO: Pod daemon-set-ph7tq is not available
Dec  8 16:25:45.824: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:45.824: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:45.824: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:46.843: INFO: Pod daemon-set-pdgtp is not available
Dec  8 16:25:46.847: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:46.847: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:46.847: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  8 16:25:46.851: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:46.851: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:46.851: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:46.855: INFO: Number of nodes with available pods: 1
Dec  8 16:25:46.855: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:25:47.863: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:47.863: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:47.863: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:47.866: INFO: Number of nodes with available pods: 1
Dec  8 16:25:47.866: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:25:48.871: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:48.871: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:48.871: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:25:48.875: INFO: Number of nodes with available pods: 2
Dec  8 16:25:48.875: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-465bd, will wait for the garbage collector to delete the pods
Dec  8 16:25:48.988: INFO: Deleting {extensions DaemonSet} daemon-set took: 40.165595ms
Dec  8 16:25:49.188: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.168285ms
Dec  8 16:26:01.800: INFO: Number of nodes with available pods: 0
Dec  8 16:26:01.800: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 16:26:01.804: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-465bd/daemonsets","resourceVersion":"14429"},"items":null}

Dec  8 16:26:01.807: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-465bd/pods","resourceVersion":"14429"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:26:01.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-465bd" for this suite.
Dec  8 16:26:09.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:26:09.910: INFO: namespace: e2e-tests-daemonsets-465bd, resource: bindings, ignored listing per whitelist
Dec  8 16:26:10.007: INFO: namespace e2e-tests-daemonsets-465bd deletion completed in 8.185317919s

• [SLOW TEST:99.600 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:26:10.008: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f8d16bc7-fb05-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:26:10.396: INFO: Waiting up to 5m0s for pod "pod-configmaps-f8db5196-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-qfz6r" to be "success or failure"
Dec  8 16:26:10.410: INFO: Pod "pod-configmaps-f8db5196-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 14.163359ms
Dec  8 16:26:12.414: INFO: Pod "pod-configmaps-f8db5196-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017814677s
Dec  8 16:26:14.418: INFO: Pod "pod-configmaps-f8db5196-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02206425s
STEP: Saw pod success
Dec  8 16:26:14.418: INFO: Pod "pod-configmaps-f8db5196-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:26:14.421: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-f8db5196-fb05-11e8-b692-aec8003d5667 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:26:14.509: INFO: Waiting for pod pod-configmaps-f8db5196-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:26:14.513: INFO: Pod pod-configmaps-f8db5196-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:26:14.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qfz6r" for this suite.
Dec  8 16:26:20.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:26:20.640: INFO: namespace: e2e-tests-configmap-qfz6r, resource: bindings, ignored listing per whitelist
Dec  8 16:26:20.707: INFO: namespace e2e-tests-configmap-qfz6r deletion completed in 6.185669357s

• [SLOW TEST:10.699 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:26:20.707: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 16:26:21.049: INFO: Waiting up to 5m0s for pod "downward-api-ff351a95-fb05-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-hl9cp" to be "success or failure"
Dec  8 16:26:21.053: INFO: Pod "downward-api-ff351a95-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.241584ms
Dec  8 16:26:23.058: INFO: Pod "downward-api-ff351a95-fb05-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008550198s
Dec  8 16:26:25.065: INFO: Pod "downward-api-ff351a95-fb05-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016000935s
STEP: Saw pod success
Dec  8 16:26:25.065: INFO: Pod "downward-api-ff351a95-fb05-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:26:25.071: INFO: Trying to get logs from node k8s-g2 pod downward-api-ff351a95-fb05-11e8-b692-aec8003d5667 container dapi-container: <nil>
STEP: delete the pod
Dec  8 16:26:25.155: INFO: Waiting for pod downward-api-ff351a95-fb05-11e8-b692-aec8003d5667 to disappear
Dec  8 16:26:25.159: INFO: Pod downward-api-ff351a95-fb05-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:26:25.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hl9cp" for this suite.
Dec  8 16:26:31.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:26:31.314: INFO: namespace: e2e-tests-downward-api-hl9cp, resource: bindings, ignored listing per whitelist
Dec  8 16:26:31.352: INFO: namespace e2e-tests-downward-api-hl9cp deletion completed in 6.183487144s

• [SLOW TEST:10.645 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:26:31.352: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:26:31.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0595382c-fb06-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-rwk2z" to be "success or failure"
Dec  8 16:26:31.755: INFO: Pod "downwardapi-volume-0595382c-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 20.746378ms
Dec  8 16:26:33.765: INFO: Pod "downwardapi-volume-0595382c-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030712452s
Dec  8 16:26:35.793: INFO: Pod "downwardapi-volume-0595382c-fb06-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058154987s
STEP: Saw pod success
Dec  8 16:26:35.793: INFO: Pod "downwardapi-volume-0595382c-fb06-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:26:35.797: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-0595382c-fb06-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:26:35.862: INFO: Waiting for pod downwardapi-volume-0595382c-fb06-11e8-b692-aec8003d5667 to disappear
Dec  8 16:26:35.865: INFO: Pod downwardapi-volume-0595382c-fb06-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:26:35.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rwk2z" for this suite.
Dec  8 16:26:41.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:26:42.027: INFO: namespace: e2e-tests-projected-rwk2z, resource: bindings, ignored listing per whitelist
Dec  8 16:26:42.081: INFO: namespace e2e-tests-projected-rwk2z deletion completed in 6.208443091s

• [SLOW TEST:10.729 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:26:42.081: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-m8t7z
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 16:26:42.443: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 16:27:10.817: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.95:8080/dial?request=hostName&protocol=http&host=10.244.4.78&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-m8t7z PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:27:10.817: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:27:10.908: INFO: Waiting for endpoints: map[]
Dec  8 16:27:10.912: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.95:8080/dial?request=hostName&protocol=http&host=10.244.3.94&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-m8t7z PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:27:10.912: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:27:10.982: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:27:10.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-m8t7z" for this suite.
Dec  8 16:27:35.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:27:35.120: INFO: namespace: e2e-tests-pod-network-test-m8t7z, resource: bindings, ignored listing per whitelist
Dec  8 16:27:35.183: INFO: namespace e2e-tests-pod-network-test-m8t7z deletion completed in 24.192801866s

• [SLOW TEST:53.101 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:27:35.183: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  8 16:27:35.492: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrt45,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrt45/configmaps/e2e-watch-test-label-changed,UID:2b933403-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:14784,Generation:0,CreationTimestamp:2018-12-08 16:27:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 16:27:35.492: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrt45,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrt45/configmaps/e2e-watch-test-label-changed,UID:2b933403-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:14785,Generation:0,CreationTimestamp:2018-12-08 16:27:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  8 16:27:35.492: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrt45,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrt45/configmaps/e2e-watch-test-label-changed,UID:2b933403-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:14786,Generation:0,CreationTimestamp:2018-12-08 16:27:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  8 16:27:45.633: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrt45,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrt45/configmaps/e2e-watch-test-label-changed,UID:2b933403-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:14806,Generation:0,CreationTimestamp:2018-12-08 16:27:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 16:27:45.633: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrt45,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrt45/configmaps/e2e-watch-test-label-changed,UID:2b933403-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:14807,Generation:0,CreationTimestamp:2018-12-08 16:27:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  8 16:27:45.633: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrt45,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrt45/configmaps/e2e-watch-test-label-changed,UID:2b933403-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:14808,Generation:0,CreationTimestamp:2018-12-08 16:27:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:27:45.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nrt45" for this suite.
Dec  8 16:27:51.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:27:51.798: INFO: namespace: e2e-tests-watch-nrt45, resource: bindings, ignored listing per whitelist
Dec  8 16:27:51.814: INFO: namespace e2e-tests-watch-nrt45 deletion completed in 6.173106143s

• [SLOW TEST:16.631 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:27:51.814: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-357f881e-fb06-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:27:52.105: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3581edc4-fb06-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-4qq7x" to be "success or failure"
Dec  8 16:27:52.211: INFO: Pod "pod-projected-configmaps-3581edc4-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 106.836454ms
Dec  8 16:27:54.215: INFO: Pod "pod-projected-configmaps-3581edc4-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.11087444s
Dec  8 16:27:56.220: INFO: Pod "pod-projected-configmaps-3581edc4-fb06-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115185317s
STEP: Saw pod success
Dec  8 16:27:56.220: INFO: Pod "pod-projected-configmaps-3581edc4-fb06-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:27:56.223: INFO: Trying to get logs from node k8s-g1 pod pod-projected-configmaps-3581edc4-fb06-11e8-b692-aec8003d5667 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:27:56.305: INFO: Waiting for pod pod-projected-configmaps-3581edc4-fb06-11e8-b692-aec8003d5667 to disappear
Dec  8 16:27:56.312: INFO: Pod pod-projected-configmaps-3581edc4-fb06-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:27:56.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4qq7x" for this suite.
Dec  8 16:28:02.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:28:02.424: INFO: namespace: e2e-tests-projected-4qq7x, resource: bindings, ignored listing per whitelist
Dec  8 16:28:02.504: INFO: namespace e2e-tests-projected-4qq7x deletion completed in 6.184121539s

• [SLOW TEST:10.690 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:28:02.504: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1208 16:28:12.893445      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 16:28:12.893: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:28:12.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8r5gh" for this suite.
Dec  8 16:28:19.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:28:19.156: INFO: namespace: e2e-tests-gc-8r5gh, resource: bindings, ignored listing per whitelist
Dec  8 16:28:19.167: INFO: namespace e2e-tests-gc-8r5gh deletion completed in 6.266550743s

• [SLOW TEST:16.663 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:28:19.168: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:28:19.498: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45d28aad-fb06-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-tdpj9" to be "success or failure"
Dec  8 16:28:19.553: INFO: Pod "downwardapi-volume-45d28aad-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 55.883328ms
Dec  8 16:28:21.557: INFO: Pod "downwardapi-volume-45d28aad-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059730481s
Dec  8 16:28:23.561: INFO: Pod "downwardapi-volume-45d28aad-fb06-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063488698s
STEP: Saw pod success
Dec  8 16:28:23.561: INFO: Pod "downwardapi-volume-45d28aad-fb06-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:28:23.564: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-45d28aad-fb06-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:28:23.655: INFO: Waiting for pod downwardapi-volume-45d28aad-fb06-11e8-b692-aec8003d5667 to disappear
Dec  8 16:28:23.659: INFO: Pod downwardapi-volume-45d28aad-fb06-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:28:23.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tdpj9" for this suite.
Dec  8 16:28:29.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:28:29.728: INFO: namespace: e2e-tests-projected-tdpj9, resource: bindings, ignored listing per whitelist
Dec  8 16:28:29.869: INFO: namespace e2e-tests-projected-tdpj9 deletion completed in 6.201678601s

• [SLOW TEST:10.701 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:28:29.869: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  8 16:28:30.110: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-a,UID:4c28f5c0-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15009,Generation:0,CreationTimestamp:2018-12-08 16:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 16:28:30.110: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-a,UID:4c28f5c0-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15009,Generation:0,CreationTimestamp:2018-12-08 16:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  8 16:28:40.153: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-a,UID:4c28f5c0-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15027,Generation:0,CreationTimestamp:2018-12-08 16:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  8 16:28:40.153: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-a,UID:4c28f5c0-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15027,Generation:0,CreationTimestamp:2018-12-08 16:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  8 16:28:50.181: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-a,UID:4c28f5c0-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15046,Generation:0,CreationTimestamp:2018-12-08 16:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 16:28:50.181: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-a,UID:4c28f5c0-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15046,Generation:0,CreationTimestamp:2018-12-08 16:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  8 16:29:00.212: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-a,UID:4c28f5c0-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15065,Generation:0,CreationTimestamp:2018-12-08 16:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 16:29:00.212: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-a,UID:4c28f5c0-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15065,Generation:0,CreationTimestamp:2018-12-08 16:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  8 16:29:10.234: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-b,UID:641343b5-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15083,Generation:0,CreationTimestamp:2018-12-08 16:29:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 16:29:10.234: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-b,UID:641343b5-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15083,Generation:0,CreationTimestamp:2018-12-08 16:29:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  8 16:29:20.261: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-b,UID:641343b5-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15102,Generation:0,CreationTimestamp:2018-12-08 16:29:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 16:29:20.262: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gvgl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvgl5/configmaps/e2e-watch-test-configmap-b,UID:641343b5-fb06-11e8-b4e1-448a5b81d79a,ResourceVersion:15102,Generation:0,CreationTimestamp:2018-12-08 16:29:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:29:30.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gvgl5" for this suite.
Dec  8 16:29:36.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:29:36.341: INFO: namespace: e2e-tests-watch-gvgl5, resource: bindings, ignored listing per whitelist
Dec  8 16:29:36.469: INFO: namespace e2e-tests-watch-gvgl5 deletion completed in 6.199574749s

• [SLOW TEST:66.600 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:29:36.470: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-73dcf15a-fb06-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:29:36.739: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-73dff621-fb06-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-cxj9g" to be "success or failure"
Dec  8 16:29:36.800: INFO: Pod "pod-projected-secrets-73dff621-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 61.042335ms
Dec  8 16:29:38.804: INFO: Pod "pod-projected-secrets-73dff621-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065209264s
Dec  8 16:29:40.811: INFO: Pod "pod-projected-secrets-73dff621-fb06-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07153515s
STEP: Saw pod success
Dec  8 16:29:40.811: INFO: Pod "pod-projected-secrets-73dff621-fb06-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:29:40.816: INFO: Trying to get logs from node k8s-g2 pod pod-projected-secrets-73dff621-fb06-11e8-b692-aec8003d5667 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:29:40.923: INFO: Waiting for pod pod-projected-secrets-73dff621-fb06-11e8-b692-aec8003d5667 to disappear
Dec  8 16:29:40.927: INFO: Pod pod-projected-secrets-73dff621-fb06-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:29:40.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cxj9g" for this suite.
Dec  8 16:29:46.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:29:47.179: INFO: namespace: e2e-tests-projected-cxj9g, resource: bindings, ignored listing per whitelist
Dec  8 16:29:47.231: INFO: namespace e2e-tests-projected-cxj9g deletion completed in 6.295847059s

• [SLOW TEST:10.761 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:29:47.231: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Dec  8 16:29:47.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-cnb9p'
Dec  8 16:29:47.819: INFO: stderr: ""
Dec  8 16:29:47.819: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  8 16:29:48.824: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 16:29:48.824: INFO: Found 0 / 1
Dec  8 16:29:49.833: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 16:29:49.833: INFO: Found 0 / 1
Dec  8 16:29:50.823: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 16:29:50.823: INFO: Found 1 / 1
Dec  8 16:29:50.823: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 16:29:50.827: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 16:29:50.827: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  8 16:29:50.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 logs redis-master-nwfbz redis-master --namespace=e2e-tests-kubectl-cnb9p'
Dec  8 16:29:50.909: INFO: stderr: ""
Dec  8 16:29:50.909: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 16:29:50.055 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 16:29:50.055 # Server started, Redis version 3.2.12\n1:M 08 Dec 16:29:50.055 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 16:29:50.055 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  8 16:29:50.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 log redis-master-nwfbz redis-master --namespace=e2e-tests-kubectl-cnb9p --tail=1'
Dec  8 16:29:50.981: INFO: stderr: ""
Dec  8 16:29:50.981: INFO: stdout: "1:M 08 Dec 16:29:50.055 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  8 16:29:50.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 log redis-master-nwfbz redis-master --namespace=e2e-tests-kubectl-cnb9p --limit-bytes=1'
Dec  8 16:29:51.051: INFO: stderr: ""
Dec  8 16:29:51.051: INFO: stdout: " "
STEP: exposing timestamps
Dec  8 16:29:51.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 log redis-master-nwfbz redis-master --namespace=e2e-tests-kubectl-cnb9p --tail=1 --timestamps'
Dec  8 16:29:51.125: INFO: stderr: ""
Dec  8 16:29:51.125: INFO: stdout: "2018-12-08T16:29:50.055720145Z 1:M 08 Dec 16:29:50.055 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  8 16:29:53.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 log redis-master-nwfbz redis-master --namespace=e2e-tests-kubectl-cnb9p --since=1s'
Dec  8 16:29:53.762: INFO: stderr: ""
Dec  8 16:29:53.762: INFO: stdout: ""
Dec  8 16:29:53.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 log redis-master-nwfbz redis-master --namespace=e2e-tests-kubectl-cnb9p --since=24h'
Dec  8 16:29:53.864: INFO: stderr: ""
Dec  8 16:29:53.864: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 16:29:50.055 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 16:29:50.055 # Server started, Redis version 3.2.12\n1:M 08 Dec 16:29:50.055 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 16:29:50.055 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Dec  8 16:29:53.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cnb9p'
Dec  8 16:29:54.001: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:29:54.001: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  8 16:29:54.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-cnb9p'
Dec  8 16:29:54.071: INFO: stderr: "No resources found.\n"
Dec  8 16:29:54.071: INFO: stdout: ""
Dec  8 16:29:54.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -l name=nginx --namespace=e2e-tests-kubectl-cnb9p -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 16:29:54.142: INFO: stderr: ""
Dec  8 16:29:54.142: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:29:54.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cnb9p" for this suite.
Dec  8 16:30:00.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:30:00.292: INFO: namespace: e2e-tests-kubectl-cnb9p, resource: bindings, ignored listing per whitelist
Dec  8 16:30:00.362: INFO: namespace e2e-tests-kubectl-cnb9p deletion completed in 6.21287181s

• [SLOW TEST:13.132 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:30:00.363: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:30:20.603: INFO: Container started at 2018-12-08 16:30:04 +0000 UTC, pod became ready at 2018-12-08 16:30:20 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:30:20.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c6g2c" for this suite.
Dec  8 16:30:42.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:30:42.743: INFO: namespace: e2e-tests-container-probe-c6g2c, resource: bindings, ignored listing per whitelist
Dec  8 16:30:42.818: INFO: namespace e2e-tests-container-probe-c6g2c deletion completed in 22.207448477s

• [SLOW TEST:42.455 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:30:42.818: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:30:43.095: INFO: (0) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 8.474907ms)
Dec  8 16:30:43.101: INFO: (1) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.760665ms)
Dec  8 16:30:43.107: INFO: (2) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.614121ms)
Dec  8 16:30:43.113: INFO: (3) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.879356ms)
Dec  8 16:30:43.133: INFO: (4) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 19.78001ms)
Dec  8 16:30:43.138: INFO: (5) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.110565ms)
Dec  8 16:30:43.142: INFO: (6) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.806958ms)
Dec  8 16:30:43.147: INFO: (7) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.990489ms)
Dec  8 16:30:43.153: INFO: (8) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.088627ms)
Dec  8 16:30:43.158: INFO: (9) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.955277ms)
Dec  8 16:30:43.162: INFO: (10) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.834765ms)
Dec  8 16:30:43.168: INFO: (11) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.209877ms)
Dec  8 16:30:43.174: INFO: (12) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 6.620593ms)
Dec  8 16:30:43.180: INFO: (13) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.808662ms)
Dec  8 16:30:43.185: INFO: (14) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.094232ms)
Dec  8 16:30:43.190: INFO: (15) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.220125ms)
Dec  8 16:30:43.195: INFO: (16) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.967255ms)
Dec  8 16:30:43.201: INFO: (17) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.625332ms)
Dec  8 16:30:43.206: INFO: (18) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.096749ms)
Dec  8 16:30:43.211: INFO: (19) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.098894ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:30:43.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wsrns" for this suite.
Dec  8 16:30:49.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:30:49.438: INFO: namespace: e2e-tests-proxy-wsrns, resource: bindings, ignored listing per whitelist
Dec  8 16:30:49.508: INFO: namespace e2e-tests-proxy-wsrns deletion completed in 6.291888253s

• [SLOW TEST:6.690 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:30:49.508: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:30:49.761: INFO: (0) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 6.265515ms)
Dec  8 16:30:49.767: INFO: (1) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.870441ms)
Dec  8 16:30:49.772: INFO: (2) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.103996ms)
Dec  8 16:30:49.799: INFO: (3) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 26.656228ms)
Dec  8 16:30:49.804: INFO: (4) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.158886ms)
Dec  8 16:30:49.810: INFO: (5) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.372169ms)
Dec  8 16:30:49.815: INFO: (6) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.116881ms)
Dec  8 16:30:49.821: INFO: (7) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.834635ms)
Dec  8 16:30:49.826: INFO: (8) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.357733ms)
Dec  8 16:30:49.831: INFO: (9) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.134598ms)
Dec  8 16:30:49.836: INFO: (10) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.087131ms)
Dec  8 16:30:49.841: INFO: (11) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.089655ms)
Dec  8 16:30:49.846: INFO: (12) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.085721ms)
Dec  8 16:30:49.851: INFO: (13) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.846915ms)
Dec  8 16:30:49.856: INFO: (14) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.966752ms)
Dec  8 16:30:49.861: INFO: (15) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.132571ms)
Dec  8 16:30:49.867: INFO: (16) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.090169ms)
Dec  8 16:30:49.872: INFO: (17) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.212811ms)
Dec  8 16:30:49.877: INFO: (18) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.840966ms)
Dec  8 16:30:49.882: INFO: (19) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.938238ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:30:49.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-dgzd4" for this suite.
Dec  8 16:30:55.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:30:56.097: INFO: namespace: e2e-tests-proxy-dgzd4, resource: bindings, ignored listing per whitelist
Dec  8 16:30:56.097: INFO: namespace e2e-tests-proxy-dgzd4 deletion completed in 6.211542417s

• [SLOW TEST:6.589 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:30:56.097: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-a356fc8e-fb06-11e8-b692-aec8003d5667
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:31:00.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q7fbb" for this suite.
Dec  8 16:31:24.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:31:24.666: INFO: namespace: e2e-tests-configmap-q7fbb, resource: bindings, ignored listing per whitelist
Dec  8 16:31:24.718: INFO: namespace e2e-tests-configmap-q7fbb deletion completed in 24.200607938s

• [SLOW TEST:28.621 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:31:24.718: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b4665726-fb06-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:31:25.080: INFO: Waiting up to 5m0s for pod "pod-secrets-b46bdd4d-fb06-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-g4hbs" to be "success or failure"
Dec  8 16:31:25.113: INFO: Pod "pod-secrets-b46bdd4d-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 33.048085ms
Dec  8 16:31:27.121: INFO: Pod "pod-secrets-b46bdd4d-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040619672s
Dec  8 16:31:29.125: INFO: Pod "pod-secrets-b46bdd4d-fb06-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044999406s
STEP: Saw pod success
Dec  8 16:31:29.125: INFO: Pod "pod-secrets-b46bdd4d-fb06-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:31:29.128: INFO: Trying to get logs from node k8s-g1 pod pod-secrets-b46bdd4d-fb06-11e8-b692-aec8003d5667 container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:31:29.215: INFO: Waiting for pod pod-secrets-b46bdd4d-fb06-11e8-b692-aec8003d5667 to disappear
Dec  8 16:31:29.222: INFO: Pod pod-secrets-b46bdd4d-fb06-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:31:29.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g4hbs" for this suite.
Dec  8 16:31:35.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:31:35.341: INFO: namespace: e2e-tests-secrets-g4hbs, resource: bindings, ignored listing per whitelist
Dec  8 16:31:35.471: INFO: namespace e2e-tests-secrets-g4hbs deletion completed in 6.240854427s

• [SLOW TEST:10.753 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:31:35.471: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  8 16:31:35.754: INFO: Waiting up to 5m0s for pod "var-expansion-bacf3fb0-fb06-11e8-b692-aec8003d5667" in namespace "e2e-tests-var-expansion-bb2md" to be "success or failure"
Dec  8 16:31:35.783: INFO: Pod "var-expansion-bacf3fb0-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 29.291408ms
Dec  8 16:31:37.787: INFO: Pod "var-expansion-bacf3fb0-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033620603s
Dec  8 16:31:39.791: INFO: Pod "var-expansion-bacf3fb0-fb06-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03696728s
STEP: Saw pod success
Dec  8 16:31:39.791: INFO: Pod "var-expansion-bacf3fb0-fb06-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:31:39.793: INFO: Trying to get logs from node k8s-g1 pod var-expansion-bacf3fb0-fb06-11e8-b692-aec8003d5667 container dapi-container: <nil>
STEP: delete the pod
Dec  8 16:31:39.904: INFO: Waiting for pod var-expansion-bacf3fb0-fb06-11e8-b692-aec8003d5667 to disappear
Dec  8 16:31:39.908: INFO: Pod var-expansion-bacf3fb0-fb06-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:31:39.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bb2md" for this suite.
Dec  8 16:31:45.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:31:46.056: INFO: namespace: e2e-tests-var-expansion-bb2md, resource: bindings, ignored listing per whitelist
Dec  8 16:31:46.080: INFO: namespace e2e-tests-var-expansion-bb2md deletion completed in 6.164831184s

• [SLOW TEST:10.609 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:31:46.080: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  8 16:31:46.328: INFO: Waiting up to 5m0s for pod "client-containers-c11a52a2-fb06-11e8-b692-aec8003d5667" in namespace "e2e-tests-containers-h5hk7" to be "success or failure"
Dec  8 16:31:46.364: INFO: Pod "client-containers-c11a52a2-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 35.448846ms
Dec  8 16:31:48.368: INFO: Pod "client-containers-c11a52a2-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039466499s
Dec  8 16:31:50.371: INFO: Pod "client-containers-c11a52a2-fb06-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043124942s
STEP: Saw pod success
Dec  8 16:31:50.371: INFO: Pod "client-containers-c11a52a2-fb06-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:31:50.375: INFO: Trying to get logs from node k8s-g2 pod client-containers-c11a52a2-fb06-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:31:50.462: INFO: Waiting for pod client-containers-c11a52a2-fb06-11e8-b692-aec8003d5667 to disappear
Dec  8 16:31:50.465: INFO: Pod client-containers-c11a52a2-fb06-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:31:50.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-h5hk7" for this suite.
Dec  8 16:31:56.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:31:56.568: INFO: namespace: e2e-tests-containers-h5hk7, resource: bindings, ignored listing per whitelist
Dec  8 16:31:56.650: INFO: namespace e2e-tests-containers-h5hk7 deletion completed in 6.177388412s

• [SLOW TEST:10.570 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:31:56.650: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-jpx9w
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 16:31:56.884: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 16:32:19.237: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.87:8080/dial?request=hostName&protocol=udp&host=10.244.3.100&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-jpx9w PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:32:19.237: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:32:19.304: INFO: Waiting for endpoints: map[]
Dec  8 16:32:19.308: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.87:8080/dial?request=hostName&protocol=udp&host=10.244.4.86&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-jpx9w PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:32:19.308: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:32:19.380: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:32:19.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-jpx9w" for this suite.
Dec  8 16:32:43.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:32:43.456: INFO: namespace: e2e-tests-pod-network-test-jpx9w, resource: bindings, ignored listing per whitelist
Dec  8 16:32:43.571: INFO: namespace e2e-tests-pod-network-test-jpx9w deletion completed in 24.183281648s

• [SLOW TEST:46.920 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:32:43.571: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:32:43.852: INFO: Creating ReplicaSet my-hostname-basic-e369acb7-fb06-11e8-b692-aec8003d5667
Dec  8 16:32:43.896: INFO: Pod name my-hostname-basic-e369acb7-fb06-11e8-b692-aec8003d5667: Found 0 pods out of 1
Dec  8 16:32:48.901: INFO: Pod name my-hostname-basic-e369acb7-fb06-11e8-b692-aec8003d5667: Found 1 pods out of 1
Dec  8 16:32:48.901: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e369acb7-fb06-11e8-b692-aec8003d5667" is running
Dec  8 16:32:48.906: INFO: Pod "my-hostname-basic-e369acb7-fb06-11e8-b692-aec8003d5667-56hg4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 16:32:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 16:32:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 16:32:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 16:32:43 +0000 UTC Reason: Message:}])
Dec  8 16:32:48.906: INFO: Trying to dial the pod
Dec  8 16:32:53.919: INFO: Controller my-hostname-basic-e369acb7-fb06-11e8-b692-aec8003d5667: Got expected result from replica 1 [my-hostname-basic-e369acb7-fb06-11e8-b692-aec8003d5667-56hg4]: "my-hostname-basic-e369acb7-fb06-11e8-b692-aec8003d5667-56hg4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:32:53.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-bzcxf" for this suite.
Dec  8 16:33:00.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:33:00.241: INFO: namespace: e2e-tests-replicaset-bzcxf, resource: bindings, ignored listing per whitelist
Dec  8 16:33:00.284: INFO: namespace e2e-tests-replicaset-bzcxf deletion completed in 6.357274725s

• [SLOW TEST:16.713 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:33:00.284: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 16:33:05.202: INFO: Successfully updated pod "labelsupdateed61ba78-fb06-11e8-b692-aec8003d5667"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:33:07.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m69gh" for this suite.
Dec  8 16:33:31.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:33:31.412: INFO: namespace: e2e-tests-projected-m69gh, resource: bindings, ignored listing per whitelist
Dec  8 16:33:31.529: INFO: namespace e2e-tests-projected-m69gh deletion completed in 24.296754586s

• [SLOW TEST:31.245 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:33:31.529: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:33:31.808: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fff66517-fb06-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-44vbm" to be "success or failure"
Dec  8 16:33:31.812: INFO: Pod "downwardapi-volume-fff66517-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.440797ms
Dec  8 16:33:33.817: INFO: Pod "downwardapi-volume-fff66517-fb06-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008502015s
Dec  8 16:33:35.821: INFO: Pod "downwardapi-volume-fff66517-fb06-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012369928s
STEP: Saw pod success
Dec  8 16:33:35.821: INFO: Pod "downwardapi-volume-fff66517-fb06-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:33:35.824: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-fff66517-fb06-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:33:35.917: INFO: Waiting for pod downwardapi-volume-fff66517-fb06-11e8-b692-aec8003d5667 to disappear
Dec  8 16:33:35.921: INFO: Pod downwardapi-volume-fff66517-fb06-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:33:35.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-44vbm" for this suite.
Dec  8 16:33:41.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:33:41.998: INFO: namespace: e2e-tests-downward-api-44vbm, resource: bindings, ignored listing per whitelist
Dec  8 16:33:42.099: INFO: namespace e2e-tests-downward-api-44vbm deletion completed in 6.169252264s

• [SLOW TEST:10.570 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:33:42.099: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  8 16:33:42.336: INFO: Waiting up to 5m0s for pod "pod-064335b4-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-l8sc7" to be "success or failure"
Dec  8 16:33:42.344: INFO: Pod "pod-064335b4-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 7.900229ms
Dec  8 16:33:44.348: INFO: Pod "pod-064335b4-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011904761s
Dec  8 16:33:46.352: INFO: Pod "pod-064335b4-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015684897s
STEP: Saw pod success
Dec  8 16:33:46.352: INFO: Pod "pod-064335b4-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:33:46.355: INFO: Trying to get logs from node k8s-g2 pod pod-064335b4-fb07-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:33:46.403: INFO: Waiting for pod pod-064335b4-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:33:46.407: INFO: Pod pod-064335b4-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:33:46.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l8sc7" for this suite.
Dec  8 16:33:52.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:33:52.546: INFO: namespace: e2e-tests-emptydir-l8sc7, resource: bindings, ignored listing per whitelist
Dec  8 16:33:52.591: INFO: namespace e2e-tests-emptydir-l8sc7 deletion completed in 6.175098986s

• [SLOW TEST:10.492 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:33:52.592: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:33:52.886: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c8c6415-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-9v975" to be "success or failure"
Dec  8 16:33:52.890: INFO: Pod "downwardapi-volume-0c8c6415-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.839591ms
Dec  8 16:33:54.894: INFO: Pod "downwardapi-volume-0c8c6415-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007880639s
Dec  8 16:33:56.897: INFO: Pod "downwardapi-volume-0c8c6415-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011605516s
STEP: Saw pod success
Dec  8 16:33:56.897: INFO: Pod "downwardapi-volume-0c8c6415-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:33:56.901: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-0c8c6415-fb07-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:33:56.972: INFO: Waiting for pod downwardapi-volume-0c8c6415-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:33:56.975: INFO: Pod downwardapi-volume-0c8c6415-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:33:56.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9v975" for this suite.
Dec  8 16:34:03.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:34:03.125: INFO: namespace: e2e-tests-projected-9v975, resource: bindings, ignored listing per whitelist
Dec  8 16:34:03.169: INFO: namespace e2e-tests-projected-9v975 deletion completed in 6.186690612s

• [SLOW TEST:10.578 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:34:03.170: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-12d2f855-fb07-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:34:03.465: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-12d96021-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-52bnv" to be "success or failure"
Dec  8 16:34:03.499: INFO: Pod "pod-projected-secrets-12d96021-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 34.031421ms
Dec  8 16:34:05.550: INFO: Pod "pod-projected-secrets-12d96021-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085497928s
Dec  8 16:34:07.555: INFO: Pod "pod-projected-secrets-12d96021-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.090111209s
STEP: Saw pod success
Dec  8 16:34:07.555: INFO: Pod "pod-projected-secrets-12d96021-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:34:07.558: INFO: Trying to get logs from node k8s-g1 pod pod-projected-secrets-12d96021-fb07-11e8-b692-aec8003d5667 container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:34:07.707: INFO: Waiting for pod pod-projected-secrets-12d96021-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:34:07.711: INFO: Pod pod-projected-secrets-12d96021-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:34:07.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-52bnv" for this suite.
Dec  8 16:34:13.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:34:13.939: INFO: namespace: e2e-tests-projected-52bnv, resource: bindings, ignored listing per whitelist
Dec  8 16:34:13.947: INFO: namespace e2e-tests-projected-52bnv deletion completed in 6.227633508s

• [SLOW TEST:10.778 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:34:13.948: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 16:34:14.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-5ljfd'
Dec  8 16:34:17.160: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 16:34:17.160: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  8 16:34:17.177: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-cv4ts]
Dec  8 16:34:17.177: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-cv4ts" in namespace "e2e-tests-kubectl-5ljfd" to be "running and ready"
Dec  8 16:34:17.234: INFO: Pod "e2e-test-nginx-rc-cv4ts": Phase="Pending", Reason="", readiness=false. Elapsed: 57.512724ms
Dec  8 16:34:19.239: INFO: Pod "e2e-test-nginx-rc-cv4ts": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061678791s
Dec  8 16:34:21.244: INFO: Pod "e2e-test-nginx-rc-cv4ts": Phase="Running", Reason="", readiness=true. Elapsed: 4.067534415s
Dec  8 16:34:21.245: INFO: Pod "e2e-test-nginx-rc-cv4ts" satisfied condition "running and ready"
Dec  8 16:34:21.245: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-cv4ts]
Dec  8 16:34:21.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5ljfd'
Dec  8 16:34:21.340: INFO: stderr: ""
Dec  8 16:34:21.340: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Dec  8 16:34:21.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5ljfd'
Dec  8 16:34:21.415: INFO: stderr: ""
Dec  8 16:34:21.415: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:34:21.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5ljfd" for this suite.
Dec  8 16:34:27.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:34:27.663: INFO: namespace: e2e-tests-kubectl-5ljfd, resource: bindings, ignored listing per whitelist
Dec  8 16:34:27.670: INFO: namespace e2e-tests-kubectl-5ljfd deletion completed in 6.247794811s

• [SLOW TEST:13.723 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:34:27.670: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  8 16:34:28.482: INFO: Waiting up to 5m0s for pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7" in namespace "e2e-tests-svcaccounts-d6xxb" to be "success or failure"
Dec  8 16:34:28.529: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7": Phase="Pending", Reason="", readiness=false. Elapsed: 47.508774ms
Dec  8 16:34:30.535: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053190696s
Dec  8 16:34:32.539: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057858407s
Dec  8 16:34:34.544: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062116039s
STEP: Saw pod success
Dec  8 16:34:34.544: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7" satisfied condition "success or failure"
Dec  8 16:34:34.547: INFO: Trying to get logs from node k8s-g2 pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7 container token-test: <nil>
STEP: delete the pod
Dec  8 16:34:34.640: INFO: Waiting for pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7 to disappear
Dec  8 16:34:34.644: INFO: Pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6rwl7 no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  8 16:34:34.696: INFO: Waiting up to 5m0s for pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h" in namespace "e2e-tests-svcaccounts-d6xxb" to be "success or failure"
Dec  8 16:34:34.760: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h": Phase="Pending", Reason="", readiness=false. Elapsed: 63.637644ms
Dec  8 16:34:36.765: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068165049s
Dec  8 16:34:38.769: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0725499s
Dec  8 16:34:40.773: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.076221705s
STEP: Saw pod success
Dec  8 16:34:40.773: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h" satisfied condition "success or failure"
Dec  8 16:34:40.776: INFO: Trying to get logs from node k8s-g1 pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h container root-ca-test: <nil>
STEP: delete the pod
Dec  8 16:34:40.882: INFO: Waiting for pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h to disappear
Dec  8 16:34:40.887: INFO: Pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-5426h no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  8 16:34:40.906: INFO: Waiting up to 5m0s for pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w" in namespace "e2e-tests-svcaccounts-d6xxb" to be "success or failure"
Dec  8 16:34:40.910: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w": Phase="Pending", Reason="", readiness=false. Elapsed: 3.919685ms
Dec  8 16:34:42.913: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007584269s
Dec  8 16:34:44.917: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011277581s
Dec  8 16:34:46.921: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015794423s
STEP: Saw pod success
Dec  8 16:34:46.921: INFO: Pod "pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w" satisfied condition "success or failure"
Dec  8 16:34:46.926: INFO: Trying to get logs from node k8s-g2 pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w container namespace-test: <nil>
STEP: delete the pod
Dec  8 16:34:47.035: INFO: Waiting for pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w to disappear
Dec  8 16:34:47.039: INFO: Pod pod-service-account-21bdee7e-fb07-11e8-b692-aec8003d5667-6wn9w no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:34:47.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-d6xxb" for this suite.
Dec  8 16:34:55.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:34:55.203: INFO: namespace: e2e-tests-svcaccounts-d6xxb, resource: bindings, ignored listing per whitelist
Dec  8 16:34:55.237: INFO: namespace e2e-tests-svcaccounts-d6xxb deletion completed in 8.188304696s

• [SLOW TEST:27.567 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:34:55.237: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  8 16:34:55.502: INFO: Waiting up to 5m0s for pod "pod-31db75e6-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-96c4w" to be "success or failure"
Dec  8 16:34:55.506: INFO: Pod "pod-31db75e6-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.752302ms
Dec  8 16:34:57.511: INFO: Pod "pod-31db75e6-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008270779s
Dec  8 16:34:59.514: INFO: Pod "pod-31db75e6-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012179849s
Dec  8 16:35:01.519: INFO: Pod "pod-31db75e6-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016774808s
STEP: Saw pod success
Dec  8 16:35:01.519: INFO: Pod "pod-31db75e6-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:35:01.523: INFO: Trying to get logs from node k8s-g1 pod pod-31db75e6-fb07-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:35:01.654: INFO: Waiting for pod pod-31db75e6-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:35:01.658: INFO: Pod pod-31db75e6-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:35:01.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-96c4w" for this suite.
Dec  8 16:35:07.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:35:07.820: INFO: namespace: e2e-tests-emptydir-96c4w, resource: bindings, ignored listing per whitelist
Dec  8 16:35:07.830: INFO: namespace e2e-tests-emptydir-96c4w deletion completed in 6.164982174s

• [SLOW TEST:12.593 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:35:07.830: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5hsqt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 16:35:08.137: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 16:35:34.593: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.4.94 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5hsqt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:35:34.593: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:35:35.670: INFO: Found all expected endpoints: [netserver-0]
Dec  8 16:35:35.673: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.3.106 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5hsqt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:35:35.673: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:35:36.739: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:35:36.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5hsqt" for this suite.
Dec  8 16:36:00.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:36:00.842: INFO: namespace: e2e-tests-pod-network-test-5hsqt, resource: bindings, ignored listing per whitelist
Dec  8 16:36:00.970: INFO: namespace e2e-tests-pod-network-test-5hsqt deletion completed in 24.223906905s

• [SLOW TEST:53.140 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:36:00.970: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 16:36:01.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-26bjn'
Dec  8 16:36:01.301: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 16:36:01.301: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Dec  8 16:36:05.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-26bjn'
Dec  8 16:36:05.433: INFO: stderr: ""
Dec  8 16:36:05.433: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:36:05.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-26bjn" for this suite.
Dec  8 16:36:11.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:36:11.547: INFO: namespace: e2e-tests-kubectl-26bjn, resource: bindings, ignored listing per whitelist
Dec  8 16:36:11.643: INFO: namespace e2e-tests-kubectl-26bjn deletion completed in 6.203389191s

• [SLOW TEST:10.673 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:36:11.644: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-5f703558-fb07-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:36:12.040: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5f7ab072-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-lb25k" to be "success or failure"
Dec  8 16:36:12.079: INFO: Pod "pod-projected-secrets-5f7ab072-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 39.902794ms
Dec  8 16:36:14.085: INFO: Pod "pod-projected-secrets-5f7ab072-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045865414s
Dec  8 16:36:16.089: INFO: Pod "pod-projected-secrets-5f7ab072-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049402799s
STEP: Saw pod success
Dec  8 16:36:16.089: INFO: Pod "pod-projected-secrets-5f7ab072-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:36:16.092: INFO: Trying to get logs from node k8s-g1 pod pod-projected-secrets-5f7ab072-fb07-11e8-b692-aec8003d5667 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:36:16.233: INFO: Waiting for pod pod-projected-secrets-5f7ab072-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:36:16.237: INFO: Pod pod-projected-secrets-5f7ab072-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:36:16.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lb25k" for this suite.
Dec  8 16:36:22.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:36:22.417: INFO: namespace: e2e-tests-projected-lb25k, resource: bindings, ignored listing per whitelist
Dec  8 16:36:22.425: INFO: namespace e2e-tests-projected-lb25k deletion completed in 6.176788461s

• [SLOW TEST:10.781 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:36:22.425: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:36:22.816: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  8 16:36:27.821: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 16:36:27.821: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 16:36:27.865: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-8hqvf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8hqvf/deployments/test-cleanup-deployment,UID:68ea1b75-fb07-11e8-b4e1-448a5b81d79a,ResourceVersion:16641,Generation:1,CreationTimestamp:2018-12-08 16:36:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  8 16:36:27.902: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:36:27.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8hqvf" for this suite.
Dec  8 16:36:34.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:36:34.198: INFO: namespace: e2e-tests-deployment-8hqvf, resource: bindings, ignored listing per whitelist
Dec  8 16:36:34.287: INFO: namespace e2e-tests-deployment-8hqvf deletion completed in 6.354980052s

• [SLOW TEST:11.862 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:36:34.287: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-6cec0d95-fb07-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:36:34.615: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6cee6dd4-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-fksfb" to be "success or failure"
Dec  8 16:36:34.676: INFO: Pod "pod-projected-secrets-6cee6dd4-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 60.468809ms
Dec  8 16:36:36.692: INFO: Pod "pod-projected-secrets-6cee6dd4-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077243419s
Dec  8 16:36:38.697: INFO: Pod "pod-projected-secrets-6cee6dd4-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.082234577s
STEP: Saw pod success
Dec  8 16:36:38.697: INFO: Pod "pod-projected-secrets-6cee6dd4-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:36:38.701: INFO: Trying to get logs from node k8s-g2 pod pod-projected-secrets-6cee6dd4-fb07-11e8-b692-aec8003d5667 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:36:38.771: INFO: Waiting for pod pod-projected-secrets-6cee6dd4-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:36:38.774: INFO: Pod pod-projected-secrets-6cee6dd4-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:36:38.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fksfb" for this suite.
Dec  8 16:36:44.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:36:44.881: INFO: namespace: e2e-tests-projected-fksfb, resource: bindings, ignored listing per whitelist
Dec  8 16:36:44.967: INFO: namespace e2e-tests-projected-fksfb deletion completed in 6.185360528s

• [SLOW TEST:10.679 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:36:44.967: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 16:36:45.244: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:45.245: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:45.245: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:45.301: INFO: Number of nodes with available pods: 0
Dec  8 16:36:45.301: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:36:46.308: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:46.308: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:46.308: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:46.312: INFO: Number of nodes with available pods: 0
Dec  8 16:36:46.312: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:36:47.338: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:47.338: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:47.338: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:47.342: INFO: Number of nodes with available pods: 0
Dec  8 16:36:47.342: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:36:48.308: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:48.308: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:48.308: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:48.311: INFO: Number of nodes with available pods: 2
Dec  8 16:36:48.311: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  8 16:36:48.383: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:48.383: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:48.383: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:48.387: INFO: Number of nodes with available pods: 1
Dec  8 16:36:48.387: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:49.395: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:49.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:49.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:49.399: INFO: Number of nodes with available pods: 1
Dec  8 16:36:49.399: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:50.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:50.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:50.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:50.398: INFO: Number of nodes with available pods: 1
Dec  8 16:36:50.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:51.397: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:51.397: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:51.397: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:51.401: INFO: Number of nodes with available pods: 1
Dec  8 16:36:51.401: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:52.393: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:52.393: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:52.393: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:52.397: INFO: Number of nodes with available pods: 1
Dec  8 16:36:52.397: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:53.393: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:53.393: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:53.393: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:53.398: INFO: Number of nodes with available pods: 1
Dec  8 16:36:53.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:54.395: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:54.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:54.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:54.399: INFO: Number of nodes with available pods: 1
Dec  8 16:36:54.399: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:55.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:55.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:55.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:55.398: INFO: Number of nodes with available pods: 1
Dec  8 16:36:55.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:56.393: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:56.393: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:56.393: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:56.397: INFO: Number of nodes with available pods: 1
Dec  8 16:36:56.397: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:57.395: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:57.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:57.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:57.399: INFO: Number of nodes with available pods: 1
Dec  8 16:36:57.399: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:58.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:58.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:58.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:58.398: INFO: Number of nodes with available pods: 1
Dec  8 16:36:58.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:36:59.395: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:59.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:59.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:36:59.399: INFO: Number of nodes with available pods: 1
Dec  8 16:36:59.399: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:00.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:00.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:00.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:00.398: INFO: Number of nodes with available pods: 1
Dec  8 16:37:00.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:01.397: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:01.397: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:01.397: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:01.402: INFO: Number of nodes with available pods: 1
Dec  8 16:37:01.402: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:02.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:02.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:02.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:02.397: INFO: Number of nodes with available pods: 1
Dec  8 16:37:02.397: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:03.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:03.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:03.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:03.400: INFO: Number of nodes with available pods: 1
Dec  8 16:37:03.400: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:04.396: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:04.396: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:04.396: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:04.400: INFO: Number of nodes with available pods: 1
Dec  8 16:37:04.400: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:05.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:05.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:05.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:05.398: INFO: Number of nodes with available pods: 1
Dec  8 16:37:05.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:06.396: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:06.396: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:06.396: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:06.401: INFO: Number of nodes with available pods: 1
Dec  8 16:37:06.401: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:07.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:07.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:07.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:07.398: INFO: Number of nodes with available pods: 1
Dec  8 16:37:07.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:08.395: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:08.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:08.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:08.401: INFO: Number of nodes with available pods: 1
Dec  8 16:37:08.401: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:09.397: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:09.397: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:09.397: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:09.402: INFO: Number of nodes with available pods: 1
Dec  8 16:37:09.402: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:10.396: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:10.396: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:10.396: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:10.401: INFO: Number of nodes with available pods: 1
Dec  8 16:37:10.401: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:11.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:11.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:11.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:11.398: INFO: Number of nodes with available pods: 1
Dec  8 16:37:11.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:12.393: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:12.393: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:12.393: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:12.397: INFO: Number of nodes with available pods: 1
Dec  8 16:37:12.397: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:13.395: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:13.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:13.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:13.399: INFO: Number of nodes with available pods: 1
Dec  8 16:37:13.399: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:14.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:14.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:14.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:14.398: INFO: Number of nodes with available pods: 1
Dec  8 16:37:14.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:15.397: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:15.397: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:15.397: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:15.403: INFO: Number of nodes with available pods: 1
Dec  8 16:37:15.403: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:16.396: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:16.396: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:16.396: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:16.400: INFO: Number of nodes with available pods: 1
Dec  8 16:37:16.400: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:17.395: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:17.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:17.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:17.399: INFO: Number of nodes with available pods: 1
Dec  8 16:37:17.399: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:18.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:18.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:18.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:18.397: INFO: Number of nodes with available pods: 1
Dec  8 16:37:18.397: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:19.403: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:19.403: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:19.403: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:19.412: INFO: Number of nodes with available pods: 1
Dec  8 16:37:19.412: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:20.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:20.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:20.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:20.398: INFO: Number of nodes with available pods: 1
Dec  8 16:37:20.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:21.405: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:21.405: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:21.405: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:21.409: INFO: Number of nodes with available pods: 1
Dec  8 16:37:21.409: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:22.400: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:22.400: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:22.400: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:22.412: INFO: Number of nodes with available pods: 1
Dec  8 16:37:22.412: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:23.394: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:23.394: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:23.394: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:23.398: INFO: Number of nodes with available pods: 1
Dec  8 16:37:23.398: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:24.396: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:24.396: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:24.396: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:24.400: INFO: Number of nodes with available pods: 1
Dec  8 16:37:24.400: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:37:25.395: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:25.395: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:25.395: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:37:25.400: INFO: Number of nodes with available pods: 2
Dec  8 16:37:25.400: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-qc2x8, will wait for the garbage collector to delete the pods
Dec  8 16:37:25.479: INFO: Deleting {extensions DaemonSet} daemon-set took: 20.104132ms
Dec  8 16:37:25.679: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.140415ms
Dec  8 16:38:01.683: INFO: Number of nodes with available pods: 0
Dec  8 16:38:01.683: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 16:38:01.686: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qc2x8/daemonsets","resourceVersion":"16935"},"items":null}

Dec  8 16:38:01.689: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qc2x8/pods","resourceVersion":"16935"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:38:01.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qc2x8" for this suite.
Dec  8 16:38:09.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:38:09.871: INFO: namespace: e2e-tests-daemonsets-qc2x8, resource: bindings, ignored listing per whitelist
Dec  8 16:38:09.890: INFO: namespace e2e-tests-daemonsets-qc2x8 deletion completed in 8.183176855s

• [SLOW TEST:84.923 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:38:09.890: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a5e6cf37-fb07-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:38:10.179: INFO: Waiting up to 5m0s for pod "pod-configmaps-a5e99f06-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-6bkj4" to be "success or failure"
Dec  8 16:38:10.187: INFO: Pod "pod-configmaps-a5e99f06-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 8.638496ms
Dec  8 16:38:12.192: INFO: Pod "pod-configmaps-a5e99f06-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012945181s
Dec  8 16:38:14.196: INFO: Pod "pod-configmaps-a5e99f06-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017276939s
STEP: Saw pod success
Dec  8 16:38:14.196: INFO: Pod "pod-configmaps-a5e99f06-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:38:14.200: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-a5e99f06-fb07-11e8-b692-aec8003d5667 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:38:14.285: INFO: Waiting for pod pod-configmaps-a5e99f06-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:38:14.288: INFO: Pod pod-configmaps-a5e99f06-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:38:14.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6bkj4" for this suite.
Dec  8 16:38:20.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:38:20.392: INFO: namespace: e2e-tests-configmap-6bkj4, resource: bindings, ignored listing per whitelist
Dec  8 16:38:20.486: INFO: namespace e2e-tests-configmap-6bkj4 deletion completed in 6.189728055s

• [SLOW TEST:10.596 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:38:20.486: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 16:38:20.838: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:20.838: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:20.838: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:20.842: INFO: Number of nodes with available pods: 0
Dec  8 16:38:20.842: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:38:21.848: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:21.848: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:21.848: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:21.852: INFO: Number of nodes with available pods: 0
Dec  8 16:38:21.852: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:38:22.853: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:22.853: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:22.853: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:22.890: INFO: Number of nodes with available pods: 0
Dec  8 16:38:22.890: INFO: Node k8s-g1 is running more than one daemon pod
Dec  8 16:38:23.849: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:23.849: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:23.849: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:23.853: INFO: Number of nodes with available pods: 2
Dec  8 16:38:23.853: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  8 16:38:23.910: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:23.910: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:23.910: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:23.957: INFO: Number of nodes with available pods: 1
Dec  8 16:38:23.957: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:38:24.966: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:24.966: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:24.966: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:24.970: INFO: Number of nodes with available pods: 1
Dec  8 16:38:24.970: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:38:25.964: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:25.964: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:25.964: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:25.968: INFO: Number of nodes with available pods: 1
Dec  8 16:38:25.968: INFO: Node k8s-g2 is running more than one daemon pod
Dec  8 16:38:26.966: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:26.966: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:26.966: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  8 16:38:26.970: INFO: Number of nodes with available pods: 2
Dec  8 16:38:26.970: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-rlgjx, will wait for the garbage collector to delete the pods
Dec  8 16:38:27.045: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.914269ms
Dec  8 16:38:27.245: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.143603ms
Dec  8 16:39:11.705: INFO: Number of nodes with available pods: 0
Dec  8 16:39:11.705: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 16:39:11.710: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rlgjx/daemonsets","resourceVersion":"17176"},"items":null}

Dec  8 16:39:11.728: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rlgjx/pods","resourceVersion":"17176"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:39:11.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rlgjx" for this suite.
Dec  8 16:39:19.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:39:19.906: INFO: namespace: e2e-tests-daemonsets-rlgjx, resource: bindings, ignored listing per whitelist
Dec  8 16:39:20.410: INFO: namespace e2e-tests-daemonsets-rlgjx deletion completed in 8.664105031s

• [SLOW TEST:59.924 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:39:20.410: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d00f1516-fb07-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:39:20.953: INFO: Waiting up to 5m0s for pod "pod-configmaps-d01538d3-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-pn65v" to be "success or failure"
Dec  8 16:39:20.986: INFO: Pod "pod-configmaps-d01538d3-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 33.478734ms
Dec  8 16:39:22.990: INFO: Pod "pod-configmaps-d01538d3-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037118132s
Dec  8 16:39:24.995: INFO: Pod "pod-configmaps-d01538d3-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042225314s
STEP: Saw pod success
Dec  8 16:39:24.995: INFO: Pod "pod-configmaps-d01538d3-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:39:24.999: INFO: Trying to get logs from node k8s-g2 pod pod-configmaps-d01538d3-fb07-11e8-b692-aec8003d5667 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:39:25.054: INFO: Waiting for pod pod-configmaps-d01538d3-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:39:25.058: INFO: Pod pod-configmaps-d01538d3-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:39:25.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pn65v" for this suite.
Dec  8 16:39:33.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:39:33.158: INFO: namespace: e2e-tests-configmap-pn65v, resource: bindings, ignored listing per whitelist
Dec  8 16:39:33.256: INFO: namespace e2e-tests-configmap-pn65v deletion completed in 8.188381798s

• [SLOW TEST:12.846 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:39:33.256: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Dec  8 16:39:33.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-jc5q8'
Dec  8 16:39:33.806: INFO: stderr: ""
Dec  8 16:39:33.806: INFO: stdout: "pod/pause created\n"
Dec  8 16:39:33.806: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  8 16:39:33.806: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-jc5q8" to be "running and ready"
Dec  8 16:39:33.871: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 64.645954ms
Dec  8 16:39:35.878: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071389016s
Dec  8 16:39:37.882: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.075691402s
Dec  8 16:39:37.882: INFO: Pod "pause" satisfied condition "running and ready"
Dec  8 16:39:37.882: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  8 16:39:37.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-jc5q8'
Dec  8 16:39:38.066: INFO: stderr: ""
Dec  8 16:39:38.066: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  8 16:39:38.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pod pause -L testing-label --namespace=e2e-tests-kubectl-jc5q8'
Dec  8 16:39:38.191: INFO: stderr: ""
Dec  8 16:39:38.191: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  8 16:39:38.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 label pods pause testing-label- --namespace=e2e-tests-kubectl-jc5q8'
Dec  8 16:39:38.330: INFO: stderr: ""
Dec  8 16:39:38.330: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  8 16:39:38.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pod pause -L testing-label --namespace=e2e-tests-kubectl-jc5q8'
Dec  8 16:39:38.472: INFO: stderr: ""
Dec  8 16:39:38.472: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Dec  8 16:39:38.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jc5q8'
Dec  8 16:39:38.633: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:39:38.636: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  8 16:39:38.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-jc5q8'
Dec  8 16:39:38.743: INFO: stderr: "No resources found.\n"
Dec  8 16:39:38.743: INFO: stdout: ""
Dec  8 16:39:38.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -l name=pause --namespace=e2e-tests-kubectl-jc5q8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 16:39:38.828: INFO: stderr: ""
Dec  8 16:39:38.828: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:39:38.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jc5q8" for this suite.
Dec  8 16:39:44.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:39:44.911: INFO: namespace: e2e-tests-kubectl-jc5q8, resource: bindings, ignored listing per whitelist
Dec  8 16:39:45.004: INFO: namespace e2e-tests-kubectl-jc5q8 deletion completed in 6.167798601s

• [SLOW TEST:11.748 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:39:45.004: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  8 16:39:45.273: INFO: Waiting up to 5m0s for pod "pod-de970afe-fb07-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-lqffw" to be "success or failure"
Dec  8 16:39:45.277: INFO: Pod "pod-de970afe-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.837242ms
Dec  8 16:39:47.281: INFO: Pod "pod-de970afe-fb07-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007631026s
Dec  8 16:39:49.285: INFO: Pod "pod-de970afe-fb07-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012064913s
STEP: Saw pod success
Dec  8 16:39:49.285: INFO: Pod "pod-de970afe-fb07-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:39:49.290: INFO: Trying to get logs from node k8s-g2 pod pod-de970afe-fb07-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:39:49.402: INFO: Waiting for pod pod-de970afe-fb07-11e8-b692-aec8003d5667 to disappear
Dec  8 16:39:49.407: INFO: Pod pod-de970afe-fb07-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:39:49.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lqffw" for this suite.
Dec  8 16:39:55.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:39:55.536: INFO: namespace: e2e-tests-emptydir-lqffw, resource: bindings, ignored listing per whitelist
Dec  8 16:39:55.625: INFO: namespace e2e-tests-emptydir-lqffw deletion completed in 6.207675995s

• [SLOW TEST:10.621 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:39:55.626: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  8 16:39:55.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:39:56.129: INFO: stderr: ""
Dec  8 16:39:56.129: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 16:39:56.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:39:56.195: INFO: stderr: ""
Dec  8 16:39:56.195: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Dec  8 16:40:01.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:01.300: INFO: stderr: ""
Dec  8 16:40:01.300: INFO: stdout: "update-demo-nautilus-ttjvl update-demo-nautilus-xlx2t "
Dec  8 16:40:01.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-ttjvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:01.359: INFO: stderr: ""
Dec  8 16:40:01.359: INFO: stdout: "true"
Dec  8 16:40:01.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-ttjvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:01.419: INFO: stderr: ""
Dec  8 16:40:01.419: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 16:40:01.419: INFO: validating pod update-demo-nautilus-ttjvl
Dec  8 16:40:01.424: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 16:40:01.424: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 16:40:01.424: INFO: update-demo-nautilus-ttjvl is verified up and running
Dec  8 16:40:01.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-xlx2t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:01.485: INFO: stderr: ""
Dec  8 16:40:01.485: INFO: stdout: "true"
Dec  8 16:40:01.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-xlx2t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:01.544: INFO: stderr: ""
Dec  8 16:40:01.544: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 16:40:01.544: INFO: validating pod update-demo-nautilus-xlx2t
Dec  8 16:40:01.549: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 16:40:01.549: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 16:40:01.549: INFO: update-demo-nautilus-xlx2t is verified up and running
STEP: scaling down the replication controller
Dec  8 16:40:01.549: INFO: scanned /root for discovery docs: <nil>
Dec  8 16:40:01.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:02.662: INFO: stderr: ""
Dec  8 16:40:02.662: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 16:40:02.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:02.792: INFO: stderr: ""
Dec  8 16:40:02.792: INFO: stdout: "update-demo-nautilus-ttjvl update-demo-nautilus-xlx2t "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  8 16:40:07.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:07.863: INFO: stderr: ""
Dec  8 16:40:07.863: INFO: stdout: "update-demo-nautilus-ttjvl "
Dec  8 16:40:07.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-ttjvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:07.968: INFO: stderr: ""
Dec  8 16:40:07.968: INFO: stdout: "true"
Dec  8 16:40:07.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-ttjvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:08.076: INFO: stderr: ""
Dec  8 16:40:08.076: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 16:40:08.076: INFO: validating pod update-demo-nautilus-ttjvl
Dec  8 16:40:08.152: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 16:40:08.152: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 16:40:08.152: INFO: update-demo-nautilus-ttjvl is verified up and running
STEP: scaling up the replication controller
Dec  8 16:40:08.153: INFO: scanned /root for discovery docs: <nil>
Dec  8 16:40:08.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:09.363: INFO: stderr: ""
Dec  8 16:40:09.363: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 16:40:09.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:09.430: INFO: stderr: ""
Dec  8 16:40:09.430: INFO: stdout: "update-demo-nautilus-ttjvl update-demo-nautilus-vz4bl "
Dec  8 16:40:09.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-ttjvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:09.497: INFO: stderr: ""
Dec  8 16:40:09.497: INFO: stdout: "true"
Dec  8 16:40:09.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-ttjvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:09.557: INFO: stderr: ""
Dec  8 16:40:09.557: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 16:40:09.557: INFO: validating pod update-demo-nautilus-ttjvl
Dec  8 16:40:09.562: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 16:40:09.562: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 16:40:09.562: INFO: update-demo-nautilus-ttjvl is verified up and running
Dec  8 16:40:09.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-vz4bl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:09.627: INFO: stderr: ""
Dec  8 16:40:09.627: INFO: stdout: ""
Dec  8 16:40:09.627: INFO: update-demo-nautilus-vz4bl is created but not running
Dec  8 16:40:14.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:14.712: INFO: stderr: ""
Dec  8 16:40:14.712: INFO: stdout: "update-demo-nautilus-ttjvl update-demo-nautilus-vz4bl "
Dec  8 16:40:14.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-ttjvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:14.772: INFO: stderr: ""
Dec  8 16:40:14.772: INFO: stdout: "true"
Dec  8 16:40:14.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-ttjvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:14.831: INFO: stderr: ""
Dec  8 16:40:14.831: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 16:40:14.831: INFO: validating pod update-demo-nautilus-ttjvl
Dec  8 16:40:14.835: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 16:40:14.835: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 16:40:14.835: INFO: update-demo-nautilus-ttjvl is verified up and running
Dec  8 16:40:14.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-vz4bl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:14.894: INFO: stderr: ""
Dec  8 16:40:14.895: INFO: stdout: "true"
Dec  8 16:40:14.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-vz4bl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:14.954: INFO: stderr: ""
Dec  8 16:40:14.954: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 16:40:14.954: INFO: validating pod update-demo-nautilus-vz4bl
Dec  8 16:40:14.959: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 16:40:14.959: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 16:40:14.959: INFO: update-demo-nautilus-vz4bl is verified up and running
STEP: using delete to clean up resources
Dec  8 16:40:14.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:15.042: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:40:15.042: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  8 16:40:15.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-nvkkb'
Dec  8 16:40:15.172: INFO: stderr: "No resources found.\n"
Dec  8 16:40:15.172: INFO: stdout: ""
Dec  8 16:40:15.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -l name=update-demo --namespace=e2e-tests-kubectl-nvkkb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 16:40:15.248: INFO: stderr: ""
Dec  8 16:40:15.248: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:40:15.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nvkkb" for this suite.
Dec  8 16:40:39.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:40:39.407: INFO: namespace: e2e-tests-kubectl-nvkkb, resource: bindings, ignored listing per whitelist
Dec  8 16:40:39.464: INFO: namespace e2e-tests-kubectl-nvkkb deletion completed in 24.208219863s

• [SLOW TEST:43.838 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:40:39.464: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:40:39.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-52dn4" for this suite.
Dec  8 16:40:45.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:40:45.822: INFO: namespace: e2e-tests-services-52dn4, resource: bindings, ignored listing per whitelist
Dec  8 16:40:45.853: INFO: namespace e2e-tests-services-52dn4 deletion completed in 6.162689258s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.389 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:40:45.853: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:40:52.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-gcf9n" for this suite.
Dec  8 16:40:58.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:40:58.809: INFO: namespace: e2e-tests-namespaces-gcf9n, resource: bindings, ignored listing per whitelist
Dec  8 16:40:58.856: INFO: namespace e2e-tests-namespaces-gcf9n deletion completed in 6.158380131s
STEP: Destroying namespace "e2e-tests-nsdeletetest-c56kg" for this suite.
Dec  8 16:40:58.860: INFO: Namespace e2e-tests-nsdeletetest-c56kg was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-224hm" for this suite.
Dec  8 16:41:04.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:41:05.011: INFO: namespace: e2e-tests-nsdeletetest-224hm, resource: bindings, ignored listing per whitelist
Dec  8 16:41:05.026: INFO: namespace e2e-tests-nsdeletetest-224hm deletion completed in 6.166266564s

• [SLOW TEST:19.173 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:41:05.026: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-0e4d9eb0-fb08-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:41:05.360: INFO: Waiting up to 5m0s for pod "pod-secrets-0e4fe9d3-fb08-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-kkmzj" to be "success or failure"
Dec  8 16:41:05.448: INFO: Pod "pod-secrets-0e4fe9d3-fb08-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 87.652935ms
Dec  8 16:41:07.454: INFO: Pod "pod-secrets-0e4fe9d3-fb08-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093157376s
Dec  8 16:41:09.511: INFO: Pod "pod-secrets-0e4fe9d3-fb08-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.151057229s
STEP: Saw pod success
Dec  8 16:41:09.512: INFO: Pod "pod-secrets-0e4fe9d3-fb08-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:41:09.515: INFO: Trying to get logs from node k8s-g2 pod pod-secrets-0e4fe9d3-fb08-11e8-b692-aec8003d5667 container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:41:09.557: INFO: Waiting for pod pod-secrets-0e4fe9d3-fb08-11e8-b692-aec8003d5667 to disappear
Dec  8 16:41:09.560: INFO: Pod pod-secrets-0e4fe9d3-fb08-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:41:09.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kkmzj" for this suite.
Dec  8 16:41:15.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:41:15.666: INFO: namespace: e2e-tests-secrets-kkmzj, resource: bindings, ignored listing per whitelist
Dec  8 16:41:15.802: INFO: namespace e2e-tests-secrets-kkmzj deletion completed in 6.233545573s

• [SLOW TEST:10.775 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:41:15.802: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-bwhx8
Dec  8 16:41:22.088: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-bwhx8
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 16:41:22.091: INFO: Initial restart count of pod liveness-http is 0
Dec  8 16:41:38.157: INFO: Restart count of pod e2e-tests-container-probe-bwhx8/liveness-http is now 1 (16.065289038s elapsed)
Dec  8 16:41:58.233: INFO: Restart count of pod e2e-tests-container-probe-bwhx8/liveness-http is now 2 (36.142059836s elapsed)
Dec  8 16:42:18.289: INFO: Restart count of pod e2e-tests-container-probe-bwhx8/liveness-http is now 3 (56.197925108s elapsed)
Dec  8 16:42:38.335: INFO: Restart count of pod e2e-tests-container-probe-bwhx8/liveness-http is now 4 (1m16.24342398s elapsed)
Dec  8 16:43:50.514: INFO: Restart count of pod e2e-tests-container-probe-bwhx8/liveness-http is now 5 (2m28.422919707s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:43:50.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bwhx8" for this suite.
Dec  8 16:43:56.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:43:56.777: INFO: namespace: e2e-tests-container-probe-bwhx8, resource: bindings, ignored listing per whitelist
Dec  8 16:43:56.835: INFO: namespace e2e-tests-container-probe-bwhx8 deletion completed in 6.237645969s

• [SLOW TEST:161.033 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:43:56.835: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  8 16:43:57.063: INFO: Waiting up to 5m0s for pod "pod-74ab0ce5-fb08-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-84qnj" to be "success or failure"
Dec  8 16:43:57.159: INFO: Pod "pod-74ab0ce5-fb08-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 96.121735ms
Dec  8 16:43:59.164: INFO: Pod "pod-74ab0ce5-fb08-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101516643s
Dec  8 16:44:01.169: INFO: Pod "pod-74ab0ce5-fb08-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105637775s
STEP: Saw pod success
Dec  8 16:44:01.169: INFO: Pod "pod-74ab0ce5-fb08-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:44:01.173: INFO: Trying to get logs from node k8s-g2 pod pod-74ab0ce5-fb08-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:44:01.285: INFO: Waiting for pod pod-74ab0ce5-fb08-11e8-b692-aec8003d5667 to disappear
Dec  8 16:44:01.289: INFO: Pod pod-74ab0ce5-fb08-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:44:01.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-84qnj" for this suite.
Dec  8 16:44:07.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:44:07.499: INFO: namespace: e2e-tests-emptydir-84qnj, resource: bindings, ignored listing per whitelist
Dec  8 16:44:07.514: INFO: namespace e2e-tests-emptydir-84qnj deletion completed in 6.216963497s

• [SLOW TEST:10.679 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:44:07.514: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  8 16:44:15.962: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:15.962: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.030: INFO: Exec stderr: ""
Dec  8 16:44:16.030: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.030: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.095: INFO: Exec stderr: ""
Dec  8 16:44:16.095: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.095: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.166: INFO: Exec stderr: ""
Dec  8 16:44:16.166: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.166: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.230: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  8 16:44:16.230: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.230: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.307: INFO: Exec stderr: ""
Dec  8 16:44:16.307: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.307: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.378: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  8 16:44:16.378: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.378: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.445: INFO: Exec stderr: ""
Dec  8 16:44:16.445: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.445: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.516: INFO: Exec stderr: ""
Dec  8 16:44:16.516: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.516: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.584: INFO: Exec stderr: ""
Dec  8 16:44:16.584: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-hn5nh PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:44:16.584: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:44:16.657: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:44:16.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-hn5nh" for this suite.
Dec  8 16:45:04.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:45:04.806: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-hn5nh, resource: bindings, ignored listing per whitelist
Dec  8 16:45:04.826: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-hn5nh deletion completed in 48.159805938s

• [SLOW TEST:57.312 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:45:04.826: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  8 16:45:13.421: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 16:45:13.428: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 16:45:15.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 16:45:15.434: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 16:45:17.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 16:45:17.434: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:45:17.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-f2frm" for this suite.
Dec  8 16:45:41.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:45:41.583: INFO: namespace: e2e-tests-container-lifecycle-hook-f2frm, resource: bindings, ignored listing per whitelist
Dec  8 16:45:41.630: INFO: namespace e2e-tests-container-lifecycle-hook-f2frm deletion completed in 24.18748769s

• [SLOW TEST:36.804 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:45:41.630: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  8 16:45:41.968: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-260986308 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:45:42.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-flh2m" for this suite.
Dec  8 16:45:48.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:45:48.196: INFO: namespace: e2e-tests-kubectl-flh2m, resource: bindings, ignored listing per whitelist
Dec  8 16:45:48.259: INFO: namespace e2e-tests-kubectl-flh2m deletion completed in 6.231850643s

• [SLOW TEST:6.629 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:45:48.259: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-xwwt
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 16:45:48.590: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-xwwt" in namespace "e2e-tests-subpath-shfqq" to be "success or failure"
Dec  8 16:45:48.622: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Pending", Reason="", readiness=false. Elapsed: 32.68242ms
Dec  8 16:45:50.655: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065728421s
Dec  8 16:45:52.659: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069848012s
Dec  8 16:45:54.665: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 6.075112462s
Dec  8 16:45:56.669: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 8.079636874s
Dec  8 16:45:58.674: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 10.083891125s
Dec  8 16:46:00.685: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 12.095822012s
Dec  8 16:46:02.689: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 14.099410232s
Dec  8 16:46:04.693: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 16.103354537s
Dec  8 16:46:06.697: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 18.107242119s
Dec  8 16:46:08.702: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 20.112576385s
Dec  8 16:46:10.711: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 22.12099115s
Dec  8 16:46:12.716: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Running", Reason="", readiness=false. Elapsed: 24.125870984s
Dec  8 16:46:14.729: INFO: Pod "pod-subpath-test-projected-xwwt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.139303208s
STEP: Saw pod success
Dec  8 16:46:14.729: INFO: Pod "pod-subpath-test-projected-xwwt" satisfied condition "success or failure"
Dec  8 16:46:14.733: INFO: Trying to get logs from node k8s-g1 pod pod-subpath-test-projected-xwwt container test-container-subpath-projected-xwwt: <nil>
STEP: delete the pod
Dec  8 16:46:14.914: INFO: Waiting for pod pod-subpath-test-projected-xwwt to disappear
Dec  8 16:46:14.918: INFO: Pod pod-subpath-test-projected-xwwt no longer exists
STEP: Deleting pod pod-subpath-test-projected-xwwt
Dec  8 16:46:14.918: INFO: Deleting pod "pod-subpath-test-projected-xwwt" in namespace "e2e-tests-subpath-shfqq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:46:14.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-shfqq" for this suite.
Dec  8 16:46:21.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:46:21.117: INFO: namespace: e2e-tests-subpath-shfqq, resource: bindings, ignored listing per whitelist
Dec  8 16:46:21.215: INFO: namespace e2e-tests-subpath-shfqq deletion completed in 6.286173256s

• [SLOW TEST:32.956 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:46:21.215: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  8 16:46:21.575: INFO: Waiting up to 5m0s for pod "pod-cabe20f1-fb08-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-vdr8w" to be "success or failure"
Dec  8 16:46:21.606: INFO: Pod "pod-cabe20f1-fb08-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 31.690411ms
Dec  8 16:46:23.611: INFO: Pod "pod-cabe20f1-fb08-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036201112s
Dec  8 16:46:25.615: INFO: Pod "pod-cabe20f1-fb08-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040327603s
STEP: Saw pod success
Dec  8 16:46:25.615: INFO: Pod "pod-cabe20f1-fb08-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:46:25.618: INFO: Trying to get logs from node k8s-g2 pod pod-cabe20f1-fb08-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:46:25.658: INFO: Waiting for pod pod-cabe20f1-fb08-11e8-b692-aec8003d5667 to disappear
Dec  8 16:46:25.662: INFO: Pod pod-cabe20f1-fb08-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:46:25.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vdr8w" for this suite.
Dec  8 16:46:31.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:46:31.836: INFO: namespace: e2e-tests-emptydir-vdr8w, resource: bindings, ignored listing per whitelist
Dec  8 16:46:31.880: INFO: namespace e2e-tests-emptydir-vdr8w deletion completed in 6.210254196s

• [SLOW TEST:10.665 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:46:31.880: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:46:32.117: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d114fe3b-fb08-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-t5mqd" to be "success or failure"
Dec  8 16:46:32.155: INFO: Pod "downwardapi-volume-d114fe3b-fb08-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 37.569969ms
Dec  8 16:46:34.160: INFO: Pod "downwardapi-volume-d114fe3b-fb08-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042191407s
Dec  8 16:46:36.164: INFO: Pod "downwardapi-volume-d114fe3b-fb08-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046770373s
STEP: Saw pod success
Dec  8 16:46:36.164: INFO: Pod "downwardapi-volume-d114fe3b-fb08-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:46:36.168: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-d114fe3b-fb08-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:46:36.245: INFO: Waiting for pod downwardapi-volume-d114fe3b-fb08-11e8-b692-aec8003d5667 to disappear
Dec  8 16:46:36.270: INFO: Pod downwardapi-volume-d114fe3b-fb08-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:46:36.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t5mqd" for this suite.
Dec  8 16:46:42.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:46:42.390: INFO: namespace: e2e-tests-projected-t5mqd, resource: bindings, ignored listing per whitelist
Dec  8 16:46:42.481: INFO: namespace e2e-tests-projected-t5mqd deletion completed in 6.202960004s

• [SLOW TEST:10.601 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:46:42.481: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 16:46:42.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-cddlr'
Dec  8 16:46:45.925: INFO: stderr: ""
Dec  8 16:46:45.925: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  8 16:46:50.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-cddlr -o json'
Dec  8 16:46:51.080: INFO: stderr: ""
Dec  8 16:46:51.080: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.244.3.124/32\"\n        },\n        \"creationTimestamp\": \"2018-12-08T16:46:45Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-cddlr\",\n        \"resourceVersion\": \"18639\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-cddlr/pods/e2e-test-nginx-pod\",\n        \"uid\": \"d951f9ee-fb08-11e8-b4e1-448a5b81d79a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-dqql7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"k8s-g2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-dqql7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-dqql7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T16:46:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T16:46:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T16:46:48Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T16:46:45Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://01cff712294c2fc643cb339a4776ace44990cfba22a0db279d243c3219a208a4\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-08T16:46:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.22.132.14\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.3.124\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-08T16:46:46Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  8 16:46:51.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 replace -f - --namespace=e2e-tests-kubectl-cddlr'
Dec  8 16:46:51.383: INFO: stderr: ""
Dec  8 16:46:51.383: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Dec  8 16:46:51.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-cddlr'
Dec  8 16:46:53.766: INFO: stderr: ""
Dec  8 16:46:53.766: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:46:53.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cddlr" for this suite.
Dec  8 16:46:59.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:46:59.844: INFO: namespace: e2e-tests-kubectl-cddlr, resource: bindings, ignored listing per whitelist
Dec  8 16:46:59.947: INFO: namespace e2e-tests-kubectl-cddlr deletion completed in 6.173995931s

• [SLOW TEST:17.466 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:46:59.947: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-e1dc1cf0-fb08-11e8-b692-aec8003d5667
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-e1dc1cf0-fb08-11e8-b692-aec8003d5667
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:48:29.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4s4gf" for this suite.
Dec  8 16:48:53.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:48:53.606: INFO: namespace: e2e-tests-configmap-4s4gf, resource: bindings, ignored listing per whitelist
Dec  8 16:48:53.606: INFO: namespace e2e-tests-configmap-4s4gf deletion completed in 24.151876946s

• [SLOW TEST:113.659 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:48:53.606: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 16:48:53.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jpzjv'
Dec  8 16:48:53.932: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 16:48:53.932: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Dec  8 16:48:53.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-jpzjv'
Dec  8 16:48:54.237: INFO: stderr: ""
Dec  8 16:48:54.237: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:48:54.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jpzjv" for this suite.
Dec  8 16:49:00.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:49:00.309: INFO: namespace: e2e-tests-kubectl-jpzjv, resource: bindings, ignored listing per whitelist
Dec  8 16:49:00.436: INFO: namespace e2e-tests-kubectl-jpzjv deletion completed in 6.190718432s

• [SLOW TEST:6.830 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:49:00.436: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 16:49:00.656: INFO: Waiting up to 5m0s for pod "downward-api-299baeb9-fb09-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-fg982" to be "success or failure"
Dec  8 16:49:00.696: INFO: Pod "downward-api-299baeb9-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 40.10515ms
Dec  8 16:49:02.701: INFO: Pod "downward-api-299baeb9-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044492822s
Dec  8 16:49:04.705: INFO: Pod "downward-api-299baeb9-fb09-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048860038s
STEP: Saw pod success
Dec  8 16:49:04.705: INFO: Pod "downward-api-299baeb9-fb09-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:49:04.709: INFO: Trying to get logs from node k8s-g1 pod downward-api-299baeb9-fb09-11e8-b692-aec8003d5667 container dapi-container: <nil>
STEP: delete the pod
Dec  8 16:49:04.813: INFO: Waiting for pod downward-api-299baeb9-fb09-11e8-b692-aec8003d5667 to disappear
Dec  8 16:49:04.820: INFO: Pod downward-api-299baeb9-fb09-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:49:04.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fg982" for this suite.
Dec  8 16:49:10.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:49:10.970: INFO: namespace: e2e-tests-downward-api-fg982, resource: bindings, ignored listing per whitelist
Dec  8 16:49:10.999: INFO: namespace e2e-tests-downward-api-fg982 deletion completed in 6.170160103s

• [SLOW TEST:10.563 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:49:10.999: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  8 16:49:15.298: INFO: Pod pod-hostip-2fed4686-fb09-11e8-b692-aec8003d5667 has hostIP: 172.22.132.14
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:49:15.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-26nwh" for this suite.
Dec  8 16:49:39.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:49:39.451: INFO: namespace: e2e-tests-pods-26nwh, resource: bindings, ignored listing per whitelist
Dec  8 16:49:39.486: INFO: namespace e2e-tests-pods-26nwh deletion completed in 24.180153591s

• [SLOW TEST:28.487 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:49:39.486: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:49:39.995: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"40f60c6c-fb09-11e8-b4e1-448a5b81d79a", Controller:(*bool)(0xc42096de46), BlockOwnerDeletion:(*bool)(0xc42096de47)}}
Dec  8 16:49:40.035: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"40ed0dd8-fb09-11e8-b4e1-448a5b81d79a", Controller:(*bool)(0xc420eb505e), BlockOwnerDeletion:(*bool)(0xc420eb505f)}}
Dec  8 16:49:40.093: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"40ef1354-fb09-11e8-b4e1-448a5b81d79a", Controller:(*bool)(0xc421c18406), BlockOwnerDeletion:(*bool)(0xc421c18407)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:49:45.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l2lb7" for this suite.
Dec  8 16:49:51.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:49:51.328: INFO: namespace: e2e-tests-gc-l2lb7, resource: bindings, ignored listing per whitelist
Dec  8 16:49:51.392: INFO: namespace e2e-tests-gc-l2lb7 deletion completed in 6.19980681s

• [SLOW TEST:11.905 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:49:51.392: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-9x765
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 16:49:51.615: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 16:50:18.098: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.3.127:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9x765 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:50:18.098: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:50:18.179: INFO: Found all expected endpoints: [netserver-0]
Dec  8 16:50:18.183: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.4.108:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9x765 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 16:50:18.183: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
Dec  8 16:50:18.258: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:50:18.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-9x765" for this suite.
Dec  8 16:50:42.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:50:42.331: INFO: namespace: e2e-tests-pod-network-test-9x765, resource: bindings, ignored listing per whitelist
Dec  8 16:50:42.429: INFO: namespace e2e-tests-pod-network-test-9x765 deletion completed in 24.16306098s

• [SLOW TEST:51.037 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:50:42.429: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  8 16:50:42.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 api-versions'
Dec  8 16:50:42.900: INFO: stderr: ""
Dec  8 16:50:42.900: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:50:42.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mcc5m" for this suite.
Dec  8 16:50:48.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:50:48.991: INFO: namespace: e2e-tests-kubectl-mcc5m, resource: bindings, ignored listing per whitelist
Dec  8 16:50:49.086: INFO: namespace e2e-tests-kubectl-mcc5m deletion completed in 6.177604933s

• [SLOW TEST:6.657 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:50:49.087: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8xlrx
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-8xlrx
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-8xlrx
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-8xlrx
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-8xlrx
Dec  8 16:50:53.436: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8xlrx, name: ss-0, uid: 6c906666-fb09-11e8-9316-54a05085d523, status phase: Failed. Waiting for statefulset controller to delete.
Dec  8 16:50:53.450: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8xlrx, name: ss-0, uid: 6c906666-fb09-11e8-9316-54a05085d523, status phase: Failed. Waiting for statefulset controller to delete.
Dec  8 16:50:53.460: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-8xlrx
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-8xlrx
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-8xlrx and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 16:50:57.580: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8xlrx
Dec  8 16:50:57.584: INFO: Scaling statefulset ss to 0
Dec  8 16:51:17.627: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 16:51:17.631: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:51:17.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8xlrx" for this suite.
Dec  8 16:51:25.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:51:25.829: INFO: namespace: e2e-tests-statefulset-8xlrx, resource: bindings, ignored listing per whitelist
Dec  8 16:51:25.867: INFO: namespace e2e-tests-statefulset-8xlrx deletion completed in 8.18483575s

• [SLOW TEST:36.780 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:51:25.867: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  8 16:51:26.181: INFO: Waiting up to 5m0s for pod "client-containers-8059eb30-fb09-11e8-b692-aec8003d5667" in namespace "e2e-tests-containers-cmm8m" to be "success or failure"
Dec  8 16:51:26.193: INFO: Pod "client-containers-8059eb30-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 11.484194ms
Dec  8 16:51:28.198: INFO: Pod "client-containers-8059eb30-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016648031s
Dec  8 16:51:30.203: INFO: Pod "client-containers-8059eb30-fb09-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021537872s
STEP: Saw pod success
Dec  8 16:51:30.203: INFO: Pod "client-containers-8059eb30-fb09-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:51:30.207: INFO: Trying to get logs from node k8s-g2 pod client-containers-8059eb30-fb09-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:51:30.260: INFO: Waiting for pod client-containers-8059eb30-fb09-11e8-b692-aec8003d5667 to disappear
Dec  8 16:51:30.263: INFO: Pod client-containers-8059eb30-fb09-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:51:30.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-cmm8m" for this suite.
Dec  8 16:51:36.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:51:36.456: INFO: namespace: e2e-tests-containers-cmm8m, resource: bindings, ignored listing per whitelist
Dec  8 16:51:36.506: INFO: namespace e2e-tests-containers-cmm8m deletion completed in 6.234837637s

• [SLOW TEST:10.639 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:51:36.506: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-86ac7007-fb09-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 16:51:36.817: INFO: Waiting up to 5m0s for pod "pod-secrets-86b2260b-fb09-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-xpx5j" to be "success or failure"
Dec  8 16:51:36.849: INFO: Pod "pod-secrets-86b2260b-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 31.849799ms
Dec  8 16:51:38.867: INFO: Pod "pod-secrets-86b2260b-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049967972s
Dec  8 16:51:40.875: INFO: Pod "pod-secrets-86b2260b-fb09-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05810948s
STEP: Saw pod success
Dec  8 16:51:40.875: INFO: Pod "pod-secrets-86b2260b-fb09-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:51:40.878: INFO: Trying to get logs from node k8s-g1 pod pod-secrets-86b2260b-fb09-11e8-b692-aec8003d5667 container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 16:51:40.943: INFO: Waiting for pod pod-secrets-86b2260b-fb09-11e8-b692-aec8003d5667 to disappear
Dec  8 16:51:40.946: INFO: Pod pod-secrets-86b2260b-fb09-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:51:40.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xpx5j" for this suite.
Dec  8 16:51:47.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:51:47.183: INFO: namespace: e2e-tests-secrets-xpx5j, resource: bindings, ignored listing per whitelist
Dec  8 16:51:47.200: INFO: namespace e2e-tests-secrets-xpx5j deletion completed in 6.246024996s

• [SLOW TEST:10.694 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:51:47.200: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:51:47.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8d1c6292-fb09-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-kk8vx" to be "success or failure"
Dec  8 16:51:47.635: INFO: Pod "downwardapi-volume-8d1c6292-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 48.670543ms
Dec  8 16:51:49.638: INFO: Pod "downwardapi-volume-8d1c6292-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052079875s
Dec  8 16:51:51.661: INFO: Pod "downwardapi-volume-8d1c6292-fb09-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.075101423s
STEP: Saw pod success
Dec  8 16:51:51.661: INFO: Pod "downwardapi-volume-8d1c6292-fb09-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:51:51.665: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-8d1c6292-fb09-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:51:51.803: INFO: Waiting for pod downwardapi-volume-8d1c6292-fb09-11e8-b692-aec8003d5667 to disappear
Dec  8 16:51:51.806: INFO: Pod downwardapi-volume-8d1c6292-fb09-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:51:51.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kk8vx" for this suite.
Dec  8 16:51:57.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:51:57.988: INFO: namespace: e2e-tests-downward-api-kk8vx, resource: bindings, ignored listing per whitelist
Dec  8 16:51:58.014: INFO: namespace e2e-tests-downward-api-kk8vx deletion completed in 6.20006106s

• [SLOW TEST:10.814 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:51:58.014: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 16:51:58.256: INFO: Creating deployment "nginx-deployment"
Dec  8 16:51:58.297: INFO: Waiting for observed generation 1
Dec  8 16:52:00.306: INFO: Waiting for all required pods to come up
Dec  8 16:52:00.313: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  8 16:52:06.326: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  8 16:52:06.334: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  8 16:52:06.378: INFO: Updating deployment nginx-deployment
Dec  8 16:52:06.378: INFO: Waiting for observed generation 2
Dec  8 16:52:08.385: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  8 16:52:08.389: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  8 16:52:08.392: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  8 16:52:08.403: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  8 16:52:08.403: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  8 16:52:08.407: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  8 16:52:08.413: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  8 16:52:08.413: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  8 16:52:08.433: INFO: Updating deployment nginx-deployment
Dec  8 16:52:08.433: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  8 16:52:08.439: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  8 16:52:10.459: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 16:52:10.609: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-2b75m,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2b75m/deployments/nginx-deployment,UID:937e3a5f-fb09-11e8-b4e1-448a5b81d79a,ResourceVersion:19932,Generation:3,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-12-08 16:52:08 +0000 UTC 2018-12-08 16:52:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-08 16:52:09 +0000 UTC 2018-12-08 16:51:58 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  8 16:52:10.613: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-2b75m,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2b75m/replicasets/nginx-deployment-7dc8f79789,UID:9855c2e7-fb09-11e8-9316-54a05085d523,ResourceVersion:19917,Generation:3,CreationTimestamp:2018-12-08 16:52:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 937e3a5f-fb09-11e8-b4e1-448a5b81d79a 0xc421bcf6d7 0xc421bcf6d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 16:52:10.613: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  8 16:52:10.613: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-2b75m,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2b75m/replicasets/nginx-deployment-7f9675fb8b,UID:938c76a5-fb09-11e8-9316-54a05085d523,ResourceVersion:19927,Generation:3,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 937e3a5f-fb09-11e8-b4e1-448a5b81d79a 0xc421bcf797 0xc421bcf798}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  8 16:52:10.647: INFO: Pod "nginx-deployment-7dc8f79789-299hd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-299hd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-299hd,UID:989bf85f-fb09-11e8-9316-54a05085d523,ResourceVersion:19853,Generation:0,CreationTimestamp:2018-12-08 16:52:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a58977 0xc422a58978}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a589f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a58a10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.647: INFO: Pod "nginx-deployment-7dc8f79789-85f82" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-85f82,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-85f82,UID:99c1f348-fb09-11e8-9316-54a05085d523,ResourceVersion:19929,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a58ad0 0xc422a58ad1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a58b50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a58b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.647: INFO: Pod "nginx-deployment-7dc8f79789-b24sj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-b24sj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-b24sj,UID:99c1e68f-fb09-11e8-9316-54a05085d523,ResourceVersion:19935,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a58c30 0xc422a58c31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a58cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a58ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:08 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.647: INFO: Pod "nginx-deployment-7dc8f79789-b6n8w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-b6n8w,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-b6n8w,UID:99d64441-fb09-11e8-9316-54a05085d523,ResourceVersion:19934,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a58db0 0xc422a58db1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a58e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a58e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.647: INFO: Pod "nginx-deployment-7dc8f79789-dz4ln" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dz4ln,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-dz4ln,UID:99ade87a-fb09-11e8-9316-54a05085d523,ResourceVersion:19921,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a58f10 0xc422a58f11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a58fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a58fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:08 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.647: INFO: Pod "nginx-deployment-7dc8f79789-kxzst" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kxzst,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-kxzst,UID:985ad7b1-fb09-11e8-9316-54a05085d523,ResourceVersion:19937,Generation:0,CreationTimestamp:2018-12-08 16:52:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.3.136/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a59090 0xc422a59091}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a59140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.647: INFO: Pod "nginx-deployment-7dc8f79789-lbcd7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-lbcd7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-lbcd7,UID:988fe2dc-fb09-11e8-9316-54a05085d523,ResourceVersion:19941,Generation:0,CreationTimestamp:2018-12-08 16:52:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.118/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a59210 0xc422a59211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a592b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.647: INFO: Pod "nginx-deployment-7dc8f79789-np7vd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-np7vd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-np7vd,UID:9861a08c-fb09-11e8-9316-54a05085d523,ResourceVersion:19898,Generation:0,CreationTimestamp:2018-12-08 16:52:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.117/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a59380 0xc422a59381}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a59420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7dc8f79789-rd2c6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rd2c6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-rd2c6,UID:9861a363-fb09-11e8-9316-54a05085d523,ResourceVersion:19972,Generation:0,CreationTimestamp:2018-12-08 16:52:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.3.137/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a59510 0xc422a59511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a595b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:06 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7dc8f79789-rqvnc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rqvnc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-rqvnc,UID:99d65c02-fb09-11e8-9316-54a05085d523,ResourceVersion:19954,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a59710 0xc422a59711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a597b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7dc8f79789-vcgpx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vcgpx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-vcgpx,UID:99efe4a5-fb09-11e8-9316-54a05085d523,ResourceVersion:19914,Generation:0,CreationTimestamp:2018-12-08 16:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a59870 0xc422a59871}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a598f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a59910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7dc8f79789-vhz8c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vhz8c,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-vhz8c,UID:99d66ac2-fb09-11e8-9316-54a05085d523,ResourceVersion:19960,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a59980 0xc422a59981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a59a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7dc8f79789-xqhvs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xqhvs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7dc8f79789-xqhvs,UID:99d669d9-fb09-11e8-9316-54a05085d523,ResourceVersion:19967,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9855c2e7-fb09-11e8-9316-54a05085d523 0xc422a59b30 0xc422a59b31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a59be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-2zpwd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2zpwd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-2zpwd,UID:99c1e087-fb09-11e8-9316-54a05085d523,ResourceVersion:19928,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422a59ca0 0xc422a59ca1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a59d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:08 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-5rrxq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5rrxq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-5rrxq,UID:99efcd29-fb09-11e8-9316-54a05085d523,ResourceVersion:19910,Generation:0,CreationTimestamp:2018-12-08 16:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422a59e27 0xc422a59e28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a59ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a59ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-62zwk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-62zwk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-62zwk,UID:93a009f6-fb09-11e8-9316-54a05085d523,ResourceVersion:19776,Generation:0,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.112/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422a59f90 0xc422a59f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be20a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be20c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:58 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:10.244.4.112,StartTime:2018-12-08 16:51:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 16:52:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://3f53abfe0ffe6eedc59a1add05ec859d8b5d681da29219c4f2578e3c6dc1c27f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-77kvb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-77kvb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-77kvb,UID:99d647d7-fb09-11e8-9316-54a05085d523,ResourceVersion:19946,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be2187 0xc422be2188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be2200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-7mjzq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7mjzq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-7mjzq,UID:99efbebc-fb09-11e8-9316-54a05085d523,ResourceVersion:19966,Generation:0,CreationTimestamp:2018-12-08 16:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be22d7 0xc422be22d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be2350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-bps2q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bps2q,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-bps2q,UID:99d66334-fb09-11e8-9316-54a05085d523,ResourceVersion:19955,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be2427 0xc422be2428}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be24a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be24c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-c6m4g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-c6m4g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-c6m4g,UID:99d67910-fb09-11e8-9316-54a05085d523,ResourceVersion:19970,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be2577 0xc422be2578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be25f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-czhxf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-czhxf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-czhxf,UID:93ddb1f0-fb09-11e8-9316-54a05085d523,ResourceVersion:19773,Generation:0,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.3.133/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be26d7 0xc422be26d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be2750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:10.244.3.133,StartTime:2018-12-08 16:51:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 16:52:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://1f4b7cc907b5cb199e58bc76f8844b9084d8746926e6adc991f396a1629fe2a7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.648: INFO: Pod "nginx-deployment-7f9675fb8b-dqsz9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dqsz9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-dqsz9,UID:93ddad0b-fb09-11e8-9316-54a05085d523,ResourceVersion:19788,Generation:0,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.114/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be2847 0xc422be2848}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be28c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be28e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:10.244.4.114,StartTime:2018-12-08 16:51:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 16:52:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://ab1e5b25bac811fb8cd75d236b46b938d1b1d8cd72c7abb52508cd8010031dbd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-f5l2r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f5l2r,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-f5l2r,UID:99efdb74-fb09-11e8-9316-54a05085d523,ResourceVersion:19913,Generation:0,CreationTimestamp:2018-12-08 16:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be29a7 0xc422be29a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be2a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-glspx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-glspx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-glspx,UID:99c1e718-fb09-11e8-9316-54a05085d523,ResourceVersion:19945,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be2ac0 0xc422be2ac1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be2b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:08 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-hjmfc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hjmfc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-hjmfc,UID:99efdfa3-fb09-11e8-9316-54a05085d523,ResourceVersion:19969,Generation:0,CreationTimestamp:2018-12-08 16:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be2c07 0xc422be2c08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be2c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-lngrg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lngrg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-lngrg,UID:93f71659-fb09-11e8-9316-54a05085d523,ResourceVersion:19784,Generation:0,CreationTimestamp:2018-12-08 16:51:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.115/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be2d67 0xc422be2d68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be2de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:10.244.4.115,StartTime:2018-12-08 16:51:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 16:52:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://6a79185aafa573c980f25725a4feb0d565cf1b2babf1e678073d60bf91ce001a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-mphb4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mphb4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-mphb4,UID:99addf8c-fb09-11e8-9316-54a05085d523,ResourceVersion:19920,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be2ec7 0xc422be2ec8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be2f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be2f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:08 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-qbbh5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qbbh5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-qbbh5,UID:99d6490b-fb09-11e8-9316-54a05085d523,ResourceVersion:19961,Generation:0,CreationTimestamp:2018-12-08 16:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be3017 0xc422be3018}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be3090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be30b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 16:52:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-sjz9c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sjz9c,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-sjz9c,UID:99efd025-fb09-11e8-9316-54a05085d523,ResourceVersion:19911,Generation:0,CreationTimestamp:2018-12-08 16:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be3167 0xc422be3168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be31e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be3200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:09 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-swx48" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-swx48,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-swx48,UID:93b82105-fb09-11e8-9316-54a05085d523,ResourceVersion:19782,Generation:0,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.113/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be3280 0xc422be3281}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be32f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be3310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:58 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:10.244.4.113,StartTime:2018-12-08 16:51:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 16:52:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://09a4bd17f9edbbf3cf801af00e540b24b255ba88abaa3d972cdad1c33c141153}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-vj2qq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vj2qq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-vj2qq,UID:93dda9aa-fb09-11e8-9316-54a05085d523,ResourceVersion:19799,Generation:0,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.116/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be33e7 0xc422be33e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be3460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be3480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.13,PodIP:10.244.4.116,StartTime:2018-12-08 16:51:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 16:52:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://f8f2f3bed8752deb80e1ccff217bc2c9fe85f438b8817226ae01a6ec23a76373}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-xdmkf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xdmkf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-xdmkf,UID:93dd9f04-fb09-11e8-9316-54a05085d523,ResourceVersion:19760,Generation:0,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.3.132/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be3557 0xc422be3558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be35d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be35f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:59 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:10.244.3.132,StartTime:2018-12-08 16:51:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 16:52:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://54fb2d96e22b3f53a1ff1a64200529e167f16f33268759d0bacbab6275481a59}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 16:52:10.649: INFO: Pod "nginx-deployment-7f9675fb8b-xff97" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xff97,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-2b75m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2b75m/pods/nginx-deployment-7f9675fb8b-xff97,UID:93b8156c-fb09-11e8-9316-54a05085d523,ResourceVersion:19765,Generation:0,CreationTimestamp:2018-12-08 16:51:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.3.131/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 938c76a5-fb09-11e8-9316-54a05085d523 0xc422be36d7 0xc422be36d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h9p4b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h9p4b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h9p4b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422be3750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422be3770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:52:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:51:58 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:10.244.3.131,StartTime:2018-12-08 16:51:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 16:52:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://e4a99f4704685eab06040ce7c4de916401a11f17d983006ea8d5f53904096a67}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:52:10.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2b75m" for this suite.
Dec  8 16:52:28.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:52:28.943: INFO: namespace: e2e-tests-deployment-2b75m, resource: bindings, ignored listing per whitelist
Dec  8 16:52:29.005: INFO: namespace e2e-tests-deployment-2b75m deletion completed in 18.297084703s

• [SLOW TEST:30.990 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:52:29.005: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  8 16:52:29.271: INFO: Waiting up to 5m0s for pod "pod-a5f41d86-fb09-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-4twhg" to be "success or failure"
Dec  8 16:52:29.326: INFO: Pod "pod-a5f41d86-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 54.102503ms
Dec  8 16:52:31.330: INFO: Pod "pod-a5f41d86-fb09-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058895636s
Dec  8 16:52:33.338: INFO: Pod "pod-a5f41d86-fb09-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066859313s
STEP: Saw pod success
Dec  8 16:52:33.338: INFO: Pod "pod-a5f41d86-fb09-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:52:33.341: INFO: Trying to get logs from node k8s-g1 pod pod-a5f41d86-fb09-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:52:33.424: INFO: Waiting for pod pod-a5f41d86-fb09-11e8-b692-aec8003d5667 to disappear
Dec  8 16:52:33.430: INFO: Pod pod-a5f41d86-fb09-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:52:33.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4twhg" for this suite.
Dec  8 16:52:39.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:52:39.579: INFO: namespace: e2e-tests-emptydir-4twhg, resource: bindings, ignored listing per whitelist
Dec  8 16:52:39.615: INFO: namespace e2e-tests-emptydir-4twhg deletion completed in 6.173034866s

• [SLOW TEST:10.610 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:52:39.615: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  8 16:52:39.833: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 16:52:39.857: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 16:52:39.864: INFO: 
Logging pods the kubelet thinks is on node k8s-g1 before test
Dec  8 16:52:39.875: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 15:38:07 +0000 UTC (1 container statuses recorded)
Dec  8 16:52:39.875: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  8 16:52:39.875: INFO: sonobuoy-e2e-job-b2f0b9428b2343be from heptio-sonobuoy started at 2018-12-08 15:38:14 +0000 UTC (2 container statuses recorded)
Dec  8 16:52:39.875: INFO: 	Container e2e ready: true, restart count 0
Dec  8 16:52:39.875: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 16:52:39.875: INFO: sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-dprzm from heptio-sonobuoy started at 2018-12-08 15:38:15 +0000 UTC (2 container statuses recorded)
Dec  8 16:52:39.875: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  8 16:52:39.875: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  8 16:52:39.875: INFO: kube-proxy-npf4v from kube-system started at 2018-12-08 15:13:14 +0000 UTC (1 container statuses recorded)
Dec  8 16:52:39.875: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 16:52:39.875: INFO: calico-node-j2p5w from kube-system started at 2018-12-08 15:12:24 +0000 UTC (2 container statuses recorded)
Dec  8 16:52:39.875: INFO: 	Container calico-node ready: true, restart count 0
Dec  8 16:52:39.875: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 16:52:39.875: INFO: nvidia-device-plugin-daemonset-1.12-wtl6n from kube-system started at 2018-12-08 15:13:14 +0000 UTC (1 container statuses recorded)
Dec  8 16:52:39.875: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  8 16:52:39.875: INFO: 
Logging pods the kubelet thinks is on node k8s-g2 before test
Dec  8 16:52:39.883: INFO: kube-proxy-mn5f4 from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:52:39.883: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 16:52:39.883: INFO: calico-node-gqg76 from kube-system started at 2018-12-08 15:12:24 +0000 UTC (2 container statuses recorded)
Dec  8 16:52:39.883: INFO: 	Container calico-node ready: true, restart count 0
Dec  8 16:52:39.883: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 16:52:39.883: INFO: sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-jlvwf from heptio-sonobuoy started at 2018-12-08 15:38:15 +0000 UTC (2 container statuses recorded)
Dec  8 16:52:39.883: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  8 16:52:39.883: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  8 16:52:39.883: INFO: coredns-84ff64cf58-x62gl from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:52:39.883: INFO: 	Container coredns ready: true, restart count 0
Dec  8 16:52:39.883: INFO: nvidia-device-plugin-daemonset-1.12-wv4wg from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:52:39.883: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  8 16:52:39.883: INFO: coredns-84ff64cf58-psbbm from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:52:39.883: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156e69b7b2644a63], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:52:40.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-lxz27" for this suite.
Dec  8 16:52:46.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:52:47.031: INFO: namespace: e2e-tests-sched-pred-lxz27, resource: bindings, ignored listing per whitelist
Dec  8 16:52:47.108: INFO: namespace e2e-tests-sched-pred-lxz27 deletion completed in 6.172269667s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.494 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:52:47.109: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-b0c85c3e-fb09-11e8-b692-aec8003d5667
Dec  8 16:52:47.428: INFO: Pod name my-hostname-basic-b0c85c3e-fb09-11e8-b692-aec8003d5667: Found 0 pods out of 1
Dec  8 16:52:52.432: INFO: Pod name my-hostname-basic-b0c85c3e-fb09-11e8-b692-aec8003d5667: Found 1 pods out of 1
Dec  8 16:52:52.432: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b0c85c3e-fb09-11e8-b692-aec8003d5667" are running
Dec  8 16:52:52.436: INFO: Pod "my-hostname-basic-b0c85c3e-fb09-11e8-b692-aec8003d5667-54f7x" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 16:52:47 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 16:52:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 16:52:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 16:52:47 +0000 UTC Reason: Message:}])
Dec  8 16:52:52.436: INFO: Trying to dial the pod
Dec  8 16:52:57.454: INFO: Controller my-hostname-basic-b0c85c3e-fb09-11e8-b692-aec8003d5667: Got expected result from replica 1 [my-hostname-basic-b0c85c3e-fb09-11e8-b692-aec8003d5667-54f7x]: "my-hostname-basic-b0c85c3e-fb09-11e8-b692-aec8003d5667-54f7x", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:52:57.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2tfj8" for this suite.
Dec  8 16:53:03.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:53:03.524: INFO: namespace: e2e-tests-replication-controller-2tfj8, resource: bindings, ignored listing per whitelist
Dec  8 16:53:03.629: INFO: namespace e2e-tests-replication-controller-2tfj8 deletion completed in 6.167421769s

• [SLOW TEST:16.521 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:53:03.629: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  8 16:53:03.905: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 16:53:04.015: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 16:53:04.019: INFO: 
Logging pods the kubelet thinks is on node k8s-g1 before test
Dec  8 16:53:04.029: INFO: kube-proxy-npf4v from kube-system started at 2018-12-08 15:13:14 +0000 UTC (1 container statuses recorded)
Dec  8 16:53:04.029: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 16:53:04.029: INFO: calico-node-j2p5w from kube-system started at 2018-12-08 15:12:24 +0000 UTC (2 container statuses recorded)
Dec  8 16:53:04.029: INFO: 	Container calico-node ready: true, restart count 0
Dec  8 16:53:04.029: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 16:53:04.029: INFO: nvidia-device-plugin-daemonset-1.12-wtl6n from kube-system started at 2018-12-08 15:13:14 +0000 UTC (1 container statuses recorded)
Dec  8 16:53:04.029: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  8 16:53:04.029: INFO: sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-dprzm from heptio-sonobuoy started at 2018-12-08 15:38:15 +0000 UTC (2 container statuses recorded)
Dec  8 16:53:04.029: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  8 16:53:04.029: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  8 16:53:04.029: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 15:38:07 +0000 UTC (1 container statuses recorded)
Dec  8 16:53:04.029: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  8 16:53:04.029: INFO: sonobuoy-e2e-job-b2f0b9428b2343be from heptio-sonobuoy started at 2018-12-08 15:38:14 +0000 UTC (2 container statuses recorded)
Dec  8 16:53:04.029: INFO: 	Container e2e ready: true, restart count 0
Dec  8 16:53:04.029: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 16:53:04.029: INFO: 
Logging pods the kubelet thinks is on node k8s-g2 before test
Dec  8 16:53:04.038: INFO: coredns-84ff64cf58-psbbm from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:53:04.038: INFO: 	Container coredns ready: true, restart count 0
Dec  8 16:53:04.038: INFO: kube-proxy-mn5f4 from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:53:04.038: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 16:53:04.038: INFO: calico-node-gqg76 from kube-system started at 2018-12-08 15:12:24 +0000 UTC (2 container statuses recorded)
Dec  8 16:53:04.038: INFO: 	Container calico-node ready: true, restart count 0
Dec  8 16:53:04.038: INFO: 	Container install-cni ready: true, restart count 0
Dec  8 16:53:04.038: INFO: sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-jlvwf from heptio-sonobuoy started at 2018-12-08 15:38:15 +0000 UTC (2 container statuses recorded)
Dec  8 16:53:04.038: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  8 16:53:04.038: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  8 16:53:04.038: INFO: coredns-84ff64cf58-x62gl from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:53:04.038: INFO: 	Container coredns ready: true, restart count 0
Dec  8 16:53:04.038: INFO: nvidia-device-plugin-daemonset-1.12-wv4wg from kube-system started at 2018-12-08 15:12:22 +0000 UTC (1 container statuses recorded)
Dec  8 16:53:04.038: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s-g1
STEP: verifying the node has the label node k8s-g2
Dec  8 16:53:04.201: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-g1
Dec  8 16:53:04.201: INFO: Pod sonobuoy-e2e-job-b2f0b9428b2343be requesting resource cpu=0m on Node k8s-g1
Dec  8 16:53:04.201: INFO: Pod sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-dprzm requesting resource cpu=0m on Node k8s-g1
Dec  8 16:53:04.201: INFO: Pod sonobuoy-systemd-logs-daemon-set-fb8680d9ae5f4f6c-jlvwf requesting resource cpu=0m on Node k8s-g2
Dec  8 16:53:04.201: INFO: Pod calico-node-gqg76 requesting resource cpu=250m on Node k8s-g2
Dec  8 16:53:04.201: INFO: Pod calico-node-j2p5w requesting resource cpu=250m on Node k8s-g1
Dec  8 16:53:04.201: INFO: Pod coredns-84ff64cf58-psbbm requesting resource cpu=100m on Node k8s-g2
Dec  8 16:53:04.201: INFO: Pod coredns-84ff64cf58-x62gl requesting resource cpu=100m on Node k8s-g2
Dec  8 16:53:04.201: INFO: Pod kube-proxy-mn5f4 requesting resource cpu=0m on Node k8s-g2
Dec  8 16:53:04.201: INFO: Pod kube-proxy-npf4v requesting resource cpu=0m on Node k8s-g1
Dec  8 16:53:04.201: INFO: Pod nvidia-device-plugin-daemonset-1.12-wtl6n requesting resource cpu=0m on Node k8s-g1
Dec  8 16:53:04.201: INFO: Pod nvidia-device-plugin-daemonset-1.12-wv4wg requesting resource cpu=0m on Node k8s-g2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bacc12ba-fb09-11e8-b692-aec8003d5667.156e69bd5f148fad], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bgx7b/filler-pod-bacc12ba-fb09-11e8-b692-aec8003d5667 to k8s-g1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bacc12ba-fb09-11e8-b692-aec8003d5667.156e69bdc7b0ac8c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bacc12ba-fb09-11e8-b692-aec8003d5667.156e69bdd6c3be9f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bacc12ba-fb09-11e8-b692-aec8003d5667.156e69bdebb72aba], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bad5f425-fb09-11e8-b692-aec8003d5667.156e69bd63a521f0], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bgx7b/filler-pod-bad5f425-fb09-11e8-b692-aec8003d5667 to k8s-g2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bad5f425-fb09-11e8-b692-aec8003d5667.156e69bdbd6317b2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bad5f425-fb09-11e8-b692-aec8003d5667.156e69bdccb1b44e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bad5f425-fb09-11e8-b692-aec8003d5667.156e69bde5a42e06], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156e69be547bbe71], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node k8s-g1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-g2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:53:09.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bgx7b" for this suite.
Dec  8 16:53:15.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:53:15.700: INFO: namespace: e2e-tests-sched-pred-bgx7b, resource: bindings, ignored listing per whitelist
Dec  8 16:53:15.790: INFO: namespace e2e-tests-sched-pred-bgx7b deletion completed in 6.15689435s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.161 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:53:15.790: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 16:53:15.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-sm6pg'
Dec  8 16:53:16.086: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  8 16:53:16.086: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Dec  8 16:53:18.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-sm6pg'
Dec  8 16:53:18.170: INFO: stderr: ""
Dec  8 16:53:18.170: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:53:18.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sm6pg" for this suite.
Dec  8 16:54:42.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:54:42.289: INFO: namespace: e2e-tests-kubectl-sm6pg, resource: bindings, ignored listing per whitelist
Dec  8 16:54:42.361: INFO: namespace e2e-tests-kubectl-sm6pg deletion completed in 1m24.181915472s

• [SLOW TEST:86.570 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:54:42.361: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gspgq
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-gspgq
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-gspgq
Dec  8 16:54:42.693: INFO: Found 0 stateful pods, waiting for 1
Dec  8 16:54:52.698: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  8 16:54:52.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-gspgq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 16:54:52.874: INFO: stderr: ""
Dec  8 16:54:52.874: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 16:54:52.874: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 16:54:52.878: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  8 16:55:02.882: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 16:55:02.882: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 16:55:02.913: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:02.913: INFO: ss-0  k8s-g1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:02.913: INFO: 
Dec  8 16:55:02.913: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  8 16:55:03.963: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995561224s
Dec  8 16:55:04.979: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.945768569s
Dec  8 16:55:05.984: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.929621021s
Dec  8 16:55:06.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.924580522s
Dec  8 16:55:07.993: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.919803129s
Dec  8 16:55:08.997: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.915380719s
Dec  8 16:55:10.007: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.91142554s
Dec  8 16:55:11.013: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.901385139s
Dec  8 16:55:12.018: INFO: Verifying statefulset ss doesn't scale past 3 for another 896.144509ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-gspgq
Dec  8 16:55:13.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-gspgq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 16:55:13.152: INFO: stderr: ""
Dec  8 16:55:13.152: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 16:55:13.152: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 16:55:13.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-gspgq ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 16:55:13.328: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  8 16:55:13.328: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 16:55:13.328: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 16:55:13.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-gspgq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 16:55:13.468: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  8 16:55:13.468: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 16:55:13.468: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 16:55:13.493: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:55:13.493: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 16:55:13.493: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  8 16:55:13.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-gspgq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 16:55:13.631: INFO: stderr: ""
Dec  8 16:55:13.631: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 16:55:13.631: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 16:55:13.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-gspgq ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 16:55:13.851: INFO: stderr: ""
Dec  8 16:55:13.851: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 16:55:13.851: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 16:55:13.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 exec --namespace=e2e-tests-statefulset-gspgq ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 16:55:14.039: INFO: stderr: ""
Dec  8 16:55:14.039: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 16:55:14.039: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 16:55:14.039: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 16:55:14.047: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  8 16:55:24.121: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 16:55:24.121: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 16:55:24.121: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 16:55:24.151: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:24.151: INFO: ss-0  k8s-g1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:24.151: INFO: ss-1  k8s-g2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:02 +0000 UTC  }]
Dec  8 16:55:24.151: INFO: ss-2  k8s-g1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  }]
Dec  8 16:55:24.151: INFO: 
Dec  8 16:55:24.151: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 16:55:25.159: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:25.159: INFO: ss-0  k8s-g1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:25.159: INFO: ss-1  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:02 +0000 UTC  }]
Dec  8 16:55:25.159: INFO: ss-2  k8s-g1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  }]
Dec  8 16:55:25.159: INFO: 
Dec  8 16:55:25.159: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 16:55:26.164: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:26.164: INFO: ss-0  k8s-g1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:26.164: INFO: ss-1  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:02 +0000 UTC  }]
Dec  8 16:55:26.164: INFO: ss-2  k8s-g1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  }]
Dec  8 16:55:26.164: INFO: 
Dec  8 16:55:26.164: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 16:55:27.168: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:27.169: INFO: ss-0  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:27.169: INFO: ss-1  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:02 +0000 UTC  }]
Dec  8 16:55:27.169: INFO: 
Dec  8 16:55:27.169: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 16:55:28.173: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:28.173: INFO: ss-0  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:28.173: INFO: ss-1  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:02 +0000 UTC  }]
Dec  8 16:55:28.173: INFO: 
Dec  8 16:55:28.173: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 16:55:29.177: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:29.177: INFO: ss-0  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:29.177: INFO: ss-1  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:02 +0000 UTC  }]
Dec  8 16:55:29.177: INFO: 
Dec  8 16:55:29.177: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 16:55:30.184: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:30.184: INFO: ss-0  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:30.185: INFO: ss-1  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:02 +0000 UTC  }]
Dec  8 16:55:30.185: INFO: 
Dec  8 16:55:30.185: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 16:55:31.190: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  8 16:55:31.190: INFO: ss-0  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:54:42 +0000 UTC  }]
Dec  8 16:55:31.190: INFO: ss-1  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 16:55:02 +0000 UTC  }]
Dec  8 16:55:31.190: INFO: 
Dec  8 16:55:31.190: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 16:55:32.194: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.956631824s
Dec  8 16:55:33.198: INFO: Verifying statefulset ss doesn't scale past 0 for another 952.521757ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-gspgq
Dec  8 16:55:34.208: INFO: Scaling statefulset ss to 0
Dec  8 16:55:34.219: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 16:55:34.222: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gspgq
Dec  8 16:55:34.226: INFO: Scaling statefulset ss to 0
Dec  8 16:55:34.237: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 16:55:34.240: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:55:34.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gspgq" for this suite.
Dec  8 16:55:42.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:55:42.484: INFO: namespace: e2e-tests-statefulset-gspgq, resource: bindings, ignored listing per whitelist
Dec  8 16:55:42.517: INFO: namespace e2e-tests-statefulset-gspgq deletion completed in 8.221045414s

• [SLOW TEST:60.156 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:55:42.517: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:55:42.769: INFO: Waiting up to 5m0s for pod "downwardapi-volume-194af844-fb0a-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-n7k24" to be "success or failure"
Dec  8 16:55:42.806: INFO: Pod "downwardapi-volume-194af844-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 37.95952ms
Dec  8 16:55:44.811: INFO: Pod "downwardapi-volume-194af844-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042199146s
Dec  8 16:55:46.815: INFO: Pod "downwardapi-volume-194af844-fb0a-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045987405s
STEP: Saw pod success
Dec  8 16:55:46.815: INFO: Pod "downwardapi-volume-194af844-fb0a-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:55:46.819: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-194af844-fb0a-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:55:46.960: INFO: Waiting for pod downwardapi-volume-194af844-fb0a-11e8-b692-aec8003d5667 to disappear
Dec  8 16:55:46.963: INFO: Pod downwardapi-volume-194af844-fb0a-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:55:46.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n7k24" for this suite.
Dec  8 16:55:52.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:55:53.111: INFO: namespace: e2e-tests-projected-n7k24, resource: bindings, ignored listing per whitelist
Dec  8 16:55:53.146: INFO: namespace e2e-tests-projected-n7k24 deletion completed in 6.175332132s

• [SLOW TEST:10.630 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:55:53.147: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec  8 16:55:57.711: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:56:22.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-npwnv" for this suite.
Dec  8 16:56:28.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:56:29.110: INFO: namespace: e2e-tests-namespaces-npwnv, resource: bindings, ignored listing per whitelist
Dec  8 16:56:29.215: INFO: namespace e2e-tests-namespaces-npwnv deletion completed in 6.24471519s
STEP: Destroying namespace "e2e-tests-nsdeletetest-nv8dx" for this suite.
Dec  8 16:56:29.218: INFO: Namespace e2e-tests-nsdeletetest-nv8dx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-5hxj9" for this suite.
Dec  8 16:56:35.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:56:35.394: INFO: namespace: e2e-tests-nsdeletetest-5hxj9, resource: bindings, ignored listing per whitelist
Dec  8 16:56:35.406: INFO: namespace e2e-tests-nsdeletetest-5hxj9 deletion completed in 6.187495911s

• [SLOW TEST:42.259 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:56:35.406: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-38d1466a-fb0a-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:56:35.749: INFO: Waiting up to 5m0s for pod "pod-configmaps-38d9f995-fb0a-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-zhcvc" to be "success or failure"
Dec  8 16:56:35.788: INFO: Pod "pod-configmaps-38d9f995-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 38.809516ms
Dec  8 16:56:37.792: INFO: Pod "pod-configmaps-38d9f995-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043220759s
Dec  8 16:56:39.796: INFO: Pod "pod-configmaps-38d9f995-fb0a-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046940249s
STEP: Saw pod success
Dec  8 16:56:39.796: INFO: Pod "pod-configmaps-38d9f995-fb0a-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:56:39.799: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-38d9f995-fb0a-11e8-b692-aec8003d5667 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:56:39.897: INFO: Waiting for pod pod-configmaps-38d9f995-fb0a-11e8-b692-aec8003d5667 to disappear
Dec  8 16:56:39.907: INFO: Pod pod-configmaps-38d9f995-fb0a-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:56:39.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zhcvc" for this suite.
Dec  8 16:56:45.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:56:46.106: INFO: namespace: e2e-tests-configmap-zhcvc, resource: bindings, ignored listing per whitelist
Dec  8 16:56:46.122: INFO: namespace e2e-tests-configmap-zhcvc deletion completed in 6.206877814s

• [SLOW TEST:10.716 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:56:46.122: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3f38a715-fb0a-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 16:56:46.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f3af178-fb0a-11e8-b692-aec8003d5667" in namespace "e2e-tests-configmap-dzdgr" to be "success or failure"
Dec  8 16:56:46.506: INFO: Pod "pod-configmaps-3f3af178-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 58.003765ms
Dec  8 16:56:48.510: INFO: Pod "pod-configmaps-3f3af178-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061753746s
Dec  8 16:56:50.515: INFO: Pod "pod-configmaps-3f3af178-fb0a-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066196371s
STEP: Saw pod success
Dec  8 16:56:50.515: INFO: Pod "pod-configmaps-3f3af178-fb0a-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:56:50.520: INFO: Trying to get logs from node k8s-g2 pod pod-configmaps-3f3af178-fb0a-11e8-b692-aec8003d5667 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 16:56:50.622: INFO: Waiting for pod pod-configmaps-3f3af178-fb0a-11e8-b692-aec8003d5667 to disappear
Dec  8 16:56:50.632: INFO: Pod pod-configmaps-3f3af178-fb0a-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:56:50.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dzdgr" for this suite.
Dec  8 16:56:56.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:56:56.797: INFO: namespace: e2e-tests-configmap-dzdgr, resource: bindings, ignored listing per whitelist
Dec  8 16:56:56.875: INFO: namespace e2e-tests-configmap-dzdgr deletion completed in 6.23536177s

• [SLOW TEST:10.753 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:56:56.875: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  8 16:56:57.116: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  8 16:56:57.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:00.209: INFO: stderr: ""
Dec  8 16:57:00.209: INFO: stdout: "service/redis-slave created\n"
Dec  8 16:57:00.209: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  8 16:57:00.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:00.569: INFO: stderr: ""
Dec  8 16:57:00.569: INFO: stdout: "service/redis-master created\n"
Dec  8 16:57:00.569: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  8 16:57:00.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:00.987: INFO: stderr: ""
Dec  8 16:57:00.987: INFO: stdout: "service/frontend created\n"
Dec  8 16:57:00.988: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  8 16:57:00.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:01.278: INFO: stderr: ""
Dec  8 16:57:01.278: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  8 16:57:01.278: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  8 16:57:01.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:01.655: INFO: stderr: ""
Dec  8 16:57:01.655: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  8 16:57:01.655: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  8 16:57:01.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:02.046: INFO: stderr: ""
Dec  8 16:57:02.046: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  8 16:57:02.046: INFO: Waiting for all frontend pods to be Running.
Dec  8 16:57:42.097: INFO: Waiting for frontend to serve content.
Dec  8 16:57:43.108: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec  8 16:57:48.124: INFO: Trying to add a new entry to the guestbook.
Dec  8 16:57:48.142: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  8 16:57:48.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:48.296: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:57:48.296: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 16:57:48.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:48.490: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:57:48.490: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 16:57:48.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:48.737: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:57:48.737: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 16:57:48.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:48.862: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:57:48.862: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 16:57:48.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:49.056: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:57:49.056: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 16:57:49.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-44vk7'
Dec  8 16:57:49.216: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 16:57:49.216: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:57:49.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-44vk7" for this suite.
Dec  8 16:58:29.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:58:29.391: INFO: namespace: e2e-tests-kubectl-44vk7, resource: bindings, ignored listing per whitelist
Dec  8 16:58:29.570: INFO: namespace e2e-tests-kubectl-44vk7 deletion completed in 40.346486345s

• [SLOW TEST:92.694 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:58:29.570: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  8 16:58:29.859: INFO: Waiting up to 5m0s for pod "pod-7ce02b3f-fb0a-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-5fgvj" to be "success or failure"
Dec  8 16:58:29.920: INFO: Pod "pod-7ce02b3f-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 61.843851ms
Dec  8 16:58:31.925: INFO: Pod "pod-7ce02b3f-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066183869s
Dec  8 16:58:33.929: INFO: Pod "pod-7ce02b3f-fb0a-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07025494s
STEP: Saw pod success
Dec  8 16:58:33.929: INFO: Pod "pod-7ce02b3f-fb0a-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:58:33.933: INFO: Trying to get logs from node k8s-g1 pod pod-7ce02b3f-fb0a-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 16:58:34.035: INFO: Waiting for pod pod-7ce02b3f-fb0a-11e8-b692-aec8003d5667 to disappear
Dec  8 16:58:34.039: INFO: Pod pod-7ce02b3f-fb0a-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:58:34.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5fgvj" for this suite.
Dec  8 16:58:40.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:58:40.118: INFO: namespace: e2e-tests-emptydir-5fgvj, resource: bindings, ignored listing per whitelist
Dec  8 16:58:40.224: INFO: namespace e2e-tests-emptydir-5fgvj deletion completed in 6.176799357s

• [SLOW TEST:10.654 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:58:40.224: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-hqw4x
Dec  8 16:58:44.570: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-hqw4x
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 16:58:44.573: INFO: Initial restart count of pod liveness-exec is 0
Dec  8 16:59:30.740: INFO: Restart count of pod e2e-tests-container-probe-hqw4x/liveness-exec is now 1 (46.16643124s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:59:30.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hqw4x" for this suite.
Dec  8 16:59:36.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:59:37.073: INFO: namespace: e2e-tests-container-probe-hqw4x, resource: bindings, ignored listing per whitelist
Dec  8 16:59:37.094: INFO: namespace e2e-tests-container-probe-hqw4x deletion completed in 6.250582593s

• [SLOW TEST:56.870 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:59:37.094: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 16:59:37.330: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a51a3cb9-fb0a-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-pmh86" to be "success or failure"
Dec  8 16:59:37.365: INFO: Pod "downwardapi-volume-a51a3cb9-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 34.516393ms
Dec  8 16:59:39.369: INFO: Pod "downwardapi-volume-a51a3cb9-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03895209s
Dec  8 16:59:41.373: INFO: Pod "downwardapi-volume-a51a3cb9-fb0a-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042651876s
STEP: Saw pod success
Dec  8 16:59:41.373: INFO: Pod "downwardapi-volume-a51a3cb9-fb0a-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 16:59:41.377: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-a51a3cb9-fb0a-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 16:59:41.443: INFO: Waiting for pod downwardapi-volume-a51a3cb9-fb0a-11e8-b692-aec8003d5667 to disappear
Dec  8 16:59:41.466: INFO: Pod downwardapi-volume-a51a3cb9-fb0a-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 16:59:41.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pmh86" for this suite.
Dec  8 16:59:47.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 16:59:47.583: INFO: namespace: e2e-tests-projected-pmh86, resource: bindings, ignored listing per whitelist
Dec  8 16:59:47.645: INFO: namespace e2e-tests-projected-pmh86 deletion completed in 6.170669884s

• [SLOW TEST:10.551 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 16:59:47.645: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1208 17:00:18.613242      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 17:00:18.613: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:00:18.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5zfmx" for this suite.
Dec  8 17:00:26.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:00:26.698: INFO: namespace: e2e-tests-gc-5zfmx, resource: bindings, ignored listing per whitelist
Dec  8 17:00:26.810: INFO: namespace e2e-tests-gc-5zfmx deletion completed in 8.192150619s

• [SLOW TEST:39.166 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:00:26.810: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:01:27.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xxh65" for this suite.
Dec  8 17:01:51.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:01:51.316: INFO: namespace: e2e-tests-container-probe-xxh65, resource: bindings, ignored listing per whitelist
Dec  8 17:01:51.375: INFO: namespace e2e-tests-container-probe-xxh65 deletion completed in 24.208644955s

• [SLOW TEST:84.565 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:01:51.375: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 17:01:51.665: INFO: Waiting up to 5m0s for pod "downward-api-f52cb892-fb0a-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-hpgql" to be "success or failure"
Dec  8 17:01:51.699: INFO: Pod "downward-api-f52cb892-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 34.607457ms
Dec  8 17:01:53.703: INFO: Pod "downward-api-f52cb892-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038440601s
Dec  8 17:01:55.708: INFO: Pod "downward-api-f52cb892-fb0a-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043230626s
STEP: Saw pod success
Dec  8 17:01:55.708: INFO: Pod "downward-api-f52cb892-fb0a-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:01:55.712: INFO: Trying to get logs from node k8s-g2 pod downward-api-f52cb892-fb0a-11e8-b692-aec8003d5667 container dapi-container: <nil>
STEP: delete the pod
Dec  8 17:01:55.833: INFO: Waiting for pod downward-api-f52cb892-fb0a-11e8-b692-aec8003d5667 to disappear
Dec  8 17:01:55.836: INFO: Pod downward-api-f52cb892-fb0a-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:01:55.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hpgql" for this suite.
Dec  8 17:02:01.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:02:01.903: INFO: namespace: e2e-tests-downward-api-hpgql, resource: bindings, ignored listing per whitelist
Dec  8 17:02:02.028: INFO: namespace e2e-tests-downward-api-hpgql deletion completed in 6.184532447s

• [SLOW TEST:10.653 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:02:02.028: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-fb7ebc83-fb0a-11e8-b692-aec8003d5667
STEP: Creating secret with name secret-projected-all-test-volume-fb7ebc73-fb0a-11e8-b692-aec8003d5667
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  8 17:02:02.316: INFO: Waiting up to 5m0s for pod "projected-volume-fb7ebc4c-fb0a-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-w6z2d" to be "success or failure"
Dec  8 17:02:02.341: INFO: Pod "projected-volume-fb7ebc4c-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 24.98996ms
Dec  8 17:02:04.345: INFO: Pod "projected-volume-fb7ebc4c-fb0a-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029074546s
Dec  8 17:02:06.349: INFO: Pod "projected-volume-fb7ebc4c-fb0a-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033314693s
STEP: Saw pod success
Dec  8 17:02:06.349: INFO: Pod "projected-volume-fb7ebc4c-fb0a-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:02:06.353: INFO: Trying to get logs from node k8s-g2 pod projected-volume-fb7ebc4c-fb0a-11e8-b692-aec8003d5667 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  8 17:02:06.451: INFO: Waiting for pod projected-volume-fb7ebc4c-fb0a-11e8-b692-aec8003d5667 to disappear
Dec  8 17:02:06.455: INFO: Pod projected-volume-fb7ebc4c-fb0a-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:02:06.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w6z2d" for this suite.
Dec  8 17:02:12.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:02:12.570: INFO: namespace: e2e-tests-projected-w6z2d, resource: bindings, ignored listing per whitelist
Dec  8 17:02:12.622: INFO: namespace e2e-tests-projected-w6z2d deletion completed in 6.159696047s

• [SLOW TEST:10.593 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:02:12.622: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  8 17:02:12.999: INFO: Waiting up to 5m0s for pod "pod-01e24c5d-fb0b-11e8-b692-aec8003d5667" in namespace "e2e-tests-emptydir-9rkmz" to be "success or failure"
Dec  8 17:02:13.034: INFO: Pod "pod-01e24c5d-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 34.357401ms
Dec  8 17:02:15.038: INFO: Pod "pod-01e24c5d-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039156963s
Dec  8 17:02:17.043: INFO: Pod "pod-01e24c5d-fb0b-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043311722s
STEP: Saw pod success
Dec  8 17:02:17.043: INFO: Pod "pod-01e24c5d-fb0b-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:02:17.046: INFO: Trying to get logs from node k8s-g1 pod pod-01e24c5d-fb0b-11e8-b692-aec8003d5667 container test-container: <nil>
STEP: delete the pod
Dec  8 17:02:17.220: INFO: Waiting for pod pod-01e24c5d-fb0b-11e8-b692-aec8003d5667 to disappear
Dec  8 17:02:17.224: INFO: Pod pod-01e24c5d-fb0b-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:02:17.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9rkmz" for this suite.
Dec  8 17:02:23.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:02:23.413: INFO: namespace: e2e-tests-emptydir-9rkmz, resource: bindings, ignored listing per whitelist
Dec  8 17:02:23.430: INFO: namespace e2e-tests-emptydir-9rkmz deletion completed in 6.189700923s

• [SLOW TEST:10.808 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:02:23.430: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-mlst
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 17:02:23.769: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mlst" in namespace "e2e-tests-subpath-mgx8p" to be "success or failure"
Dec  8 17:02:23.803: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Pending", Reason="", readiness=false. Elapsed: 34.279198ms
Dec  8 17:02:25.826: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057487464s
Dec  8 17:02:27.831: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061949739s
Dec  8 17:02:29.834: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 6.065611181s
Dec  8 17:02:31.838: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 8.069465879s
Dec  8 17:02:33.843: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 10.073972069s
Dec  8 17:02:35.846: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 12.077815207s
Dec  8 17:02:37.850: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 14.081525615s
Dec  8 17:02:39.854: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 16.085375431s
Dec  8 17:02:41.858: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 18.089378925s
Dec  8 17:02:43.862: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 20.093159885s
Dec  8 17:02:45.866: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Running", Reason="", readiness=false. Elapsed: 22.096874142s
Dec  8 17:02:47.870: INFO: Pod "pod-subpath-test-secret-mlst": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.101217947s
STEP: Saw pod success
Dec  8 17:02:47.870: INFO: Pod "pod-subpath-test-secret-mlst" satisfied condition "success or failure"
Dec  8 17:02:47.874: INFO: Trying to get logs from node k8s-g2 pod pod-subpath-test-secret-mlst container test-container-subpath-secret-mlst: <nil>
STEP: delete the pod
Dec  8 17:02:47.983: INFO: Waiting for pod pod-subpath-test-secret-mlst to disappear
Dec  8 17:02:47.987: INFO: Pod pod-subpath-test-secret-mlst no longer exists
STEP: Deleting pod pod-subpath-test-secret-mlst
Dec  8 17:02:47.987: INFO: Deleting pod "pod-subpath-test-secret-mlst" in namespace "e2e-tests-subpath-mgx8p"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:02:47.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mgx8p" for this suite.
Dec  8 17:02:54.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:02:54.043: INFO: namespace: e2e-tests-subpath-mgx8p, resource: bindings, ignored listing per whitelist
Dec  8 17:02:54.156: INFO: namespace e2e-tests-subpath-mgx8p deletion completed in 6.158785961s

• [SLOW TEST:30.726 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:02:54.156: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 17:02:54.417: INFO: Creating deployment "test-recreate-deployment"
Dec  8 17:02:54.453: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  8 17:02:54.461: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec  8 17:02:56.480: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  8 17:02:56.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679885374, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679885374, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679885374, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679885374, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 17:02:58.506: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  8 17:02:58.521: INFO: Updating deployment test-recreate-deployment
Dec  8 17:02:58.521: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 17:02:59.296: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-mk4gj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mk4gj/deployments/test-recreate-deployment,UID:1a98abff-fb0b-11e8-b4e1-448a5b81d79a,ResourceVersion:22452,Generation:2,CreationTimestamp:2018-12-08 17:02:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-08 17:02:59 +0000 UTC 2018-12-08 17:02:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-08 17:02:59 +0000 UTC 2018-12-08 17:02:54 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  8 17:02:59.300: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-mk4gj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mk4gj/replicasets/test-recreate-deployment-7cf749666b,UID:1d4baa41-fb0b-11e8-9316-54a05085d523,ResourceVersion:22450,Generation:1,CreationTimestamp:2018-12-08 17:02:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1a98abff-fb0b-11e8-b4e1-448a5b81d79a 0xc420b9c767 0xc420b9c768}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 17:02:59.300: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  8 17:02:59.300: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-mk4gj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mk4gj/replicasets/test-recreate-deployment-79f694ff59,UID:1aa0ca16-fb0b-11e8-9316-54a05085d523,ResourceVersion:22441,Generation:2,CreationTimestamp:2018-12-08 17:02:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1a98abff-fb0b-11e8-b4e1-448a5b81d79a 0xc420b9c6a7 0xc420b9c6a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 17:02:59.305: INFO: Pod "test-recreate-deployment-7cf749666b-kdm92" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-kdm92,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-mk4gj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mk4gj/pods/test-recreate-deployment-7cf749666b-kdm92,UID:1d4ed4fd-fb0b-11e8-9316-54a05085d523,ResourceVersion:22453,Generation:0,CreationTimestamp:2018-12-08 17:02:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 1d4baa41-fb0b-11e8-9316-54a05085d523 0xc420b9d337 0xc420b9d338}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-skbdk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-skbdk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-skbdk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b9d450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b9d470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 17:02:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 17:02:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 17:02:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 17:02:59 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:,StartTime:2018-12-08 17:02:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:02:59.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-mk4gj" for this suite.
Dec  8 17:03:07.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:03:07.556: INFO: namespace: e2e-tests-deployment-mk4gj, resource: bindings, ignored listing per whitelist
Dec  8 17:03:07.603: INFO: namespace e2e-tests-deployment-mk4gj deletion completed in 8.289113964s

• [SLOW TEST:13.447 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:03:07.603: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  8 17:03:07.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-k4k4t'
Dec  8 17:03:08.203: INFO: stderr: ""
Dec  8 17:03:08.203: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 17:03:09.208: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 17:03:09.208: INFO: Found 0 / 1
Dec  8 17:03:10.207: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 17:03:10.207: INFO: Found 0 / 1
Dec  8 17:03:11.206: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 17:03:11.206: INFO: Found 0 / 1
Dec  8 17:03:12.206: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 17:03:12.206: INFO: Found 1 / 1
Dec  8 17:03:12.206: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  8 17:03:12.209: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 17:03:12.209: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 17:03:12.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 patch pod redis-master-sl7m5 --namespace=e2e-tests-kubectl-k4k4t -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  8 17:03:12.333: INFO: stderr: ""
Dec  8 17:03:12.333: INFO: stdout: "pod/redis-master-sl7m5 patched\n"
STEP: checking annotations
Dec  8 17:03:12.336: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 17:03:12.337: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:03:12.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k4k4t" for this suite.
Dec  8 17:03:36.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:03:36.438: INFO: namespace: e2e-tests-kubectl-k4k4t, resource: bindings, ignored listing per whitelist
Dec  8 17:03:36.497: INFO: namespace e2e-tests-kubectl-k4k4t deletion completed in 24.152853571s

• [SLOW TEST:28.894 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:03:36.497: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-33cdb462-fb0b-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 17:03:36.773: INFO: Waiting up to 5m0s for pod "pod-secrets-33d02b03-fb0b-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-tj72b" to be "success or failure"
Dec  8 17:03:36.807: INFO: Pod "pod-secrets-33d02b03-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 33.316752ms
Dec  8 17:03:38.811: INFO: Pod "pod-secrets-33d02b03-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037204083s
Dec  8 17:03:40.836: INFO: Pod "pod-secrets-33d02b03-fb0b-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062207176s
STEP: Saw pod success
Dec  8 17:03:40.836: INFO: Pod "pod-secrets-33d02b03-fb0b-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:03:40.840: INFO: Trying to get logs from node k8s-g2 pod pod-secrets-33d02b03-fb0b-11e8-b692-aec8003d5667 container secret-env-test: <nil>
STEP: delete the pod
Dec  8 17:03:40.933: INFO: Waiting for pod pod-secrets-33d02b03-fb0b-11e8-b692-aec8003d5667 to disappear
Dec  8 17:03:40.937: INFO: Pod pod-secrets-33d02b03-fb0b-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:03:40.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tj72b" for this suite.
Dec  8 17:03:46.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:03:47.064: INFO: namespace: e2e-tests-secrets-tj72b, resource: bindings, ignored listing per whitelist
Dec  8 17:03:47.119: INFO: namespace e2e-tests-secrets-tj72b deletion completed in 6.173991198s

• [SLOW TEST:10.622 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:03:47.119: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3a27521f-fb0b-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 17:03:47.402: INFO: Waiting up to 5m0s for pod "pod-secrets-3a29d9a7-fb0b-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-fhv6c" to be "success or failure"
Dec  8 17:03:47.532: INFO: Pod "pod-secrets-3a29d9a7-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 129.365287ms
Dec  8 17:03:49.537: INFO: Pod "pod-secrets-3a29d9a7-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.134421957s
Dec  8 17:03:51.541: INFO: Pod "pod-secrets-3a29d9a7-fb0b-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.139009771s
STEP: Saw pod success
Dec  8 17:03:51.541: INFO: Pod "pod-secrets-3a29d9a7-fb0b-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:03:51.544: INFO: Trying to get logs from node k8s-g1 pod pod-secrets-3a29d9a7-fb0b-11e8-b692-aec8003d5667 container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 17:03:51.641: INFO: Waiting for pod pod-secrets-3a29d9a7-fb0b-11e8-b692-aec8003d5667 to disappear
Dec  8 17:03:51.646: INFO: Pod pod-secrets-3a29d9a7-fb0b-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:03:51.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fhv6c" for this suite.
Dec  8 17:03:57.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:03:57.927: INFO: namespace: e2e-tests-secrets-fhv6c, resource: bindings, ignored listing per whitelist
Dec  8 17:03:57.999: INFO: namespace e2e-tests-secrets-fhv6c deletion completed in 6.3434716s

• [SLOW TEST:10.880 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:03:57.999: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 17:03:58.364: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40a6a3ce-fb0b-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-9h4sq" to be "success or failure"
Dec  8 17:03:58.367: INFO: Pod "downwardapi-volume-40a6a3ce-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.65018ms
Dec  8 17:04:00.372: INFO: Pod "downwardapi-volume-40a6a3ce-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00800474s
Dec  8 17:04:02.379: INFO: Pod "downwardapi-volume-40a6a3ce-fb0b-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015104702s
STEP: Saw pod success
Dec  8 17:04:02.379: INFO: Pod "downwardapi-volume-40a6a3ce-fb0b-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:04:02.382: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-40a6a3ce-fb0b-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 17:04:02.426: INFO: Waiting for pod downwardapi-volume-40a6a3ce-fb0b-11e8-b692-aec8003d5667 to disappear
Dec  8 17:04:02.447: INFO: Pod downwardapi-volume-40a6a3ce-fb0b-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:04:02.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9h4sq" for this suite.
Dec  8 17:04:08.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:04:08.605: INFO: namespace: e2e-tests-projected-9h4sq, resource: bindings, ignored listing per whitelist
Dec  8 17:04:08.651: INFO: namespace e2e-tests-projected-9h4sq deletion completed in 6.195420767s

• [SLOW TEST:10.652 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:04:08.652: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-46facd25-fb0b-11e8-b692-aec8003d5667
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-46facd25-fb0b-11e8-b692-aec8003d5667
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:05:37.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q75rq" for this suite.
Dec  8 17:05:59.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:05:59.931: INFO: namespace: e2e-tests-projected-q75rq, resource: bindings, ignored listing per whitelist
Dec  8 17:06:00.005: INFO: namespace e2e-tests-projected-q75rq deletion completed in 22.262083851s

• [SLOW TEST:111.354 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:06:00.006: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8960cbbe-fb0b-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 17:06:00.364: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89682103-fb0b-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-tdhd7" to be "success or failure"
Dec  8 17:06:00.444: INFO: Pod "pod-projected-configmaps-89682103-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 79.616517ms
Dec  8 17:06:02.448: INFO: Pod "pod-projected-configmaps-89682103-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083886494s
Dec  8 17:06:04.468: INFO: Pod "pod-projected-configmaps-89682103-fb0b-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.103395481s
STEP: Saw pod success
Dec  8 17:06:04.468: INFO: Pod "pod-projected-configmaps-89682103-fb0b-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:06:04.471: INFO: Trying to get logs from node k8s-g2 pod pod-projected-configmaps-89682103-fb0b-11e8-b692-aec8003d5667 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 17:06:04.599: INFO: Waiting for pod pod-projected-configmaps-89682103-fb0b-11e8-b692-aec8003d5667 to disappear
Dec  8 17:06:04.602: INFO: Pod pod-projected-configmaps-89682103-fb0b-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:06:04.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tdhd7" for this suite.
Dec  8 17:06:10.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:06:10.730: INFO: namespace: e2e-tests-projected-tdhd7, resource: bindings, ignored listing per whitelist
Dec  8 17:06:10.759: INFO: namespace e2e-tests-projected-tdhd7 deletion completed in 6.148187226s

• [SLOW TEST:10.754 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:06:10.759: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  8 17:06:11.023: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-g2bj6" to be "success or failure"
Dec  8 17:06:11.027: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.974211ms
Dec  8 17:06:13.030: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007680467s
Dec  8 17:06:15.036: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013361418s
STEP: Saw pod success
Dec  8 17:06:15.036: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  8 17:06:15.040: INFO: Trying to get logs from node k8s-g1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  8 17:06:15.075: INFO: Waiting for pod pod-host-path-test to disappear
Dec  8 17:06:15.079: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:06:15.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-g2bj6" for this suite.
Dec  8 17:06:21.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:06:21.206: INFO: namespace: e2e-tests-hostpath-g2bj6, resource: bindings, ignored listing per whitelist
Dec  8 17:06:21.277: INFO: namespace e2e-tests-hostpath-g2bj6 deletion completed in 6.190355601s

• [SLOW TEST:10.518 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:06:21.277: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  8 17:06:26.111: INFO: Successfully updated pod "pod-update-activedeadlineseconds-960bad78-fb0b-11e8-b692-aec8003d5667"
Dec  8 17:06:26.111: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-960bad78-fb0b-11e8-b692-aec8003d5667" in namespace "e2e-tests-pods-blrzg" to be "terminated due to deadline exceeded"
Dec  8 17:06:26.123: INFO: Pod "pod-update-activedeadlineseconds-960bad78-fb0b-11e8-b692-aec8003d5667": Phase="Running", Reason="", readiness=true. Elapsed: 11.417993ms
Dec  8 17:06:28.127: INFO: Pod "pod-update-activedeadlineseconds-960bad78-fb0b-11e8-b692-aec8003d5667": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.015896672s
Dec  8 17:06:28.127: INFO: Pod "pod-update-activedeadlineseconds-960bad78-fb0b-11e8-b692-aec8003d5667" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:06:28.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-blrzg" for this suite.
Dec  8 17:06:34.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:06:34.309: INFO: namespace: e2e-tests-pods-blrzg, resource: bindings, ignored listing per whitelist
Dec  8 17:06:34.312: INFO: namespace e2e-tests-pods-blrzg deletion completed in 6.178400724s

• [SLOW TEST:13.035 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:06:34.312: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 17:06:39.277: INFO: Successfully updated pod "labelsupdate9dd7a55e-fb0b-11e8-b692-aec8003d5667"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:06:41.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-26llq" for this suite.
Dec  8 17:07:05.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:07:05.400: INFO: namespace: e2e-tests-downward-api-26llq, resource: bindings, ignored listing per whitelist
Dec  8 17:07:05.561: INFO: namespace e2e-tests-downward-api-26llq deletion completed in 24.260835741s

• [SLOW TEST:31.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:07:05.561: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  8 17:07:05.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 create -f - --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:08.983: INFO: stderr: ""
Dec  8 17:07:08.983: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 17:07:08.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:09.059: INFO: stderr: ""
Dec  8 17:07:09.059: INFO: stdout: "update-demo-nautilus-wj28k "
STEP: Replicas for name=update-demo: expected=2 actual=1
Dec  8 17:07:14.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:14.176: INFO: stderr: ""
Dec  8 17:07:14.176: INFO: stdout: "update-demo-nautilus-4zj6q update-demo-nautilus-wj28k "
Dec  8 17:07:14.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-4zj6q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:14.244: INFO: stderr: ""
Dec  8 17:07:14.244: INFO: stdout: "true"
Dec  8 17:07:14.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-4zj6q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:14.306: INFO: stderr: ""
Dec  8 17:07:14.306: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 17:07:14.307: INFO: validating pod update-demo-nautilus-4zj6q
Dec  8 17:07:14.311: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 17:07:14.311: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 17:07:14.311: INFO: update-demo-nautilus-4zj6q is verified up and running
Dec  8 17:07:14.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-wj28k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:14.371: INFO: stderr: ""
Dec  8 17:07:14.371: INFO: stdout: "true"
Dec  8 17:07:14.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods update-demo-nautilus-wj28k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:14.429: INFO: stderr: ""
Dec  8 17:07:14.430: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 17:07:14.430: INFO: validating pod update-demo-nautilus-wj28k
Dec  8 17:07:14.435: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 17:07:14.435: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 17:07:14.435: INFO: update-demo-nautilus-wj28k is verified up and running
STEP: using delete to clean up resources
Dec  8 17:07:14.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:14.515: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 17:07:14.515: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  8 17:07:14.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-qn99x'
Dec  8 17:07:14.598: INFO: stderr: "No resources found.\n"
Dec  8 17:07:14.598: INFO: stdout: ""
Dec  8 17:07:14.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 get pods -l name=update-demo --namespace=e2e-tests-kubectl-qn99x -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 17:07:14.678: INFO: stderr: ""
Dec  8 17:07:14.678: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:07:14.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qn99x" for this suite.
Dec  8 17:07:38.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:07:38.781: INFO: namespace: e2e-tests-kubectl-qn99x, resource: bindings, ignored listing per whitelist
Dec  8 17:07:38.886: INFO: namespace e2e-tests-kubectl-qn99x deletion completed in 24.199715656s

• [SLOW TEST:33.325 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:07:38.886: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-fx855
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fx855 to expose endpoints map[]
Dec  8 17:07:39.246: INFO: Get endpoints failed (5.575718ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  8 17:07:40.250: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fx855 exposes endpoints map[] (1.00971799s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-fx855
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fx855 to expose endpoints map[pod1:[80]]
Dec  8 17:07:43.366: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fx855 exposes endpoints map[pod1:[80]] (3.100023694s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-fx855
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fx855 to expose endpoints map[pod1:[80] pod2:[80]]
Dec  8 17:07:46.517: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fx855 exposes endpoints map[pod1:[80] pod2:[80]] (3.10900177s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-fx855
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fx855 to expose endpoints map[pod2:[80]]
Dec  8 17:07:47.599: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fx855 exposes endpoints map[pod2:[80]] (1.040589128s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-fx855
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fx855 to expose endpoints map[]
Dec  8 17:07:48.633: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fx855 exposes endpoints map[] (1.006717226s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:07:48.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fx855" for this suite.
Dec  8 17:07:54.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:07:54.831: INFO: namespace: e2e-tests-services-fx855, resource: bindings, ignored listing per whitelist
Dec  8 17:07:54.953: INFO: namespace e2e-tests-services-fx855 deletion completed in 6.21432396s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:16.067 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:07:54.953: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vlqmr
Dec  8 17:08:01.229: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vlqmr
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 17:08:01.234: INFO: Initial restart count of pod liveness-http is 0
Dec  8 17:08:21.284: INFO: Restart count of pod e2e-tests-container-probe-vlqmr/liveness-http is now 1 (20.050070666s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:08:21.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vlqmr" for this suite.
Dec  8 17:08:27.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:08:27.420: INFO: namespace: e2e-tests-container-probe-vlqmr, resource: bindings, ignored listing per whitelist
Dec  8 17:08:27.496: INFO: namespace e2e-tests-container-probe-vlqmr deletion completed in 6.166534375s

• [SLOW TEST:32.543 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:08:27.496: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 17:08:27.722: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e13c8368-fb0b-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-nh8p2" to be "success or failure"
Dec  8 17:08:27.726: INFO: Pod "downwardapi-volume-e13c8368-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.820068ms
Dec  8 17:08:29.731: INFO: Pod "downwardapi-volume-e13c8368-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008152s
Dec  8 17:08:31.735: INFO: Pod "downwardapi-volume-e13c8368-fb0b-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012463073s
STEP: Saw pod success
Dec  8 17:08:31.735: INFO: Pod "downwardapi-volume-e13c8368-fb0b-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:08:31.738: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-e13c8368-fb0b-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 17:08:31.782: INFO: Waiting for pod downwardapi-volume-e13c8368-fb0b-11e8-b692-aec8003d5667 to disappear
Dec  8 17:08:31.786: INFO: Pod downwardapi-volume-e13c8368-fb0b-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:08:31.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nh8p2" for this suite.
Dec  8 17:08:37.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:08:37.962: INFO: namespace: e2e-tests-projected-nh8p2, resource: bindings, ignored listing per whitelist
Dec  8 17:08:38.048: INFO: namespace e2e-tests-projected-nh8p2 deletion completed in 6.254173923s

• [SLOW TEST:10.553 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:08:38.049: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tncvr.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tncvr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tncvr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tncvr.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tncvr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tncvr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  8 17:09:06.462: INFO: DNS probes using e2e-tests-dns-tncvr/dns-test-e790bf7d-fb0b-11e8-b692-aec8003d5667 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:09:06.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tncvr" for this suite.
Dec  8 17:09:14.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:09:14.614: INFO: namespace: e2e-tests-dns-tncvr, resource: bindings, ignored listing per whitelist
Dec  8 17:09:14.709: INFO: namespace e2e-tests-dns-tncvr deletion completed in 8.158919753s

• [SLOW TEST:36.661 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:09:14.710: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fd68dfb0-fb0b-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume configMaps
Dec  8 17:09:15.033: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fd71e572-fb0b-11e8-b692-aec8003d5667" in namespace "e2e-tests-projected-rpjk7" to be "success or failure"
Dec  8 17:09:15.037: INFO: Pod "pod-projected-configmaps-fd71e572-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.702425ms
Dec  8 17:09:17.042: INFO: Pod "pod-projected-configmaps-fd71e572-fb0b-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008067036s
Dec  8 17:09:19.046: INFO: Pod "pod-projected-configmaps-fd71e572-fb0b-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01225168s
STEP: Saw pod success
Dec  8 17:09:19.046: INFO: Pod "pod-projected-configmaps-fd71e572-fb0b-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:09:19.049: INFO: Trying to get logs from node k8s-g1 pod pod-projected-configmaps-fd71e572-fb0b-11e8-b692-aec8003d5667 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 17:09:19.115: INFO: Waiting for pod pod-projected-configmaps-fd71e572-fb0b-11e8-b692-aec8003d5667 to disappear
Dec  8 17:09:19.152: INFO: Pod pod-projected-configmaps-fd71e572-fb0b-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:09:19.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rpjk7" for this suite.
Dec  8 17:09:25.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:09:25.356: INFO: namespace: e2e-tests-projected-rpjk7, resource: bindings, ignored listing per whitelist
Dec  8 17:09:25.378: INFO: namespace e2e-tests-projected-rpjk7 deletion completed in 6.191566919s

• [SLOW TEST:10.668 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:09:25.378: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-bqx6g/secret-test-03e0ad4c-fb0c-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 17:09:25.857: INFO: Waiting up to 5m0s for pod "pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-bqx6g" to be "success or failure"
Dec  8 17:09:25.860: INFO: Pod "pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.356565ms
Dec  8 17:09:27.865: INFO: Pod "pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008013691s
Dec  8 17:09:29.869: INFO: Pod "pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011740599s
Dec  8 17:09:31.873: INFO: Pod "pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015670793s
STEP: Saw pod success
Dec  8 17:09:31.873: INFO: Pod "pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:09:31.876: INFO: Trying to get logs from node k8s-g2 pod pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667 container env-test: <nil>
STEP: delete the pod
Dec  8 17:09:31.946: INFO: Waiting for pod pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667 to disappear
Dec  8 17:09:31.950: INFO: Pod pod-configmaps-03e28c69-fb0c-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:09:31.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bqx6g" for this suite.
Dec  8 17:09:38.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:09:38.085: INFO: namespace: e2e-tests-secrets-bqx6g, resource: bindings, ignored listing per whitelist
Dec  8 17:09:38.225: INFO: namespace e2e-tests-secrets-bqx6g deletion completed in 6.265203787s

• [SLOW TEST:12.847 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:09:38.226: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 17:09:38.502: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b69a926-fb0c-11e8-b692-aec8003d5667" in namespace "e2e-tests-downward-api-g6qql" to be "success or failure"
Dec  8 17:09:38.506: INFO: Pod "downwardapi-volume-0b69a926-fb0c-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.726802ms
Dec  8 17:09:40.511: INFO: Pod "downwardapi-volume-0b69a926-fb0c-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008475548s
Dec  8 17:09:42.523: INFO: Pod "downwardapi-volume-0b69a926-fb0c-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020515496s
STEP: Saw pod success
Dec  8 17:09:42.523: INFO: Pod "downwardapi-volume-0b69a926-fb0c-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:09:42.526: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-0b69a926-fb0c-11e8-b692-aec8003d5667 container client-container: <nil>
STEP: delete the pod
Dec  8 17:09:42.644: INFO: Waiting for pod downwardapi-volume-0b69a926-fb0c-11e8-b692-aec8003d5667 to disappear
Dec  8 17:09:42.649: INFO: Pod downwardapi-volume-0b69a926-fb0c-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:09:42.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g6qql" for this suite.
Dec  8 17:09:48.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:09:48.758: INFO: namespace: e2e-tests-downward-api-g6qql, resource: bindings, ignored listing per whitelist
Dec  8 17:09:48.845: INFO: namespace e2e-tests-downward-api-g6qql deletion completed in 6.187969313s

• [SLOW TEST:10.619 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:09:48.845: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  8 17:09:49.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-260986308 cluster-info'
Dec  8 17:09:49.183: INFO: stderr: ""
Dec  8 17:09:49.183: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:09:49.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k9wmg" for this suite.
Dec  8 17:09:55.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:09:55.351: INFO: namespace: e2e-tests-kubectl-k9wmg, resource: bindings, ignored listing per whitelist
Dec  8 17:09:55.362: INFO: namespace e2e-tests-kubectl-k9wmg deletion completed in 6.155983189s

• [SLOW TEST:6.517 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:09:55.362: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  8 17:10:00.343: INFO: Successfully updated pod "pod-update-15abc996-fb0c-11e8-b692-aec8003d5667"
STEP: verifying the updated pod is in kubernetes
Dec  8 17:10:00.421: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:10:00.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5xp2x" for this suite.
Dec  8 17:10:24.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:10:24.646: INFO: namespace: e2e-tests-pods-5xp2x, resource: bindings, ignored listing per whitelist
Dec  8 17:10:24.711: INFO: namespace e2e-tests-pods-5xp2x deletion completed in 24.253286595s

• [SLOW TEST:29.349 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  8 17:10:24.711: INFO: >>> kubeConfig: /tmp/kubeconfig-260986308
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-271f8d3f-fb0c-11e8-b692-aec8003d5667
STEP: Creating a pod to test consume secrets
Dec  8 17:10:24.973: INFO: Waiting up to 5m0s for pod "pod-secrets-2723ee5a-fb0c-11e8-b692-aec8003d5667" in namespace "e2e-tests-secrets-v2jbr" to be "success or failure"
Dec  8 17:10:24.977: INFO: Pod "pod-secrets-2723ee5a-fb0c-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 3.9555ms
Dec  8 17:10:26.987: INFO: Pod "pod-secrets-2723ee5a-fb0c-11e8-b692-aec8003d5667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013700739s
Dec  8 17:10:28.991: INFO: Pod "pod-secrets-2723ee5a-fb0c-11e8-b692-aec8003d5667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017415914s
STEP: Saw pod success
Dec  8 17:10:28.991: INFO: Pod "pod-secrets-2723ee5a-fb0c-11e8-b692-aec8003d5667" satisfied condition "success or failure"
Dec  8 17:10:28.994: INFO: Trying to get logs from node k8s-g1 pod pod-secrets-2723ee5a-fb0c-11e8-b692-aec8003d5667 container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 17:10:29.091: INFO: Waiting for pod pod-secrets-2723ee5a-fb0c-11e8-b692-aec8003d5667 to disappear
Dec  8 17:10:29.094: INFO: Pod pod-secrets-2723ee5a-fb0c-11e8-b692-aec8003d5667 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  8 17:10:29.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v2jbr" for this suite.
Dec  8 17:10:35.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 17:10:35.197: INFO: namespace: e2e-tests-secrets-v2jbr, resource: bindings, ignored listing per whitelist
Dec  8 17:10:35.267: INFO: namespace e2e-tests-secrets-v2jbr deletion completed in 6.164590931s

• [SLOW TEST:10.556 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SDec  8 17:10:35.267: INFO: Running AfterSuite actions on all node
Dec  8 17:10:35.267: INFO: Running AfterSuite actions on node 1
Dec  8 17:10:35.267: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5478.918 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h31m19.466809101s
Test Suite Passed
